(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else if(typeof exports === 'object')
		exports["LiaPlusVoice"] = factory();
	else
		root["LiaPlusVoice"] = factory();
})(this, () => {
return /******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "../lib/voice-sdk/dist/esm/CommandMapper.js"
/*!**************************************************!*\
  !*** ../lib/voice-sdk/dist/esm/CommandMapper.js ***!
  \**************************************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CommandMapper: () => (/* binding */ CommandMapper)
/* harmony export */ });
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _regenerator() { /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/babel/babel/blob/main/packages/babel-helpers/LICENSE */ var e, t, r = "function" == typeof Symbol ? Symbol : {}, n = r.iterator || "@@iterator", o = r.toStringTag || "@@toStringTag"; function i(r, n, o, i) { var c = n && n.prototype instanceof Generator ? n : Generator, u = Object.create(c.prototype); return _regeneratorDefine2(u, "_invoke", function (r, n, o) { var i, c, u, f = 0, p = o || [], y = !1, G = { p: 0, n: 0, v: e, a: d, f: d.bind(e, 4), d: function d(t, r) { return i = t, c = 0, u = e, G.n = r, a; } }; function d(r, n) { for (c = r, u = n, t = 0; !y && f && !o && t < p.length; t++) { var o, i = p[t], d = G.p, l = i[2]; r > 3 ? (o = l === n) && (u = i[(c = i[4]) ? 5 : (c = 3, 3)], i[4] = i[5] = e) : i[0] <= d && ((o = r < 2 && d < i[1]) ? (c = 0, G.v = n, G.n = i[1]) : d < l && (o = r < 3 || i[0] > n || n > l) && (i[4] = r, i[5] = n, G.n = l, c = 0)); } if (o || r > 1) return a; throw y = !0, n; } return function (o, p, l) { if (f > 1) throw TypeError("Generator is already running"); for (y && 1 === p && d(p, l), c = p, u = l; (t = c < 2 ? e : u) || !y;) { i || (c ? c < 3 ? (c > 1 && (G.n = -1), d(c, u)) : G.n = u : G.v = u); try { if (f = 2, i) { if (c || (o = "next"), t = i[o]) { if (!(t = t.call(i, u))) throw TypeError("iterator result is not an object"); if (!t.done) return t; u = t.value, c < 2 && (c = 0); } else 1 === c && (t = i["return"]) && t.call(i), c < 2 && (u = TypeError("The iterator does not provide a '" + o + "' method"), c = 1); i = e; } else if ((t = (y = G.n < 0) ? u : r.call(n, G)) !== a) break; } catch (t) { i = e, c = 1, u = t; } finally { f = 1; } } return { value: t, done: y }; }; }(r, o, i), !0), u; } var a = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} t = Object.getPrototypeOf; var c = [][n] ? t(t([][n]())) : (_regeneratorDefine2(t = {}, n, function () { return this; }), t), u = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(c); function f(e) { return Object.setPrototypeOf ? Object.setPrototypeOf(e, GeneratorFunctionPrototype) : (e.__proto__ = GeneratorFunctionPrototype, _regeneratorDefine2(e, o, "GeneratorFunction")), e.prototype = Object.create(u), e; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, _regeneratorDefine2(u, "constructor", GeneratorFunctionPrototype), _regeneratorDefine2(GeneratorFunctionPrototype, "constructor", GeneratorFunction), GeneratorFunction.displayName = "GeneratorFunction", _regeneratorDefine2(GeneratorFunctionPrototype, o, "GeneratorFunction"), _regeneratorDefine2(u), _regeneratorDefine2(u, o, "Generator"), _regeneratorDefine2(u, n, function () { return this; }), _regeneratorDefine2(u, "toString", function () { return "[object Generator]"; }), (_regenerator = function _regenerator() { return { w: i, m: f }; })(); }
function _regeneratorDefine2(e, r, n, t) { var i = Object.defineProperty; try { i({}, "", {}); } catch (e) { i = 0; } _regeneratorDefine2 = function _regeneratorDefine(e, r, n, t) { function o(r, n) { _regeneratorDefine2(e, r, function (e) { return this._invoke(r, n, e); }); } r ? i ? i(e, r, { value: n, enumerable: !t, configurable: !t, writable: !t }) : e[r] = n : (o("next", 0), o("throw", 1), o("return", 2)); }, _regeneratorDefine2(e, r, n, t); }
function asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }
function _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, "next", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, "throw", n); } _next(void 0); }); }; }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * CommandMapper - Maps voice commands to DOM actions
 * Uses fuzzy matching and AI to understand user intent
 */
var CommandMapper = /*#__PURE__*/function () {
  function CommandMapper(apiEndpoint) {
    _classCallCheck(this, CommandMapper);
    this.apiEndpoint = apiEndpoint;
  }
  /**
   * Map user voice command to action
   */
  return _createClass(CommandMapper, [{
    key: "mapCommand",
    value: (function () {
      var _mapCommand = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee(command) {
        var transcript, patternMatch, aiMatch, _t;
        return _regenerator().w(function (_context) {
          while (1) switch (_context.p = _context.n) {
            case 0:
              transcript = command.transcript.toLowerCase().trim(); // Try pattern-based matching first (fast path)
              patternMatch = this.patternMatch(transcript, command.domAnalysis);
              if (!(patternMatch && patternMatch.confidence > 0.8)) {
                _context.n = 1;
                break;
              }
              return _context.a(2, patternMatch);
            case 1:
              _context.p = 1;
              _context.n = 2;
              return this.aiMatch(command);
            case 2:
              aiMatch = _context.v;
              return _context.a(2, aiMatch);
            case 3:
              _context.p = 3;
              _t = _context.v;
              console.error('AI matching failed, falling back to pattern match:', _t);
              return _context.a(2, patternMatch || {
                action: 'unknown',
                confidence: 0,
                targetDescription: 'Could not understand command'
              });
          }
        }, _callee, this, [[1, 3]]);
      }));
      function mapCommand(_x) {
        return _mapCommand.apply(this, arguments);
      }
      return mapCommand;
    }()
    /**
     * Pattern-based matching for common commands
     */
    )
  }, {
    key: "patternMatch",
    value: function patternMatch(transcript, domAnalysis) {
      // Scroll commands
      if (/scroll (down|up)|go (down|up)|page (down|up)/.test(transcript)) {
        var direction = transcript.includes('down') ? 'down' : 'up';
        return {
          action: 'scroll',
          parameters: {
            direction: direction,
            amount: 500
          },
          confidence: 0.95,
          targetDescription: "Scroll ".concat(direction)
        };
      }
      // Navigate to top/bottom
      if (/go to (top|bottom)|scroll to (top|bottom)/.test(transcript)) {
        var position = transcript.includes('top') ? 'top' : 'bottom';
        return {
          action: 'scroll',
          parameters: {
            position: position
          },
          confidence: 0.95,
          targetDescription: "Go to ".concat(position, " of page")
        };
      }
      // Click commands
      var clickMatch = transcript.match(/click (on |the )?(.*)/i);
      if (clickMatch) {
        var targetText = clickMatch[2];
        var element = this.findElementByText(targetText, domAnalysis);
        if (element) {
          return {
            action: 'click',
            target: element,
            confidence: 0.85,
            targetDescription: "Click on ".concat(targetText)
          };
        }
      }
      // Navigate commands
      var navMatch = transcript.match(/go to|navigate to|open|show (.*)/i);
      if (navMatch) {
        var _targetText = navMatch[1];
        var navElement = this.findNavigationElement(_targetText, domAnalysis);
        if (navElement) {
          return {
            action: 'navigate',
            target: navElement,
            confidence: 0.85,
            targetDescription: "Navigate to ".concat(_targetText)
          };
        }
      }
      // Form filling commands
      if (/fill (the |this )?(form|contact|application)/.test(transcript)) {
        var form = document.querySelector('form');
        if (form) {
          return {
            action: 'fill_form',
            target: form,
            confidence: 0.9,
            targetDescription: 'Fill form with voice input'
          };
        }
      }
      // Submit commands
      if (/submit|send|complete/.test(transcript)) {
        var submitBtn = document.querySelector('button[type="submit"], input[type="submit"]');
        if (submitBtn) {
          return {
            action: 'submit',
            target: submitBtn,
            confidence: 0.9,
            targetDescription: 'Submit form'
          };
        }
      }
      // Read commands
      if (/read (this|the page|content)/.test(transcript)) {
        var main = document.querySelector('main, [role="main"], article');
        if (main) {
          return {
            action: 'read',
            target: main,
            confidence: 0.9,
            targetDescription: 'Read page content'
          };
        }
      }
      // Search commands
      if (/search for|find/.test(transcript)) {
        var searchInput = document.querySelector('input[type="search"], input[name*="search"]');
        if (searchInput) {
          return {
            action: 'focus',
            target: searchInput,
            confidence: 0.85,
            targetDescription: 'Focus on search box'
          };
        }
      }
      return null;
    }
    /**
     * AI-powered command matching
     */
  }, {
    key: "aiMatch",
    value: (function () {
      var _aiMatch = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee2(command) {
        var _command$pageContext;
        var response, result;
        return _regenerator().w(function (_context2) {
          while (1) switch (_context2.n) {
            case 0:
              _context2.n = 1;
              return fetch("".concat(this.apiEndpoint, "/voice-ai"), {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  command: command.transcript,
                  language: command.language,
                  domAnalysis: command.domAnalysis,
                  currentUrl: ((_command$pageContext = command.pageContext) === null || _command$pageContext === void 0 ? void 0 : _command$pageContext.url) || window.location.href
                })
              });
            case 1:
              response = _context2.v;
              if (response.ok) {
                _context2.n = 2;
                break;
              }
              throw new Error('AI command mapping failed');
            case 2:
              _context2.n = 3;
              return response.json();
            case 3:
              result = _context2.v;
              return _context2.a(2, {
                action: result.action,
                parameters: result.parameters,
                confidence: result.confidence || 0.7,
                targetDescription: result.response
              });
          }
        }, _callee2, this);
      }));
      function aiMatch(_x2) {
        return _aiMatch.apply(this, arguments);
      }
      return aiMatch;
    }()
    /**
     * Find element by text content (fuzzy matching)
     */
    )
  }, {
    key: "findElementByText",
    value: function findElementByText(text, domAnalysis) {
      var searchText = text.toLowerCase();
      // Search in buttons
      var buttons = Array.from(document.querySelectorAll('button, [role="button"]'));
      for (var _i = 0, _buttons = buttons; _i < _buttons.length; _i++) {
        var _btn$textContent;
        var btn = _buttons[_i];
        var btnText = ((_btn$textContent = btn.textContent) === null || _btn$textContent === void 0 ? void 0 : _btn$textContent.toLowerCase()) || '';
        if (btnText.includes(searchText) || this.fuzzyMatch(btnText, searchText)) {
          return btn;
        }
      }
      // Search in links
      var links = Array.from(document.querySelectorAll('a'));
      for (var _i2 = 0, _links = links; _i2 < _links.length; _i2++) {
        var _link$textContent;
        var link = _links[_i2];
        var linkText = ((_link$textContent = link.textContent) === null || _link$textContent === void 0 ? void 0 : _link$textContent.toLowerCase()) || '';
        if (linkText.includes(searchText) || this.fuzzyMatch(linkText, searchText)) {
          return link;
        }
      }
      // Search in any clickable elements
      var clickable = Array.from(document.querySelectorAll('[onclick], [role="button"], [tabindex]'));
      for (var _i3 = 0, _clickable = clickable; _i3 < _clickable.length; _i3++) {
        var _el$textContent;
        var el = _clickable[_i3];
        var elText = ((_el$textContent = el.textContent) === null || _el$textContent === void 0 ? void 0 : _el$textContent.toLowerCase()) || '';
        if (elText.includes(searchText) || this.fuzzyMatch(elText, searchText)) {
          return el;
        }
      }
      return null;
    }
    /**
     * Find navigation element by text
     */
  }, {
    key: "findNavigationElement",
    value: function findNavigationElement(text, domAnalysis) {
      var searchText = text.toLowerCase();
      // Search in nav elements first
      var navLinks = Array.from(document.querySelectorAll('nav a, [role="navigation"] a, header a'));
      for (var _i4 = 0, _navLinks = navLinks; _i4 < _navLinks.length; _i4++) {
        var _link$textContent2;
        var link = _navLinks[_i4];
        var linkText = ((_link$textContent2 = link.textContent) === null || _link$textContent2 === void 0 ? void 0 : _link$textContent2.toLowerCase()) || '';
        if (linkText.includes(searchText) || this.fuzzyMatch(linkText, searchText)) {
          return link;
        }
      }
      // Fallback to all links
      return this.findElementByText(text, domAnalysis);
    }
    /**
     * Fuzzy text matching using Levenshtein distance
     */
  }, {
    key: "fuzzyMatch",
    value: function fuzzyMatch(str1, str2) {
      var threshold = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0.7;
      var distance = this.levenshteinDistance(str1, str2);
      var maxLen = Math.max(str1.length, str2.length);
      var similarity = 1 - distance / maxLen;
      return similarity >= threshold;
    }
    /**
     * Calculate Levenshtein distance between two strings
     */
  }, {
    key: "levenshteinDistance",
    value: function levenshteinDistance(str1, str2) {
      var matrix = [];
      for (var i = 0; i <= str2.length; i++) {
        matrix[i] = [i];
      }
      for (var j = 0; j <= str1.length; j++) {
        matrix[0][j] = j;
      }
      for (var _i5 = 1; _i5 <= str2.length; _i5++) {
        for (var _j = 1; _j <= str1.length; _j++) {
          if (str2.charAt(_i5 - 1) === str1.charAt(_j - 1)) {
            matrix[_i5][_j] = matrix[_i5 - 1][_j - 1];
          } else {
            matrix[_i5][_j] = Math.min(matrix[_i5 - 1][_j - 1] + 1, matrix[_i5][_j - 1] + 1, matrix[_i5 - 1][_j] + 1);
          }
        }
      }
      return matrix[str2.length][str1.length];
    }
    /**
     * Execute the mapped command
     */
  }, {
    key: "executeCommand",
    value: (function () {
      var _executeCommand = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee3(intent) {
        var event, text, _event, _t2;
        return _regenerator().w(function (_context3) {
          while (1) switch (_context3.n) {
            case 0:
              _t2 = intent.action;
              _context3.n = _t2 === 'scroll' ? 1 : _t2 === 'click' ? 2 : _t2 === 'navigate' ? 3 : _t2 === 'fill_form' ? 4 : _t2 === 'submit' ? 5 : _t2 === 'focus' ? 6 : _t2 === 'read' ? 7 : 8;
              break;
            case 1:
              this.executeScroll(intent.parameters);
              return _context3.a(3, 9);
            case 2:
              if (intent.target) {
                intent.target.click();
              }
              return _context3.a(3, 9);
            case 3:
              if (intent.target && intent.target.tagName === 'A') {
                intent.target.click();
              }
              return _context3.a(3, 9);
            case 4:
              // This will trigger form handler
              if (intent.target) {
                intent.target.scrollIntoView({
                  behavior: 'smooth',
                  block: 'center'
                });
                // Emit event for form handler to take over
                event = new CustomEvent('voiceFormStart', {
                  detail: {
                    form: intent.target
                  }
                });
                document.dispatchEvent(event);
              }
              return _context3.a(3, 9);
            case 5:
              if (intent.target) {
                intent.target.click();
              }
              return _context3.a(3, 9);
            case 6:
              if (intent.target) {
                intent.target.focus();
                intent.target.scrollIntoView({
                  behavior: 'smooth',
                  block: 'center'
                });
              }
              return _context3.a(3, 9);
            case 7:
              if (intent.target) {
                text = intent.target.textContent || '';
                _event = new CustomEvent('voiceRead', {
                  detail: {
                    text: text
                  }
                });
                document.dispatchEvent(_event);
              }
              return _context3.a(3, 9);
            case 8:
              console.log('Unknown action:', intent.action);
            case 9:
              return _context3.a(2);
          }
        }, _callee3, this);
      }));
      function executeCommand(_x3) {
        return _executeCommand.apply(this, arguments);
      }
      return executeCommand;
    }()
    /**
     * Execute scroll command
     */
    )
  }, {
    key: "executeScroll",
    value: function executeScroll(params) {
      if (!params) return;
      if (params.position) {
        if (params.position === 'top') {
          window.scrollTo({
            top: 0,
            behavior: 'smooth'
          });
        } else if (params.position === 'bottom') {
          window.scrollTo({
            top: document.body.scrollHeight,
            behavior: 'smooth'
          });
        }
      } else if (params.direction) {
        var amount = params.amount || 500;
        var currentScroll = window.scrollY;
        var newScroll = params.direction === 'down' ? currentScroll + amount : currentScroll - amount;
        window.scrollTo({
          top: newScroll,
          behavior: 'smooth'
        });
      }
    }
  }]);
}();

/***/ },

/***/ "../lib/voice-sdk/dist/esm/DOMAnalyzer.js"
/*!************************************************!*\
  !*** ../lib/voice-sdk/dist/esm/DOMAnalyzer.js ***!
  \************************************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   DOMAnalyzer: () => (/* binding */ DOMAnalyzer)
/* harmony export */ });
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * DOMAnalyzer - Dynamically analyzes any website's DOM structure
 * Extracts forms, navigation, content, and interactive elements
 */
var DOMAnalyzer = /*#__PURE__*/function () {
  function DOMAnalyzer() {
    _classCallCheck(this, DOMAnalyzer);
  }
  return _createClass(DOMAnalyzer, [{
    key: "analyze",
    value:
    /**
     * Analyze the entire page structure
     */
    function analyze() {
      console.log('[DOMAnalyzer] Starting page analysis...');
      var startTime = Date.now();
      var analysis = {
        forms: this.extractForms(),
        navigation: this.extractNavigation(),
        content: this.extractContent(),
        interactions: this.extractInteractables(),
        landmarks: this.extractLandmarks(),
        pageInfo: this.extractPageInfo()
      };
      var duration = Date.now() - startTime;
      console.log("[DOMAnalyzer] Analysis complete in ".concat(duration, "ms:"), {
        forms: analysis.forms.length,
        navigation: analysis.navigation.length,
        interactions: analysis.interactions.length,
        landmarks: analysis.landmarks.length,
        pageTitle: analysis.pageInfo.title
      });
      return analysis;
    }
    /**
     * Extract all forms and their fields
     */
  }, {
    key: "extractForms",
    value: function extractForms() {
      var _this = this;
      var forms = Array.from(document.querySelectorAll('form'));
      console.log("[DOMAnalyzer] Found ".concat(forms.length, " form(s)"));
      return forms.map(function (form, index) {
        var fields = _this.extractFormFields(form);
        var buttons = _this.extractFormButtons(form);
        var multiStep = _this.detectMultiStep(form);
        console.log("[DOMAnalyzer] Form ".concat(index, ":"), {
          id: form.id || "form-".concat(index),
          fields: fields.length,
          buttons: buttons.length
        });
        return {
          id: form.id || "form-".concat(index),
          action: form.action || window.location.href,
          method: form.method || 'GET',
          fields: fields,
          buttons: buttons,
          multiStep: multiStep.isMultiStep,
          currentStep: multiStep.currentStep,
          totalSteps: multiStep.totalSteps
        };
      });
    }
    /**
     * Extract fields from a form with intelligent label detection
     */
  }, {
    key: "extractFormFields",
    value: function extractFormFields(form) {
      var _this2 = this;
      var inputs = form.querySelectorAll('input, select, textarea');
      return Array.from(inputs).filter(function (input) {
        var el = input;
        // Filter out hidden, submit, button types
        return el.type !== 'hidden' && el.type !== 'submit' && el.type !== 'button' && el.type !== 'reset';
      }).map(function (input, index) {
        var field = input;
        return {
          id: field.id || "field-".concat(index),
          name: field.name || field.id || "field-".concat(index),
          type: _this2.getFieldType(field),
          label: _this2.findLabel(field),
          placeholder: _this2.getPlaceholder(field),
          required: _this2.isRequired(field),
          value: _this2.getValue(field),
          options: _this2.extractOptions(field),
          validation: _this2.extractValidation(field),
          ariaLabel: field.getAttribute('aria-label') || undefined,
          ariaDescribedBy: field.getAttribute('aria-describedby') || undefined,
          surroundingText: _this2.getSurroundingText(field),
          index: index // NEW: Store position for selector fallback
        };
      });
    }
    /**
     * Get field type with smart detection
     */
  }, {
    key: "getFieldType",
    value: function getFieldType(field) {
      if (field.tagName === 'SELECT') return 'select';
      if (field.tagName === 'TEXTAREA') return 'textarea';
      var input = field;
      return input.type || 'text';
    }
    /**
     * Find label using multiple strategies
     */
  }, {
    key: "findLabel",
    value: function findLabel(field) {
      // Strategy 1: Associated label element
      if (field.id) {
        var label = document.querySelector("label[for=\"".concat(field.id, "\"]"));
        if (label !== null && label !== void 0 && label.textContent) {
          return label.textContent.trim();
        }
      }
      // Strategy 2: Parent label
      var parentLabel = field.closest('label');
      if (parentLabel) {
        var _clone$textContent;
        var clone = parentLabel.cloneNode(true);
        var fieldClone = clone.querySelector('input, select, textarea');
        fieldClone === null || fieldClone === void 0 || fieldClone.remove();
        var text = (_clone$textContent = clone.textContent) === null || _clone$textContent === void 0 ? void 0 : _clone$textContent.trim();
        if (text) return text;
      }
      // Strategy 3: ARIA label
      var ariaLabel = field.getAttribute('aria-label');
      if (ariaLabel) return ariaLabel;
      // Strategy 4: ARIA labelledby
      var ariaLabelledBy = field.getAttribute('aria-labelledby');
      if (ariaLabelledBy) {
        var labelElement = document.getElementById(ariaLabelledBy);
        if (labelElement !== null && labelElement !== void 0 && labelElement.textContent) {
          return labelElement.textContent.trim();
        }
      }
      // Strategy 5: Previous sibling text
      var prevSibling = field.previousElementSibling;
      if (prevSibling && prevSibling.textContent) {
        var _text = prevSibling.textContent.trim();
        if (_text.length < 100) return _text;
      }
      // Strategy 6: Name or ID as fallback
      var name = field.getAttribute('name');
      var id = field.getAttribute('id');
      return name || id || null;
    }
    /**
     * Get placeholder text
     */
  }, {
    key: "getPlaceholder",
    value: function getPlaceholder(field) {
      var placeholder = field.getAttribute('placeholder');
      if (placeholder) return placeholder;
      // Check for aria-placeholder
      var ariaPlaceholder = field.getAttribute('aria-placeholder');
      return ariaPlaceholder || null;
    }
    /**
     * Check if field is required
     */
  }, {
    key: "isRequired",
    value: function isRequired(field) {
      // Check required attribute
      if (field.hasAttribute('required')) return true;
      // Check aria-required
      if (field.getAttribute('aria-required') === 'true') return true;
      // Check for asterisk or "required" in label
      var label = this.findLabel(field);
      if (label && (label.includes('*') || label.toLowerCase().includes('required'))) {
        return true;
      }
      return false;
    }
    /**
     * Get current field value
     */
  }, {
    key: "getValue",
    value: function getValue(field) {
      if (field.tagName === 'SELECT') {
        var select = field;
        return select.value || '';
      }
      if (field.tagName === 'TEXTAREA') {
        var textarea = field;
        return textarea.value || '';
      }
      var input = field;
      if (input.type === 'checkbox' || input.type === 'radio') {
        return input.checked ? 'checked' : '';
      }
      return input.value || '';
    }
    /**
     * Extract options for select/radio/checkbox
     */
  }, {
    key: "extractOptions",
    value: function extractOptions(field) {
      var _this3 = this;
      if (field.tagName === 'SELECT') {
        var select = field;
        return Array.from(select.options).map(function (opt) {
          return opt.text;
        });
      }
      // For radio buttons, find all with same name
      if (field.tagName === 'INPUT') {
        var input = field;
        if (input.type === 'radio' || input.type === 'checkbox') {
          var name = input.name;
          if (name) {
            var group = document.querySelectorAll("input[name=\"".concat(name, "\"]"));
            return Array.from(group).map(function (el) {
              var label = _this3.findLabel(el);
              return label || el.value;
            });
          }
        }
      }
      return [];
    }
    /**
     * Extract validation rules
     */
  }, {
    key: "extractValidation",
    value: function extractValidation(field) {
      var validation = {};
      var pattern = field.getAttribute('pattern');
      if (pattern) validation.pattern = pattern;
      var min = field.getAttribute('min');
      if (min) validation.min = min;
      var max = field.getAttribute('max');
      if (max) validation.max = max;
      var minLength = field.getAttribute('minlength');
      if (minLength) validation.minLength = parseInt(minLength);
      var maxLength = field.getAttribute('maxlength');
      if (maxLength) validation.maxLength = parseInt(maxLength);
      return Object.keys(validation).length > 0 ? validation : undefined;
    }
    /**
     * Get surrounding text for context
     */
  }, {
    key: "getSurroundingText",
    value: function getSurroundingText(field) {
      var _clone$textContent2;
      var parent = field.parentElement;
      if (!parent) return '';
      var clone = parent.cloneNode(true);
      var inputs = clone.querySelectorAll('input, select, textarea');
      inputs.forEach(function (el) {
        return el.remove();
      });
      var text = ((_clone$textContent2 = clone.textContent) === null || _clone$textContent2 === void 0 ? void 0 : _clone$textContent2.trim()) || '';
      return text.slice(0, 200); // Limit to 200 chars
    }
    /**
     * Extract form buttons
     */
  }, {
    key: "extractFormButtons",
    value: function extractFormButtons(form) {
      var buttons = form.querySelectorAll('button, input[type="submit"], input[type="button"]');
      return Array.from(buttons).map(function (btn, index) {
        var button = btn;
        // Get button text from various sources
        var text = '';
        if (button.tagName === 'BUTTON') {
          var _button$textContent, _button$innerText;
          // For button elements, get inner text
          text = ((_button$textContent = button.textContent) === null || _button$textContent === void 0 ? void 0 : _button$textContent.trim()) || ((_button$innerText = button.innerText) === null || _button$innerText === void 0 ? void 0 : _button$innerText.trim()) || '';
        } else if (button.tagName === 'INPUT') {
          // For input elements, get value
          text = button.value || '';
        }
        // Fallback to aria-label if no text found
        if (!text) {
          text = button.getAttribute('aria-label') || 'Submit';
        }
        return {
          type: button.type || 'button',
          text: text,
          id: button.id || "button-".concat(index),
          name: button.name || button.id || "button-".concat(index),
          ariaLabel: button.getAttribute('aria-label') || undefined
        };
      });
    }
    /**
     * Detect if form is multi-step
     */
  }, {
    key: "detectMultiStep",
    value: function detectMultiStep(form) {
      // Check for step indicators
      var stepIndicators = form.querySelectorAll('[class*="step"], [data-step], [aria-label*="step"]');
      if (stepIndicators.length > 0) {
        // Try to find current step
        var currentStepEl = form.querySelector('.active[class*="step"], [aria-current="step"]');
        var currentStep = currentStepEl ? Array.from(stepIndicators).indexOf(currentStepEl) + 1 : 1;
        return {
          isMultiStep: true,
          currentStep: currentStep,
          totalSteps: stepIndicators.length
        };
      }
      // Check for next/previous buttons
      var nextBtn = form.querySelector('button[class*="next"], button[name*="next"]');
      var prevBtn = form.querySelector('button[class*="prev"], button[name*="prev"]');
      if (nextBtn || prevBtn) {
        return {
          isMultiStep: true
        };
      }
      return {
        isMultiStep: false
      };
    }
    /**
     * Extract navigation elements
     */
  }, {
    key: "extractNavigation",
    value: function extractNavigation() {
      var navElements = [];
      // Find navigation containers
      var navContainers = document.querySelectorAll('nav, [role="navigation"], header, .nav, .menu, .navbar');
      navContainers.forEach(function (container) {
        // Extract links
        var links = container.querySelectorAll('a');
        links.forEach(function (link) {
          var _link$textContent;
          navElements.push({
            type: 'link',
            text: ((_link$textContent = link.textContent) === null || _link$textContent === void 0 ? void 0 : _link$textContent.trim()) || '',
            href: link.href,
            id: link.id,
            ariaLabel: link.getAttribute('aria-label') || undefined,
            role: link.getAttribute('role') || undefined
          });
        });
        // Extract buttons
        var buttons = container.querySelectorAll('button');
        buttons.forEach(function (button) {
          var _button$textContent2;
          navElements.push({
            type: 'button',
            text: ((_button$textContent2 = button.textContent) === null || _button$textContent2 === void 0 ? void 0 : _button$textContent2.trim()) || '',
            id: button.id,
            ariaLabel: button.getAttribute('aria-label') || undefined,
            role: button.getAttribute('role') || undefined
          });
        });
      });
      return navElements;
    }
    /**
     * Extract content structure
     */
  }, {
    key: "extractContent",
    value: function extractContent() {
      var content = [];
      // Extract headings
      var headings = document.querySelectorAll('h1, h2, h3, h4, h5, h6');
      headings.forEach(function (heading) {
        var _heading$textContent;
        content.push({
          type: 'heading',
          level: parseInt(heading.tagName[1]),
          text: ((_heading$textContent = heading.textContent) === null || _heading$textContent === void 0 ? void 0 : _heading$textContent.trim()) || '',
          id: heading.id,
          ariaLabel: heading.getAttribute('aria-label') || undefined
        });
      });
      // Extract main content areas
      var mainElements = document.querySelectorAll('main, [role="main"], article, section');
      mainElements.forEach(function (element) {
        var _element$textContent;
        content.push({
          type: element.tagName.toLowerCase(),
          text: ((_element$textContent = element.textContent) === null || _element$textContent === void 0 ? void 0 : _element$textContent.slice(0, 500).trim()) || '',
          id: element.id,
          ariaLabel: element.getAttribute('aria-label') || undefined
        });
      });
      return content;
    }
    /**
     * Extract all interactable elements
     */
  }, {
    key: "extractInteractables",
    value: function extractInteractables() {
      var interactions = [];
      // Buttons
      document.querySelectorAll('button').forEach(function (btn) {
        var _btn$textContent;
        interactions.push({
          type: 'button',
          text: ((_btn$textContent = btn.textContent) === null || _btn$textContent === void 0 ? void 0 : _btn$textContent.trim()) || '',
          id: btn.id,
          role: btn.getAttribute('role') || undefined,
          ariaLabel: btn.getAttribute('aria-label') || undefined,
          clickable: true
        });
      });
      // Links
      document.querySelectorAll('a[href]').forEach(function (link) {
        var _anchor$textContent;
        var anchor = link;
        interactions.push({
          type: 'link',
          text: ((_anchor$textContent = anchor.textContent) === null || _anchor$textContent === void 0 ? void 0 : _anchor$textContent.trim()) || '',
          id: anchor.id,
          role: anchor.getAttribute('role') || undefined,
          ariaLabel: anchor.getAttribute('aria-label') || undefined,
          clickable: true
        });
      });
      return interactions;
    }
    /**
     * Extract ARIA landmarks
     */
  }, {
    key: "extractLandmarks",
    value: function extractLandmarks() {
      var landmarks = [];
      var landmarkRoles = ['banner', 'navigation', 'main', 'complementary', 'contentinfo', 'search', 'form', 'region'];
      landmarkRoles.forEach(function (role) {
        var elements = document.querySelectorAll("[role=\"".concat(role, "\"]"));
        elements.forEach(function (el, index) {
          landmarks.push({
            role: role,
            label: el.getAttribute('aria-label') || undefined,
            element: el.tagName.toLowerCase() + (el.id ? "#".concat(el.id) : "-".concat(index))
          });
        });
      });
      // Also check semantic HTML landmarks
      var semanticLandmarks = [{
        tag: 'header',
        role: 'banner'
      }, {
        tag: 'nav',
        role: 'navigation'
      }, {
        tag: 'main',
        role: 'main'
      }, {
        tag: 'aside',
        role: 'complementary'
      }, {
        tag: 'footer',
        role: 'contentinfo'
      }];
      semanticLandmarks.forEach(function (_ref) {
        var tag = _ref.tag,
          role = _ref.role;
        var elements = document.querySelectorAll(tag);
        elements.forEach(function (el, index) {
          if (!el.hasAttribute('role')) {
            landmarks.push({
              role: role,
              label: el.getAttribute('aria-label') || undefined,
              element: "".concat(tag).concat(el.id ? "#".concat(el.id) : "-".concat(index))
            });
          }
        });
      });
      return landmarks;
    }
    /**
     * Extract page information
     */
  }, {
    key: "extractPageInfo",
    value: function extractPageInfo() {
      var _document$querySelect;
      return {
        title: document.title,
        url: window.location.href,
        language: document.documentElement.lang || 'en',
        description: ((_document$querySelect = document.querySelector('meta[name="description"]')) === null || _document$querySelect === void 0 ? void 0 : _document$querySelect.getAttribute('content')) || undefined
      };
    }
    /**
     * Get specific form by index or ID
     */
  }, {
    key: "getForm",
    value: function getForm(identifier) {
      var forms = this.extractForms();
      if (typeof identifier === 'number') {
        return forms[identifier] || null;
      }
      return forms.find(function (f) {
        return f.id === identifier;
      }) || null;
    }
    /**
     * Find elements by text content (fuzzy matching)
     */
  }, {
    key: "findByText",
    value: function findByText(text, elementType) {
      var searchText = text.toLowerCase();
      var selector = '*';
      if (elementType) {
        selector = elementType;
      }
      var elements = Array.from(document.querySelectorAll(selector));
      return elements.filter(function (el) {
        var _el$textContent, _el$getAttribute;
        var content = ((_el$textContent = el.textContent) === null || _el$textContent === void 0 ? void 0 : _el$textContent.toLowerCase()) || '';
        var label = ((_el$getAttribute = el.getAttribute('aria-label')) === null || _el$getAttribute === void 0 ? void 0 : _el$getAttribute.toLowerCase()) || '';
        return content.includes(searchText) || label.includes(searchText);
      });
    }
  }]);
}();

/***/ },

/***/ "../lib/voice-sdk/dist/esm/FormHandler.js"
/*!************************************************!*\
  !*** ../lib/voice-sdk/dist/esm/FormHandler.js ***!
  \************************************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   FormHandler: () => (/* binding */ FormHandler)
/* harmony export */ });
/* harmony import */ var _DOMAnalyzer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./DOMAnalyzer */ "../lib/voice-sdk/dist/esm/DOMAnalyzer.js");
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _slicedToArray(r, e) { return _arrayWithHoles(r) || _iterableToArrayLimit(r, e) || _unsupportedIterableToArray(r, e) || _nonIterableRest(); }
function _nonIterableRest() { throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }
function _iterableToArrayLimit(r, l) { var t = null == r ? null : "undefined" != typeof Symbol && r[Symbol.iterator] || r["@@iterator"]; if (null != t) { var e, n, i, u, a = [], f = !0, o = !1; try { if (i = (t = t.call(r)).next, 0 === l) { if (Object(t) !== t) return; f = !1; } else for (; !(f = (e = i.call(t)).done) && (a.push(e.value), a.length !== l); f = !0); } catch (r) { o = !0, n = r; } finally { try { if (!f && null != t["return"] && (u = t["return"](), Object(u) !== u)) return; } finally { if (o) throw n; } } return a; } }
function _arrayWithHoles(r) { if (Array.isArray(r)) return r; }
function _createForOfIteratorHelper(r, e) { var t = "undefined" != typeof Symbol && r[Symbol.iterator] || r["@@iterator"]; if (!t) { if (Array.isArray(r) || (t = _unsupportedIterableToArray(r)) || e && r && "number" == typeof r.length) { t && (r = t); var _n = 0, F = function F() {}; return { s: F, n: function n() { return _n >= r.length ? { done: !0 } : { done: !1, value: r[_n++] }; }, e: function e(r) { throw r; }, f: F }; } throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); } var o, a = !0, u = !1; return { s: function s() { t = t.call(r); }, n: function n() { var r = t.next(); return a = r.done, r; }, e: function e(r) { u = !0, o = r; }, f: function f() { try { a || null == t["return"] || t["return"](); } finally { if (u) throw o; } } }; }
function _unsupportedIterableToArray(r, a) { if (r) { if ("string" == typeof r) return _arrayLikeToArray(r, a); var t = {}.toString.call(r).slice(8, -1); return "Object" === t && r.constructor && (t = r.constructor.name), "Map" === t || "Set" === t ? Array.from(r) : "Arguments" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? _arrayLikeToArray(r, a) : void 0; } }
function _arrayLikeToArray(r, a) { (null == a || a > r.length) && (a = r.length); for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e]; return n; }
function _regenerator() { /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/babel/babel/blob/main/packages/babel-helpers/LICENSE */ var e, t, r = "function" == typeof Symbol ? Symbol : {}, n = r.iterator || "@@iterator", o = r.toStringTag || "@@toStringTag"; function i(r, n, o, i) { var c = n && n.prototype instanceof Generator ? n : Generator, u = Object.create(c.prototype); return _regeneratorDefine2(u, "_invoke", function (r, n, o) { var i, c, u, f = 0, p = o || [], y = !1, G = { p: 0, n: 0, v: e, a: d, f: d.bind(e, 4), d: function d(t, r) { return i = t, c = 0, u = e, G.n = r, a; } }; function d(r, n) { for (c = r, u = n, t = 0; !y && f && !o && t < p.length; t++) { var o, i = p[t], d = G.p, l = i[2]; r > 3 ? (o = l === n) && (u = i[(c = i[4]) ? 5 : (c = 3, 3)], i[4] = i[5] = e) : i[0] <= d && ((o = r < 2 && d < i[1]) ? (c = 0, G.v = n, G.n = i[1]) : d < l && (o = r < 3 || i[0] > n || n > l) && (i[4] = r, i[5] = n, G.n = l, c = 0)); } if (o || r > 1) return a; throw y = !0, n; } return function (o, p, l) { if (f > 1) throw TypeError("Generator is already running"); for (y && 1 === p && d(p, l), c = p, u = l; (t = c < 2 ? e : u) || !y;) { i || (c ? c < 3 ? (c > 1 && (G.n = -1), d(c, u)) : G.n = u : G.v = u); try { if (f = 2, i) { if (c || (o = "next"), t = i[o]) { if (!(t = t.call(i, u))) throw TypeError("iterator result is not an object"); if (!t.done) return t; u = t.value, c < 2 && (c = 0); } else 1 === c && (t = i["return"]) && t.call(i), c < 2 && (u = TypeError("The iterator does not provide a '" + o + "' method"), c = 1); i = e; } else if ((t = (y = G.n < 0) ? u : r.call(n, G)) !== a) break; } catch (t) { i = e, c = 1, u = t; } finally { f = 1; } } return { value: t, done: y }; }; }(r, o, i), !0), u; } var a = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} t = Object.getPrototypeOf; var c = [][n] ? t(t([][n]())) : (_regeneratorDefine2(t = {}, n, function () { return this; }), t), u = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(c); function f(e) { return Object.setPrototypeOf ? Object.setPrototypeOf(e, GeneratorFunctionPrototype) : (e.__proto__ = GeneratorFunctionPrototype, _regeneratorDefine2(e, o, "GeneratorFunction")), e.prototype = Object.create(u), e; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, _regeneratorDefine2(u, "constructor", GeneratorFunctionPrototype), _regeneratorDefine2(GeneratorFunctionPrototype, "constructor", GeneratorFunction), GeneratorFunction.displayName = "GeneratorFunction", _regeneratorDefine2(GeneratorFunctionPrototype, o, "GeneratorFunction"), _regeneratorDefine2(u), _regeneratorDefine2(u, o, "Generator"), _regeneratorDefine2(u, n, function () { return this; }), _regeneratorDefine2(u, "toString", function () { return "[object Generator]"; }), (_regenerator = function _regenerator() { return { w: i, m: f }; })(); }
function _regeneratorDefine2(e, r, n, t) { var i = Object.defineProperty; try { i({}, "", {}); } catch (e) { i = 0; } _regeneratorDefine2 = function _regeneratorDefine(e, r, n, t) { function o(r, n) { _regeneratorDefine2(e, r, function (e) { return this._invoke(r, n, e); }); } r ? i ? i(e, r, { value: n, enumerable: !t, configurable: !t, writable: !t }) : e[r] = n : (o("next", 0), o("throw", 1), o("return", 2)); }, _regeneratorDefine2(e, r, n, t); }
function asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }
function _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, "next", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, "throw", n); } _next(void 0); }); }; }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * FormHandler - Adaptive form filling with voice
 * Works with any form structure without predefined schemas
 */

var FormHandler = /*#__PURE__*/function () {
  function FormHandler(apiEndpoint, onSpeak) {
    _classCallCheck(this, FormHandler);
    this.currentSession = null;
    this.apiEndpoint = apiEndpoint;
    this.analyzer = new _DOMAnalyzer__WEBPACK_IMPORTED_MODULE_0__.DOMAnalyzer();
    this.onSpeak = onSpeak;
  }
  /**
   * Start form filling session
   */
  return _createClass(FormHandler, [{
    key: "startFormFilling",
    value: (function () {
      var _startFormFilling = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee(form) {
        var language,
          schema,
          greeting,
          _args = arguments;
        return _regenerator().w(function (_context) {
          while (1) switch (_context.n) {
            case 0:
              language = _args.length > 1 && _args[1] !== undefined ? _args[1] : 'en-US';
              // Extract form schema
              schema = this.extractFormSchema(form);
              if (!(!schema.fields || schema.fields.length === 0)) {
                _context.n = 1;
                break;
              }
              this.speak('No fillable fields found in this form.', language);
              return _context.a(2);
            case 1:
              // Initialize session
              this.currentSession = {
                form: form,
                schema: schema,
                collectedData: {},
                currentFieldIndex: 0,
                conversation: [],
                language: language
              };
              // Classify fields using AI
              _context.n = 2;
              return this.classifyFields(schema);
            case 2:
              // Start conversation
              greeting = language === 'hi-IN' ? "\u092E\u0948\u0902 \u0906\u092A\u0915\u0940 \u092B\u0949\u0930\u094D\u092E \u092D\u0930\u0928\u0947 \u092E\u0947\u0902 \u092E\u0926\u0926 \u0915\u0930\u0942\u0902\u0917\u0940\u0964 \u0907\u0938 \u092B\u0949\u0930\u094D\u092E \u092E\u0947\u0902 ".concat(schema.fields.length, " \u092B\u0940\u0932\u094D\u0921\u094D\u0938 \u0939\u0948\u0902\u0964 \u091A\u0932\u093F\u090F \u0936\u0941\u0930\u0942 \u0915\u0930\u0924\u0947 \u0939\u0948\u0902\u0964") : "I'll help you fill this form. There are ".concat(schema.fields.length, " fields to complete. Let's get started.");
              this.speak(greeting, language);
              // Ask first question
              _context.n = 3;
              return this.askNextField();
            case 3:
              return _context.a(2);
          }
        }, _callee, this);
      }));
      function startFormFilling(_x) {
        return _startFormFilling.apply(this, arguments);
      }
      return startFormFilling;
    }()
    /**
     * Process voice input for form filling
     */
    )
  }, {
    key: "processVoiceInput",
    value: (function () {
      var _processVoiceInput = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee2(transcript) {
        var response, _t;
        return _regenerator().w(function (_context2) {
          while (1) switch (_context2.p = _context2.n) {
            case 0:
              if (this.currentSession) {
                _context2.n = 1;
                break;
              }
              console.error('No active form filling session');
              return _context2.a(2);
            case 1:
              // Add to conversation
              this.currentSession.conversation.push({
                role: 'user',
                content: transcript
              });
              // Send to AI for processing
              _context2.p = 2;
              _context2.n = 3;
              return this.callFormAI(transcript);
            case 3:
              response = _context2.v;
              // Add AI response to conversation
              this.currentSession.conversation.push({
                role: 'assistant',
                content: response.response
              });
              // Update collected data
              if (response.extractedData) {
                Object.assign(this.currentSession.collectedData, response.extractedData);
                // Fill the fields
                this.fillFields(response.extractedData);
              }
              // Speak response
              this.speak(response.response, this.currentSession.language);
              // Check if complete
              if (!response.isComplete) {
                _context2.n = 5;
                break;
              }
              _context2.n = 4;
              return this.completeForm();
            case 4:
              _context2.n = 6;
              break;
            case 5:
              if (response.nextQuestion) {
                // Continue to next field
                this.currentSession.currentFieldIndex++;
              }
            case 6:
              _context2.n = 8;
              break;
            case 7:
              _context2.p = 7;
              _t = _context2.v;
              console.error('Form filling error:', _t);
              this.speak('Sorry, I had trouble processing that. Could you repeat?', this.currentSession.language);
            case 8:
              return _context2.a(2);
          }
        }, _callee2, this, [[2, 7]]);
      }));
      function processVoiceInput(_x2) {
        return _processVoiceInput.apply(this, arguments);
      }
      return processVoiceInput;
    }()
    /**
     * Extract form schema from HTML form
     */
    )
  }, {
    key: "extractFormSchema",
    value: function extractFormSchema(form) {
      var _this = this;
      var tempAnalysis = this.analyzer.analyze();
      var formAnalysis = tempAnalysis.forms.find(function (f) {
        var formEl = document.getElementById(f.id);
        return formEl === form;
      });
      if (formAnalysis) {
        return formAnalysis;
      }
      // Fallback: create schema manually
      var fields = Array.from(form.querySelectorAll('input, select, textarea')).filter(function (el) {
        var input = el;
        return input.type !== 'hidden' && input.type !== 'submit' && input.type !== 'button';
      }).map(function (el, i) {
        return _this.createFieldSchema(el, i);
      });
      return {
        id: form.id || 'form-0',
        action: form.action,
        method: form.method,
        fields: fields,
        buttons: [],
        multiStep: false
      };
    }
    /**
     * Create field schema from HTML element
     */
  }, {
    key: "createFieldSchema",
    value: function createFieldSchema(element, index) {
      var label = this.findFieldLabel(element);
      var placeholder = element.getAttribute('placeholder');
      return {
        id: element.id || "field-".concat(index),
        name: element.name || element.id || "field-".concat(index),
        type: this.getFieldType(element),
        label: label,
        placeholder: placeholder,
        required: element.hasAttribute('required'),
        value: this.getFieldValue(element),
        options: this.getFieldOptions(element),
        validation: this.getFieldValidation(element)
      };
    }
    /**
     * Find label for field
     */
  }, {
    key: "findFieldLabel",
    value: function findFieldLabel(element) {
      if (element.id) {
        var _label$textContent;
        var label = document.querySelector("label[for=\"".concat(element.id, "\"]"));
        if (label) return ((_label$textContent = label.textContent) === null || _label$textContent === void 0 ? void 0 : _label$textContent.trim()) || null;
      }
      var parentLabel = element.closest('label');
      if (parentLabel) {
        var _clone$querySelector, _clone$textContent;
        var clone = parentLabel.cloneNode(true);
        (_clone$querySelector = clone.querySelector('input, select, textarea')) === null || _clone$querySelector === void 0 || _clone$querySelector.remove();
        return ((_clone$textContent = clone.textContent) === null || _clone$textContent === void 0 ? void 0 : _clone$textContent.trim()) || null;
      }
      return element.getAttribute('aria-label') || element.getAttribute('name') || null;
    }
    /**
     * Get field type
     */
  }, {
    key: "getFieldType",
    value: function getFieldType(element) {
      if (element.tagName === 'SELECT') return 'select';
      if (element.tagName === 'TEXTAREA') return 'textarea';
      return element.type || 'text';
    }
    /**
     * Get field value
     */
  }, {
    key: "getFieldValue",
    value: function getFieldValue(element) {
      if (element.tagName === 'SELECT') {
        return element.value;
      }
      if (element.tagName === 'TEXTAREA') {
        return element.value;
      }
      return element.value || '';
    }
    /**
     * Get field options for select/radio/checkbox
     */
  }, {
    key: "getFieldOptions",
    value: function getFieldOptions(element) {
      if (element.tagName === 'SELECT') {
        return Array.from(element.options).map(function (opt) {
          return opt.text;
        });
      }
      return [];
    }
    /**
     * Get field validation rules
     */
  }, {
    key: "getFieldValidation",
    value: function getFieldValidation(element) {
      var validation = {};
      if (element.hasAttribute('pattern')) {
        validation.pattern = element.getAttribute('pattern');
      }
      if (element.hasAttribute('min')) {
        validation.min = element.getAttribute('min');
      }
      if (element.hasAttribute('max')) {
        validation.max = element.getAttribute('max');
      }
      if (element.hasAttribute('minlength')) {
        validation.minLength = parseInt(element.getAttribute('minlength') || '0');
      }
      if (element.hasAttribute('maxlength')) {
        validation.maxLength = parseInt(element.getAttribute('maxlength') || '0');
      }
      return Object.keys(validation).length > 0 ? validation : undefined;
    }
    /**
     * Classify fields using AI
     */
  }, {
    key: "classifyFields",
    value: (function () {
      var _classifyFields = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee3(schema) {
        var _iterator, _step, field, _this$currentSession, response, classification, _t2, _t3;
        return _regenerator().w(function (_context3) {
          while (1) switch (_context3.p = _context3.n) {
            case 0:
              _iterator = _createForOfIteratorHelper(schema.fields);
              _context3.p = 1;
              _iterator.s();
            case 2:
              if ((_step = _iterator.n()).done) {
                _context3.n = 9;
                break;
              }
              field = _step.value;
              _context3.p = 3;
              _context3.n = 4;
              return fetch("".concat(this.apiEndpoint, "/classify-field"), {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  fieldContext: {
                    label: field.label,
                    placeholder: field.placeholder,
                    name: field.name,
                    type: field.type,
                    ariaLabel: field.ariaLabel,
                    options: field.options,
                    validation: field.validation
                  },
                  language: (_this$currentSession = this.currentSession) === null || _this$currentSession === void 0 ? void 0 : _this$currentSession.language
                })
              });
            case 4:
              response = _context3.v;
              if (!response.ok) {
                _context3.n = 6;
                break;
              }
              _context3.n = 5;
              return response.json();
            case 5:
              classification = _context3.v;
              field.aiClassification = classification;
            case 6:
              _context3.n = 8;
              break;
            case 7:
              _context3.p = 7;
              _t2 = _context3.v;
              console.error('Field classification failed:', _t2);
            case 8:
              _context3.n = 2;
              break;
            case 9:
              _context3.n = 11;
              break;
            case 10:
              _context3.p = 10;
              _t3 = _context3.v;
              _iterator.e(_t3);
            case 11:
              _context3.p = 11;
              _iterator.f();
              return _context3.f(11);
            case 12:
              return _context3.a(2);
          }
        }, _callee3, this, [[3, 7], [1, 10, 11, 12]]);
      }));
      function classifyFields(_x3) {
        return _classifyFields.apply(this, arguments);
      }
      return classifyFields;
    }()
    /**
     * Ask for next field
     */
    )
  }, {
    key: "askNextField",
    value: (function () {
      var _askNextField = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee4() {
        var field, question;
        return _regenerator().w(function (_context4) {
          while (1) switch (_context4.n) {
            case 0:
              if (this.currentSession) {
                _context4.n = 1;
                break;
              }
              return _context4.a(2);
            case 1:
              field = this.currentSession.schema.fields[this.currentSession.currentFieldIndex];
              if (field) {
                _context4.n = 2;
                break;
              }
              return _context4.a(2);
            case 2:
              question = this.generateQuestion(field);
              this.speak(question, this.currentSession.language);
            case 3:
              return _context4.a(2);
          }
        }, _callee4, this);
      }));
      function askNextField() {
        return _askNextField.apply(this, arguments);
      }
      return askNextField;
    }()
    /**
     * Generate question for field
     */
    )
  }, {
    key: "generateQuestion",
    value: function generateQuestion(field) {
      var _this$currentSession2;
      var lang = ((_this$currentSession2 = this.currentSession) === null || _this$currentSession2 === void 0 ? void 0 : _this$currentSession2.language) || 'en-US';
      if (lang === 'hi-IN') {
        if (field.type === 'select' && field.options.length > 0) {
          return "\u0915\u0943\u092A\u092F\u093E ".concat(field.label || field.name, " \u091A\u0941\u0928\u0947\u0902: ").concat(field.options.join(', '));
        }
        return "\u0915\u0943\u092A\u092F\u093E ".concat(field.label || field.name, " \u092C\u0924\u093E\u090F\u0902").concat(field.required ? ' ( )' : '');
      } else {
        if (field.type === 'select' && field.options.length > 0) {
          return "Please select ".concat(field.label || field.name, ": ").concat(field.options.join(', '));
        }
        return "Please provide your ".concat(field.label || field.name).concat(field.required ? ' (required)' : '');
      }
    }
    /**
     * Call form AI endpoint
     */
  }, {
    key: "callFormAI",
    value: (function () {
      var _callFormAI = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee5(transcript) {
        var response;
        return _regenerator().w(function (_context5) {
          while (1) switch (_context5.n) {
            case 0:
              if (this.currentSession) {
                _context5.n = 1;
                break;
              }
              throw new Error('No active session');
            case 1:
              _context5.n = 2;
              return fetch("".concat(this.apiEndpoint, "/voice-form-ai"), {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  conversation: this.currentSession.conversation.map(function (msg) {
                    return {
                      role: msg.role,
                      content: msg.content
                    };
                  }),
                  formSchema: this.currentSession.schema,
                  collectedData: this.currentSession.collectedData,
                  language: this.currentSession.language
                })
              });
            case 2:
              response = _context5.v;
              if (response.ok) {
                _context5.n = 3;
                break;
              }
              throw new Error('Form AI processing failed');
            case 3:
              _context5.n = 4;
              return response.json();
            case 4:
              return _context5.a(2, _context5.v);
          }
        }, _callee5, this);
      }));
      function callFormAI(_x4) {
        return _callFormAI.apply(this, arguments);
      }
      return callFormAI;
    }()
    /**
     * Fill fields with collected data
     */
    )
  }, {
    key: "fillFields",
    value: function fillFields(data) {
      var _this2 = this;
      if (!this.currentSession) return;
      var _loop = function _loop() {
        var _Object$entries$_i = _slicedToArray(_Object$entries[_i], 2),
          key = _Object$entries$_i[0],
          value = _Object$entries$_i[1];
        var field = _this2.currentSession.schema.fields.find(function (f) {
          var _f$label;
          return f.name === key || f.id === key || ((_f$label = f.label) === null || _f$label === void 0 ? void 0 : _f$label.toLowerCase()) === key.toLowerCase();
        });
        if (field) {
          var element = _this2.currentSession.form.querySelector("[name=\"".concat(field.name, "\"], #").concat(field.id));
          if (element) {
            if (element.tagName === 'SELECT') {
              element.value = value;
            } else if (element.tagName === 'TEXTAREA') {
              element.value = value;
            } else {
              var input = element;
              if (input.type === 'checkbox' || input.type === 'radio') {
                input.checked = !!value;
              } else {
                input.value = value;
              }
            }
            // Trigger change event
            element.dispatchEvent(new Event('change', {
              bubbles: true
            }));
            element.dispatchEvent(new Event('input', {
              bubbles: true
            }));
          }
        }
      };
      for (var _i = 0, _Object$entries = Object.entries(data); _i < _Object$entries.length; _i++) {
        _loop();
      }
    }
    /**
     * Complete form filling
     */
  }, {
    key: "completeForm",
    value: (function () {
      var _completeForm = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee6() {
        var lang, message, event;
        return _regenerator().w(function (_context6) {
          while (1) switch (_context6.n) {
            case 0:
              if (this.currentSession) {
                _context6.n = 1;
                break;
              }
              return _context6.a(2);
            case 1:
              lang = this.currentSession.language;
              message = lang === 'hi-IN' ? '           ?' : 'Form is complete. Would you like to submit it?';
              this.speak(message, lang);
              if (this.onFormComplete) {
                this.onFormComplete(this.currentSession.collectedData);
              }
              // Emit event
              event = new CustomEvent('voiceFormComplete', {
                detail: {
                  form: this.currentSession.form,
                  data: this.currentSession.collectedData
                }
              });
              document.dispatchEvent(event);
            case 2:
              return _context6.a(2);
          }
        }, _callee6, this);
      }));
      function completeForm() {
        return _completeForm.apply(this, arguments);
      }
      return completeForm;
    }()
    /**
     * Submit form
     */
    )
  }, {
    key: "submitForm",
    value: function submitForm() {
      if (!this.currentSession) return;
      var submitBtn = this.currentSession.form.querySelector('button[type="submit"], input[type="submit"]');
      if (submitBtn) {
        submitBtn.click();
      } else {
        this.currentSession.form.submit();
      }
    }
    /**
     * Cancel form filling
     */
  }, {
    key: "cancelFormFilling",
    value: function cancelFormFilling() {
      this.currentSession = null;
    }
    /**
     * Speak text (delegates to onSpeak callback)
     */
  }, {
    key: "speak",
    value: function speak(text, language) {
      if (this.onSpeak) {
        this.onSpeak(text);
      }
      console.log('[FormHandler] Speaking:', text);
    }
    /**
     * Set form complete callback
     */
  }, {
    key: "onComplete",
    value: function onComplete(callback) {
      this.onFormComplete = callback;
    }
    /**
     * Get current session info
     */
  }, {
    key: "getSessionInfo",
    value: function getSessionInfo() {
      return this.currentSession;
    }
  }]);
}();

/***/ },

/***/ "../lib/voice-sdk/dist/esm/NavigationMap.js"
/*!**************************************************!*\
  !*** ../lib/voice-sdk/dist/esm/NavigationMap.js ***!
  \**************************************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   NavigationMap: () => (/* binding */ NavigationMap)
/* harmony export */ });
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * NavigationMap - Provides intelligent route matching for voice navigation
 * Maps natural language to actual website routes
 */
var NavigationMap = /*#__PURE__*/function () {
  function NavigationMap() {
    _classCallCheck(this, NavigationMap);
    this.routes = [];
    this.initializeRoutes();
  }
  /**
   * Initialize route definitions with keywords and aliases
   */
  return _createClass(NavigationMap, [{
    key: "initializeRoutes",
    value: function initializeRoutes() {
      this.routes = [{
        path: '/',
        keywords: ['home', 'homepage', 'main page', 'start', 'landing'],
        aliases: ['home page', 'main'],
        priority: 10
      }, {
        path: '/about-us',
        keywords: ['about', 'about us', 'about liaplus', 'company', 'who are we', 'team'],
        aliases: ['about page', 'company info', 'our company', 'our team'],
        priority: 10
      }, {
        path: '/pricing',
        keywords: ['pricing', 'price', 'cost', 'plans', 'subscription', 'how much'],
        aliases: ['pricing page', 'pricing plans', 'subscription plans', 'costs'],
        priority: 10
      }, {
        path: '/contact-us',
        keywords: ['contact', 'contact us', 'get in touch', 'reach us', 'support', 'help'],
        aliases: ['contact page', 'contact form', 'customer support'],
        priority: 10
      }, {
        path: '/solutions',
        keywords: ['solutions', 'products', 'services', 'offerings', 'what we offer'],
        aliases: ['our solutions', 'product page'],
        priority: 8
      }, {
        path: '/trusted-by',
        keywords: ['trusted by', 'customers', 'clients', 'testimonials', 'reviews'],
        aliases: ['customer stories', 'client reviews', 'who trusts us'],
        priority: 7
      }, {
        path: '/partner-program',
        keywords: ['partner', 'partnership', 'partner program', 'become a partner', 'partners'],
        aliases: ['partner with us', 'partnership program'],
        priority: 7
      }, {
        path: '/partner-program/var',
        keywords: ['var', 'value added reseller', 'reseller program', 'var partner'],
        aliases: ['var partnership', 'reseller'],
        priority: 6
      }, {
        path: '/partner-program/technology-integration',
        keywords: ['technology integration', 'tech integration', 'integration partner', 'api partner'],
        aliases: ['integration partnership', 'technology partner'],
        priority: 6
      }, {
        path: '/privacy-policy',
        keywords: ['privacy', 'privacy policy', 'data protection', 'privacy statement'],
        aliases: ['data privacy', 'privacy terms'],
        priority: 5
      }, {
        path: '/terms-and-conditions',
        keywords: ['terms', 'terms and conditions', 'terms of service', 'tos', 'legal terms'],
        aliases: ['terms of use', 'service terms'],
        priority: 5
      }, {
        path: '/trust-center',
        keywords: ['trust', 'trust center', 'security', 'compliance', 'certifications'],
        aliases: ['security center', 'compliance center'],
        priority: 6
      }, {
        path: '/manifesto',
        keywords: ['manifesto', 'mission', 'vision', 'values', 'our beliefs'],
        aliases: ['company manifesto', 'our mission'],
        priority: 5
      }, {
        path: '/news',
        keywords: ['news', 'blog', 'updates', 'announcements', 'latest news'],
        aliases: ['news page', 'company news', 'blog posts'],
        priority: 7
      }, {
        path: '/integration',
        keywords: ['integration', 'integrations', 'connect', 'plugins', 'extensions'],
        aliases: ['integration page', 'connect apps'],
        priority: 7
      }, {
        path: '/glossary',
        keywords: ['glossary', 'terms', 'definitions', 'dictionary', 'terminology'],
        aliases: ['glossary page', 'term definitions'],
        priority: 5
      }, {
        path: '/resources/what-is-liaplus',
        keywords: ['what is liaplus', 'liaplus explained', 'introduction', 'getting started'],
        aliases: ['about liaplus', 'liaplus intro'],
        priority: 6
      }, {
        path: '/resources/case-studies',
        keywords: ['case studies', 'success stories', 'customer stories', 'case study'],
        aliases: ['customer case studies', 'use cases'],
        priority: 7
      }, {
        path: '/resources/key-capabilities',
        keywords: ['capabilities', 'key capabilities', 'features', 'what can it do'],
        aliases: ['key features', 'product capabilities'],
        priority: 6
      }, {
        path: '/resources/roi-calculator',
        keywords: ['roi', 'roi calculator', 'return on investment', 'calculate roi', 'savings calculator'],
        aliases: ['calculator', 'cost savings'],
        priority: 6
      }, {
        path: '/resources/agentic-ai',
        keywords: ['agentic ai', 'ai agents', 'agentic', 'artificial intelligence'],
        aliases: ['ai technology', 'agentic artificial intelligence'],
        priority: 6
      }, {
        path: '/resources/voice-bots-vs-voice-ai-agents',
        keywords: ['voice bots', 'voice ai', 'bots vs agents', 'voice agents', 'comparison'],
        aliases: ['voice bots vs agents', 'ai voice comparison'],
        priority: 5
      }, {
        path: '/resources/developer-tools',
        keywords: ['developer', 'developer tools', 'api', 'sdk', 'documentation', 'docs'],
        aliases: ['dev tools', 'developer docs', 'api docs'],
        priority: 7
      }];
    }
    /**
     * Find the best matching route for a given destination string
     */
  }, {
    key: "findRoute",
    value: function findRoute(destination) {
      var destLower = destination.toLowerCase().trim();
      if (!destLower) return null;
      // Score each route based on how well it matches
      var scoredRoutes = this.routes.map(function (route) {
        var _route$aliases, _route$aliases2, _route$aliases3;
        var score = 0;
        // Exact keyword match gets highest score
        if (route.keywords.some(function (keyword) {
          return keyword === destLower;
        })) {
          score += 100;
        }
        // Exact alias match
        if ((_route$aliases = route.aliases) !== null && _route$aliases !== void 0 && _route$aliases.some(function (alias) {
          return alias === destLower;
        })) {
          score += 90;
        }
        // Keyword contains destination
        if (route.keywords.some(function (keyword) {
          return keyword.includes(destLower);
        })) {
          score += 50;
        }
        // Destination contains keyword
        if (route.keywords.some(function (keyword) {
          return destLower.includes(keyword);
        })) {
          score += 40;
        }
        // Alias contains destination
        if ((_route$aliases2 = route.aliases) !== null && _route$aliases2 !== void 0 && _route$aliases2.some(function (alias) {
          return alias.includes(destLower);
        })) {
          score += 45;
        }
        // Destination contains alias
        if ((_route$aliases3 = route.aliases) !== null && _route$aliases3 !== void 0 && _route$aliases3.some(function (alias) {
          return destLower.includes(alias);
        })) {
          score += 35;
        }
        // Check if path matches (e.g., "pricing" matches "/pricing")
        var pathName = route.path.split('/').pop() || '';
        if (pathName && destLower.includes(pathName)) {
          score += 30;
        }
        // Apply priority multiplier
        if (route.priority) {
          score *= 1 + route.priority / 20;
        }
        return {
          route: route,
          score: score
        };
      });
      // Sort by score descending
      scoredRoutes.sort(function (a, b) {
        return b.score - a.score;
      });
      // Return best match if score is above threshold
      var bestMatch = scoredRoutes[0];
      if (bestMatch && bestMatch.score > 20) {
        return bestMatch.route;
      }
      return null;
    }
    /**
     * Get all available routes
     */
  }, {
    key: "getAllRoutes",
    value: function getAllRoutes() {
      return this.routes;
    }
    /**
     * Get route by exact path
     */
  }, {
    key: "getRouteByPath",
    value: function getRouteByPath(path) {
      return this.routes.find(function (r) {
        return r.path === path;
      }) || null;
    }
    /**
     * Add custom route at runtime
     */
  }, {
    key: "addRoute",
    value: function addRoute(route) {
      this.routes.push(route);
    }
    /**
     * Build full URL from path
     */
  }, {
    key: "buildUrl",
    value: function buildUrl(path, baseUrl) {
      var base = baseUrl || window.location.origin;
      return "".concat(base).concat(path);
    }
  }]);
}();

/***/ },

/***/ "../lib/voice-sdk/dist/esm/VoiceNavigator.js"
/*!***************************************************!*\
  !*** ../lib/voice-sdk/dist/esm/VoiceNavigator.js ***!
  \***************************************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VoiceNavigator: () => (/* binding */ VoiceNavigator)
/* harmony export */ });
/* harmony import */ var _DOMAnalyzer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./DOMAnalyzer */ "../lib/voice-sdk/dist/esm/DOMAnalyzer.js");
/* harmony import */ var _CommandMapper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./CommandMapper */ "../lib/voice-sdk/dist/esm/CommandMapper.js");
/* harmony import */ var _FormHandler__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FormHandler */ "../lib/voice-sdk/dist/esm/FormHandler.js");
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _regenerator() { /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/babel/babel/blob/main/packages/babel-helpers/LICENSE */ var e, t, r = "function" == typeof Symbol ? Symbol : {}, n = r.iterator || "@@iterator", o = r.toStringTag || "@@toStringTag"; function i(r, n, o, i) { var c = n && n.prototype instanceof Generator ? n : Generator, u = Object.create(c.prototype); return _regeneratorDefine2(u, "_invoke", function (r, n, o) { var i, c, u, f = 0, p = o || [], y = !1, G = { p: 0, n: 0, v: e, a: d, f: d.bind(e, 4), d: function d(t, r) { return i = t, c = 0, u = e, G.n = r, a; } }; function d(r, n) { for (c = r, u = n, t = 0; !y && f && !o && t < p.length; t++) { var o, i = p[t], d = G.p, l = i[2]; r > 3 ? (o = l === n) && (u = i[(c = i[4]) ? 5 : (c = 3, 3)], i[4] = i[5] = e) : i[0] <= d && ((o = r < 2 && d < i[1]) ? (c = 0, G.v = n, G.n = i[1]) : d < l && (o = r < 3 || i[0] > n || n > l) && (i[4] = r, i[5] = n, G.n = l, c = 0)); } if (o || r > 1) return a; throw y = !0, n; } return function (o, p, l) { if (f > 1) throw TypeError("Generator is already running"); for (y && 1 === p && d(p, l), c = p, u = l; (t = c < 2 ? e : u) || !y;) { i || (c ? c < 3 ? (c > 1 && (G.n = -1), d(c, u)) : G.n = u : G.v = u); try { if (f = 2, i) { if (c || (o = "next"), t = i[o]) { if (!(t = t.call(i, u))) throw TypeError("iterator result is not an object"); if (!t.done) return t; u = t.value, c < 2 && (c = 0); } else 1 === c && (t = i["return"]) && t.call(i), c < 2 && (u = TypeError("The iterator does not provide a '" + o + "' method"), c = 1); i = e; } else if ((t = (y = G.n < 0) ? u : r.call(n, G)) !== a) break; } catch (t) { i = e, c = 1, u = t; } finally { f = 1; } } return { value: t, done: y }; }; }(r, o, i), !0), u; } var a = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} t = Object.getPrototypeOf; var c = [][n] ? t(t([][n]())) : (_regeneratorDefine2(t = {}, n, function () { return this; }), t), u = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(c); function f(e) { return Object.setPrototypeOf ? Object.setPrototypeOf(e, GeneratorFunctionPrototype) : (e.__proto__ = GeneratorFunctionPrototype, _regeneratorDefine2(e, o, "GeneratorFunction")), e.prototype = Object.create(u), e; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, _regeneratorDefine2(u, "constructor", GeneratorFunctionPrototype), _regeneratorDefine2(GeneratorFunctionPrototype, "constructor", GeneratorFunction), GeneratorFunction.displayName = "GeneratorFunction", _regeneratorDefine2(GeneratorFunctionPrototype, o, "GeneratorFunction"), _regeneratorDefine2(u), _regeneratorDefine2(u, o, "Generator"), _regeneratorDefine2(u, n, function () { return this; }), _regeneratorDefine2(u, "toString", function () { return "[object Generator]"; }), (_regenerator = function _regenerator() { return { w: i, m: f }; })(); }
function _regeneratorDefine2(e, r, n, t) { var i = Object.defineProperty; try { i({}, "", {}); } catch (e) { i = 0; } _regeneratorDefine2 = function _regeneratorDefine(e, r, n, t) { function o(r, n) { _regeneratorDefine2(e, r, function (e) { return this._invoke(r, n, e); }); } r ? i ? i(e, r, { value: n, enumerable: !t, configurable: !t, writable: !t }) : e[r] = n : (o("next", 0), o("throw", 1), o("return", 2)); }, _regeneratorDefine2(e, r, n, t); }
function asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }
function _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, "next", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, "throw", n); } _next(void 0); }); }; }
function ownKeys(e, r) { var t = Object.keys(e); if (Object.getOwnPropertySymbols) { var o = Object.getOwnPropertySymbols(e); r && (o = o.filter(function (r) { return Object.getOwnPropertyDescriptor(e, r).enumerable; })), t.push.apply(t, o); } return t; }
function _objectSpread(e) { for (var r = 1; r < arguments.length; r++) { var t = null != arguments[r] ? arguments[r] : {}; r % 2 ? ownKeys(Object(t), !0).forEach(function (r) { _defineProperty(e, r, t[r]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) { Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r)); }); } return e; }
function _defineProperty(e, r, t) { return (r = _toPropertyKey(r)) in e ? Object.defineProperty(e, r, { value: t, enumerable: !0, configurable: !0, writable: !0 }) : e[r] = t, e; }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * VoiceNavigator - Main SDK class for dynamic voice navigation
 * Works on any website without configuration
 */



var VoiceNavigator = /*#__PURE__*/function () {
  function VoiceNavigator(config) {
    var _this = this;
    _classCallCheck(this, VoiceNavigator);
    this.synthesis = null;
    this.isListening = false;
    this.isActive = false;
    this.eventListeners = new Map();
    this.currentDOMAnalysis = null;
    this.config = _objectSpread({
      language: 'en-US',
      confirmActions: true,
      autoStart: false
    }, config);
    // Ensure apiEndpoint is set
    if (!this.config.apiEndpoint) {
      throw new Error('apiEndpoint is required in VoiceNavigatorConfig');
    }
    this.analyzer = new _DOMAnalyzer__WEBPACK_IMPORTED_MODULE_0__.DOMAnalyzer();
    this.commandMapper = new _CommandMapper__WEBPACK_IMPORTED_MODULE_1__.CommandMapper(this.config.apiEndpoint);
    this.formHandler = new _FormHandler__WEBPACK_IMPORTED_MODULE_2__.FormHandler(this.config.apiEndpoint, function (text) {
      return _this.speak(text);
    });
    this.initializeSpeech();
    this.setupEventListeners();
    if (this.config.autoStart) {
      this.start();
    }
  }
  /**
   * Initialize speech recognition and synthesis
   */
  return _createClass(VoiceNavigator, [{
    key: "initializeSpeech",
    value: function initializeSpeech() {
      var _this2 = this;
      // Check for browser support
      var SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        console.error('Speech recognition not supported in this browser');
        return;
      }
      this.recognition = new SpeechRecognition();
      this.recognition.continuous = true;
      this.recognition.interimResults = false;
      this.recognition.lang = this.config.language;
      this.recognition.onstart = function () {
        _this2.isListening = true;
        _this2.emit('listening', {
          listening: true
        });
        console.log('[VoiceNav] Listening started');
      };
      this.recognition.onend = function () {
        _this2.isListening = false;
        _this2.emit('listening', {
          listening: false
        });
        // Auto-restart if still active
        if (_this2.isActive) {
          setTimeout(function () {
            if (_this2.isActive) {
              _this2.recognition.start();
            }
          }, 1000);
        }
      };
      this.recognition.onresult = /*#__PURE__*/function () {
        var _ref = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee(event) {
          var last, transcript, confidence;
          return _regenerator().w(function (_context) {
            while (1) switch (_context.n) {
              case 0:
                last = event.results.length - 1;
                transcript = event.results[last][0].transcript;
                confidence = event.results[last][0].confidence;
                console.log('[VoiceNav] Heard:', transcript, 'Confidence:', confidence);
                _this2.emit('command', {
                  transcript: transcript,
                  confidence: confidence
                });
                _context.n = 1;
                return _this2.processCommand(transcript);
              case 1:
                return _context.a(2);
            }
          }, _callee);
        }));
        return function (_x) {
          return _ref.apply(this, arguments);
        };
      }();
      this.recognition.onerror = function (event) {
        console.error('[VoiceNav] Recognition error:', event.error);
        _this2.emit('error', {
          error: event.error
        });
      };
      // Initialize synthesis
      this.synthesis = new SpeechSynthesisUtterance();
      this.synthesis.lang = this.config.language;
    }
    /**
     * Setup internal event listeners
     */
  }, {
    key: "setupEventListeners",
    value: function setupEventListeners() {
      var _this3 = this;
      // Listen for form events
      document.addEventListener('voiceFormStart', function (event) {
        _this3.emit('formStart', {
          form: event.detail.form
        });
      });
      document.addEventListener('voiceFormComplete', function (event) {
        _this3.emit('formComplete', {
          form: event.detail.form,
          data: event.detail.data
        });
      });
      // Listen for page changes (SPA navigation)
      var lastUrl = window.location.href;
      new MutationObserver(function () {
        var currentUrl = window.location.href;
        if (currentUrl !== lastUrl) {
          lastUrl = currentUrl;
          _this3.onPageChange();
        }
      }).observe(document, {
        subtree: true,
        childList: true
      });
    }
    /**
     * Start voice navigation
     */
  }, {
    key: "start",
    value: (function () {
      var _start = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee2() {
        var response, insights, suggestion, _t;
        return _regenerator().w(function (_context2) {
          while (1) switch (_context2.p = _context2.n) {
            case 0:
              if (!this.isActive) {
                _context2.n = 1;
                break;
              }
              console.log('[VoiceNav] Already active');
              return _context2.a(2);
            case 1:
              console.log('[VoiceNav] Starting...');
              // Analyze current page
              this.currentDOMAnalysis = this.analyzer.analyze();
              console.log('[VoiceNav] DOM Analysis:', this.currentDOMAnalysis);
              // Get AI insights about the page
              _context2.p = 2;
              _context2.n = 3;
              return fetch("".concat(this.config.apiEndpoint, "/analyze-dom"), {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  url: window.location.href,
                  domAnalysis: this.currentDOMAnalysis,
                  language: this.config.language
                })
              });
            case 3:
              response = _context2.v;
              if (!response.ok) {
                _context2.n = 5;
                break;
              }
              _context2.n = 4;
              return response.json();
            case 4:
              insights = _context2.v;
              console.log('[VoiceNav] Page insights:', insights);
              // Speak suggestions
              if (insights.suggestions && insights.suggestions.length > 0) {
                suggestion = insights.suggestions[0];
                this.speak("Voice navigation ready. ".concat(suggestion));
              } else {
                this.speak('Voice navigation ready. Say a command to begin.');
              }
            case 5:
              _context2.n = 7;
              break;
            case 6:
              _context2.p = 6;
              _t = _context2.v;
              console.error('[VoiceNav] Failed to get page insights:', _t);
              this.speak('Voice navigation ready. Say a command to begin.');
            case 7:
              this.isActive = true;
              this.recognition.start();
              this.emit('ready', {
                domAnalysis: this.currentDOMAnalysis
              });
            case 8:
              return _context2.a(2);
          }
        }, _callee2, this, [[2, 6]]);
      }));
      function start() {
        return _start.apply(this, arguments);
      }
      return start;
    }()
    /**
     * Stop voice navigation
     */
    )
  }, {
    key: "stop",
    value: function stop() {
      console.log('[VoiceNav] Stopping...');
      this.isActive = false;
      this.isListening = false;
      if (this.recognition) {
        this.recognition.stop();
      }
      this.speak('Voice navigation stopped.');
    }
    /**
     * Process voice command
     */
  }, {
    key: "processCommand",
    value: (function () {
      var _processCommand = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee3(transcript) {
        var lowerTranscript, intent, _t2;
        return _regenerator().w(function (_context3) {
          while (1) switch (_context3.p = _context3.n) {
            case 0:
              if (this.currentDOMAnalysis) {
                _context3.n = 1;
                break;
              }
              console.error('[VoiceNav] No DOM analysis available');
              return _context3.a(2);
            case 1:
              lowerTranscript = transcript.toLowerCase(); // Check for stop commands
              if (!/stop|exit|quit|close voice/.test(lowerTranscript)) {
                _context3.n = 2;
                break;
              }
              this.stop();
              return _context3.a(2);
            case 2:
              if (!this.formHandler.getSessionInfo()) {
                _context3.n = 4;
                break;
              }
              _context3.n = 3;
              return this.formHandler.processVoiceInput(transcript);
            case 3:
              return _context3.a(2);
            case 4:
              _context3.p = 4;
              _context3.n = 5;
              return this.commandMapper.mapCommand({
                transcript: transcript,
                language: this.config.language,
                domAnalysis: this.currentDOMAnalysis,
                pageContext: {
                  url: window.location.href,
                  title: document.title
                }
              });
            case 5:
              intent = _context3.v;
              console.log('[VoiceNav] Command intent:', intent);
              // Confirm action if required
              if (this.config.confirmActions && intent.confidence < 0.9) {
                this.speak("I think you want to ".concat(intent.targetDescription, ". Is that correct?"));
                // In a full implementation, you'd wait for confirmation
                // For now, we'll just execute
              }
              // Execute the command
              if (!(intent.action === 'fill_form' && intent.target)) {
                _context3.n = 7;
                break;
              }
              _context3.n = 6;
              return this.formHandler.startFormFilling(intent.target, this.config.language);
            case 6:
              _context3.n = 9;
              break;
            case 7:
              _context3.n = 8;
              return this.commandMapper.executeCommand(intent);
            case 8:
              if (intent.targetDescription) {
                this.speak(intent.targetDescription);
              }
            case 9:
              this.emit('action', {
                intent: intent
              });
              _context3.n = 11;
              break;
            case 10:
              _context3.p = 10;
              _t2 = _context3.v;
              console.error('[VoiceNav] Command processing error:', _t2);
              this.speak('Sorry, I could not understand that command. Please try again.');
              this.emit('error', {
                error: _t2
              });
            case 11:
              return _context3.a(2);
          }
        }, _callee3, this, [[4, 10]]);
      }));
      function processCommand(_x2) {
        return _processCommand.apply(this, arguments);
      }
      return processCommand;
    }()
    /**
     * Speak text using TTS
     */
    )
  }, {
    key: "speak",
    value: function speak(text) {
      // Stop any ongoing speech
      window.speechSynthesis.cancel();
      if (this.synthesis) {
        this.synthesis.text = text;
        this.synthesis.lang = this.config.language;
        window.speechSynthesis.speak(this.synthesis);
      }
      console.log('[VoiceNav] Speaking:', text);
    }
    /**
     * Handle page changes (SPA navigation)
     */
  }, {
    key: "onPageChange",
    value: (function () {
      var _onPageChange = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee4() {
        return _regenerator().w(function (_context4) {
          while (1) switch (_context4.n) {
            case 0:
              console.log('[VoiceNav] Page changed, re-analyzing...');
              // Re-analyze DOM
              this.currentDOMAnalysis = this.analyzer.analyze();
              // Cancel any ongoing form filling
              this.formHandler.cancelFormFilling();
              this.speak('Page changed. Voice navigation is ready.');
            case 1:
              return _context4.a(2);
          }
        }, _callee4, this);
      }));
      function onPageChange() {
        return _onPageChange.apply(this, arguments);
      }
      return onPageChange;
    }()
    /**
     * Change language
     */
    )
  }, {
    key: "setLanguage",
    value: function setLanguage(language) {
      this.config.language = language;
      if (this.recognition) {
        this.recognition.lang = language;
      }
      if (this.synthesis) {
        this.synthesis.lang = language;
      }
    }
    /**
     * Register event listener
     */
  }, {
    key: "on",
    value: function on(event, callback) {
      if (!this.eventListeners.has(event)) {
        this.eventListeners.set(event, []);
      }
      this.eventListeners.get(event).push(callback);
    }
    /**
     * Remove event listener
     */
  }, {
    key: "off",
    value: function off(event, callback) {
      var listeners = this.eventListeners.get(event);
      if (listeners) {
        var index = listeners.indexOf(callback);
        if (index > -1) {
          listeners.splice(index, 1);
        }
      }
    }
    /**
     * Emit event
     */
  }, {
    key: "emit",
    value: function emit(event, data) {
      var listeners = this.eventListeners.get(event);
      if (listeners) {
        listeners.forEach(function (callback) {
          return callback(data);
        });
      }
    }
    /**
     * Get current DOM analysis
     */
  }, {
    key: "getDOMAnalysis",
    value: function getDOMAnalysis() {
      return this.currentDOMAnalysis;
    }
    /**
     * Manually trigger DOM re-analysis
     */
  }, {
    key: "refresh",
    value: function refresh() {
      this.currentDOMAnalysis = this.analyzer.analyze();
      console.log('[VoiceNav] DOM re-analyzed:', this.currentDOMAnalysis);
    }
    /**
     * Check if currently listening
     */
  }, {
    key: "isCurrentlyListening",
    value: function isCurrentlyListening() {
      return this.isListening;
    }
    /**
     * Check if currently active
     */
  }, {
    key: "isCurrentlyActive",
    value: function isCurrentlyActive() {
      return this.isActive;
    }
  }]);
}();
// Export for use in browser
if (typeof window !== 'undefined') {
  window.VoiceNavigator = VoiceNavigator;
}

/***/ },

/***/ "../lib/voice-sdk/dist/esm/index.js"
/*!******************************************!*\
  !*** ../lib/voice-sdk/dist/esm/index.js ***!
  \******************************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CommandMapper: () => (/* reexport safe */ _CommandMapper__WEBPACK_IMPORTED_MODULE_2__.CommandMapper),
/* harmony export */   DOMAnalyzer: () => (/* reexport safe */ _DOMAnalyzer__WEBPACK_IMPORTED_MODULE_1__.DOMAnalyzer),
/* harmony export */   FormHandler: () => (/* reexport safe */ _FormHandler__WEBPACK_IMPORTED_MODULE_3__.FormHandler),
/* harmony export */   NavigationMap: () => (/* reexport safe */ _NavigationMap__WEBPACK_IMPORTED_MODULE_4__.NavigationMap),
/* harmony export */   VoiceNavigator: () => (/* reexport safe */ _VoiceNavigator__WEBPACK_IMPORTED_MODULE_0__.VoiceNavigator),
/* harmony export */   "default": () => (/* reexport safe */ _VoiceNavigator__WEBPACK_IMPORTED_MODULE_0__.VoiceNavigator)
/* harmony export */ });
/* harmony import */ var _VoiceNavigator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./VoiceNavigator */ "../lib/voice-sdk/dist/esm/VoiceNavigator.js");
/* harmony import */ var _DOMAnalyzer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DOMAnalyzer */ "../lib/voice-sdk/dist/esm/DOMAnalyzer.js");
/* harmony import */ var _CommandMapper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./CommandMapper */ "../lib/voice-sdk/dist/esm/CommandMapper.js");
/* harmony import */ var _FormHandler__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./FormHandler */ "../lib/voice-sdk/dist/esm/FormHandler.js");
/* harmony import */ var _NavigationMap__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./NavigationMap */ "../lib/voice-sdk/dist/esm/NavigationMap.js");
/**
 * @liaplus/voice-navigation
 * Dynamic voice navigation SDK for any website
 */





// Default export for convenience


/***/ },

/***/ "./src/ApiManager.js"
/*!***************************!*\
  !*** ./src/ApiManager.js ***!
  \***************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   ApiManager: () => (/* binding */ ApiManager)
/* harmony export */ });
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _regenerator() { /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/babel/babel/blob/main/packages/babel-helpers/LICENSE */ var e, t, r = "function" == typeof Symbol ? Symbol : {}, n = r.iterator || "@@iterator", o = r.toStringTag || "@@toStringTag"; function i(r, n, o, i) { var c = n && n.prototype instanceof Generator ? n : Generator, u = Object.create(c.prototype); return _regeneratorDefine2(u, "_invoke", function (r, n, o) { var i, c, u, f = 0, p = o || [], y = !1, G = { p: 0, n: 0, v: e, a: d, f: d.bind(e, 4), d: function d(t, r) { return i = t, c = 0, u = e, G.n = r, a; } }; function d(r, n) { for (c = r, u = n, t = 0; !y && f && !o && t < p.length; t++) { var o, i = p[t], d = G.p, l = i[2]; r > 3 ? (o = l === n) && (u = i[(c = i[4]) ? 5 : (c = 3, 3)], i[4] = i[5] = e) : i[0] <= d && ((o = r < 2 && d < i[1]) ? (c = 0, G.v = n, G.n = i[1]) : d < l && (o = r < 3 || i[0] > n || n > l) && (i[4] = r, i[5] = n, G.n = l, c = 0)); } if (o || r > 1) return a; throw y = !0, n; } return function (o, p, l) { if (f > 1) throw TypeError("Generator is already running"); for (y && 1 === p && d(p, l), c = p, u = l; (t = c < 2 ? e : u) || !y;) { i || (c ? c < 3 ? (c > 1 && (G.n = -1), d(c, u)) : G.n = u : G.v = u); try { if (f = 2, i) { if (c || (o = "next"), t = i[o]) { if (!(t = t.call(i, u))) throw TypeError("iterator result is not an object"); if (!t.done) return t; u = t.value, c < 2 && (c = 0); } else 1 === c && (t = i["return"]) && t.call(i), c < 2 && (u = TypeError("The iterator does not provide a '" + o + "' method"), c = 1); i = e; } else if ((t = (y = G.n < 0) ? u : r.call(n, G)) !== a) break; } catch (t) { i = e, c = 1, u = t; } finally { f = 1; } } return { value: t, done: y }; }; }(r, o, i), !0), u; } var a = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} t = Object.getPrototypeOf; var c = [][n] ? t(t([][n]())) : (_regeneratorDefine2(t = {}, n, function () { return this; }), t), u = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(c); function f(e) { return Object.setPrototypeOf ? Object.setPrototypeOf(e, GeneratorFunctionPrototype) : (e.__proto__ = GeneratorFunctionPrototype, _regeneratorDefine2(e, o, "GeneratorFunction")), e.prototype = Object.create(u), e; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, _regeneratorDefine2(u, "constructor", GeneratorFunctionPrototype), _regeneratorDefine2(GeneratorFunctionPrototype, "constructor", GeneratorFunction), GeneratorFunction.displayName = "GeneratorFunction", _regeneratorDefine2(GeneratorFunctionPrototype, o, "GeneratorFunction"), _regeneratorDefine2(u), _regeneratorDefine2(u, o, "Generator"), _regeneratorDefine2(u, n, function () { return this; }), _regeneratorDefine2(u, "toString", function () { return "[object Generator]"; }), (_regenerator = function _regenerator() { return { w: i, m: f }; })(); }
function _regeneratorDefine2(e, r, n, t) { var i = Object.defineProperty; try { i({}, "", {}); } catch (e) { i = 0; } _regeneratorDefine2 = function _regeneratorDefine(e, r, n, t) { function o(r, n) { _regeneratorDefine2(e, r, function (e) { return this._invoke(r, n, e); }); } r ? i ? i(e, r, { value: n, enumerable: !t, configurable: !t, writable: !t }) : e[r] = n : (o("next", 0), o("throw", 1), o("return", 2)); }, _regeneratorDefine2(e, r, n, t); }
function asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }
function _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, "next", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, "throw", n); } _next(void 0); }); }; }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * API Manager - Handle API calls for both hosted and custom modes
 */

var ApiManager = /*#__PURE__*/function () {
  function ApiManager(widget) {
    _classCallCheck(this, ApiManager);
    this.widget = widget;
    this.config = widget.config;
  }

  /**
   * Get Azure Speech credentials
   */
  return _createClass(ApiManager, [{
    key: "getAzureSpeechCredentials",
    value: (function () {
      var _getAzureSpeechCredentials = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee() {
        var response, _t;
        return _regenerator().w(function (_context) {
          while (1) switch (_context.p = _context.n) {
            case 0:
              if (!(this.config.mode === 'custom')) {
                _context.n = 1;
                break;
              }
              return _context.a(2, {
                token: this.config.azureSpeech.key,
                region: this.config.azureSpeech.region,
                success: true
              });
            case 1:
              _context.p = 1;
              _context.n = 2;
              return fetch("".concat(this.config.apiBase, "/azure-speech"), {
                method: 'GET',
                headers: {
                  'Content-Type': 'application/json'
                }
              });
            case 2:
              response = _context.v;
              if (response.ok) {
                _context.n = 3;
                break;
              }
              throw new Error("HTTP error! status: ".concat(response.status));
            case 3:
              _context.n = 4;
              return response.json();
            case 4:
              return _context.a(2, _context.v);
            case 5:
              _context.p = 5;
              _t = _context.v;
              this.widget.log(' [API] Failed to get Azure Speech credentials:', _t);
              return _context.a(2, {
                success: false,
                error: _t.message
              });
          }
        }, _callee, this, [[1, 5]]);
      }));
      function getAzureSpeechCredentials() {
        return _getAzureSpeechCredentials.apply(this, arguments);
      }
      return getAzureSpeechCredentials;
    }()
    /**
     * Process voice command with AI
     */
    )
  }, {
    key: "processVoiceCommand",
    value: (function () {
      var _processVoiceCommand = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee2(command, domAnalysis, currentUrl) {
        return _regenerator().w(function (_context2) {
          while (1) switch (_context2.n) {
            case 0:
              if (!(this.config.mode === 'custom')) {
                _context2.n = 2;
                break;
              }
              _context2.n = 1;
              return this.processCommandWithCustomAI(command, domAnalysis, currentUrl);
            case 1:
              return _context2.a(2, _context2.v);
            case 2:
              _context2.n = 3;
              return this.processCommandWithHostedAI(command, domAnalysis, currentUrl);
            case 3:
              return _context2.a(2, _context2.v);
          }
        }, _callee2, this);
      }));
      function processVoiceCommand(_x, _x2, _x3) {
        return _processVoiceCommand.apply(this, arguments);
      }
      return processVoiceCommand;
    }()
    /**
     * Process command with hosted AI (default)
     */
    )
  }, {
    key: "processCommandWithHostedAI",
    value: (function () {
      var _processCommandWithHostedAI = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee3(command, domAnalysis, currentUrl) {
        var requestBody, response, data, errorData, _t2;
        return _regenerator().w(function (_context3) {
          while (1) switch (_context3.p = _context3.n) {
            case 0:
              _context3.p = 0;
              requestBody = {
                command: command,
                language: this.widget.state.language,
                currentUrl: currentUrl || window.location.href
              };
              if (this.widget.state.useDynamicMode && domAnalysis) {
                requestBody.domAnalysis = domAnalysis;
                this.widget.log(' [Dynamic Mode] Sending DOM analysis:', {
                  forms: domAnalysis.forms.length,
                  navigation: domAnalysis.navigation.length,
                  interactions: domAnalysis.interactions.length
                });
              }
              this.widget.log(' [API Call] Sending to /api/voice-ai...');
              _context3.n = 1;
              return fetch("".concat(this.config.apiBase, "/voice-ai"), {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify(requestBody)
              });
            case 1:
              response = _context3.v;
              this.widget.log(' [API Response]', response.status, response.statusText);
              if (!response.ok) {
                _context3.n = 3;
                break;
              }
              _context3.n = 2;
              return response.json();
            case 2:
              data = _context3.v;
              this.widget.log(' [AI Response]', data);
              return _context3.a(2, data);
            case 3:
              _context3.n = 4;
              return response.json()["catch"](function () {
                return {};
              });
            case 4:
              errorData = _context3.v;
              this.widget.log(' [API Error]', errorData);
              throw new Error('AI request failed');
            case 5:
              _context3.n = 7;
              break;
            case 6:
              _context3.p = 6;
              _t2 = _context3.v;
              this.widget.log(' [Error]', _t2);
              throw _t2;
            case 7:
              return _context3.a(2);
          }
        }, _callee3, this, [[0, 6]]);
      }));
      function processCommandWithHostedAI(_x4, _x5, _x6) {
        return _processCommandWithHostedAI.apply(this, arguments);
      }
      return processCommandWithHostedAI;
    }()
    /**
     * Process command with custom Azure OpenAI credentials
     */
    )
  }, {
    key: "processCommandWithCustomAI",
    value: (function () {
      var _processCommandWithCustomAI = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee4(command, domAnalysis, currentUrl) {
        var azureOpenAI, systemPrompt, contextInfo, messages, apiUrl, response, error, data, aiResponse, _t3;
        return _regenerator().w(function (_context4) {
          while (1) switch (_context4.p = _context4.n) {
            case 0:
              _context4.p = 0;
              azureOpenAI = this.config.azureOpenAI; // Build system prompt based on DOM analysis
              systemPrompt = this.buildSystemPrompt(this.widget.state.language, domAnalysis); // Build context
              contextInfo = this.buildContext(currentUrl, domAnalysis); // Build messages
              messages = [{
                role: 'system',
                content: systemPrompt
              }, {
                role: 'user',
                content: "".concat(contextInfo, "\n\nUser said: \"").concat(command, "\"\n\nWhat should I do?")
              }]; // Call Azure OpenAI
              apiUrl = "".concat(azureOpenAI.endpoint, "/openai/deployments/").concat(azureOpenAI.deployment, "/chat/completions?api-version=2024-08-01-preview");
              this.widget.log(' [Custom AI] Calling Azure OpenAI directly...');
              _context4.n = 1;
              return fetch(apiUrl, {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                  'api-key': azureOpenAI.apiKey
                },
                body: JSON.stringify({
                  messages: messages,
                  temperature: 0.7,
                  max_tokens: 250,
                  response_format: {
                    type: 'json_object'
                  }
                })
              });
            case 1:
              response = _context4.v;
              if (response.ok) {
                _context4.n = 3;
                break;
              }
              _context4.n = 2;
              return response.text();
            case 2:
              error = _context4.v;
              this.widget.log(' [Custom AI Error]', error);
              throw new Error('Custom AI request failed');
            case 3:
              _context4.n = 4;
              return response.json();
            case 4:
              data = _context4.v;
              aiResponse = JSON.parse(data.choices[0].message.content); // Ensure response has all required fields
              return _context4.a(2, {
                action: aiResponse.action || 'chat',
                parameters: aiResponse.parameters || {},
                response: aiResponse.response || '',
                context: aiResponse.context || null,
                confirmAction: aiResponse.confirmAction || false,
                confidence: aiResponse.confidence || 0.7
              });
            case 5:
              _context4.p = 5;
              _t3 = _context4.v;
              this.widget.log(' [Custom AI Error]', _t3);
              throw _t3;
            case 6:
              return _context4.a(2);
          }
        }, _callee4, this, [[0, 5]]);
      }));
      function processCommandWithCustomAI(_x7, _x8, _x9) {
        return _processCommandWithCustomAI.apply(this, arguments);
      }
      return processCommandWithCustomAI;
    }()
    /**
     * Build system prompt (simplified version from route.ts)
     */
    )
  }, {
    key: "buildSystemPrompt",
    value: function buildSystemPrompt(language, domAnalysis) {
      var _domAnalysis$forms, _domAnalysis$navigati;
      var isHindi = language === 'hi-IN';
      var formsInfo = (domAnalysis === null || domAnalysis === void 0 || (_domAnalysis$forms = domAnalysis.forms) === null || _domAnalysis$forms === void 0 ? void 0 : _domAnalysis$forms.length) > 0 ? domAnalysis.forms.map(function (f, i) {
        var _f$fields, _f$fields2;
        var fieldDetails = (_f$fields = f.fields) === null || _f$fields === void 0 ? void 0 : _f$fields.map(function (field) {
          return "".concat(field.label || field.name || field.placeholder || field.type);
        }).join(', ');
        return "Form ".concat(i + 1, ": ").concat(((_f$fields2 = f.fields) === null || _f$fields2 === void 0 ? void 0 : _f$fields2.length) || 0, " fields (").concat(fieldDetails, ")");
      }).join('\n') : 'No forms on this page';
      var navInfo = (domAnalysis === null || domAnalysis === void 0 || (_domAnalysis$navigati = domAnalysis.navigation) === null || _domAnalysis$navigati === void 0 ? void 0 : _domAnalysis$navigati.length) > 0 ? "Navigation options: ".concat(domAnalysis.navigation.slice(0, 10).map(function (n) {
        return n.text;
      }).filter(function (t) {
        return t;
      }).join(', ')) : 'No navigation menu detected';
      if (isHindi) {
        return "\u0906\u092A \u090F\u0915 intelligent voice assistant \u0939\u0948\u0902\u0964 Available actions: scroll, navigate, back, forward, refresh, zoom, click, fill_form, read, chat. Response format (JSON): {\"action\": \"exact_action_name\", \"parameters\": {}, \"response\": \"user \u0915\u094B friendly message\", \"confidence\": 0.0-1.0}. Page analysis: ".concat(formsInfo, ". Navigation: ").concat(navInfo, ".");
      }
      return "You are an intelligent voice assistant. Available actions: scroll, navigate, back, forward, refresh, zoom, click, fill_form, read, chat. Response format (JSON): {\"action\": \"exact_action_name\", \"parameters\": {}, \"response\": \"friendly message\", \"confidence\": 0.0-1.0}. Page analysis: ".concat(formsInfo, ". Navigation: ").concat(navInfo, ".");
    }

    /**
     * Build context
     */
  }, {
    key: "buildContext",
    value: function buildContext(url, domAnalysis) {
      var _domAnalysis$pageInfo;
      var context = "Current page: ".concat(url, "\nPage title: ").concat((domAnalysis === null || domAnalysis === void 0 || (_domAnalysis$pageInfo = domAnalysis.pageInfo) === null || _domAnalysis$pageInfo === void 0 ? void 0 : _domAnalysis$pageInfo.title) || 'Unknown', "\n\n");
      if (domAnalysis) {
        var _domAnalysis$forms2, _domAnalysis$navigati2, _domAnalysis$interact;
        context += "DOM Analysis:\n";
        context += "- Forms: ".concat(((_domAnalysis$forms2 = domAnalysis.forms) === null || _domAnalysis$forms2 === void 0 ? void 0 : _domAnalysis$forms2.length) || 0, "\n");
        context += "- Navigation elements: ".concat(((_domAnalysis$navigati2 = domAnalysis.navigation) === null || _domAnalysis$navigati2 === void 0 ? void 0 : _domAnalysis$navigati2.length) || 0, "\n");
        context += "- Interactive elements: ".concat(((_domAnalysis$interact = domAnalysis.interactions) === null || _domAnalysis$interact === void 0 ? void 0 : _domAnalysis$interact.length) || 0, "\n");
      }
      return context;
    }
  }]);
}();

/***/ },

/***/ "./src/AudioManager.js"
/*!*****************************!*\
  !*** ./src/AudioManager.js ***!
  \*****************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   AudioManager: () => (/* binding */ AudioManager)
/* harmony export */ });
/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/microsoft.cognitiveservices.speech.sdk.js");
/* harmony import */ var microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__);
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _regenerator() { /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/babel/babel/blob/main/packages/babel-helpers/LICENSE */ var e, t, r = "function" == typeof Symbol ? Symbol : {}, n = r.iterator || "@@iterator", o = r.toStringTag || "@@toStringTag"; function i(r, n, o, i) { var c = n && n.prototype instanceof Generator ? n : Generator, u = Object.create(c.prototype); return _regeneratorDefine2(u, "_invoke", function (r, n, o) { var i, c, u, f = 0, p = o || [], y = !1, G = { p: 0, n: 0, v: e, a: d, f: d.bind(e, 4), d: function d(t, r) { return i = t, c = 0, u = e, G.n = r, a; } }; function d(r, n) { for (c = r, u = n, t = 0; !y && f && !o && t < p.length; t++) { var o, i = p[t], d = G.p, l = i[2]; r > 3 ? (o = l === n) && (u = i[(c = i[4]) ? 5 : (c = 3, 3)], i[4] = i[5] = e) : i[0] <= d && ((o = r < 2 && d < i[1]) ? (c = 0, G.v = n, G.n = i[1]) : d < l && (o = r < 3 || i[0] > n || n > l) && (i[4] = r, i[5] = n, G.n = l, c = 0)); } if (o || r > 1) return a; throw y = !0, n; } return function (o, p, l) { if (f > 1) throw TypeError("Generator is already running"); for (y && 1 === p && d(p, l), c = p, u = l; (t = c < 2 ? e : u) || !y;) { i || (c ? c < 3 ? (c > 1 && (G.n = -1), d(c, u)) : G.n = u : G.v = u); try { if (f = 2, i) { if (c || (o = "next"), t = i[o]) { if (!(t = t.call(i, u))) throw TypeError("iterator result is not an object"); if (!t.done) return t; u = t.value, c < 2 && (c = 0); } else 1 === c && (t = i["return"]) && t.call(i), c < 2 && (u = TypeError("The iterator does not provide a '" + o + "' method"), c = 1); i = e; } else if ((t = (y = G.n < 0) ? u : r.call(n, G)) !== a) break; } catch (t) { i = e, c = 1, u = t; } finally { f = 1; } } return { value: t, done: y }; }; }(r, o, i), !0), u; } var a = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} t = Object.getPrototypeOf; var c = [][n] ? t(t([][n]())) : (_regeneratorDefine2(t = {}, n, function () { return this; }), t), u = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(c); function f(e) { return Object.setPrototypeOf ? Object.setPrototypeOf(e, GeneratorFunctionPrototype) : (e.__proto__ = GeneratorFunctionPrototype, _regeneratorDefine2(e, o, "GeneratorFunction")), e.prototype = Object.create(u), e; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, _regeneratorDefine2(u, "constructor", GeneratorFunctionPrototype), _regeneratorDefine2(GeneratorFunctionPrototype, "constructor", GeneratorFunction), GeneratorFunction.displayName = "GeneratorFunction", _regeneratorDefine2(GeneratorFunctionPrototype, o, "GeneratorFunction"), _regeneratorDefine2(u), _regeneratorDefine2(u, o, "Generator"), _regeneratorDefine2(u, n, function () { return this; }), _regeneratorDefine2(u, "toString", function () { return "[object Generator]"; }), (_regenerator = function _regenerator() { return { w: i, m: f }; })(); }
function _regeneratorDefine2(e, r, n, t) { var i = Object.defineProperty; try { i({}, "", {}); } catch (e) { i = 0; } _regeneratorDefine2 = function _regeneratorDefine(e, r, n, t) { function o(r, n) { _regeneratorDefine2(e, r, function (e) { return this._invoke(r, n, e); }); } r ? i ? i(e, r, { value: n, enumerable: !t, configurable: !t, writable: !t }) : e[r] = n : (o("next", 0), o("throw", 1), o("return", 2)); }, _regeneratorDefine2(e, r, n, t); }
function asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }
function _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, "next", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, "throw", n); } _next(void 0); }); }; }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * Audio Manager - Azure Speech SDK integration
 * Port of Azure Speech functions from voice-navigation-advanced.tsx lines 774-891
 */


var AudioManager = /*#__PURE__*/function () {
  function AudioManager(widget) {
    _classCallCheck(this, AudioManager);
    this.widget = widget;
    this.recognizer = null;
    this.synthesizer = null;
  }

  /**
   * Initialize Azure Speech (lines 774-825)
   */
  return _createClass(AudioManager, [{
    key: "initializeAzureSpeech",
    value: (function () {
      var _initializeAzureSpeech = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee() {
        var _this = this;
        var credentials, token, region, speechConfig, audioConfig, ttsConfig, audioConfigTTS, _t;
        return _regenerator().w(function (_context) {
          while (1) switch (_context.p = _context.n) {
            case 0:
              _context.p = 0;
              _context.n = 1;
              return this.widget.apiManager.getAzureSpeechCredentials();
            case 1:
              credentials = _context.v;
              if (credentials.success) {
                _context.n = 2;
                break;
              }
              this.widget.log(' [Speech] Failed to get credentials');
              return _context.a(2, false);
            case 2:
              token = credentials.token, region = credentials.region; // Setup STT (Speech-to-Text)
              speechConfig = microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__.SpeechConfig.fromSubscription(token, region);
              speechConfig.speechRecognitionLanguage = this.widget.state.language;
              audioConfig = microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__.AudioConfig.fromDefaultMicrophoneInput();
              this.recognizer = new microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__.SpeechRecognizer(speechConfig, audioConfig);

              // Event handlers
              this.recognizer.recognizing = function (s, e) {
                if (e.result.text) {
                  _this.widget.setState({
                    transcript: e.result.text.toLowerCase().trim()
                  });
                }
              };
              this.recognizer.recognized = function (s, e) {
                if (e.result.reason === microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__.ResultReason.RecognizedSpeech && e.result.text) {
                  var command = e.result.text.toLowerCase().trim();
                  _this.widget.setState({
                    transcript: command
                  });
                  _this.widget.handleVoiceCommand(command);
                }
              };
              this.recognizer.canceled = function (s, e) {
                if (e.reason !== microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__.CancellationReason.EndOfStream) {
                  _this.widget.log(' [Speech] Recognition canceled:', e.reason);
                }
              };

              // Start continuous recognition
              this.recognizer.startContinuousRecognitionAsync(function () {
                _this.widget.log(' [Speech] Recognition started');
              }, function (err) {
                _this.widget.log(' [Speech] Failed to start recognition:', err);
              });

              // Setup TTS (Text-to-Speech) with best voices
              ttsConfig = microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__.SpeechConfig.fromSubscription(token, region);
              ttsConfig.speechSynthesisLanguage = this.widget.state.language;
              // Use Swara for Hindi (best female voice), Jenny for English
              ttsConfig.speechSynthesisVoiceName = this.widget.state.language === 'hi-IN' ? 'hi-IN-SwaraNeural' : 'en-US-JennyNeural';
              audioConfigTTS = microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__.AudioConfig.fromDefaultSpeakerOutput();
              this.synthesizer = new microsoft_cognitiveservices_speech_sdk__WEBPACK_IMPORTED_MODULE_0__.SpeechSynthesizer(ttsConfig, audioConfigTTS);
              this.widget.log(' [Speech] Azure Speech initialized');
              return _context.a(2, true);
            case 3:
              _context.p = 3;
              _t = _context.v;
              this.widget.log(' [Speech] Initialization failed:', _t);
              return _context.a(2, false);
          }
        }, _callee, this, [[0, 3]]);
      }));
      function initializeAzureSpeech() {
        return _initializeAzureSpeech.apply(this, arguments);
      }
      return initializeAzureSpeech;
    }()
    /**
     * Start recognition
     */
    )
  }, {
    key: "start",
    value: (function () {
      var _start = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee2() {
        var initialized, message;
        return _regenerator().w(function (_context2) {
          while (1) switch (_context2.n) {
            case 0:
              _context2.n = 1;
              return this.initializeAzureSpeech();
            case 1:
              initialized = _context2.v;
              if (initialized) {
                message = this.widget.state.language === 'hi-IN' ? '   ' : 'Voice navigation is on';
                this.speak(message);
              } else {
                this.speak('Unable to start voice navigation');
                this.widget.setState({
                  isListening: false
                });
              }
            case 2:
              return _context2.a(2);
          }
        }, _callee2, this);
      }));
      function start() {
        return _start.apply(this, arguments);
      }
      return start;
    }()
    /**
     * Stop recognition
     */
    )
  }, {
    key: "stop",
    value: function stop() {
      var _this2 = this;
      if (this.recognizer) {
        this.recognizer.stopContinuousRecognitionAsync(function () {
          _this2.recognizer.close();
          _this2.recognizer = null;
          _this2.widget.log(' [Speech] Recognition stopped');
        }, function (err) {
          _this2.widget.log(' [Speech] Failed to stop recognition:', err);
        });
      }
      if (this.synthesizer) {
        this.synthesizer.close();
        this.synthesizer = null;
      }
      this.widget.setState({
        transcript: ''
      });
    }

    /**
     * Speak text (lines 874-884)
     */
  }, {
    key: "speak",
    value: function speak(text) {
      var _this3 = this;
      if (!this.widget.state.voiceEnabled) {
        this.widget.log(' [Speech] Voice feedback disabled');
        return;
      }
      if (this.synthesizer) {
        this.widget.log(' [Speaking]', text);
        this.synthesizer.speakTextAsync(text, function () {
          _this3.widget.log(' [Speech] Synthesis complete');
        }, function (error) {
          _this3.widget.log(' [Speech] Synthesis error:', error);
        });
      } else {
        this.widget.log(' [Speech] Synthesizer not initialized');
      }
    }

    /**
     * Stop speaking (lines 886-891)
     */
  }, {
    key: "stopSpeaking",
    value: function stopSpeaking() {
      // Azure will auto-stop on next speak
      var message = this.widget.state.language === 'hi-IN' ? ' ' : 'Stopped';
      this.speak(message);
    }

    /**
     * Reinitialize when language changes
     */
  }, {
    key: "reinitialize",
    value: (function () {
      var _reinitialize = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee3() {
        return _regenerator().w(function (_context3) {
          while (1) switch (_context3.n) {
            case 0:
              this.widget.log(' [Speech] Reinitializing for language change...');
              this.stop();
              _context3.n = 1;
              return new Promise(function (resolve) {
                return setTimeout(resolve, 500);
              });
            case 1:
              if (!this.widget.state.isListening) {
                _context3.n = 2;
                break;
              }
              _context3.n = 2;
              return this.start();
            case 2:
              return _context3.a(2);
          }
        }, _callee3, this);
      }));
      function reinitialize() {
        return _reinitialize.apply(this, arguments);
      }
      return reinitialize;
    }())
  }]);
}();

/***/ },

/***/ "./src/CommandProcessor.js"
/*!*********************************!*\
  !*** ./src/CommandProcessor.js ***!
  \*********************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   CommandProcessor: () => (/* binding */ CommandProcessor)
/* harmony export */ });
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _slicedToArray(r, e) { return _arrayWithHoles(r) || _iterableToArrayLimit(r, e) || _unsupportedIterableToArray(r, e) || _nonIterableRest(); }
function _nonIterableRest() { throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }
function _iterableToArrayLimit(r, l) { var t = null == r ? null : "undefined" != typeof Symbol && r[Symbol.iterator] || r["@@iterator"]; if (null != t) { var e, n, i, u, a = [], f = !0, o = !1; try { if (i = (t = t.call(r)).next, 0 === l) { if (Object(t) !== t) return; f = !1; } else for (; !(f = (e = i.call(t)).done) && (a.push(e.value), a.length !== l); f = !0); } catch (r) { o = !0, n = r; } finally { try { if (!f && null != t["return"] && (u = t["return"](), Object(u) !== u)) return; } finally { if (o) throw n; } } return a; } }
function _arrayWithHoles(r) { if (Array.isArray(r)) return r; }
function _createForOfIteratorHelper(r, e) { var t = "undefined" != typeof Symbol && r[Symbol.iterator] || r["@@iterator"]; if (!t) { if (Array.isArray(r) || (t = _unsupportedIterableToArray(r)) || e && r && "number" == typeof r.length) { t && (r = t); var _n = 0, F = function F() {}; return { s: F, n: function n() { return _n >= r.length ? { done: !0 } : { done: !1, value: r[_n++] }; }, e: function e(r) { throw r; }, f: F }; } throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); } var o, a = !0, u = !1; return { s: function s() { t = t.call(r); }, n: function n() { var r = t.next(); return a = r.done, r; }, e: function e(r) { u = !0, o = r; }, f: function f() { try { a || null == t["return"] || t["return"](); } finally { if (u) throw o; } } }; }
function _unsupportedIterableToArray(r, a) { if (r) { if ("string" == typeof r) return _arrayLikeToArray(r, a); var t = {}.toString.call(r).slice(8, -1); return "Object" === t && r.constructor && (t = r.constructor.name), "Map" === t || "Set" === t ? Array.from(r) : "Arguments" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? _arrayLikeToArray(r, a) : void 0; } }
function _arrayLikeToArray(r, a) { (null == a || a > r.length) && (a = r.length); for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e]; return n; }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * Command Processor - Voice command execution logic
 * Port of executeAction, fillFormDynamically, clickElementDynamically, navigateDynamically
 * from voice-navigation-advanced.tsx lines 133-772
 */

var CommandProcessor = /*#__PURE__*/function () {
  function CommandProcessor(widget) {
    _classCallCheck(this, CommandProcessor);
    this.widget = widget;
  }

  /**
   * Execute action (lines 133-230)
   */
  return _createClass(CommandProcessor, [{
    key: "executeAction",
    value: function executeAction(action) {
      var _this = this;
      var parameters = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
      this.widget.log(' [Execute Action]', action, parameters);

      // Action aliases - map various AI responses to correct actions
      var actionAliases = {
        'scroll_bottom': 'bottom',
        'scroll_to_bottom': 'bottom',
        'go_to_bottom': 'bottom',
        'scroll_top': 'top',
        'scroll_to_top': 'top',
        'go_to_top': 'top',
        'scroll_middle': 'middle',
        'scroll_to_middle': 'middle',
        'go_to_middle': 'middle',
        'go_back': 'back',
        'voice_ai_agent': 'voice_agent',
        'voice_ai': 'voice_agent'
      };

      // Apply alias mapping
      var mappedAction = actionAliases[action] || action;
      var actions = {
        // Scrolling
        'scroll_up': function scroll_up() {
          return window.scrollBy({
            top: -400,
            behavior: 'smooth'
          });
        },
        'scroll_down': function scroll_down() {
          return window.scrollBy({
            top: 400,
            behavior: 'smooth'
          });
        },
        'scroll_to_top': function scroll_to_top() {
          return window.scrollTo({
            top: 0,
            behavior: 'smooth'
          });
        },
        'scroll_to_bottom': function scroll_to_bottom() {
          return window.scrollTo({
            top: document.documentElement.scrollHeight,
            behavior: 'smooth'
          });
        },
        'top': function top() {
          return window.scrollTo({
            top: 0,
            behavior: 'smooth'
          });
        },
        'bottom': function bottom() {
          return window.scrollTo({
            top: document.documentElement.scrollHeight,
            behavior: 'smooth'
          });
        },
        'middle': function middle() {
          return window.scrollTo({
            top: document.documentElement.scrollHeight / 2,
            behavior: 'smooth'
          });
        },
        // Zoom Commands
        'zoom_in': function zoom_in() {
          var currentZoom = parseFloat(document.body.style.zoom || '1');
          document.body.style.zoom = "".concat(currentZoom + 0.1);
        },
        'zoom_out': function zoom_out() {
          var currentZoom = parseFloat(document.body.style.zoom || '1');
          document.body.style.zoom = "".concat(Math.max(0.5, currentZoom - 0.1));
        },
        'reset_zoom': function reset_zoom() {
          document.body.style.zoom = '1';
        },
        // Navigation (fallback for known routes)
        'home': function home() {
          return _this.navigateToPath('/');
        },
        'products': function products() {
          return _this.navigateToPath('/products');
        },
        'pricing': function pricing() {
          return _this.navigateToPath('/pricing');
        },
        'about': function about() {
          return _this.navigateToPath('/about-us');
        },
        'contact': function contact() {
          return _this.navigateToPath('/contact-us');
        },
        'solutions': function solutions() {
          return _this.navigateToPath('/solutions');
        },
        'careers': function careers() {
          return _this.navigateToPath('/careers');
        },
        'partners': function partners() {
          return _this.navigateToPath('/partner-program');
        },
        // Products
        'chatbot': function chatbot() {
          return _this.navigateToPath('/products/chatbot');
        },
        'voice_agent': function voice_agent() {
          return _this.navigateToPath('/products/voice-ai-agent');
        },
        'email_assistant': function email_assistant() {
          return _this.navigateToPath('/products/executive-email-assistant');
        },
        // Resources
        'roi_calculator': function roi_calculator() {
          return _this.navigateToPath('/resources/roi-calculator');
        },
        'case_studies': function case_studies() {
          return _this.navigateToPath('/resources/case-studies');
        },
        // Solutions
        'banking': function banking() {
          return _this.navigateToPath('/solutions/industries/banking-finance');
        },
        'healthcare': function healthcare() {
          return _this.navigateToPath('/solutions/industries/healthcare');
        },
        'ecommerce': function ecommerce() {
          return _this.navigateToPath('/solutions/industries/e-commerce');
        },
        // Dynamic Navigation
        'navigate': function navigate() {
          return _this.navigateDynamically(parameters);
        },
        // Dynamic Form Filling
        'fill_form': function fill_form() {
          return _this.fillFormDynamically(parameters);
        },
        // Dynamic Click
        'click': function click() {
          return _this.clickElementDynamically(parameters);
        },
        // System & Browser Navigation
        'back': function back() {
          return window.history.back();
        },
        'forward': function forward() {
          return window.history.forward();
        },
        'refresh': function refresh() {
          return window.location.reload();
        },
        'print': function print() {
          return window.print();
        },
        'hide_commands': function hide_commands() {
          return _this.widget.setState({
            showCommands: false
          });
        },
        'show_commands': function show_commands() {
          return _this.widget.setState({
            showCommands: true
          });
        },
        // Content
        'read': function read() {
          return _this.readPageContent();
        },
        'stop_reading': function stop_reading() {
          return _this.widget.stopSpeaking();
        }
      };
      var actionFn = actions[mappedAction];
      if (actionFn) {
        actionFn();
        return true;
      }
      return false;
    }

    /**
     * Navigate to path
     */
  }, {
    key: "navigateToPath",
    value: function navigateToPath(path) {
      window.location.href = path;
    }

    /**
     * Read page content
     */
  }, {
    key: "readPageContent",
    value: function readPageContent() {
      var mainContent = document.querySelector('main') || document.querySelector('#main-content') || document.body;
      if (mainContent) {
        var _mainContent$textCont;
        var text = ((_mainContent$textCont = mainContent.textContent) === null || _mainContent$textCont === void 0 ? void 0 : _mainContent$textCont.slice(0, 500)) || 'No content to read';
        this.widget.speak(text);
      }
    }

    /**
     * Fill form dynamically (lines 232-402)
     */
  }, {
    key: "fillFormDynamically",
    value: function fillFormDynamically(parameters) {
      var _this2 = this;
      this.widget.log(' [Fill Form] Parameters:', parameters);
      var domAnalysis = this.widget.state.domAnalysis;
      if (!domAnalysis || domAnalysis.forms.length === 0) {
        this.widget.log(' [Fill Form] No forms found');
        return;
      }

      // Try to find the best matching form
      var targetForm = domAnalysis.forms[0]; // Default to first form

      // If there are multiple forms, try to find one with matching fields
      if (domAnalysis.forms.length > 1 && parameters) {
        var fieldKeys = Object.keys(parameters.fields || parameters);
        var _iterator = _createForOfIteratorHelper(domAnalysis.forms),
          _step;
        try {
          for (_iterator.s(); !(_step = _iterator.n()).done;) {
            var form = _step.value;
            var hasMatchingField = form.fields.some(function (f) {
              return fieldKeys.some(function (key) {
                var _f$name, _f$label;
                return ((_f$name = f.name) === null || _f$name === void 0 ? void 0 : _f$name.toLowerCase().includes(key.toLowerCase())) || ((_f$label = f.label) === null || _f$label === void 0 ? void 0 : _f$label.toLowerCase().includes(key.toLowerCase())) || f.type === key.toLowerCase() || key === 'email' && f.type === 'email';
              });
            });
            if (hasMatchingField) {
              targetForm = form;
              break;
            }
          }
        } catch (err) {
          _iterator.e(err);
        } finally {
          _iterator.f();
        }
      }
      this.widget.log(' [Fill Form] Using form:', targetForm.id, 'with', targetForm.fields.length, 'fields');

      // Extract field values
      var fieldValues = parameters.fields || parameters;
      this.widget.log(' [Fill Form] Field values to fill:', fieldValues);
      var filledCount = 0;
      var filledFields = [];

      // Fill each parameter into matching fields
      Object.entries(fieldValues).forEach(function (_ref) {
        var _ref2 = _slicedToArray(_ref, 2),
          key = _ref2[0],
          value = _ref2[1];
        _this2.widget.log("\uD83D\uDD0D [Fill Form] Looking for field: ".concat(key, " = ").concat(value));

        // Find matching field
        var field = targetForm.fields.find(function (f) {
          var _f$name2, _f$label2, _f$id, _f$placeholder;
          var keyLower = key.toLowerCase();

          // Direct type match for email fields
          if (keyLower === 'email' && f.type === 'email') return true;

          // Check various field properties
          return ((_f$name2 = f.name) === null || _f$name2 === void 0 ? void 0 : _f$name2.toLowerCase().includes(keyLower)) || ((_f$label2 = f.label) === null || _f$label2 === void 0 ? void 0 : _f$label2.toLowerCase().includes(keyLower)) || ((_f$id = f.id) === null || _f$id === void 0 ? void 0 : _f$id.toLowerCase().includes(keyLower)) || ((_f$placeholder = f.placeholder) === null || _f$placeholder === void 0 ? void 0 : _f$placeholder.toLowerCase().includes(keyLower)) || f.type === keyLower;
        });
        if (field) {
          _this2.widget.log("\u2705 [Fill Form] Found field:", field);
          var input = null;

          // Strategy 1: By type for email fields
          if (field.type === 'email') {
            var emailInputs = document.querySelectorAll('input[type="email"]');
            if (emailInputs.length === 1) {
              input = emailInputs[0];
              _this2.widget.log(' [Fill Form] Found single email input on page');
            } else if (emailInputs.length > 1) {
              var formElement = document.querySelector("#".concat(targetForm.id)) || document.querySelectorAll('form')[domAnalysis.forms.indexOf(targetForm)];
              if (formElement) {
                input = formElement.querySelector('input[type="email"]');
                if (input) _this2.widget.log(' [Fill Form] Found email input in target form');
              }
            }
          }

          // Strategy 2: By name attribute
          if (!input && field.name && !field.name.startsWith('field-')) {
            input = document.querySelector("input[name=\"".concat(field.name, "\"], select[name=\"").concat(field.name, "\"], textarea[name=\"").concat(field.name, "\"]"));
            if (input) _this2.widget.log(' [Fill Form] Found by name:', field.name);
          }

          // Strategy 3: By id attribute
          if (!input && field.id && !field.id.startsWith('field-')) {
            input = document.querySelector("#".concat(field.id));
            if (input) _this2.widget.log(' [Fill Form] Found by ID:', field.id);
          }

          // Strategy 4: By label text
          if (!input && field.label) {
            var labels = Array.from(document.querySelectorAll('label'));
            var matchingLabel = labels.find(function (l) {
              var _l$textContent, _field$label, _field$label2;
              var labelText = (_l$textContent = l.textContent) === null || _l$textContent === void 0 ? void 0 : _l$textContent.trim().toLowerCase();
              return labelText === ((_field$label = field.label) === null || _field$label === void 0 ? void 0 : _field$label.toLowerCase()) || (labelText === null || labelText === void 0 ? void 0 : labelText.includes((_field$label2 = field.label) === null || _field$label2 === void 0 ? void 0 : _field$label2.toLowerCase()));
            });
            if (matchingLabel) {
              var forAttr = matchingLabel.getAttribute('for');
              if (forAttr) {
                input = document.querySelector("#".concat(forAttr));
                if (input) _this2.widget.log(' [Fill Form] Found by label "for" attribute');
              } else {
                input = matchingLabel.querySelector('input, select, textarea');
                if (input) _this2.widget.log(' [Fill Form] Found as child of label');
              }
            }
          }

          // Strategy 5: By placeholder
          if (!input && field.placeholder) {
            input = document.querySelector("input[placeholder*=\"".concat(field.placeholder, "\"], textarea[placeholder*=\"").concat(field.placeholder, "\"]"));
            if (input) _this2.widget.log(' [Fill Form] Found by placeholder:', field.placeholder);
          }

          // Strategy 6: By index in form
          if (!input && typeof field.index === 'number') {
            var _formElement = document.querySelector("#".concat(targetForm.id)) || document.querySelectorAll('form')[domAnalysis.forms.indexOf(targetForm)];
            if (_formElement) {
              var allInputs = _formElement.querySelectorAll('input:not([type="hidden"]):not([type="submit"]):not([type="button"]), select, textarea');
              input = allInputs[field.index];
              if (input) _this2.widget.log(' [Fill Form] Found by index:', field.index);
            }
          }
          if (input) {
            var _Object$getOwnPropert;
            // Focus the input
            input.focus();

            // Set the value
            input.value = value;

            // Trigger events for React/Vue/Angular
            input.dispatchEvent(new Event('input', {
              bubbles: true
            }));
            input.dispatchEvent(new Event('change', {
              bubbles: true
            }));

            // For React 16+
            var nativeInputValueSetter = (_Object$getOwnPropert = Object.getOwnPropertyDescriptor(window.HTMLInputElement.prototype, "value")) === null || _Object$getOwnPropert === void 0 ? void 0 : _Object$getOwnPropert.set;
            if (nativeInputValueSetter) {
              nativeInputValueSetter.call(input, value);
              input.dispatchEvent(new Event('input', {
                bubbles: true
              }));
            }
            _this2.widget.log("\u2728 [Fill Form] Successfully filled \"".concat(field.label || field.name || field.type, "\" with \"").concat(value, "\""));
            filledCount++;
            filledFields.push(field.label || field.name || field.type);
          } else {
            _this2.widget.log("\u26A0\uFE0F [Fill Form] Input element not found for field:", field);
          }
        } else {
          _this2.widget.log("\u26A0\uFE0F [Fill Form] No matching field found for \"".concat(key, "\""));
        }
      });
      if (filledCount > 0) {
        var fieldNames = filledFields.join(', ');
        this.widget.log("\u2705 [Fill Form] Successfully filled ".concat(filledCount, " field(s): ").concat(fieldNames));
      } else {
        this.widget.log(' [Fill Form] Could not fill any fields');
      }
    }

    /**
     * Click element dynamically (lines 404-546)
     */
  }, {
    key: "clickElementDynamically",
    value: function clickElementDynamically(parameters) {
      var _this3 = this;
      this.widget.log(' [Click] Parameters:', parameters);
      var domAnalysis = this.widget.state.domAnalysis;
      var target = (parameters === null || parameters === void 0 ? void 0 : parameters.target) || (parameters === null || parameters === void 0 ? void 0 : parameters.element) || (parameters === null || parameters === void 0 ? void 0 : parameters.button) || 'submit';
      var targetLower = target.toLowerCase();
      this.widget.log(' [Click] Looking for:', target);
      var element = null;

      // 1. Try to find in form buttons
      if (domAnalysis !== null && domAnalysis !== void 0 && domAnalysis.forms.length) {
        var _iterator2 = _createForOfIteratorHelper(domAnalysis.forms),
          _step2;
        try {
          var _loop = function _loop() {
            var _form$buttons;
            var form = _step2.value;
            _this3.widget.log("\uD83D\uDD0D [Click] Checking form ".concat(form.id, " buttons:"), form.buttons);
            var button = (_form$buttons = form.buttons) === null || _form$buttons === void 0 ? void 0 : _form$buttons.find(function (b) {
              var _b$text, _b$type, _b$id, _b$name, _b$text2, _b$id2, _b$name2;
              return ((_b$text = b.text) === null || _b$text === void 0 ? void 0 : _b$text.toLowerCase().includes(targetLower)) || ((_b$type = b.type) === null || _b$type === void 0 ? void 0 : _b$type.toLowerCase().includes(targetLower)) || ((_b$id = b.id) === null || _b$id === void 0 ? void 0 : _b$id.toLowerCase().includes(targetLower)) || ((_b$name = b.name) === null || _b$name === void 0 ? void 0 : _b$name.toLowerCase().includes(targetLower)) || targetLower.includes('submit') && b.type === 'submit' || targetLower.includes('subscribe') && (((_b$text2 = b.text) === null || _b$text2 === void 0 ? void 0 : _b$text2.toLowerCase().includes('subscribe')) || ((_b$id2 = b.id) === null || _b$id2 === void 0 ? void 0 : _b$id2.toLowerCase().includes('subscribe')) || ((_b$name2 = b.name) === null || _b$name2 === void 0 ? void 0 : _b$name2.toLowerCase().includes('subscribe')));
            });
            if (button) {
              _this3.widget.log(' [Click] Found button in form:', button);

              // Try multiple selectors
              if (button.id && !button.id.startsWith('button-')) {
                element = document.querySelector("#".concat(button.id));
                if (element) _this3.widget.log(' [Click] Found by ID:', button.id);
              }
              if (!element && button.name) {
                element = document.querySelector("button[name=\"".concat(button.name, "\"], input[name=\"").concat(button.name, "\"]"));
                if (element) _this3.widget.log(' [Click] Found by name:', button.name);
              }
              if (!element && button.text) {
                var buttons = Array.from(document.querySelectorAll('button, input[type="submit"], input[type="button"]'));
                element = buttons.find(function (btn) {
                  var _btn$textContent, _btn$value;
                  return ((_btn$textContent = btn.textContent) === null || _btn$textContent === void 0 ? void 0 : _btn$textContent.trim().toLowerCase()) === button.text.toLowerCase() || ((_btn$value = btn.value) === null || _btn$value === void 0 ? void 0 : _btn$value.toLowerCase()) === button.text.toLowerCase();
                });
                if (element) _this3.widget.log(' [Click] Found by text:', button.text);
              }
              if (!element) {
                var formIndex = domAnalysis.forms.indexOf(form);
                var formElement = document.querySelectorAll('form')[formIndex];
                if (formElement) {
                  element = formElement.querySelector('button[type="submit"], input[type="submit"], button:not([type="button"])');
                  if (element) _this3.widget.log(' [Click] Found submit button in form');
                }
              }
              if (element) return 1; // break
            }
          };
          for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {
            if (_loop()) break;
          }
        } catch (err) {
          _iterator2.e(err);
        } finally {
          _iterator2.f();
        }
      }

      // 2. Try to find in interactions
      if (!element && domAnalysis !== null && domAnalysis !== void 0 && domAnalysis.interactions.length) {
        this.widget.log(' [Click] Checking interactions:', domAnalysis.interactions.length);
        var interaction = domAnalysis.interactions.find(function (i) {
          var _i$text, _i$ariaLabel, _i$text2, _i$ariaLabel2;
          return ((_i$text = i.text) === null || _i$text === void 0 ? void 0 : _i$text.toLowerCase().includes(targetLower)) || ((_i$ariaLabel = i.ariaLabel) === null || _i$ariaLabel === void 0 ? void 0 : _i$ariaLabel.toLowerCase().includes(targetLower)) || targetLower.includes('subscribe') && (((_i$text2 = i.text) === null || _i$text2 === void 0 ? void 0 : _i$text2.toLowerCase().includes('subscribe')) || ((_i$ariaLabel2 = i.ariaLabel) === null || _i$ariaLabel2 === void 0 ? void 0 : _i$ariaLabel2.toLowerCase().includes('subscribe')));
        });
        if (interaction) {
          this.widget.log(' [Click] Found interaction:', interaction);
          if (interaction.id) {
            element = document.querySelector("#".concat(interaction.id));
          }
          if (!element && interaction.text) {
            var elements = Array.from(document.querySelectorAll('button, input[type="submit"], input[type="button"], a'));
            element = elements.find(function (el) {
              var _el$textContent;
              return ((_el$textContent = el.textContent) === null || _el$textContent === void 0 ? void 0 : _el$textContent.trim().toLowerCase()) === interaction.text.toLowerCase();
            });
          }
        }
      }

      // 3. Fallback: search by text content in DOM
      if (!element) {
        this.widget.log(' [Click] Fallback: searching by text content in DOM');
        var clickables = Array.from(document.querySelectorAll('button, input[type="submit"], input[type="button"], a[role="button"], [role="button"]'));

        // First try exact match
        element = clickables.find(function (btn) {
          var _btn$textContent2, _btn$value2;
          var text = ((_btn$textContent2 = btn.textContent) === null || _btn$textContent2 === void 0 ? void 0 : _btn$textContent2.trim().toLowerCase()) || ((_btn$value2 = btn.value) === null || _btn$value2 === void 0 ? void 0 : _btn$value2.toLowerCase()) || '';
          return text === targetLower;
        });

        // Then try contains match
        if (!element) {
          element = clickables.find(function (btn) {
            var _btn$textContent3, _btn$value3, _btn$getAttribute;
            var text = ((_btn$textContent3 = btn.textContent) === null || _btn$textContent3 === void 0 ? void 0 : _btn$textContent3.trim().toLowerCase()) || ((_btn$value3 = btn.value) === null || _btn$value3 === void 0 ? void 0 : _btn$value3.toLowerCase()) || '';
            var ariaLabel = ((_btn$getAttribute = btn.getAttribute('aria-label')) === null || _btn$getAttribute === void 0 ? void 0 : _btn$getAttribute.toLowerCase()) || '';
            return text.includes(targetLower) || ariaLabel.includes(targetLower) || targetLower.includes('subscribe') && (text.includes('subscribe') || ariaLabel.includes('subscribe')) || targetLower.includes('submit') && btn.getAttribute('type') === 'submit';
          });
        }
        if (element) {
          this.widget.log(' [Click] Found by DOM search:', element);
        }
      }

      // Click the element
      if (element) {
        this.widget.log(' [Click] Clicking element:', element);

        // Scroll into view
        element.scrollIntoView({
          behavior: 'smooth',
          block: 'center'
        });

        // Small delay then click
        setTimeout(function () {
          element.click();
          _this3.widget.log(' [Click] Element clicked successfully');
        }, 100);
      } else {
        this.widget.log(' [Click] Element not found for:', target);
      }
    }

    /**
     * Navigate dynamically (lines 548-772)
     */
  }, {
    key: "navigateDynamically",
    value: function navigateDynamically(parameters) {
      var _domAnalysis$navigati;
      this.widget.log(' [Navigate] Parameters:', parameters);
      var _this$widget$state = this.widget.state,
        domAnalysis = _this$widget$state.domAnalysis,
        navigationMap = _this$widget$state.navigationMap;
      var destination = (parameters === null || parameters === void 0 ? void 0 : parameters.destination) || (parameters === null || parameters === void 0 ? void 0 : parameters.target) || (parameters === null || parameters === void 0 ? void 0 : parameters.page) || '';
      var destLower = destination.toLowerCase();
      this.widget.log(' [Navigate] Looking for:', destination);
      if (!destination) {
        this.widget.log(' [Navigate] No destination specified');
        return;
      }
      var link = null;
      var targetPath = null;

      // STEP 0: Try NavigationMap first (Sitemap-based routing)
      if (navigationMap) {
        this.widget.log(' [Navigate] Checking navigation map...');
        var route = navigationMap.findRoute(destLower);
        if (route) {
          targetPath = route.path;
          this.widget.log(' [Navigate] Found in navigation map:', {
            path: route.path,
            matchedKeywords: route.keywords.filter(function (k) {
              return k.includes(destLower) || destLower.includes(k);
            })
          });
        } else {
          this.widget.log(' [Navigate] No match in navigation map');
        }
      }

      // STEP 1: Try DOM analysis navigation items
      if (!targetPath && domAnalysis !== null && domAnalysis !== void 0 && (_domAnalysis$navigati = domAnalysis.navigation) !== null && _domAnalysis$navigati !== void 0 && _domAnalysis$navigati.length) {
        this.widget.log(' [Navigate] Checking navigation items:', domAnalysis.navigation.length);
        var navItem = domAnalysis.navigation.find(function (n) {
          var _n$text, _n$ariaLabel, _n$href;
          var textLower = ((_n$text = n.text) === null || _n$text === void 0 ? void 0 : _n$text.toLowerCase()) || '';
          var ariaLabelLower = ((_n$ariaLabel = n.ariaLabel) === null || _n$ariaLabel === void 0 ? void 0 : _n$ariaLabel.toLowerCase()) || '';
          var hrefLower = ((_n$href = n.href) === null || _n$href === void 0 ? void 0 : _n$href.toLowerCase()) || '';
          if (!textLower && !ariaLabelLower && !hrefLower) {
            return false;
          }

          // Check text content
          if (textLower && (textLower.includes(destLower) || destLower.includes(textLower) || destLower.includes('about') && textLower.includes('about') || destLower.includes('contact') && textLower.includes('contact') || destLower.includes('product') && textLower.includes('product') || destLower.includes('pricing') && textLower.includes('pricing') || destLower.includes('home') && (textLower === 'home' || textLower === 'liaplus'))) {
            return true;
          }

          // Check aria-label
          if (ariaLabelLower && (ariaLabelLower.includes(destLower) || destLower.includes(ariaLabelLower) || destLower.includes('about') && ariaLabelLower.includes('about') || destLower.includes('contact') && ariaLabelLower.includes('contact') || destLower.includes('product') && ariaLabelLower.includes('product') || destLower.includes('pricing') && ariaLabelLower.includes('pricing'))) {
            return true;
          }

          // Check href
          if (hrefLower && (hrefLower.includes(destLower.replace(/\s+/g, '-')) || hrefLower.includes(destLower.replace(/\s+/g, '')))) {
            return true;
          }
          return false;
        });
        if (navItem) {
          this.widget.log(' [Navigate] Found navigation item:', navItem);

          // Try to find the actual link element
          if (navItem.href) {
            link = document.querySelector("a[href=\"".concat(navItem.href, "\"]"));
            if (!link) {
              var links = Array.from(document.querySelectorAll('a'));
              link = links.find(function (a) {
                return a.href.includes(navItem.href);
              });
            }
          }
          if (!link && navItem.text) {
            var _links = Array.from(document.querySelectorAll('a'));
            link = _links.find(function (a) {
              var _a$textContent;
              return ((_a$textContent = a.textContent) === null || _a$textContent === void 0 ? void 0 : _a$textContent.trim().toLowerCase()) === navItem.text.toLowerCase();
            });
          }
          if (!link && navItem.ariaLabel) {
            var _links2 = Array.from(document.querySelectorAll('a'));
            link = _links2.find(function (a) {
              var _a$getAttribute;
              return ((_a$getAttribute = a.getAttribute('aria-label')) === null || _a$getAttribute === void 0 ? void 0 : _a$getAttribute.toLowerCase()) === navItem.ariaLabel.toLowerCase();
            });
          }
        }
      }

      // 2. Fallback: Search all links
      if (!targetPath && !link) {
        this.widget.log(' [Navigate] Fallback: searching all links');
        var allLinks = Array.from(document.querySelectorAll('a[href]'));

        // First try exact text match
        link = allLinks.find(function (a) {
          var _a$textContent2, _a$getAttribute2;
          var text = ((_a$textContent2 = a.textContent) === null || _a$textContent2 === void 0 ? void 0 : _a$textContent2.trim().toLowerCase()) || '';
          var ariaLabel = ((_a$getAttribute2 = a.getAttribute('aria-label')) === null || _a$getAttribute2 === void 0 ? void 0 : _a$getAttribute2.toLowerCase()) || '';
          return text === destLower || ariaLabel === destLower;
        }) || null;

        // Then try scoring
        if (!link) {
          var _scoredLinks$;
          var scoredLinks = allLinks.map(function (a) {
            var _a$textContent3, _a$getAttribute3;
            var text = ((_a$textContent3 = a.textContent) === null || _a$textContent3 === void 0 ? void 0 : _a$textContent3.trim().toLowerCase()) || '';
            var ariaLabel = ((_a$getAttribute3 = a.getAttribute('aria-label')) === null || _a$getAttribute3 === void 0 ? void 0 : _a$getAttribute3.toLowerCase()) || '';
            var href = a.href.toLowerCase();
            var score = 0;
            if (text === destLower || ariaLabel === destLower) score += 100;
            if (text.includes(destLower)) score += 50;
            if (destLower.includes(text) && text.length > 2) score += 30;
            if (ariaLabel.includes(destLower)) score += 40;
            if (destLower.includes(ariaLabel) && ariaLabel.length > 2) score += 25;
            var urlPath = new URL(a.href, window.location.origin).pathname.toLowerCase();
            var destSlug = destLower.replace(/\s+/g, '-');
            if (urlPath.includes(destSlug)) score += 35;
            if (urlPath.includes(destLower.replace(/\s+/g, ''))) score += 30;

            // Specific page matches
            if (destLower.includes('about') && (text.includes('about') || ariaLabel.includes('about') || href.includes('about'))) score += 60;
            if (destLower.includes('contact') && (text.includes('contact') || ariaLabel.includes('contact') || href.includes('contact'))) score += 60;
            if (destLower.includes('product') && (text.includes('product') || ariaLabel.includes('product') || href.includes('product'))) score += 60;
            if (destLower.includes('pricing') && (text.includes('pricing') || ariaLabel.includes('pricing') || href.includes('pricing'))) score += 60;
            if (destLower.includes('home') && (href === '/' || href.endsWith('/') || text === 'home' || ariaLabel === 'home')) score += 60;
            if (!text && !ariaLabel) score -= 50;
            return {
              link: a,
              score: score
            };
          });
          scoredLinks.sort(function (a, b) {
            return b.score - a.score;
          });
          if (((_scoredLinks$ = scoredLinks[0]) === null || _scoredLinks$ === void 0 ? void 0 : _scoredLinks$.score) > 20) {
            var _link$textContent;
            link = scoredLinks[0].link;
            this.widget.log(' [Navigate] Best match found:', {
              text: (_link$textContent = link.textContent) === null || _link$textContent === void 0 ? void 0 : _link$textContent.trim(),
              ariaLabel: link.getAttribute('aria-label'),
              href: link.href,
              score: scoredLinks[0].score
            });
          }
        }
      }

      // Navigate
      if (targetPath) {
        this.widget.log(' [Navigate] Navigating to path:', targetPath);
        window.location.href = targetPath;
        this.widget.log(' [Navigate] Navigation initiated');
      } else if (link) {
        this.widget.log(' [Navigate] Navigating to:', link.href);
        var isExternal = link.hostname !== window.location.hostname;
        if (isExternal) {
          window.open(link.href, '_blank');
        } else {
          window.location.href = link.href;
        }
        this.widget.log(' [Navigate] Navigation initiated');
      } else {
        this.widget.log(' [Navigate] Link not found for:', destination);
      }
    }
  }]);
}();

/***/ },

/***/ "./src/Icons.js"
/*!**********************!*\
  !*** ./src/Icons.js ***!
  \**********************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   Icons: () => (/* binding */ Icons)
/* harmony export */ });
/**
 * Icons - SVG icons matching Lucide React icons
 * All icons from the React component
 */

var Icons = {
  accessibility: function accessibility() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <circle cx=\"16\" cy=\"4\" r=\"1\"/>\n      <path d=\"m18 19 1-7-6 1\"/>\n      <path d=\"m5 8 3-3 5.5 3-2.36 3.5\"/>\n      <path d=\"M4.24 14.5a5 5 0 0 0 6.88 6\"/>\n      <path d=\"M13.76 17.5a5 5 0 0 0-6.88-6\"/>\n    </svg>\n  ");
  },
  sparkles: function sparkles() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <path d=\"m12 3-1.912 5.813a2 2 0 0 1-1.275 1.275L3 12l5.813 1.912a2 2 0 0 1 1.275 1.275L12 21l1.912-5.813a2 2 0 0 1 1.275-1.275L21 12l-5.813-1.912a2 2 0 0 1-1.275-1.275L12 3Z\"/>\n      <path d=\"M5 3v4\"/>\n      <path d=\"M19 17v4\"/>\n      <path d=\"M3 5h4\"/>\n      <path d=\"M17 19h4\"/>\n    </svg>\n  ");
  },
  list: function list() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <line x1=\"8\" x2=\"21\" y1=\"6\" y2=\"6\"/>\n      <line x1=\"8\" x2=\"21\" y1=\"12\" y2=\"12\"/>\n      <line x1=\"8\" x2=\"21\" y1=\"18\" y2=\"18\"/>\n      <line x1=\"3\" x2=\"3.01\" y1=\"6\" y2=\"6\"/>\n      <line x1=\"3\" x2=\"3.01\" y1=\"12\" y2=\"12\"/>\n      <line x1=\"3\" x2=\"3.01\" y1=\"18\" y2=\"18\"/>\n    </svg>\n  ");
  },
  settings: function settings() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <path d=\"M12.22 2h-.44a2 2 0 0 0-2 2v.18a2 2 0 0 1-1 1.73l-.43.25a2 2 0 0 1-2 0l-.15-.08a2 2 0 0 0-2.73.73l-.22.38a2 2 0 0 0 .73 2.73l.15.1a2 2 0 0 1 1 1.72v.51a2 2 0 0 1-1 1.74l-.15.09a2 2 0 0 0-.73 2.73l.22.38a2 2 0 0 0 2.73.73l.15-.08a2 2 0 0 1 2 0l.43.25a2 2 0 0 1 1 1.73V20a2 2 0 0 0 2 2h.44a2 2 0 0 0 2-2v-.18a2 2 0 0 1 1-1.73l.43-.25a2 2 0 0 1 2 0l.15.08a2 2 0 0 0 2.73-.73l.22-.39a2 2 0 0 0-.73-2.73l-.15-.08a2 2 0 0 1-1-1.74v-.5a2 2 0 0 1 1-1.74l.15-.09a2 2 0 0 0 .73-2.73l-.22-.38a2 2 0 0 0-2.73-.73l-.15.08a2 2 0 0 1-2 0l-.43-.25a2 2 0 0 1-1-1.73V4a2 2 0 0 0-2-2z\"/>\n      <circle cx=\"12\" cy=\"12\" r=\"3\"/>\n    </svg>\n  ");
  },
  volume2: function volume2() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <polygon points=\"11 5 6 9 2 9 2 15 6 15 11 19 11 5\"/>\n      <path d=\"M15.54 8.46a5 5 0 0 1 0 7.07\"/>\n      <path d=\"M19.07 4.93a10 10 0 0 1 0 14.14\"/>\n    </svg>\n  ");
  },
  volumeX: function volumeX() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <polygon points=\"11 5 6 9 2 9 2 15 6 15 11 19 11 5\"/>\n      <line x1=\"22\" x2=\"16\" y1=\"9\" y2=\"15\"/>\n      <line x1=\"16\" x2=\"22\" y1=\"9\" y2=\"15\"/>\n    </svg>\n  ");
  },
  languages: function languages() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <path d=\"m5 8 6 6\"/>\n      <path d=\"m4 14 6-6 2-3\"/>\n      <path d=\"M2 5h12\"/>\n      <path d=\"M7 2h1\"/>\n      <path d=\"m22 22-5-10-5 10\"/>\n      <path d=\"M14 18h6\"/>\n    </svg>\n  ");
  },
  check: function check() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <polyline points=\"20 6 9 17 4 12\"/>\n    </svg>\n  ");
  },
  activity: function activity() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <path d=\"M22 12h-4l-3 9L9 3l-3 9H2\"/>\n    </svg>\n  ");
  },
  x: function x() {
    var className = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';
    return "\n    <svg class=\"".concat(className, "\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n      <path d=\"M18 6 6 18\"/>\n      <path d=\"m6 6 12 12\"/>\n    </svg>\n  ");
  }
};

/***/ },

/***/ "./src/UIComponents.js"
/*!*****************************!*\
  !*** ./src/UIComponents.js ***!
  \*****************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   UIComponents: () => (/* binding */ UIComponents)
/* harmony export */ });
/* harmony import */ var _Icons_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Icons.js */ "./src/Icons.js");
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * UI Components - DOM creation matching voice-navigation-advanced.tsx exactly
 * Lines 1027-1308 from React component
 */


var UIComponents = /*#__PURE__*/function () {
  function UIComponents(widget) {
    _classCallCheck(this, UIComponents);
    this.widget = widget;
  }

  /**
   * Create main widget container
   */
  return _createClass(UIComponents, [{
    key: "createContainer",
    value: function createContainer() {
      var container = document.createElement('div');
      container.id = 'liaplus-voice-widget';
      container.className = 'liaplus-voice-widget-root';
      return container;
    }

    /**
     * Create floating button (lines 1030-1060)
     */
  }, {
    key: "createFloatingButton",
    value: function createFloatingButton() {
      var _this = this;
      var _this$widget$state = this.widget.state,
        isListening = _this$widget$state.isListening,
        isProcessing = _this$widget$state.isProcessing;
      var buttonWrapper = document.createElement('div');
      buttonWrapper.className = 'fixed bottom-4 left-4 sm:bottom-auto sm:left-auto sm:top-6 sm:right-6 z-50';
      var relativeContainer = document.createElement('div');
      relativeContainer.className = 'relative';

      // Main button
      var button = document.createElement('button');
      button.className = "relative h-12 w-12 sm:h-10 sm:w-10 rounded-full transition-all duration-200 shadow-lg sm:shadow-none bg-background border ".concat(isListening ? 'bg-purple-100 dark:bg-purple-900 text-purple-600 dark:text-purple-400 hover:bg-purple-200 dark:hover:bg-purple-800 border-purple-300 dark:border-purple-700' : 'hover:bg-muted border-border');
      button.setAttribute('aria-label', isListening ? 'Stop voice navigation' : 'Start voice navigation');
      button.setAttribute('title', isListening ? 'Voice navigation active - Ask me anything!' : 'Click to enable voice navigation');
      button.onclick = function () {
        return _this.widget.toggleListening();
      };

      // Icon
      var iconContainer = document.createElement('span');
      iconContainer.className = 'flex items-center justify-center';
      if (isListening) {
        iconContainer.innerHTML = _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.accessibility('h-5 w-5 sm:h-4 sm:w-4 animate-pulse');

        // Processing indicator
        if (isProcessing) {
          var sparkle = document.createElement('span');
          sparkle.className = 'absolute -top-0.5 -right-0.5';
          sparkle.innerHTML = _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.sparkles('h-4 w-4 sm:h-3 sm:w-3 animate-spin');
          button.appendChild(sparkle);
        }

        // Ping animation
        var pingOuter = document.createElement('span');
        pingOuter.className = 'absolute -top-0.5 -right-0.5 flex h-3 w-3 sm:h-2 sm:w-2';
        pingOuter.innerHTML = "\n        <span class=\"animate-ping absolute inline-flex h-full w-full rounded-full bg-purple-400 opacity-75\"></span>\n        <span class=\"relative inline-flex rounded-full h-3 w-3 sm:h-2 sm:w-2 bg-purple-500\"></span>\n      ";
        button.appendChild(pingOuter);
      } else {
        iconContainer.innerHTML = _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.accessibility('h-5 w-5 sm:h-4 sm:w-4');
      }
      button.appendChild(iconContainer);
      relativeContainer.appendChild(button);

      // Secondary buttons (lines 1063-1082)
      if (isListening) {
        var commandsButton = this.createSecondaryButton('list', 'Hide examples', 'absolute bottom-0 -right-14 sm:right-auto sm:bottom-auto sm:top-0 sm:-left-12', function () {
          return _this.widget.setState({
            showCommands: !_this.widget.state.showCommands
          });
        });
        relativeContainer.appendChild(commandsButton);
        var settingsButton = this.createSecondaryButton('settings', 'Voice settings', 'absolute bottom-0 -right-28 sm:right-auto sm:bottom-auto sm:top-0 sm:-left-24', function () {
          return _this.widget.setState({
            showSettings: !_this.widget.state.showSettings
          });
        });
        relativeContainer.appendChild(settingsButton);
      }
      buttonWrapper.appendChild(relativeContainer);
      return buttonWrapper;
    }

    /**
     * Create secondary button
     */
  }, {
    key: "createSecondaryButton",
    value: function createSecondaryButton(icon, title, className, onclick) {
      var button = document.createElement('button');
      button.className = "".concat(className, " h-10 w-10 sm:h-8 sm:w-8 rounded-full hover:bg-muted shadow-lg sm:shadow-none bg-background border border-border");
      button.setAttribute('title', title);
      button.onclick = onclick;
      var iconHtml = icon === 'list' ? _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.list('h-5 w-5 sm:h-4 sm:w-4') : _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.settings('h-5 w-5 sm:h-4 sm:w-4');
      button.innerHTML = iconHtml;
      return button;
    }

    /**
     * Create transcript overlay (lines 1086-1107)
     */
  }, {
    key: "createTranscriptOverlay",
    value: function createTranscriptOverlay() {
      var _this$widget$state2 = this.widget.state,
        isListening = _this$widget$state2.isListening,
        transcript = _this$widget$state2.transcript,
        isProcessing = _this$widget$state2.isProcessing;
      if (!isListening || !transcript) return null;
      var overlay = document.createElement('div');
      overlay.className = 'absolute bottom-full mb-2 sm:top-full sm:bottom-auto sm:mt-2 sm:mb-0 right-0 left-0 sm:left-auto bg-gradient-to-r from-purple-100 to-pink-100 dark:from-purple-900 dark:to-pink-900 backdrop-blur-md border border-purple-200 dark:border-purple-700 rounded-lg px-3 py-2 sm:px-4 sm:py-3 shadow-xl min-w-[200px] sm:min-w-[280px] max-w-[calc(100vw-2rem)] sm:max-w-[400px] z-50 animate-in slide-in-from-bottom sm:slide-in-from-top-2';
      overlay.innerHTML = "\n      <div class=\"flex items-start justify-between gap-2\">\n        <div class=\"flex-1 min-w-0\">\n          <div class=\"flex items-center gap-2 mb-1\">\n            <div class=\"flex items-center gap-1\">\n              <div class=\"h-1.5 w-1.5 sm:h-2 sm:w-2 rounded-full bg-purple-500 animate-pulse\"></div>\n              <div class=\"h-1.5 w-1.5 sm:h-2 sm:w-2 rounded-full bg-purple-400 animate-pulse delay-75\"></div>\n              <div class=\"h-1.5 w-1.5 sm:h-2 sm:w-2 rounded-full bg-purple-300 animate-pulse delay-150\"></div>\n            </div>\n            <p class=\"text-[10px] sm:text-xs font-medium text-purple-900 dark:text-purple-200\">\n              ".concat(this.widget.state.language === 'hi-IN' ? '  ...' : 'Listening...', "\n            </p>\n          </div>\n          <p class=\"text-xs sm:text-sm font-semibold text-gray-900 dark:text-gray-100 truncate sm:whitespace-normal\">").concat(transcript, "</p>\n        </div>\n        ").concat(isProcessing ? "<span class=\"flex-shrink-0\">".concat(_Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.sparkles('h-3 w-3 sm:h-4 sm:w-4 text-purple-600 dark:text-purple-400 animate-spin'), "</span>") : '', "\n      </div>\n    ");
      return overlay;
    }

    /**
     * Create settings panel (lines 1110-1251)
     */
  }, {
    key: "createSettingsPanel",
    value: function createSettingsPanel() {
      var _this$widget$state3 = this.widget.state,
        showSettings = _this$widget$state3.showSettings,
        language = _this$widget$state3.language,
        voiceEnabled = _this$widget$state3.voiceEnabled,
        domAnalysis = _this$widget$state3.domAnalysis,
        useDynamicMode = _this$widget$state3.useDynamicMode,
        commandHistory = _this$widget$state3.commandHistory;
      if (!showSettings) return null;
      var panel = document.createElement('div');
      panel.className = 'absolute bottom-full mb-2 sm:top-full sm:bottom-auto sm:mt-2 sm:mb-0 right-0 left-0 sm:left-auto bg-background/95 backdrop-blur-sm border rounded-lg shadow-xl min-w-[250px] sm:min-w-[280px] max-w-[calc(100vw-2rem)] sm:max-w-[320px] z-50 animate-in slide-in-from-bottom sm:slide-in-from-top-2';
      var isHindi = language === 'hi-IN';
      panel.innerHTML = "\n      <div class=\"p-3 sm:p-4\">\n        <div class=\"flex items-center justify-between mb-3 sm:mb-4\">\n          <h3 class=\"font-semibold text-xs sm:text-sm\">\n            ".concat(isHindi ? ' ' : 'Voice Settings', "\n          </h3>\n          <button class=\"liaplus-close-settings h-7 w-7 sm:h-6 sm:w-6 hover:bg-muted rounded\">\n            ").concat(_Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.x('h-4 w-4'), "\n          </button>\n        </div>\n        \n        <div class=\"space-y-3\">\n          <!-- Language Selector -->\n          <div class=\"flex items-center justify-between\">\n            <label class=\"text-xs sm:text-sm text-muted-foreground\">\n              ").concat(isHindi ? '' : 'Language', "\n            </label>\n            <div class=\"relative\">\n              <button class=\"liaplus-lang-toggle h-7 sm:h-8 text-xs border rounded px-2 flex items-center gap-1 hover:bg-muted\">\n                ").concat(_Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.languages('h-3 w-3'), "\n                ").concat(isHindi ? '' : 'English', "\n              </button>\n              <div class=\"liaplus-lang-dropdown hidden absolute right-0 top-full mt-2 bg-background border rounded-lg shadow-lg z-50 min-w-[120px]\">\n                <button class=\"liaplus-lang-en w-full text-left px-3 py-2 hover:bg-muted transition-colors flex items-center gap-2 text-xs\">\n                  \uD83C\uDDFA\uD83C\uDDF8 English\n                  ").concat(language === 'en-US' ? _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.check('w-3 h-3 ml-auto') : '', "\n                </button>\n                <button class=\"liaplus-lang-hi w-full text-left px-3 py-2 hover:bg-muted transition-colors flex items-center gap-2 text-xs\">\n                  \uD83C\uDDEE\uD83C\uDDF3 \u0939\u093F\u0902\u0926\u0940\n                  ").concat(language === 'hi-IN' ? _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.check('w-3 h-3 ml-auto') : '', "\n                </button>\n              </div>\n            </div>\n          </div>\n          \n          <!-- Voice Feedback Toggle -->\n          <div class=\"flex items-center justify-between\">\n            <label class=\"text-xs sm:text-sm text-muted-foreground\">\n              ").concat(isHindi ? ' ' : 'Voice Feedback', "\n            </label>\n            <button class=\"liaplus-voice-toggle h-7 sm:h-8 border rounded px-2 hover:bg-muted\">\n              ").concat(voiceEnabled ? _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.volume2('h-3 w-3 sm:h-4 sm:w-4') : _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.volumeX('h-3 w-3 sm:h-4 sm:w-4'), "\n            </button>\n          </div>\n          \n          <!-- AI Mode Indicator -->\n          <div class=\"flex items-center justify-between\">\n            <div>\n              <label class=\"text-xs sm:text-sm text-muted-foreground\">\n                ").concat(isHindi ? 'AI ' : 'AI Mode', "\n              </label>\n              <p class=\"text-[10px] sm:text-xs text-muted-foreground/70\">\n                ").concat(isHindi ? '   ' : 'Understands everything', "\n              </p>\n            </div>\n            <div class=\"flex items-center gap-1\">\n              ").concat(_Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.sparkles('h-3 w-3 text-purple-600'), "\n              <span class=\"text-xs font-semibold text-purple-600\">\n                ").concat(isHindi ? '' : 'ON', "\n              </span>\n            </div>\n          </div>\n          \n          <!-- Dynamic Mode -->\n          ").concat(useDynamicMode ? "\n          <div class=\"flex items-center justify-between\">\n            <div>\n              <label class=\"text-xs sm:text-sm text-muted-foreground\">\n                ".concat(isHindi ? ' ' : 'Dynamic Mode', "\n              </label>\n              <p class=\"text-[10px] sm:text-xs text-muted-foreground/70\">\n                ").concat(domAnalysis ? "".concat(domAnalysis.forms.length, " forms, ").concat(domAnalysis.navigation.length, " nav") : 'Not analyzed yet', "\n              </p>\n            </div>\n            <button class=\"liaplus-analyze-page h-7 sm:h-8 text-xs border rounded px-2 hover:bg-muted\">\n              ").concat(domAnalysis ? _Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.activity('h-3 w-3 text-green-600 mr-1') : '', "\n              ").concat(isHindi ? '' : 'Scan', "\n            </button>\n          </div>\n          ") : '', "\n        </div>\n        \n        <!-- Command History -->\n        ").concat(commandHistory.length > 0 ? "\n        <div class=\"mt-3 sm:mt-4 pt-3 sm:pt-4 border-t\">\n          <h4 class=\"text-[10px] sm:text-xs font-semibold text-muted-foreground mb-2\">\n            ".concat(isHindi ? '  ' : 'Recent', "\n          </h4>\n          <div class=\"space-y-2 max-h-[120px] sm:max-h-[150px] overflow-y-auto\">\n            ").concat(commandHistory.slice(0, 3).map(function (cmd) {
        return "\n              <div class=\"text-xs p-2 bg-muted/50 rounded\">\n                <p class=\"font-medium truncate text-[10px] sm:text-xs\">".concat(cmd.command, "</p>\n                <p class=\"text-muted-foreground text-[9px] sm:text-[10px]\">").concat(cmd.action, "</p>\n              </div>\n            ");
      }).join(''), "\n          </div>\n        </div>\n        ") : '', "\n      </div>\n    ");

      // Attach event listeners
      this.attachSettingsPanelListeners(panel);
      return panel;
    }

    /**
     * Attach event listeners to settings panel
     */
  }, {
    key: "attachSettingsPanelListeners",
    value: function attachSettingsPanelListeners(panel) {
      var _this2 = this;
      // Close button
      panel.querySelector('.liaplus-close-settings').onclick = function () {
        _this2.widget.setState({
          showSettings: false
        });
      };

      // Language toggle
      var langToggle = panel.querySelector('.liaplus-lang-toggle');
      var langDropdown = panel.querySelector('.liaplus-lang-dropdown');
      langToggle.onclick = function (e) {
        e.stopPropagation();
        langDropdown.classList.toggle('hidden');
      };

      // Language options
      panel.querySelector('.liaplus-lang-en').onclick = function () {
        _this2.widget.setState({
          language: 'en-US'
        });
        _this2.widget.reinitializeRecognition();
      };
      panel.querySelector('.liaplus-lang-hi').onclick = function () {
        _this2.widget.setState({
          language: 'hi-IN'
        });
        _this2.widget.reinitializeRecognition();
      };

      // Voice toggle
      panel.querySelector('.liaplus-voice-toggle').onclick = function () {
        _this2.widget.setState({
          voiceEnabled: !_this2.widget.state.voiceEnabled
        });
      };

      // Analyze page
      var analyzeBtn = panel.querySelector('.liaplus-analyze-page');
      if (analyzeBtn) {
        analyzeBtn.onclick = function () {
          return _this2.widget.analyzePage();
        };
      }
    }

    /**
     * Create commands overlay (lines 1256-1304)
     */
  }, {
    key: "createCommandsOverlay",
    value: function createCommandsOverlay() {
      var _this3 = this;
      var _this$widget$state4 = this.widget.state,
        isListening = _this$widget$state4.isListening,
        showCommands = _this$widget$state4.showCommands,
        language = _this$widget$state4.language;
      if (!isListening || !showCommands) return null;
      var isHindi = language === 'hi-IN';
      var exampleCommands = isHindi ? ['"   "', '"  "', '" "', '"LiaPlus    "', '"  ?"', '"    "'] : ['"Go to home page"', '"Scroll down"', '"Show products"', '"Tell me about LiaPlus"', '"What is the pricing?"', '"Tell me about the chatbot"'];
      var overlay = document.createElement('div');
      overlay.className = 'fixed left-4 right-4 bottom-20 sm:inset-auto sm:top-20 sm:right-6 lg:right-20 w-auto sm:w-[320px] lg:w-[360px] max-h-[50vh] sm:max-h-[calc(100vh-120px)] bg-background/95 backdrop-blur-md border shadow-2xl rounded-xl z-40 animate-in slide-in-from-bottom sm:slide-in-from-left duration-300 flex flex-col overflow-hidden';
      overlay.innerHTML = "\n      <div class=\"flex items-center justify-between p-2.5 sm:p-3 border-b bg-gradient-to-r from-purple-50 to-pink-50 dark:from-purple-900/20 dark:to-pink-900/20 flex-shrink-0\">\n        <div class=\"flex items-center gap-2\">\n          ".concat(_Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.sparkles('h-3.5 w-3.5 sm:h-4 sm:w-4 text-purple-600 dark:text-purple-400 animate-pulse'), "\n          <div>\n            <h2 class=\"font-bold text-xs sm:text-sm\">\n              ").concat(isHindi ? '   ' : 'Ask Me Anything', "\n            </h2>\n            <p class=\"text-[9px] sm:text-[10px] text-muted-foreground\">\n              ").concat(isHindi ? 'AI-powered ' : 'AI-powered assistant', "\n            </p>\n          </div>\n        </div>\n        <button class=\"liaplus-close-commands h-6 w-6 sm:h-7 sm:w-7 hover:bg-muted rounded\" title=\"Hide\">\n          ").concat(_Icons_js__WEBPACK_IMPORTED_MODULE_0__.Icons.x('h-3 w-3'), "\n        </button>\n      </div>\n      \n      <div class=\"flex-1 overflow-y-auto overscroll-contain p-2.5 sm:p-3 space-y-2\">\n        <p class=\"text-[10px] sm:text-xs text-muted-foreground mb-3\">\n          ").concat(isHindi ? '   ,   ! :' : ' Just speak naturally, I understand! Examples:', "\n        </p>\n        ").concat(exampleCommands.map(function (cmd) {
        return "\n          <div class=\"text-[11px] sm:text-xs py-2 sm:py-1.5 px-2.5 sm:px-2 rounded bg-gradient-to-r from-purple-50 to-pink-50 dark:from-purple-900/20 dark:to-pink-900/20 border border-purple-200 dark:border-purple-800 text-purple-700 dark:text-purple-300 font-medium\">\n            ".concat(cmd, "\n          </div>\n        ");
      }).join(''), "\n      </div>\n      \n      <div class=\"p-2 sm:p-3 border-t bg-muted/30 text-center flex-shrink-0\">\n        <p class=\"text-[9px] sm:text-[10px] text-muted-foreground\">\n          ").concat(isHindi ? '    !' : ' Speak and I will help!', "\n        </p>\n      </div>\n    ");

      // Close button
      overlay.querySelector('.liaplus-close-commands').onclick = function () {
        _this3.widget.setState({
          showCommands: false
        });
      };
      return overlay;
    }
  }]);
}();

/***/ },

/***/ "./src/VoiceWidget.js"
/*!****************************!*\
  !*** ./src/VoiceWidget.js ***!
  \****************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   VoiceWidget: () => (/* binding */ VoiceWidget)
/* harmony export */ });
/* harmony import */ var _voice_sdk__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @voice-sdk */ "../lib/voice-sdk/dist/esm/index.js");
/* harmony import */ var _UIComponents_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./UIComponents.js */ "./src/UIComponents.js");
/* harmony import */ var _CommandProcessor_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./CommandProcessor.js */ "./src/CommandProcessor.js");
/* harmony import */ var _ApiManager_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ApiManager.js */ "./src/ApiManager.js");
/* harmony import */ var _AudioManager_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./AudioManager.js */ "./src/AudioManager.js");
/* harmony import */ var _styles_css__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./styles.css */ "./src/styles.css");
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function _toConsumableArray(r) { return _arrayWithoutHoles(r) || _iterableToArray(r) || _unsupportedIterableToArray(r) || _nonIterableSpread(); }
function _nonIterableSpread() { throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }
function _unsupportedIterableToArray(r, a) { if (r) { if ("string" == typeof r) return _arrayLikeToArray(r, a); var t = {}.toString.call(r).slice(8, -1); return "Object" === t && r.constructor && (t = r.constructor.name), "Map" === t || "Set" === t ? Array.from(r) : "Arguments" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? _arrayLikeToArray(r, a) : void 0; } }
function _iterableToArray(r) { if ("undefined" != typeof Symbol && null != r[Symbol.iterator] || null != r["@@iterator"]) return Array.from(r); }
function _arrayWithoutHoles(r) { if (Array.isArray(r)) return _arrayLikeToArray(r); }
function _arrayLikeToArray(r, a) { (null == a || a > r.length) && (a = r.length); for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e]; return n; }
function _regenerator() { /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/babel/babel/blob/main/packages/babel-helpers/LICENSE */ var e, t, r = "function" == typeof Symbol ? Symbol : {}, n = r.iterator || "@@iterator", o = r.toStringTag || "@@toStringTag"; function i(r, n, o, i) { var c = n && n.prototype instanceof Generator ? n : Generator, u = Object.create(c.prototype); return _regeneratorDefine2(u, "_invoke", function (r, n, o) { var i, c, u, f = 0, p = o || [], y = !1, G = { p: 0, n: 0, v: e, a: d, f: d.bind(e, 4), d: function d(t, r) { return i = t, c = 0, u = e, G.n = r, a; } }; function d(r, n) { for (c = r, u = n, t = 0; !y && f && !o && t < p.length; t++) { var o, i = p[t], d = G.p, l = i[2]; r > 3 ? (o = l === n) && (u = i[(c = i[4]) ? 5 : (c = 3, 3)], i[4] = i[5] = e) : i[0] <= d && ((o = r < 2 && d < i[1]) ? (c = 0, G.v = n, G.n = i[1]) : d < l && (o = r < 3 || i[0] > n || n > l) && (i[4] = r, i[5] = n, G.n = l, c = 0)); } if (o || r > 1) return a; throw y = !0, n; } return function (o, p, l) { if (f > 1) throw TypeError("Generator is already running"); for (y && 1 === p && d(p, l), c = p, u = l; (t = c < 2 ? e : u) || !y;) { i || (c ? c < 3 ? (c > 1 && (G.n = -1), d(c, u)) : G.n = u : G.v = u); try { if (f = 2, i) { if (c || (o = "next"), t = i[o]) { if (!(t = t.call(i, u))) throw TypeError("iterator result is not an object"); if (!t.done) return t; u = t.value, c < 2 && (c = 0); } else 1 === c && (t = i["return"]) && t.call(i), c < 2 && (u = TypeError("The iterator does not provide a '" + o + "' method"), c = 1); i = e; } else if ((t = (y = G.n < 0) ? u : r.call(n, G)) !== a) break; } catch (t) { i = e, c = 1, u = t; } finally { f = 1; } } return { value: t, done: y }; }; }(r, o, i), !0), u; } var a = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} t = Object.getPrototypeOf; var c = [][n] ? t(t([][n]())) : (_regeneratorDefine2(t = {}, n, function () { return this; }), t), u = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(c); function f(e) { return Object.setPrototypeOf ? Object.setPrototypeOf(e, GeneratorFunctionPrototype) : (e.__proto__ = GeneratorFunctionPrototype, _regeneratorDefine2(e, o, "GeneratorFunction")), e.prototype = Object.create(u), e; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, _regeneratorDefine2(u, "constructor", GeneratorFunctionPrototype), _regeneratorDefine2(GeneratorFunctionPrototype, "constructor", GeneratorFunction), GeneratorFunction.displayName = "GeneratorFunction", _regeneratorDefine2(GeneratorFunctionPrototype, o, "GeneratorFunction"), _regeneratorDefine2(u), _regeneratorDefine2(u, o, "Generator"), _regeneratorDefine2(u, n, function () { return this; }), _regeneratorDefine2(u, "toString", function () { return "[object Generator]"; }), (_regenerator = function _regenerator() { return { w: i, m: f }; })(); }
function _regeneratorDefine2(e, r, n, t) { var i = Object.defineProperty; try { i({}, "", {}); } catch (e) { i = 0; } _regeneratorDefine2 = function _regeneratorDefine(e, r, n, t) { function o(r, n) { _regeneratorDefine2(e, r, function (e) { return this._invoke(r, n, e); }); } r ? i ? i(e, r, { value: n, enumerable: !t, configurable: !t, writable: !t }) : e[r] = n : (o("next", 0), o("throw", 1), o("return", 2)); }, _regeneratorDefine2(e, r, n, t); }
function asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }
function _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, "next", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, "throw", n); } _next(void 0); }); }; }
function ownKeys(e, r) { var t = Object.keys(e); if (Object.getOwnPropertySymbols) { var o = Object.getOwnPropertySymbols(e); r && (o = o.filter(function (r) { return Object.getOwnPropertyDescriptor(e, r).enumerable; })), t.push.apply(t, o); } return t; }
function _objectSpread(e) { for (var r = 1; r < arguments.length; r++) { var t = null != arguments[r] ? arguments[r] : {}; r % 2 ? ownKeys(Object(t), !0).forEach(function (r) { _defineProperty(e, r, t[r]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) { Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r)); }); } return e; }
function _defineProperty(e, r, t) { return (r = _toPropertyKey(r)) in e ? Object.defineProperty(e, r, { value: t, enumerable: !0, configurable: !0, writable: !0 }) : e[r] = t, e; }
function _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError("Cannot call a class as a function"); }
function _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, "value" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }
function _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, "prototype", { writable: !1 }), e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * LiaPlus Voice Navigation Widget
 * Vanilla JavaScript port of VoiceNavigationAdvanced React component
 * 
 * This is a direct port maintaining exact UI/UX from components/voice-navigation-advanced.tsx
 */








var VoiceWidget = /*#__PURE__*/function () {
  function VoiceWidget() {
    var config = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
    _classCallCheck(this, VoiceWidget);
    // Configuration
    this.config = _objectSpread({
      apiBase: config.apiBase || 'https://liaplus.com/api',
      mode: config.mode || 'hosted',
      // 'hosted' or 'custom'
      language: config.language || 'en-US',
      autoStart: config.autoStart !== undefined ? config.autoStart : false,
      debug: config.debug !== undefined ? config.debug : true
    }, config);

    // State management (from React useState lines 31-44)
    this.state = {
      isListening: false,
      isSupported: true,
      transcript: '',
      voiceEnabled: true,
      showSettings: false,
      showCommands: true,
      commandHistory: [],
      isProcessing: false,
      language: this.config.language,
      showLanguageSelector: false,
      aiEnabled: true,
      useDynamicMode: true,
      domAnalysis: null,
      navigationMap: null
    };

    // References (from React useRef)
    this.refs = {
      recognizer: null,
      synthesizer: null,
      commandsList: null,
      mainButton: null,
      container: null
    };

    // DOM elements
    this.elements = {};

    // Managers
    this.uiComponents = new _UIComponents_js__WEBPACK_IMPORTED_MODULE_1__.UIComponents(this);
    this.commandProcessor = new _CommandProcessor_js__WEBPACK_IMPORTED_MODULE_2__.CommandProcessor(this);
    this.apiManager = new _ApiManager_js__WEBPACK_IMPORTED_MODULE_3__.ApiManager(this);
    this.audioManager = new _AudioManager_js__WEBPACK_IMPORTED_MODULE_4__.AudioManager(this);

    // Bound methods
    this.toggleListening = this.toggleListening.bind(this);
    this.handleVoiceCommand = this.handleVoiceCommand.bind(this);
    this.executeAction = this.executeAction.bind(this);
    this.speak = this.speak.bind(this);
    this.stopSpeaking = this.stopSpeaking.bind(this);

    // Initialize
    this.init();
  }

  /**
   * Initialize the widget
   */
  return _createClass(VoiceWidget, [{
    key: "init",
    value: (function () {
      var _init = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee() {
        var _this = this;
        return _regenerator().w(function (_context) {
          while (1) switch (_context.n) {
            case 0:
              this.log('Initializing LiaPlus Voice Widget', this.config);

              // Load persistent state
              this.loadStateFromLocalStorage();

              // Create DOM elements
              this.createWidgetUI();

              // Initialize NavigationMap
              _context.n = 1;
              return this.initNavigationMap();
            case 1:
              // Analyze page
              if (this.state.useDynamicMode) {
                setTimeout(function () {
                  return _this.analyzePage();
                }, 500);
              }

              // Listen for page changes
              this.observePageChanges();

              // Auto-start if configured
              if (this.config.autoStart && this.state.isListening) {
                this.startRecognition();
              }
              this.log('Widget initialized successfully');
            case 2:
              return _context.a(2);
          }
        }, _callee, this);
      }));
      function init() {
        return _init.apply(this, arguments);
      }
      return init;
    }()
    /**
     * Load state from localStorage (from React useEffect lines 68-85)
     */
    )
  }, {
    key: "loadStateFromLocalStorage",
    value: function loadStateFromLocalStorage() {
      if (typeof window === 'undefined') return;
      var savedListening = localStorage.getItem('voiceNavListening') === 'true';
      var savedVoiceEnabled = localStorage.getItem('voiceNavFeedback') !== 'false';
      var savedLanguage = localStorage.getItem('voiceNavLanguage') || 'en-US';
      var savedAI = localStorage.getItem('voiceNavAI') !== 'false';
      var savedDynamic = localStorage.getItem('voiceNavDynamic') !== 'false';
      this.setState({
        voiceEnabled: savedVoiceEnabled,
        language: savedLanguage,
        aiEnabled: savedAI,
        useDynamicMode: savedDynamic,
        isListening: savedListening
      }, false); // Don't render yet
    }

    /**
     * Save state to localStorage (from React useEffect lines 122-130)
     */
  }, {
    key: "saveStateToLocalStorage",
    value: function saveStateToLocalStorage() {
      if (typeof window === 'undefined') return;
      localStorage.setItem('voiceNavListening', this.state.isListening.toString());
      localStorage.setItem('voiceNavFeedback', this.state.voiceEnabled.toString());
      localStorage.setItem('voiceNavLanguage', this.state.language);
      localStorage.setItem('voiceNavAI', this.state.aiEnabled.toString());
      localStorage.setItem('voiceNavDynamic', this.state.useDynamicMode.toString());
    }

    /**
     * Initialize NavigationMap (from React useEffect lines 53-65)
     */
  }, {
    key: "initNavigationMap",
    value: (function () {
      var _initNavigationMap = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee2() {
        var navMap;
        return _regenerator().w(function (_context2) {
          while (1) switch (_context2.n) {
            case 0:
              try {
                navMap = new _voice_sdk__WEBPACK_IMPORTED_MODULE_0__.NavigationMap();
                this.setState({
                  navigationMap: navMap
                });
                this.log(' Navigation Map initialized with', navMap.getAllRoutes().length, 'routes');
              } catch (error) {
                this.log(' Navigation Map failed to initialize:', error);
              }
            case 1:
              return _context2.a(2);
          }
        }, _callee2, this);
      }));
      function initNavigationMap() {
        return _initNavigationMap.apply(this, arguments);
      }
      return initNavigationMap;
    }()
    /**
     * Analyze page DOM (from React useEffect lines 88-98 and analyzePage lines 101-119)
     */
    )
  }, {
    key: "analyzePage",
    value: function analyzePage() {
      if (!this.state.useDynamicMode) return;
      try {
        this.log(' Analyzing page DOM...');
        var analyzer = new _voice_sdk__WEBPACK_IMPORTED_MODULE_0__.DOMAnalyzer();
        var analysis = analyzer.analyze();
        this.setState({
          domAnalysis: analysis
        });
        this.log(' DOM Analysis complete:', {
          forms: analysis.forms.length,
          navigation: analysis.navigation.length,
          interactions: analysis.interactions.length,
          landmarks: analysis.landmarks.length,
          pageTitle: analysis.pageInfo.title
        });
      } catch (error) {
        this.log(' DOM Analysis failed:', error);
      }
    }

    /**
     * Observe page changes for re-analysis
     */
  }, {
    key: "observePageChanges",
    value: function observePageChanges() {
      var _this2 = this;
      // Listen for route changes (for SPAs)
      var lastUrl = location.href;
      new MutationObserver(function () {
        var url = location.href;
        if (url !== lastUrl) {
          lastUrl = url;
          _this2.log(' Page changed, re-analyzing...');
          setTimeout(function () {
            return _this2.analyzePage();
          }, 500);
        }
      }).observe(document.querySelector('body'), {
        subtree: true,
        childList: true
      });
    }

    /**
     * Set state and trigger re-render
     */
  }, {
    key: "setState",
    value: function setState(updates) {
      var shouldRender = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;
      var oldState = _objectSpread({}, this.state);
      this.state = _objectSpread(_objectSpread({}, this.state), updates);

      // Save to localStorage
      this.saveStateToLocalStorage();

      // Re-render if needed
      if (shouldRender) {
        this.render(oldState);
      }
    }

    /**
     * Logging utility
     */
  }, {
    key: "log",
    value: function log() {
      if (this.config.debug) {
        var _console;
        for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {
          args[_key] = arguments[_key];
        }
        (_console = console).log.apply(_console, ['[LiaPlusVoice]'].concat(args));
      }
    }

    /**
     * Toggle listening state
     */
  }, {
    key: "toggleListening",
    value: function toggleListening() {
      this.setState({
        isListening: !this.state.isListening
      });
      if (this.state.isListening) {
        this.startRecognition();
      } else {
        this.stopRecognition();
      }
    }

    /**
     * Destroy widget and cleanup
     */
  }, {
    key: "destroy",
    value: function destroy() {
      this.stopRecognition();
      if (this.refs.container && this.refs.container.parentNode) {
        this.refs.container.parentNode.removeChild(this.refs.container);
      }
      this.log('Widget destroyed');
    }

    /**
     * Create widget UI
     */
  }, {
    key: "createWidgetUI",
    value: function createWidgetUI() {
      // Create container
      this.refs.container = this.uiComponents.createContainer();
      document.body.appendChild(this.refs.container);

      // Initial render
      this.render();
    }

    /**
     * Render widget UI
     */
  }, {
    key: "render",
    value: function render() {
      var oldState = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
      if (!this.refs.container) return;

      // Clear container
      this.refs.container.innerHTML = '';

      // Create floating button wrapper
      var buttonWrapper = this.uiComponents.createFloatingButton();
      this.refs.container.appendChild(buttonWrapper);

      // Get the relative container (for positioning overlays)
      var relativeContainer = buttonWrapper.querySelector('.relative');

      // Add transcript overlay if needed
      var transcriptOverlay = this.uiComponents.createTranscriptOverlay();
      if (transcriptOverlay) {
        relativeContainer.appendChild(transcriptOverlay);
      }

      // Add settings panel if needed
      var settingsPanel = this.uiComponents.createSettingsPanel();
      if (settingsPanel) {
        relativeContainer.appendChild(settingsPanel);
      }

      // Add commands overlay if needed
      var commandsOverlay = this.uiComponents.createCommandsOverlay();
      if (commandsOverlay) {
        this.refs.container.appendChild(commandsOverlay);
      }
    }

    /**
     * Execute action (delegate to CommandProcessor)
     */
  }, {
    key: "executeAction",
    value: function executeAction(action, parameters) {
      return this.commandProcessor.executeAction(action, parameters);
    }

    /**
     * Start recognition
     */
  }, {
    key: "startRecognition",
    value: (function () {
      var _startRecognition = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee3() {
        return _regenerator().w(function (_context3) {
          while (1) switch (_context3.n) {
            case 0:
              _context3.n = 1;
              return this.audioManager.start();
            case 1:
              return _context3.a(2);
          }
        }, _callee3, this);
      }));
      function startRecognition() {
        return _startRecognition.apply(this, arguments);
      }
      return startRecognition;
    }()
    /**
     * Stop recognition
     */
    )
  }, {
    key: "stopRecognition",
    value: function stopRecognition() {
      this.audioManager.stop();
    }

    /**
     * Speak text
     */
  }, {
    key: "speak",
    value: function speak(text) {
      this.audioManager.speak(text);
    }

    /**
     * Stop speaking
     */
  }, {
    key: "stopSpeaking",
    value: function stopSpeaking() {
      this.audioManager.stopSpeaking();
    }

    /**
     * Reinitialize recognition (when language changes)
     */
  }, {
    key: "reinitializeRecognition",
    value: (function () {
      var _reinitializeRecognition = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee4() {
        return _regenerator().w(function (_context4) {
          while (1) switch (_context4.n) {
            case 0:
              _context4.n = 1;
              return this.audioManager.reinitialize();
            case 1:
              return _context4.a(2);
          }
        }, _callee4, this);
      }));
      function reinitializeRecognition() {
        return _reinitializeRecognition.apply(this, arguments);
      }
      return reinitializeRecognition;
    }()
    /**
     * Handle voice command (lines 906-999)
     */
    )
  }, {
    key: "handleVoiceCommand",
    value: (function () {
      var _handleVoiceCommand = _asyncToGenerator(/*#__PURE__*/_regenerator().m(function _callee5(command) {
        var newHistory, data, normalizedAction, executed, updatedHistory, _updatedHistory, errorMessage, _t;
        return _regenerator().w(function (_context5) {
          while (1) switch (_context5.p = _context5.n) {
            case 0:
              if (!(!command || command.length < 2)) {
                _context5.n = 1;
                break;
              }
              return _context5.a(2);
            case 1:
              this.log(' [Voice Command]', command);
              this.setState({
                isProcessing: true
              });

              // Add to command history
              newHistory = [{
                command: command,
                timestamp: Date.now(),
                action: 'Processing...'
              }].concat(_toConsumableArray(this.state.commandHistory.slice(0, 9)));
              this.setState({
                commandHistory: newHistory
              });
              _context5.p = 2;
              _context5.n = 3;
              return this.apiManager.processVoiceCommand(command, this.state.domAnalysis, window.location.href);
            case 3:
              data = _context5.v;
              this.log(' [AI Response]', data);

              // Speak the AI's response
              if (data.response) {
                this.log(' [Speaking]', data.response);
                this.speak(data.response);
              }

              // Execute the action if not just chat
              if (data.action && data.action !== 'chat') {
                // Normalize action name
                normalizedAction = data.action.replace(/\s+/g, '_').toLowerCase();
                this.log(' [Action]', normalizedAction, data.parameters || {});
                executed = this.executeAction(normalizedAction, data.parameters);
                this.log(executed ? ' [Executed]' : ' [Failed]', normalizedAction);

                // Update command history
                updatedHistory = _toConsumableArray(this.state.commandHistory);
                if (updatedHistory[0]) {
                  updatedHistory[0].action = executed ? normalizedAction : 'Unknown action';
                }
                this.setState({
                  commandHistory: updatedHistory
                });
              } else {
                // Just conversation
                this.log(' [Chat Mode]', data.response);
                _updatedHistory = _toConsumableArray(this.state.commandHistory);
                if (_updatedHistory[0]) {
                  _updatedHistory[0].action = 'Chat';
                }
                this.setState({
                  commandHistory: _updatedHistory
                });
              }
              _context5.n = 5;
              break;
            case 4:
              _context5.p = 4;
              _t = _context5.v;
              this.log(' [Error]', _t);
              errorMessage = this.state.language === 'hi-IN' ? ' ,        ' : 'Sorry, something went wrong. Please try again.';
              this.speak(errorMessage);
            case 5:
              _context5.p = 5;
              this.setState({
                isProcessing: false
              });
              this.log(' [Processing Complete]');
              return _context5.f(5);
            case 6:
              return _context5.a(2);
          }
        }, _callee5, this, [[2, 4, 5, 6]]);
      }));
      function handleVoiceCommand(_x) {
        return _handleVoiceCommand.apply(this, arguments);
      }
      return handleVoiceCommand;
    }())
  }]);
}();

/***/ },

/***/ "./node_modules/bent/src/browser.js"
/*!******************************************!*\
  !*** ./node_modules/bent/src/browser.js ***!
  \******************************************/
(module, __unused_webpack_exports, __webpack_require__) {

"use strict";

/* global fetch, btoa, Headers */
const core = __webpack_require__(/*! ./core */ "./node_modules/bent/src/core.js")

class StatusError extends Error {
  constructor (res, ...params) {
    super(...params)

    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, StatusError)
    }

    this.name = 'StatusError'
    this.message = res.statusMessage
    this.statusCode = res.status
    this.res = res
    this.json = res.json.bind(res)
    this.text = res.text.bind(res)
    this.arrayBuffer = res.arrayBuffer.bind(res)
    let buffer
    const get = () => {
      if (!buffer) buffer = this.arrayBuffer()
      return buffer
    }
    Object.defineProperty(this, 'responseBody', { get })
    // match Node.js headers object
    this.headers = {}
    for (const [key, value] of res.headers.entries()) {
      this.headers[key.toLowerCase()] = value
    }
  }
}

const mkrequest = (statusCodes, method, encoding, headers, baseurl) => async (_url, body, _headers = {}) => {
  _url = baseurl + (_url || '')
  let parsed = new URL(_url)

  if (!headers) headers = {}
  if (parsed.username) {
    headers.Authorization = 'Basic ' + btoa(parsed.username + ':' + parsed.password)
    parsed = new URL(parsed.protocol + '//' + parsed.host + parsed.pathname + parsed.search)
  }
  if (parsed.protocol !== 'https:' && parsed.protocol !== 'http:') {
    throw new Error(`Unknown protocol, ${parsed.protocol}`)
  }

  if (body) {
    if (body instanceof ArrayBuffer ||
      ArrayBuffer.isView(body) ||
      typeof body === 'string'
    ) {
      // noop
    } else if (typeof body === 'object') {
      body = JSON.stringify(body)
      headers['Content-Type'] = 'application/json'
    } else {
      throw new Error('Unknown body type.')
    }
  }

  _headers = new Headers({ ...(headers || {}), ..._headers })

  const resp = await fetch(parsed, { method, headers: _headers, body })
  resp.statusCode = resp.status

  if (!statusCodes.has(resp.status)) {
    throw new StatusError(resp)
  }

  if (encoding === 'json') return resp.json()
  else if (encoding === 'buffer') return resp.arrayBuffer()
  else if (encoding === 'string') return resp.text()
  else return resp
}

module.exports = core(mkrequest)


/***/ },

/***/ "./node_modules/bent/src/core.js"
/*!***************************************!*\
  !*** ./node_modules/bent/src/core.js ***!
  \***************************************/
(module) {

"use strict";

const encodings = new Set(['json', 'buffer', 'string'])

module.exports = mkrequest => (...args) => {
  const statusCodes = new Set()
  let method
  let encoding
  let headers
  let baseurl = ''

  args.forEach(arg => {
    if (typeof arg === 'string') {
      if (arg.toUpperCase() === arg) {
        if (method) {
          const msg = `Can't set method to ${arg}, already set to ${method}.`
          throw new Error(msg)
        } else {
          method = arg
        }
      } else if (arg.startsWith('http:') || arg.startsWith('https:')) {
        baseurl = arg
      } else {
        if (encodings.has(arg)) {
          encoding = arg
        } else {
          throw new Error(`Unknown encoding, ${arg}`)
        }
      }
    } else if (typeof arg === 'number') {
      statusCodes.add(arg)
    } else if (typeof arg === 'object') {
      if (Array.isArray(arg) || arg instanceof Set) {
        arg.forEach(code => statusCodes.add(code))
      } else {
        if (headers) {
          throw new Error('Cannot set headers twice.')
        }
        headers = arg
      }
    } else {
      throw new Error(`Unknown type: ${typeof arg}`)
    }
  })

  if (!method) method = 'GET'
  if (statusCodes.size === 0) {
    statusCodes.add(200)
  }

  return mkrequest(statusCodes, method, encoding, headers, baseurl)
}


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/microsoft.cognitiveservices.speech.sdk.js"
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/microsoft.cognitiveservices.speech.sdk.js ***!
  \*******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
/* eslint-disable @typescript-eslint/no-unused-vars */
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
const Exports_js_1 = __webpack_require__(/*! ./src/common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
// Note: this instantiation ensures the above import isn't
// removed on compile. The import being absent causes an error on running
void new Exports_js_1.AgentConfig();
// Speech SDK API
__exportStar(__webpack_require__(/*! ./src/sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js"), exports);

//# sourceMappingURL=microsoft.cognitiveservices.speech.sdk.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ConsoleLoggingListener.js"
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ConsoleLoggingListener.js ***!
  \**********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

/* eslint-disable @typescript-eslint/no-unsafe-assignment */
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConsoleLoggingListener = void 0;
const fs = __importStar(__webpack_require__(/*! fs */ "?f824"));
const LogLevel_js_1 = __webpack_require__(/*! ../sdk/LogLevel.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LogLevel.js");
const Contracts_js_1 = __webpack_require__(/*! ../sdk/Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
class ConsoleLoggingListener {
    constructor(logLevelFilter = LogLevel_js_1.LogLevel.None) {
        this.privLogPath = undefined;
        this.privEnableConsoleOutput = true;
        this.privLogLevelFilter = logLevelFilter;
    }
    set logPath(path) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(fs.openSync, "\nFile System access not available");
        this.privLogPath = path;
    }
    set enableConsoleOutput(enableOutput) {
        this.privEnableConsoleOutput = enableOutput;
    }
    onEvent(event) {
        if (event.eventType >= this.privLogLevelFilter) {
            const log = this.toString(event);
            if (!!this.logCallback) {
                this.logCallback(log);
            }
            if (!!this.privLogPath) {
                fs.writeFileSync(this.privLogPath, log + "\n", { flag: "a+" });
            }
            if (this.privEnableConsoleOutput) {
                switch (event.eventType) {
                    case LogLevel_js_1.LogLevel.Debug:
                        // eslint-disable-next-line no-console
                        console.debug(log);
                        break;
                    case LogLevel_js_1.LogLevel.Info:
                        // eslint-disable-next-line no-console
                        console.info(log);
                        break;
                    case LogLevel_js_1.LogLevel.Warning:
                        // eslint-disable-next-line no-console
                        console.warn(log);
                        break;
                    case LogLevel_js_1.LogLevel.Error:
                        // eslint-disable-next-line no-console
                        console.error(log);
                        break;
                    default:
                        // eslint-disable-next-line no-console
                        console.log(log);
                        break;
                }
            }
        }
    }
    toString(event) {
        const logFragments = [
            `${event.eventTime}`,
            `${event.name}`,
        ];
        const e = event;
        for (const prop in e) {
            if (prop && event.hasOwnProperty(prop) &&
                prop !== "eventTime" && prop !== "eventType" &&
                prop !== "eventId" && prop !== "name" &&
                prop !== "constructor") {
                // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
                const value = e[prop];
                let valueToLog = "<NULL>";
                if (value !== undefined && value !== null) {
                    if (typeof (value) === "number" || typeof (value) === "string") {
                        valueToLog = value.toString();
                    }
                    else {
                        valueToLog = JSON.stringify(value);
                    }
                }
                logFragments.push(`${prop}: ${valueToLog}`);
            }
        }
        return logFragments.join(" | ");
    }
}
exports.ConsoleLoggingListener = ConsoleLoggingListener;

//# sourceMappingURL=ConsoleLoggingListener.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js"
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js ***!
  \*******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
__exportStar(__webpack_require__(/*! ./ConsoleLoggingListener.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ConsoleLoggingListener.js"), exports);
__exportStar(__webpack_require__(/*! ./IRecorder.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/IRecorder.js"), exports);
__exportStar(__webpack_require__(/*! ./MicAudioSource.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource.js"), exports);
__exportStar(__webpack_require__(/*! ./FileAudioSource.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/FileAudioSource.js"), exports);
__exportStar(__webpack_require__(/*! ./PCMRecorder.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/PCMRecorder.js"), exports);
__exportStar(__webpack_require__(/*! ./WebsocketConnection.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketConnection.js"), exports);
__exportStar(__webpack_require__(/*! ./WebsocketMessageAdapter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketMessageAdapter.js"), exports);
__exportStar(__webpack_require__(/*! ./ReplayableAudioNode.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ReplayableAudioNode.js"), exports);
__exportStar(__webpack_require__(/*! ./ProxyInfo.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ProxyInfo.js"), exports);
__exportStar(__webpack_require__(/*! ./RestMessageAdapter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestMessageAdapter.js"), exports);
__exportStar(__webpack_require__(/*! ./RestConfigBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestConfigBase.js"), exports);

//# sourceMappingURL=Exports.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/FileAudioSource.js"
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/FileAudioSource.js ***!
  \***************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.FileAudioSource = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const AudioStreamFormat_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js");
class FileAudioSource {
    constructor(file, filename, audioSourceId) {
        this.privStreams = {};
        this.privHeaderEnd = 44;
        this.privId = audioSourceId ? audioSourceId : (0, Exports_js_2.createNoDashGuid)();
        this.privEvents = new Exports_js_2.EventSource();
        this.privSource = file;
        if (typeof window !== "undefined" && typeof Blob !== "undefined" && this.privSource instanceof Blob) {
            this.privFilename = file.name;
        }
        else {
            this.privFilename = filename || "unknown.wav";
        }
        // Read the header.
        this.privAudioFormatPromise = this.readHeader();
    }
    get format() {
        return this.privAudioFormatPromise;
    }
    turnOn() {
        if (this.privFilename.lastIndexOf(".wav") !== this.privFilename.length - 4) {
            const errorMsg = this.privFilename + " is not supported. Only WAVE files are allowed at the moment.";
            this.onEvent(new Exports_js_2.AudioSourceErrorEvent(errorMsg, ""));
            return Promise.reject(errorMsg);
        }
        this.onEvent(new Exports_js_2.AudioSourceInitializingEvent(this.privId)); // no stream id
        this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));
        return;
    }
    id() {
        return this.privId;
    }
    async attach(audioNodeId) {
        this.onEvent(new Exports_js_2.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
        const stream = await this.upload(audioNodeId);
        this.onEvent(new Exports_js_2.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
        return Promise.resolve({
            detach: async () => {
                stream.readEnded();
                delete this.privStreams[audioNodeId];
                this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
                await this.turnOff();
            },
            id: () => audioNodeId,
            read: () => stream.read(),
        });
    }
    detach(audioNodeId) {
        if (audioNodeId && this.privStreams[audioNodeId]) {
            this.privStreams[audioNodeId].close();
            delete this.privStreams[audioNodeId];
            this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
        }
    }
    turnOff() {
        for (const streamId in this.privStreams) {
            if (streamId) {
                const stream = this.privStreams[streamId];
                if (stream && !stream.isClosed) {
                    stream.close();
                }
            }
        }
        this.onEvent(new Exports_js_2.AudioSourceOffEvent(this.privId)); // no stream now
        return Promise.resolve();
    }
    get events() {
        return this.privEvents;
    }
    get deviceInfo() {
        return this.privAudioFormatPromise.then((result) => (Promise.resolve({
            bitspersample: result.bitsPerSample,
            channelcount: result.channels,
            connectivity: Exports_js_1.connectivity.Unknown,
            manufacturer: "Speech SDK",
            model: "File",
            samplerate: result.samplesPerSec,
            type: Exports_js_1.type.File,
        })));
    }
    readHeader() {
        // Read the wave header.
        const maxHeaderSize = 4296;
        const header = this.privSource.slice(0, maxHeaderSize);
        const headerResult = new Exports_js_2.Deferred();
        const processHeader = (header) => {
            const view = new DataView(header);
            const getWord = (index) => String.fromCharCode(view.getUint8(index), view.getUint8(index + 1), view.getUint8(index + 2), view.getUint8(index + 3));
            // RIFF 4 bytes.
            if ("RIFF" !== getWord(0)) {
                headerResult.reject("Invalid WAV header in file, RIFF was not found");
                return;
            }
            // length, 4 bytes
            // RIFF Type & fmt 8 bytes
            if ("WAVE" !== getWord(8) || "fmt " !== getWord(12)) {
                headerResult.reject("Invalid WAV header in file, WAVEfmt was not found");
                return;
            }
            const formatSize = view.getInt32(16, true);
            const channelCount = view.getUint16(22, true);
            const sampleRate = view.getUint32(24, true);
            const bitsPerSample = view.getUint16(34, true);
            // Confirm if header is 44 bytes long.
            let pos = 36 + Math.max(formatSize - 16, 0);
            for (; getWord(pos) !== "data"; pos += 2) {
                if (pos > maxHeaderSize - 8) {
                    headerResult.reject("Invalid WAV header in file, data block was not found");
                    return;
                }
            }
            this.privHeaderEnd = pos + 8;
            headerResult.resolve(AudioStreamFormat_js_1.AudioStreamFormat.getWaveFormatPCM(sampleRate, bitsPerSample, channelCount));
        };
        if (typeof window !== "undefined" && typeof Blob !== "undefined" && header instanceof Blob) {
            const reader = new FileReader();
            reader.onload = (event) => {
                const header = event.target.result;
                processHeader(header);
            };
            reader.readAsArrayBuffer(header);
        }
        else {
            const h = header;
            processHeader(h.buffer.slice(h.byteOffset, h.byteOffset + h.byteLength));
        }
        return headerResult.promise;
    }
    async upload(audioNodeId) {
        const onerror = (error) => {
            const errorMsg = `Error occurred while processing '${this.privFilename}'. ${error}`;
            this.onEvent(new Exports_js_2.AudioStreamNodeErrorEvent(this.privId, audioNodeId, errorMsg));
            throw new Error(errorMsg);
        };
        try {
            await this.turnOn();
            const format = await this.privAudioFormatPromise;
            const stream = new Exports_js_2.ChunkedArrayBufferStream(format.avgBytesPerSec / 10, audioNodeId);
            this.privStreams[audioNodeId] = stream;
            const chunk = this.privSource.slice(this.privHeaderEnd);
            const processFile = (buff) => {
                if (stream.isClosed) {
                    return; // output stream was closed (somebody called TurnOff). We're done here.
                }
                stream.writeStreamChunk({
                    buffer: buff,
                    isEnd: false,
                    timeReceived: Date.now(),
                });
                stream.close();
            };
            if (typeof window !== "undefined" && typeof Blob !== "undefined" && chunk instanceof Blob) {
                const reader = new FileReader();
                reader.onerror = (ev) => onerror(ev.toString());
                reader.onload = (event) => {
                    const fileBuffer = event.target.result;
                    processFile(fileBuffer);
                };
                reader.readAsArrayBuffer(chunk);
            }
            else {
                const c = chunk;
                processFile(c.buffer.slice(c.byteOffset, c.byteOffset + c.byteLength));
            }
            return stream;
        }
        catch (e) {
            onerror(e);
        }
    }
    onEvent(event) {
        this.privEvents.onEvent(event);
        Exports_js_2.Events.instance.onEvent(event);
    }
}
exports.FileAudioSource = FileAudioSource;

//# sourceMappingURL=FileAudioSource.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/IRecorder.js"
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/IRecorder.js ***!
  \*********************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IRecorder.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource.js"
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/MicAudioSource.js ***!
  \**************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MicAudioSource = exports.AudioWorkletSourceURLPropertyName = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const AudioStreamFormat_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js");
exports.AudioWorkletSourceURLPropertyName = "MICROPHONE-WorkletSourceUrl";
class MicAudioSource {
    constructor(privRecorder, deviceId, audioSourceId, mediaStream) {
        this.privRecorder = privRecorder;
        this.deviceId = deviceId;
        this.privStreams = {};
        this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;
        this.privId = audioSourceId ? audioSourceId : (0, Exports_js_2.createNoDashGuid)();
        this.privEvents = new Exports_js_2.EventSource();
        this.privMediaStream = mediaStream || null;
        this.privIsClosing = false;
    }
    get format() {
        return Promise.resolve(MicAudioSource.AUDIOFORMAT);
    }
    turnOn() {
        if (this.privInitializeDeferral) {
            return this.privInitializeDeferral.promise;
        }
        this.privInitializeDeferral = new Exports_js_2.Deferred();
        try {
            this.createAudioContext();
        }
        catch (error) {
            if (error instanceof Error) {
                const typedError = error;
                this.privInitializeDeferral.reject(typedError.name + ": " + typedError.message);
            }
            else {
                this.privInitializeDeferral.reject(error);
            }
            return this.privInitializeDeferral.promise;
        }
        const nav = window.navigator;
        let getUserMedia = (
        // eslint-disable-next-line
        nav.getUserMedia ||
            nav.webkitGetUserMedia ||
            nav.mozGetUserMedia ||
            nav.msGetUserMedia);
        if (!!nav.mediaDevices) {
            getUserMedia = (constraints, successCallback, errorCallback) => {
                nav.mediaDevices
                    .getUserMedia(constraints)
                    .then(successCallback)
                    .catch(errorCallback);
            };
        }
        if (!getUserMedia) {
            const errorMsg = "Browser does not support getUserMedia.";
            this.privInitializeDeferral.reject(errorMsg);
            this.onEvent(new Exports_js_2.AudioSourceErrorEvent(errorMsg, "")); // mic initialized error - no streamid at this point
        }
        else {
            const next = () => {
                this.onEvent(new Exports_js_2.AudioSourceInitializingEvent(this.privId)); // no stream id
                if (this.privMediaStream && this.privMediaStream.active) {
                    this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));
                    this.privInitializeDeferral.resolve();
                }
                else {
                    getUserMedia({ audio: this.deviceId ? { deviceId: this.deviceId } : true, video: false }, (mediaStream) => {
                        this.privMediaStream = mediaStream;
                        this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));
                        this.privInitializeDeferral.resolve();
                    }, (error) => {
                        const errorMsg = `Error occurred during microphone initialization: ${error}`;
                        this.privInitializeDeferral.reject(errorMsg);
                        this.onEvent(new Exports_js_2.AudioSourceErrorEvent(this.privId, errorMsg));
                    });
                }
            };
            if (this.privContext.state === "suspended") {
                // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.
                // https://github.com/WebAudio/web-audio-api/issues/790
                this.privContext.resume()
                    .then(next)
                    .catch((reason) => {
                    this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);
                });
            }
            else {
                next();
            }
        }
        return this.privInitializeDeferral.promise;
    }
    id() {
        return this.privId;
    }
    attach(audioNodeId) {
        this.onEvent(new Exports_js_2.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
        return this.listen(audioNodeId).then((stream) => {
            this.onEvent(new Exports_js_2.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
            return {
                detach: async () => {
                    stream.readEnded();
                    delete this.privStreams[audioNodeId];
                    this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
                    return this.turnOff();
                },
                id: () => audioNodeId,
                read: () => stream.read(),
            };
        });
    }
    detach(audioNodeId) {
        if (audioNodeId && this.privStreams[audioNodeId]) {
            this.privStreams[audioNodeId].close();
            delete this.privStreams[audioNodeId];
            this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
        }
    }
    async turnOff() {
        for (const streamId in this.privStreams) {
            if (streamId) {
                const stream = this.privStreams[streamId];
                if (stream) {
                    stream.close();
                }
            }
        }
        this.onEvent(new Exports_js_2.AudioSourceOffEvent(this.privId)); // no stream now
        if (this.privInitializeDeferral) {
            // Correctly handle when browser forces mic off before turnOn() completes
            // eslint-disable-next-line @typescript-eslint/await-thenable
            await this.privInitializeDeferral;
            this.privInitializeDeferral = null;
        }
        await this.destroyAudioContext();
        return;
    }
    get events() {
        return this.privEvents;
    }
    get deviceInfo() {
        return this.getMicrophoneLabel().then((label) => ({
            bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,
            channelcount: MicAudioSource.AUDIOFORMAT.channels,
            connectivity: Exports_js_1.connectivity.Unknown,
            manufacturer: "Speech SDK",
            model: label,
            samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,
            type: Exports_js_1.type.Microphones,
        }));
    }
    setProperty(name, value) {
        if (name === exports.AudioWorkletSourceURLPropertyName) {
            this.privRecorder.setWorkletUrl(value);
        }
        else {
            throw new Error("Property '" + name + "' is not supported on Microphone.");
        }
    }
    getMicrophoneLabel() {
        const defaultMicrophoneName = "microphone";
        // If we did this already, return the value.
        if (this.privMicrophoneLabel !== undefined) {
            return Promise.resolve(this.privMicrophoneLabel);
        }
        // If the stream isn't currently running, we can't query devices because security.
        if (this.privMediaStream === undefined || !this.privMediaStream.active) {
            return Promise.resolve(defaultMicrophoneName);
        }
        // Setup a default
        this.privMicrophoneLabel = defaultMicrophoneName;
        // Get the id of the device running the audio track.
        const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId;
        // If the browser doesn't support getting the device ID, set a default and return.
        if (undefined === microphoneDeviceId) {
            return Promise.resolve(this.privMicrophoneLabel);
        }
        const deferred = new Exports_js_2.Deferred();
        // Enumerate the media devices.
        navigator.mediaDevices.enumerateDevices().then((devices) => {
            for (const device of devices) {
                if (device.deviceId === microphoneDeviceId) {
                    // Found the device
                    this.privMicrophoneLabel = device.label;
                    break;
                }
            }
            deferred.resolve(this.privMicrophoneLabel);
        }, () => deferred.resolve(this.privMicrophoneLabel));
        return deferred.promise;
    }
    async listen(audioNodeId) {
        await this.turnOn();
        const stream = new Exports_js_2.ChunkedArrayBufferStream(this.privOutputChunkSize, audioNodeId);
        this.privStreams[audioNodeId] = stream;
        try {
            this.privRecorder.record(this.privContext, this.privMediaStream, stream);
        }
        catch (error) {
            this.onEvent(new Exports_js_2.AudioStreamNodeErrorEvent(this.privId, audioNodeId, error));
            throw error;
        }
        const result = stream;
        return result;
    }
    onEvent(event) {
        this.privEvents.onEvent(event);
        Exports_js_2.Events.instance.onEvent(event);
    }
    createAudioContext() {
        if (!!this.privContext) {
            return;
        }
        this.privContext = AudioStreamFormat_js_1.AudioStreamFormatImpl.getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);
    }
    async destroyAudioContext() {
        if (!this.privContext) {
            return;
        }
        this.privRecorder.releaseMediaResources(this.privContext);
        // This pattern brought to you by a bug in the TypeScript compiler where it
        // confuses the ("close" in this.privContext) with this.privContext always being null as the alternate.
        // https://github.com/Microsoft/TypeScript/issues/11498
        let hasClose = false;
        if ("close" in this.privContext) {
            hasClose = true;
        }
        if (hasClose) {
            if (!this.privIsClosing) {
                // The audio context close may take enough time that the close is called twice
                this.privIsClosing = true;
                await this.privContext.close();
                this.privContext = null;
                this.privIsClosing = false;
            }
        }
        else if (null !== this.privContext && this.privContext.state === "running") {
            // Suspend actually takes a callback, but analogous to the
            // resume method, it'll be only fired if suspend is called
            // in a direct response to a user action. The later is not always
            // the case, as TurnOff is also called, when we receive an
            // end-of-speech message from the service. So, doing a best effort
            // fire-and-forget here.
            await this.privContext.suspend();
        }
    }
}
exports.MicAudioSource = MicAudioSource;
MicAudioSource.AUDIOFORMAT = AudioStreamFormat_js_1.AudioStreamFormat.getDefaultInputFormat();

//# sourceMappingURL=MicAudioSource.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/PCMRecorder.js"
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/PCMRecorder.js ***!
  \***********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PcmRecorder = void 0;
const Exports_1 = __webpack_require__(/*! ../common/Exports */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
class PcmRecorder {
    constructor(stopInputOnRelease) {
        this.privStopInputOnRelease = stopInputOnRelease;
    }
    record(context, mediaStream, outputStream) {
        const desiredSampleRate = 16000;
        const waveStreamEncoder = new Exports_1.RiffPcmEncoder(context.sampleRate, desiredSampleRate);
        const micInput = context.createMediaStreamSource(mediaStream);
        const attachScriptProcessor = () => {
            // eslint-disable-next-line @typescript-eslint/explicit-function-return-type
            const scriptNode = (() => {
                let bufferSize = 0;
                try {
                    return context.createScriptProcessor(bufferSize, 1, 1);
                }
                catch (error) {
                    // Webkit (<= version 31) requires a valid bufferSize.
                    bufferSize = 2048;
                    let audioSampleRate = context.sampleRate;
                    while (bufferSize < 16384 && audioSampleRate >= (2 * desiredSampleRate)) {
                        bufferSize <<= 1;
                        audioSampleRate >>= 1;
                    }
                    return context.createScriptProcessor(bufferSize, 1, 1);
                }
            })();
            scriptNode.onaudioprocess = (event) => {
                const inputFrame = event.inputBuffer.getChannelData(0);
                if (outputStream && !outputStream.isClosed) {
                    const waveFrame = waveStreamEncoder.encode(inputFrame);
                    if (!!waveFrame) {
                        outputStream.writeStreamChunk({
                            buffer: waveFrame,
                            isEnd: false,
                            timeReceived: Date.now(),
                        });
                    }
                }
            };
            micInput.connect(scriptNode);
            scriptNode.connect(context.destination);
            this.privMediaResources = {
                scriptProcessorNode: scriptNode,
                source: micInput,
                stream: mediaStream,
            };
        };
        // https://webaudio.github.io/web-audio-api/#audioworklet
        // Using AudioWorklet to improve audio quality and avoid audio glitches due to blocking the UI thread
        const skipAudioWorklet = !!this.privSpeechProcessorScript && this.privSpeechProcessorScript.toLowerCase() === "ignore";
        if (!!context.audioWorklet && !skipAudioWorklet) {
            if (!this.privSpeechProcessorScript) {
                const workletScript = `class SP extends AudioWorkletProcessor {
                    constructor(options) {
                      super(options);
                    }
                    process(inputs, outputs) {
                      const input = inputs[0];
                      const output = [];
                      for (let channel = 0; channel < input.length; channel += 1) {
                        output[channel] = input[channel];
                      }
                      this.port.postMessage(output[0]);
                      return true;
                    }
                  }
                  registerProcessor('speech-processor', SP);`;
                const blob = new Blob([workletScript], { type: "application/javascript; charset=utf-8" });
                this.privSpeechProcessorScript = URL.createObjectURL(blob);
            }
            context.audioWorklet
                .addModule(this.privSpeechProcessorScript)
                .then(() => {
                const workletNode = new AudioWorkletNode(context, "speech-processor");
                workletNode.port.onmessage = (ev) => {
                    const inputFrame = ev.data;
                    if (outputStream && !outputStream.isClosed) {
                        const waveFrame = waveStreamEncoder.encode(inputFrame);
                        if (!!waveFrame) {
                            outputStream.writeStreamChunk({
                                buffer: waveFrame,
                                isEnd: false,
                                timeReceived: Date.now(),
                            });
                        }
                    }
                };
                micInput.connect(workletNode);
                workletNode.connect(context.destination);
                this.privMediaResources = {
                    scriptProcessorNode: workletNode,
                    source: micInput,
                    stream: mediaStream,
                };
            })
                .catch(() => {
                attachScriptProcessor();
            });
        }
        else {
            try {
                attachScriptProcessor();
            }
            catch (err) {
                throw new Error(`Unable to start audio worklet node for PCMRecorder: ${err}`);
            }
        }
    }
    releaseMediaResources(context) {
        if (this.privMediaResources) {
            if (this.privMediaResources.scriptProcessorNode) {
                this.privMediaResources.scriptProcessorNode.disconnect(context.destination);
                this.privMediaResources.scriptProcessorNode = null;
            }
            if (this.privMediaResources.source) {
                this.privMediaResources.source.disconnect();
                if (this.privStopInputOnRelease) {
                    this.privMediaResources.stream.getTracks().forEach((track) => track.stop());
                }
                this.privMediaResources.source = null;
            }
        }
    }
    setWorkletUrl(url) {
        this.privSpeechProcessorScript = url;
    }
}
exports.PcmRecorder = PcmRecorder;

//# sourceMappingURL=PCMRecorder.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ProxyInfo.js"
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ProxyInfo.js ***!
  \*********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ProxyInfo = void 0;
const Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
class ProxyInfo {
    constructor(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
        this.privProxyHostName = proxyHostName;
        this.privProxyPort = proxyPort;
        this.privProxyUserName = proxyUserName;
        this.privProxyPassword = proxyPassword;
    }
    static fromParameters(parameters) {
        return new ProxyInfo(parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyHostName), parseInt(parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyPort), 10), parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyUserName), parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyPassword));
    }
    static fromRecognizerConfig(config) {
        return this.fromParameters(config.parameters);
    }
    get HostName() {
        return this.privProxyHostName;
    }
    get Port() {
        return this.privProxyPort;
    }
    get UserName() {
        return this.privProxyUserName;
    }
    get Password() {
        return this.privProxyPassword;
    }
}
exports.ProxyInfo = ProxyInfo;

//# sourceMappingURL=ProxyInfo.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ReplayableAudioNode.js"
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/ReplayableAudioNode.js ***!
  \*******************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ReplayableAudioNode = void 0;
class ReplayableAudioNode {
    constructor(audioSource, bytesPerSecond) {
        this.privBuffers = [];
        this.privReplayOffset = 0;
        this.privLastShrinkOffset = 0;
        this.privBufferStartOffset = 0;
        this.privBufferSerial = 0;
        this.privBufferedBytes = 0;
        this.privReplay = false;
        this.privLastChunkAcquiredTime = 0;
        this.privAudioNode = audioSource;
        this.privBytesPerSecond = bytesPerSecond;
    }
    id() {
        return this.privAudioNode.id();
    }
    // Reads and returns the next chunk of audio buffer.
    // If replay of existing buffers are needed, read() will first seek and replay
    // existing content, and upoin completion it will read new content from the underlying
    // audio node, saving that content into the replayable buffers.
    read() {
        // if there is a replay request to honor.
        if (!!this.privReplay && this.privBuffers.length !== 0) {
            // Find the start point in the buffers.
            // Offsets are in 100ns increments.
            // So how many bytes do we need to seek to get the right offset?
            const offsetToSeek = this.privReplayOffset - this.privBufferStartOffset;
            let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);
            if (0 !== (bytesToSeek % 2)) {
                bytesToSeek++;
            }
            let i = 0;
            while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {
                bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;
            }
            if (i < this.privBuffers.length) {
                const retVal = this.privBuffers[i].chunk.buffer.slice(bytesToSeek);
                this.privReplayOffset += (retVal.byteLength / this.privBytesPerSecond) * 1e+7;
                // If we've reached the end of the buffers, stop replaying.
                if (i === this.privBuffers.length - 1) {
                    this.privReplay = false;
                }
                return Promise.resolve({
                    buffer: retVal,
                    isEnd: false,
                    timeReceived: this.privBuffers[i].chunk.timeReceived,
                });
            }
        }
        return this.privAudioNode.read()
            .then((result) => {
            if (result && result.buffer && this.privBuffers) {
                this.privBuffers.push(new BufferEntry(result, this.privBufferSerial++, this.privBufferedBytes));
                this.privBufferedBytes += result.buffer.byteLength;
            }
            return result;
        });
    }
    detach() {
        this.privBuffers = undefined;
        return this.privAudioNode.detach();
    }
    replay() {
        if (this.privBuffers && 0 !== this.privBuffers.length) {
            this.privReplay = true;
            this.privReplayOffset = this.privLastShrinkOffset;
        }
    }
    // Shrinks the existing audio buffers to start at the new offset, or at the
    // beginning of the buffer closest to the requested offset.
    // A replay request will start from the last shrink point.
    shrinkBuffers(offset) {
        if (this.privBuffers === undefined || this.privBuffers.length === 0) {
            return;
        }
        this.privLastShrinkOffset = offset;
        // Find the start point in the buffers.
        // Offsets are in 100ns increments.
        // So how many bytes do we need to seek to get the right offset?
        const offsetToSeek = offset - this.privBufferStartOffset;
        let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);
        let i = 0;
        while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {
            bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;
        }
        this.privBufferStartOffset = Math.round(offset - ((bytesToSeek / this.privBytesPerSecond) * 1e+7));
        this.privBuffers = this.privBuffers.slice(i);
    }
    // Finds the time a buffer of audio was first seen by offset.
    findTimeAtOffset(offset) {
        if (offset < this.privBufferStartOffset || this.privBuffers === undefined) {
            return 0;
        }
        for (const value of this.privBuffers) {
            const startOffset = (value.byteOffset / this.privBytesPerSecond) * 1e7;
            const endOffset = startOffset + ((value.chunk.buffer.byteLength / this.privBytesPerSecond) * 1e7);
            if (offset >= startOffset && offset <= endOffset) {
                return value.chunk.timeReceived;
            }
        }
        return 0;
    }
}
exports.ReplayableAudioNode = ReplayableAudioNode;
// Primary use of this class is to help debugging problems with the replay
// code. If the memory cost of alloc / dealloc gets too much, drop it and just use
// the ArrayBuffer directly.
class BufferEntry {
    constructor(chunk, serial, byteOffset) {
        this.chunk = chunk;
        this.serial = serial;
        this.byteOffset = byteOffset;
    }
}

//# sourceMappingURL=ReplayableAudioNode.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestConfigBase.js"
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestConfigBase.js ***!
  \**************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RestConfigBase = void 0;
class RestConfigBase {
    static get requestOptions() {
        return RestConfigBase.privDefaultRequestOptions;
    }
    static get configParams() {
        return RestConfigBase.privDefaultParams;
    }
    static get restErrors() {
        return RestConfigBase.privRestErrors;
    }
}
exports.RestConfigBase = RestConfigBase;
RestConfigBase.privDefaultRequestOptions = {
    headers: {
        Accept: "application/json",
    },
    ignoreCache: false,
    timeout: 10000,
};
RestConfigBase.privRestErrors = {
    authInvalidSubscriptionKey: "You must specify either an authentication token to use, or a Cognitive Speech subscription key.",
    authInvalidSubscriptionRegion: "You must specify the Cognitive Speech region to use.",
    invalidArgs: "Required input not found: {arg}.",
    invalidCreateJoinConversationResponse: "Creating/Joining conversation failed with HTTP {status}.",
    invalidParticipantRequest: "The requested participant was not found.",
    permissionDeniedConnect: "Required credentials not found.",
    permissionDeniedConversation: "Invalid operation: only the host can {command} the conversation.",
    permissionDeniedParticipant: "Invalid operation: only the host can {command} a participant.",
    permissionDeniedSend: "Invalid operation: the conversation is not in a connected state.",
    permissionDeniedStart: "Invalid operation: there is already an active conversation.",
};
RestConfigBase.privDefaultParams = {
    apiVersion: "api-version",
    authorization: "Authorization",
    clientAppId: "X-ClientAppId",
    contentTypeKey: "Content-Type",
    correlationId: "X-CorrelationId",
    languageCode: "language",
    nickname: "nickname",
    profanity: "profanity",
    requestId: "X-RequestId",
    roomId: "roomid",
    sessionToken: "token",
    subscriptionKey: "Ocp-Apim-Subscription-Key",
    subscriptionRegion: "Ocp-Apim-Subscription-Region",
    token: "X-CapitoToken",
};

//# sourceMappingURL=RestConfigBase.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestMessageAdapter.js"
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestMessageAdapter.js ***!
  \******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RestMessageAdapter = exports.RestRequestType = void 0;
const bent_1 = __importDefault(__webpack_require__(/*! bent */ "./node_modules/bent/src/browser.js"));
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
var RestRequestType;
(function (RestRequestType) {
    RestRequestType["Get"] = "GET";
    RestRequestType["Post"] = "POST";
    RestRequestType["Delete"] = "DELETE";
    RestRequestType["File"] = "file";
})(RestRequestType = exports.RestRequestType || (exports.RestRequestType = {}));
// accept rest operations via request method and return abstracted objects from server response
class RestMessageAdapter {
    constructor(configParams) {
        if (!configParams) {
            throw new Exports_js_1.ArgumentNullError("configParams");
        }
        this.privHeaders = configParams.headers;
        this.privIgnoreCache = configParams.ignoreCache;
    }
    static extractHeaderValue(headerKey, headers) {
        let headerValue = "";
        try {
            const arr = headers.trim().split(/[\r\n]+/);
            const headerMap = {};
            arr.forEach((line) => {
                const parts = line.split(": ");
                const header = parts.shift().toLowerCase();
                const value = parts.join(": ");
                headerMap[header] = value;
            });
            headerValue = headerMap[headerKey.toLowerCase()];
        }
        catch (e) {
            // ignore the error
        }
        return headerValue;
    }
    set options(configParams) {
        this.privHeaders = configParams.headers;
        this.privIgnoreCache = configParams.ignoreCache;
    }
    setHeaders(key, value) {
        this.privHeaders[key] = value;
    }
    request(method, uri, queryParams = {}, body = null) {
        const responseReceivedDeferral = new Exports_js_1.Deferred();
        const requestCommand = method === RestRequestType.File ? "POST" : method;
        const handleRestResponse = (data, j = {}) => {
            const d = data;
            return {
                data: JSON.stringify(j),
                headers: JSON.stringify(data.headers),
                json: j,
                ok: data.statusCode >= 200 && data.statusCode < 300,
                status: data.statusCode,
                statusText: j.error ? j.error.message : d.statusText ? d.statusText : d.statusMessage
            };
        };
        const send = (postData) => {
            const sendRequest = (0, bent_1.default)(uri, requestCommand, this.privHeaders, 200, 201, 202, 204, 400, 401, 402, 403, 404);
            const params = this.queryParams(queryParams) === "" ? "" : `?${this.queryParams(queryParams)}`;
            sendRequest(params, postData).then(async (data) => {
                if (method === RestRequestType.Delete || data.statusCode === 204) {
                    // No JSON from Delete and reset (204) operations
                    responseReceivedDeferral.resolve(handleRestResponse(data));
                }
                else {
                    try {
                        const j = await data.json();
                        responseReceivedDeferral.resolve(handleRestResponse(data, j));
                    }
                    catch {
                        responseReceivedDeferral.resolve(handleRestResponse(data));
                    }
                }
            }).catch((error) => {
                responseReceivedDeferral.reject(error);
            });
        };
        if (this.privIgnoreCache) {
            this.privHeaders["Cache-Control"] = "no-cache";
        }
        if (method === RestRequestType.Post && body) {
            this.privHeaders["content-type"] = "application/json";
            this.privHeaders["Content-Type"] = "application/json";
        }
        send(body);
        return responseReceivedDeferral.promise;
    }
    queryParams(params = {}) {
        return Object.keys(params)
            .map((k) => encodeURIComponent(k) + "=" + encodeURIComponent(params[k]))
            .join("&");
    }
}
exports.RestMessageAdapter = RestMessageAdapter;

//# sourceMappingURL=RestMessageAdapter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketConnection.js"
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketConnection.js ***!
  \*******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.WebsocketConnection = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const WebsocketMessageAdapter_js_1 = __webpack_require__(/*! ./WebsocketMessageAdapter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketMessageAdapter.js");
class WebsocketConnection {
    constructor(uri, queryParameters, headers, messageFormatter, proxyInfo, enableCompression = false, connectionId) {
        this.privIsDisposed = false;
        if (!uri) {
            throw new Exports_js_1.ArgumentNullError("uri");
        }
        if (!messageFormatter) {
            throw new Exports_js_1.ArgumentNullError("messageFormatter");
        }
        this.privMessageFormatter = messageFormatter;
        let queryParams = "";
        let i = 0;
        if (queryParameters) {
            for (const paramName in queryParameters) {
                if (paramName) {
                    queryParams += ((i === 0) && (uri.indexOf("?") === -1)) ? "?" : "&";
                    const key = encodeURIComponent(paramName);
                    queryParams += key;
                    let val = queryParameters[paramName];
                    if (val) {
                        val = encodeURIComponent(val);
                        queryParams += `=${val}`;
                    }
                    i++;
                }
            }
        }
        if (headers) {
            for (const headerName in headers) {
                if (headerName) {
                    queryParams += ((i === 0) && (uri.indexOf("?") === -1)) ? "?" : "&";
                    const val = encodeURIComponent(headers[headerName]);
                    queryParams += `${headerName}=${val}`;
                    i++;
                }
            }
        }
        this.privUri = uri + queryParams;
        this.privId = connectionId ? connectionId : (0, Exports_js_1.createNoDashGuid)();
        this.privConnectionMessageAdapter = new WebsocketMessageAdapter_js_1.WebsocketMessageAdapter(this.privUri, this.id, this.privMessageFormatter, proxyInfo, headers, enableCompression);
    }
    async dispose() {
        this.privIsDisposed = true;
        if (this.privConnectionMessageAdapter) {
            await this.privConnectionMessageAdapter.close();
        }
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    get id() {
        return this.privId;
    }
    get uri() {
        return this.privUri;
    }
    state() {
        return this.privConnectionMessageAdapter.state;
    }
    open() {
        return this.privConnectionMessageAdapter.open();
    }
    send(message) {
        return this.privConnectionMessageAdapter.send(message);
    }
    read() {
        return this.privConnectionMessageAdapter.read();
    }
    get events() {
        return this.privConnectionMessageAdapter.events;
    }
}
exports.WebsocketConnection = WebsocketConnection;

//# sourceMappingURL=WebsocketConnection.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketMessageAdapter.js"
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/WebsocketMessageAdapter.js ***!
  \***********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.WebsocketMessageAdapter = void 0;
const net = __importStar(__webpack_require__(/*! net */ "?540f"));
const tls = __importStar(__webpack_require__(/*! tls */ "?71f6"));
const agent_base_1 = __importDefault(__webpack_require__(/*! agent-base */ "?875c"));
const https_proxy_agent_1 = __importDefault(__webpack_require__(/*! https-proxy-agent */ "?a523"));
const ws_1 = __importDefault(__webpack_require__(/*! ws */ "?3dbe"));
const HeaderNames_js_1 = __webpack_require__(/*! ../common.speech/HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
class WebsocketMessageAdapter {
    constructor(uri, connectionId, messageFormatter, proxyInfo, headers, enableCompression) {
        if (!uri) {
            throw new Exports_js_1.ArgumentNullError("uri");
        }
        if (!messageFormatter) {
            throw new Exports_js_1.ArgumentNullError("messageFormatter");
        }
        this.proxyInfo = proxyInfo;
        this.privConnectionEvents = new Exports_js_1.EventSource();
        this.privConnectionId = connectionId;
        this.privMessageFormatter = messageFormatter;
        this.privConnectionState = Exports_js_1.ConnectionState.None;
        this.privUri = uri;
        this.privHeaders = headers;
        this.privEnableCompression = enableCompression;
        // Add the connection ID to the headers
        this.privHeaders[HeaderNames_js_1.HeaderNames.ConnectionId] = this.privConnectionId;
        this.privHeaders.connectionId = this.privConnectionId;
        this.privLastErrorReceived = "";
    }
    get state() {
        return this.privConnectionState;
    }
    open() {
        if (this.privConnectionState === Exports_js_1.ConnectionState.Disconnected) {
            return Promise.reject(`Cannot open a connection that is in ${this.privConnectionState} state`);
        }
        if (this.privConnectionEstablishDeferral) {
            return this.privConnectionEstablishDeferral.promise;
        }
        this.privConnectionEstablishDeferral = new Exports_js_1.Deferred();
        this.privCertificateValidatedDeferral = new Exports_js_1.Deferred();
        this.privConnectionState = Exports_js_1.ConnectionState.Connecting;
        try {
            if (typeof WebSocket !== "undefined" && !WebsocketMessageAdapter.forceNpmWebSocket) {
                // Browser handles cert checks.
                this.privCertificateValidatedDeferral.resolve();
                this.privWebsocketClient = new WebSocket(this.privUri);
            }
            else {
                // Workaround for https://github.com/microsoft/cognitive-services-speech-sdk-js/issues/465
                // Which is root caused by https://github.com/TooTallNate/node-agent-base/issues/61
                const uri = new URL(this.privUri);
                let protocol = uri.protocol;
                if (protocol?.toLocaleLowerCase() === "wss:") {
                    protocol = "https:";
                }
                else if (protocol?.toLocaleLowerCase() === "ws:") {
                    protocol = "http:";
                }
                const options = { headers: this.privHeaders, perMessageDeflate: this.privEnableCompression, followRedirects: protocol.toLocaleLowerCase() === "https:" };
                // The ocsp library will handle validation for us and fail the connection if needed.
                this.privCertificateValidatedDeferral.resolve();
                options.agent = this.getAgent();
                // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
                options.agent.protocol = protocol;
                this.privWebsocketClient = new ws_1.default(this.privUri, options);
                this.privWebsocketClient.on("redirect", (redirectUrl) => {
                    const event = new Exports_js_1.ConnectionRedirectEvent(this.privConnectionId, redirectUrl, this.privUri, `Getting redirect URL from endpoint ${this.privUri} with redirect URL '${redirectUrl}'`);
                    Exports_js_1.Events.instance.onEvent(event);
                });
            }
            this.privWebsocketClient.binaryType = "arraybuffer";
            this.privReceivingMessageQueue = new Exports_js_1.Queue();
            this.privDisconnectDeferral = new Exports_js_1.Deferred();
            this.privSendMessageQueue = new Exports_js_1.Queue();
            this.processSendQueue().catch((reason) => {
                Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));
            });
        }
        catch (error) {
            this.privConnectionEstablishDeferral.resolve(new Exports_js_1.ConnectionOpenResponse(500, error));
            return this.privConnectionEstablishDeferral.promise;
        }
        this.onEvent(new Exports_js_1.ConnectionStartEvent(this.privConnectionId, this.privUri));
        this.privWebsocketClient.onopen = () => {
            this.privCertificateValidatedDeferral.promise.then(() => {
                this.privConnectionState = Exports_js_1.ConnectionState.Connected;
                this.onEvent(new Exports_js_1.ConnectionEstablishedEvent(this.privConnectionId));
                this.privConnectionEstablishDeferral.resolve(new Exports_js_1.ConnectionOpenResponse(200, ""));
            }, (error) => {
                this.privConnectionEstablishDeferral.reject(error);
            });
        };
        this.privWebsocketClient.onerror = (e) => {
            this.onEvent(new Exports_js_1.ConnectionErrorEvent(this.privConnectionId, e.message, e.type));
            this.privLastErrorReceived = e.message;
        };
        this.privWebsocketClient.onclose = (e) => {
            if (this.privConnectionState === Exports_js_1.ConnectionState.Connecting) {
                this.privConnectionState = Exports_js_1.ConnectionState.Disconnected;
                // this.onEvent(new ConnectionEstablishErrorEvent(this.connectionId, e.code, e.reason));
                this.privConnectionEstablishDeferral.resolve(new Exports_js_1.ConnectionOpenResponse(e.code, e.reason + " " + this.privLastErrorReceived));
            }
            else {
                this.privConnectionState = Exports_js_1.ConnectionState.Disconnected;
                this.privWebsocketClient = null;
                this.onEvent(new Exports_js_1.ConnectionClosedEvent(this.privConnectionId, e.code, e.reason));
            }
            this.onClose(e.code, e.reason).catch((reason) => {
                Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));
            });
        };
        this.privWebsocketClient.onmessage = (e) => {
            const networkReceivedTime = new Date().toISOString();
            if (this.privConnectionState === Exports_js_1.ConnectionState.Connected) {
                const deferred = new Exports_js_1.Deferred();
                // let id = ++this.idCounter;
                this.privReceivingMessageQueue.enqueueFromPromise(deferred.promise);
                if (e.data instanceof ArrayBuffer) {
                    const rawMessage = new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Binary, e.data);
                    this.privMessageFormatter
                        .toConnectionMessage(rawMessage)
                        .then((connectionMessage) => {
                        this.onEvent(new Exports_js_1.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));
                        deferred.resolve(connectionMessage);
                    }, (error) => {
                        // TODO: Events for these ?
                        deferred.reject(`Invalid binary message format. Error: ${error}`);
                    });
                }
                else {
                    const rawMessage = new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Text, e.data);
                    this.privMessageFormatter
                        .toConnectionMessage(rawMessage)
                        .then((connectionMessage) => {
                        this.onEvent(new Exports_js_1.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));
                        deferred.resolve(connectionMessage);
                    }, (error) => {
                        // TODO: Events for these ?
                        deferred.reject(`Invalid text message format. Error: ${error}`);
                    });
                }
            }
        };
        return this.privConnectionEstablishDeferral.promise;
    }
    send(message) {
        if (this.privConnectionState !== Exports_js_1.ConnectionState.Connected) {
            return Promise.reject(`Cannot send on connection that is in ${Exports_js_1.ConnectionState[this.privConnectionState]} state`);
        }
        const messageSendStatusDeferral = new Exports_js_1.Deferred();
        const messageSendDeferral = new Exports_js_1.Deferred();
        this.privSendMessageQueue.enqueueFromPromise(messageSendDeferral.promise);
        this.privMessageFormatter
            .fromConnectionMessage(message)
            .then((rawMessage) => {
            messageSendDeferral.resolve({
                Message: message,
                RawWebsocketMessage: rawMessage,
                sendStatusDeferral: messageSendStatusDeferral,
            });
        }, (error) => {
            messageSendDeferral.reject(`Error formatting the message. ${error}`);
        });
        return messageSendStatusDeferral.promise;
    }
    read() {
        if (this.privConnectionState !== Exports_js_1.ConnectionState.Connected) {
            return Promise.reject(`Cannot read on connection that is in ${this.privConnectionState} state`);
        }
        return this.privReceivingMessageQueue.dequeue();
    }
    close(reason) {
        if (this.privWebsocketClient) {
            if (this.privConnectionState !== Exports_js_1.ConnectionState.Disconnected) {
                this.privWebsocketClient.close(1000, reason ? reason : "Normal closure by client");
            }
        }
        else {
            return Promise.resolve();
        }
        return this.privDisconnectDeferral.promise;
    }
    get events() {
        return this.privConnectionEvents;
    }
    sendRawMessage(sendItem) {
        try {
            // indicates we are draining the queue and it came with no message;
            if (!sendItem) {
                return Promise.resolve();
            }
            this.onEvent(new Exports_js_1.ConnectionMessageSentEvent(this.privConnectionId, new Date().toISOString(), sendItem.Message));
            // add a check for the ws readystate in order to stop the red console error 'WebSocket is already in CLOSING or CLOSED state' appearing
            if (this.isWebsocketOpen) {
                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
                this.privWebsocketClient.send(sendItem.RawWebsocketMessage.payload);
            }
            else {
                return Promise.reject("websocket send error: Websocket not ready " + this.privConnectionId + " " + sendItem.Message.id + " " + new Error().stack);
            }
            return Promise.resolve();
        }
        catch (e) {
            return Promise.reject(`websocket send error: ${e}`);
        }
    }
    async onClose(code, reason) {
        const closeReason = `Connection closed. ${code}: ${reason}`;
        this.privConnectionState = Exports_js_1.ConnectionState.Disconnected;
        this.privDisconnectDeferral.resolve();
        await this.privReceivingMessageQueue.drainAndDispose(() => {
            // TODO: Events for these ?
            // Logger.instance.onEvent(new LoggingEvent(LogType.Warning, null, `Failed to process received message. Reason: ${closeReason}, Message: ${JSON.stringify(pendingReceiveItem)}`));
        }, closeReason);
        await this.privSendMessageQueue.drainAndDispose((pendingSendItem) => {
            pendingSendItem.sendStatusDeferral.reject(closeReason);
        }, closeReason);
    }
    async processSendQueue() {
        while (true) {
            const itemToSend = this.privSendMessageQueue.dequeue();
            const sendItem = await itemToSend;
            // indicates we are draining the queue and it came with no message;
            if (!sendItem) {
                return;
            }
            try {
                await this.sendRawMessage(sendItem);
                sendItem.sendStatusDeferral.resolve();
            }
            catch (sendError) {
                sendItem.sendStatusDeferral.reject(sendError);
            }
        }
    }
    onEvent(event) {
        this.privConnectionEvents.onEvent(event);
        Exports_js_1.Events.instance.onEvent(event);
    }
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    getAgent() {
        // eslint-disable-next-line @typescript-eslint/unbound-method
        const agent = new agent_base_1.default.Agent(this.createConnection);
        if (this.proxyInfo !== undefined &&
            this.proxyInfo.HostName !== undefined &&
            this.proxyInfo.Port > 0) {
            agent.proxyInfo = this.proxyInfo;
        }
        return agent;
    }
    static GetProxyAgent(proxyInfo) {
        const httpProxyOptions = {
            host: proxyInfo.HostName,
            port: proxyInfo.Port,
        };
        if (!!proxyInfo.UserName) {
            httpProxyOptions.headers = {
                "Proxy-Authentication": "Basic " + Buffer.from(`${proxyInfo.UserName}:${(proxyInfo.Password === undefined) ? "" : proxyInfo.Password}`).toString("base64"),
            };
        }
        else {
            httpProxyOptions.headers = {};
        }
        httpProxyOptions.headers.requestOCSP = "true";
        const httpProxyAgent = new https_proxy_agent_1.default(httpProxyOptions);
        return httpProxyAgent;
    }
    createConnection(request, options) {
        let socketPromise;
        options = {
            ...options,
            ...{
                requestOCSP: true,
                servername: options.host
            }
        };
        if (!!this.proxyInfo) {
            const httpProxyAgent = WebsocketMessageAdapter.GetProxyAgent(this.proxyInfo);
            const baseAgent = httpProxyAgent;
            socketPromise = new Promise((resolve, reject) => {
                baseAgent.callback(request, options, (error, socket) => {
                    if (!!error) {
                        reject(error);
                    }
                    else {
                        resolve(socket);
                    }
                });
            });
        }
        else {
            if (!!options.secureEndpoint) {
                socketPromise = Promise.resolve(tls.connect(options));
            }
            else {
                socketPromise = Promise.resolve(net.connect(options));
            }
        }
        return socketPromise;
    }
    get isWebsocketOpen() {
        return this.privWebsocketClient && this.privWebsocketClient.readyState === this.privWebsocketClient.OPEN;
    }
}
exports.WebsocketMessageAdapter = WebsocketMessageAdapter;
WebsocketMessageAdapter.forceNpmWebSocket = false;

//# sourceMappingURL=WebsocketMessageAdapter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AgentConfig.js"
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AgentConfig.js ***!
  \**********************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AgentConfig = void 0;
/**
 * Represents the JSON used in the agent.config message sent to the speech service.
 */
class AgentConfig {
    toJsonString() {
        return JSON.stringify(this.iPrivConfig);
    }
    get() {
        return this.iPrivConfig;
    }
    /**
     * Setter for the agent.config object.
     * @param value a JSON serializable object.
     */
    set(value) {
        this.iPrivConfig = value;
    }
}
exports.AgentConfig = AgentConfig;

//# sourceMappingURL=AgentConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AvatarSynthesisAdapter.js"
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AvatarSynthesisAdapter.js ***!
  \*********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AvatarSynthesisAdapter = void 0;
const Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
class AvatarSynthesisAdapter extends Exports_js_2.SynthesisAdapterBase {
    constructor(authentication, connectionFactory, synthesizerConfig, avatarSynthesizer, avatarConfig) {
        super(authentication, connectionFactory, synthesizerConfig, undefined);
        this.privAvatarSynthesizer = avatarSynthesizer;
        this.privSynthesizer = avatarSynthesizer;
        this.privAvatarConfig = avatarConfig;
    }
    setSynthesisContextSynthesisSection() {
        this.privSynthesisContext.setSynthesisSection(undefined);
    }
    setSpeechConfigSynthesisSection() {
        this.privSynthesizerConfig.synthesisVideoSection = {
            format: {
                bitrate: this.privAvatarConfig.videoFormat?.bitrate,
                codec: this.privAvatarConfig.videoFormat?.codec,
                crop: {
                    bottomRight: {
                        x: this.privAvatarConfig.videoFormat?.cropRange?.bottomRight?.x,
                        y: this.privAvatarConfig.videoFormat?.cropRange?.bottomRight?.y,
                    },
                    topLeft: {
                        x: this.privAvatarConfig.videoFormat?.cropRange?.topLeft?.x,
                        y: this.privAvatarConfig.videoFormat?.cropRange?.topLeft?.y,
                    },
                },
                resolution: {
                    height: this.privAvatarConfig.videoFormat?.height,
                    width: this.privAvatarConfig.videoFormat?.width,
                },
            },
            protocol: {
                name: "WebRTC",
                webrtcConfig: {
                    clientDescription: btoa(this.privSynthesizerConfig.parameters.getProperty(Exports_js_1.PropertyId.TalkingAvatarService_WebRTC_SDP)),
                    iceServers: this.privAvatarConfig.remoteIceServers ?? this.privAvatarSynthesizer.iceServers,
                },
            },
            talkingAvatar: {
                background: {
                    color: this.privAvatarConfig.backgroundColor,
                    image: {
                        url: this.privAvatarConfig.backgroundImage?.toString(),
                    }
                },
                character: this.privAvatarConfig.character,
                customized: this.privAvatarConfig.customized,
                photoAvatarBaseModel: this.privAvatarConfig.photoAvatarBaseModel,
                style: this.privAvatarConfig.style,
                useBuiltInVoice: this.privAvatarConfig.useBuiltInVoice,
            }
        };
    }
    onAvatarEvent(metadata) {
        if (!!this.privAvatarSynthesizer.avatarEventReceived) {
            const avatarEventArgs = new Exports_js_1.AvatarEventArgs(metadata.Data.Offset, metadata.Data.Name);
            try {
                this.privAvatarSynthesizer.avatarEventReceived(this.privAvatarSynthesizer, avatarEventArgs);
            }
            catch (error) {
                // Not going to let errors in the event handler
                // trip things up.
            }
        }
    }
}
exports.AvatarSynthesisAdapter = AvatarSynthesisAdapter;

//# sourceMappingURL=AvatarSynthesisAdapter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveSubscriptionKeyAuthentication.js"
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveSubscriptionKeyAuthentication.js ***!
  \*************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CognitiveSubscriptionKeyAuthentication = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const IAuthentication_js_1 = __webpack_require__(/*! ./IAuthentication.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js");
/**
 * @class
 */
class CognitiveSubscriptionKeyAuthentication {
    /**
     * Creates and initializes an instance of the CognitiveSubscriptionKeyAuthentication class.
     * @constructor
     * @param {string} subscriptionKey - The subscription key
     */
    constructor(subscriptionKey) {
        if (!subscriptionKey) {
            throw new Exports_js_1.ArgumentNullError("subscriptionKey");
        }
        this.privAuthInfo = new IAuthentication_js_1.AuthInfo(HeaderNames_js_1.HeaderNames.AuthKey, subscriptionKey);
    }
    /**
     * Fetches the subscription key.
     * @member
     * @function
     * @public
     * @param {string} authFetchEventId - The id to fetch.
     */
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    fetch(authFetchEventId) {
        return Promise.resolve(this.privAuthInfo);
    }
    /**
     * Fetches the subscription key.
     * @member
     * @function
     * @public
     * @param {string} authFetchEventId - The id to fetch.
     */
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    fetchOnExpiry(authFetchEventId) {
        return Promise.resolve(this.privAuthInfo);
    }
}
exports.CognitiveSubscriptionKeyAuthentication = CognitiveSubscriptionKeyAuthentication;

//# sourceMappingURL=CognitiveSubscriptionKeyAuthentication.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveTokenAuthentication.js"
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveTokenAuthentication.js ***!
  \***************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CognitiveTokenAuthentication = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const IAuthentication_js_1 = __webpack_require__(/*! ./IAuthentication.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
class CognitiveTokenAuthentication {
    constructor(fetchCallback, fetchOnExpiryCallback) {
        if (!fetchCallback) {
            throw new Exports_js_1.ArgumentNullError("fetchCallback");
        }
        if (!fetchOnExpiryCallback) {
            throw new Exports_js_1.ArgumentNullError("fetchOnExpiryCallback");
        }
        this.privFetchCallback = fetchCallback;
        this.privFetchOnExpiryCallback = fetchOnExpiryCallback;
    }
    fetch(authFetchEventId) {
        return this.privFetchCallback(authFetchEventId).then((token) => new IAuthentication_js_1.AuthInfo(HeaderNames_js_1.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));
    }
    fetchOnExpiry(authFetchEventId) {
        return this.privFetchOnExpiryCallback(authFetchEventId).then((token) => new IAuthentication_js_1.AuthInfo(HeaderNames_js_1.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));
    }
}
exports.CognitiveTokenAuthentication = CognitiveTokenAuthentication;
CognitiveTokenAuthentication.privTokenPrefix = "Bearer ";

//# sourceMappingURL=CognitiveTokenAuthentication.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js"
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js ***!
  \********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConnectionFactoryBase = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js");
class ConnectionFactoryBase {
    static getHostSuffix(region) {
        if (!!region) {
            if (region.toLowerCase().startsWith("china")) {
                return ".azure.cn";
            }
            if (region.toLowerCase().startsWith("usgov")) {
                return ".azure.us";
            }
        }
        return ".microsoft.com";
    }
    setCommonUrlParams(config, queryParams, endpoint) {
        const propertyIdToParameterMap = new Map([
            [Exports_js_3.PropertyId.Speech_SegmentationSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.SegmentationSilenceTimeoutMs],
            [Exports_js_3.PropertyId.SpeechServiceConnection_EnableAudioLogging, QueryParameterNames_js_1.QueryParameterNames.EnableAudioLogging],
            [Exports_js_3.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.EndSilenceTimeoutMs],
            [Exports_js_3.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.InitialSilenceTimeoutMs],
            [Exports_js_3.PropertyId.SpeechServiceResponse_PostProcessingOption, QueryParameterNames_js_1.QueryParameterNames.Postprocessing],
            [Exports_js_3.PropertyId.SpeechServiceResponse_ProfanityOption, QueryParameterNames_js_1.QueryParameterNames.Profanity],
            [Exports_js_3.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, QueryParameterNames_js_1.QueryParameterNames.EnableWordLevelTimestamps],
            [Exports_js_3.PropertyId.SpeechServiceResponse_StablePartialResultThreshold, QueryParameterNames_js_1.QueryParameterNames.StableIntermediateThreshold],
        ]);
        propertyIdToParameterMap.forEach((parameterName, propertyId) => {
            this.setUrlParameter(propertyId, parameterName, config, queryParams, endpoint);
        });
        const serviceProperties = JSON.parse(config.parameters.getProperty(Exports_js_1.ServicePropertiesPropertyName, "{}"));
        Object.keys(serviceProperties).forEach((value) => {
            queryParams[value] = serviceProperties[value];
        });
    }
    setUrlParameter(propId, parameterName, config, queryParams, endpoint) {
        const value = config.parameters.getProperty(propId, undefined);
        // FIXME: The .search() check will incorrectly match parameter name anywhere in the string
        //        including e.g. the path portion, or even as a substring of other query parameters
        if (value && (!endpoint || endpoint.search(parameterName) === -1)) {
            queryParams[parameterName] = value.toLocaleLowerCase();
        }
    }
    static async getRedirectUrlFromEndpoint(endpoint) {
        // make a rest call to the endpoint to get the redirect url
        const redirectUrl = new URL(endpoint);
        redirectUrl.protocol = "https:";
        redirectUrl.port = "443";
        const params = redirectUrl.searchParams;
        params.append("GenerateRedirectResponse", "true");
        const redirectedUrlString = redirectUrl.toString();
        Exports_js_2.Events.instance.onEvent(new Exports_js_2.ConnectionRedirectEvent("", redirectedUrlString, undefined, "ConnectionFactoryBase: redirectUrl request"));
        const redirectResponse = await fetch(redirectedUrlString);
        if (redirectResponse.status !== 200) {
            return endpoint;
        }
        // Fix: properly read the response text
        const redirectUrlString = await redirectResponse.text();
        Exports_js_2.Events.instance.onEvent(new Exports_js_2.ConnectionRedirectEvent("", redirectUrlString, endpoint, "ConnectionFactoryBase: redirectUrlString"));
        try {
            // Validate the URL before returning
            return new URL(redirectUrlString.trim()).toString();
        }
        catch (error) {
            return endpoint; // Return original endpoint if the redirect URL is invalid
        }
    }
}
exports.ConnectionFactoryBase = ConnectionFactoryBase;

//# sourceMappingURL=ConnectionFactoryBase.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationServiceRecognizer.js"
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationServiceRecognizer.js ***!
  \****************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationServiceRecognizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
class ConversationServiceRecognizer extends Exports_js_2.ServiceRecognizerBase {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);
        this.handleSpeechPhraseMessage = async (textBody) => this.handleSpeechPhrase(textBody);
        this.handleSpeechHypothesisMessage = (textBody) => this.handleSpeechHypothesis(textBody);
    }
    processTypeSpecificMessages(connectionMessage) {
        void connectionMessage;
        return;
    }
    handleRecognizedCallback(result, offset, sessionId) {
        void result;
        void offset;
        void sessionId;
        return;
    }
    handleRecognizingCallback(result, duration, sessionId) {
        void result;
        void duration;
        void sessionId;
        return;
    }
    async processSpeechMessages(connectionMessage) {
        let processed = false;
        switch (connectionMessage.path.toLowerCase()) {
            case "speech.hypothesis":
            case "speech.fragment":
                if (!!this.handleSpeechHypothesisMessage) {
                    this.handleSpeechHypothesisMessage(connectionMessage.textBody);
                }
                processed = true;
                break;
            case "speech.phrase":
                if (!!this.handleSpeechPhraseMessage) {
                    await this.handleSpeechPhraseMessage(connectionMessage.textBody);
                }
                processed = true;
                break;
            default:
                break;
        }
        return processed;
    }
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        // Implementing to allow inheritance
        void sessionId;
        void requestId;
        void cancellationReason;
        void errorCode;
        void error;
    }
    async handleSpeechPhrase(textBody) {
        const simple = Exports_js_2.SimpleSpeechPhrase.fromJSON(textBody, this.privRequestSession.currentTurnAudioOffset);
        const resultReason = Exports_js_2.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);
        let result;
        const resultProps = new Exports_js_1.PropertyCollection();
        resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, textBody);
        this.privRequestSession.onPhraseRecognized(simple.Offset + simple.Duration);
        if (Exports_js_1.ResultReason.Canceled === resultReason) {
            const cancelReason = Exports_js_2.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);
            const cancellationErrorCode = Exports_js_2.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);
            await this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_2.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
        }
        else {
            if (simple.RecognitionStatus !== Exports_js_2.RecognitionStatus.EndOfDictation) {
                if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.OutputFormatPropertyName) === Exports_js_1.OutputFormat[Exports_js_1.OutputFormat.Simple]) {
                    result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, simple.asJson(), resultProps);
                }
                else {
                    const detailed = Exports_js_2.DetailedSpeechPhrase.fromJSON(textBody, this.privRequestSession.currentTurnAudioOffset);
                    result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.Text, detailed.Duration, detailed.Offset, detailed.Language, detailed.LanguageDetectionConfidence, detailed.SpeakerId, undefined, detailed.asJson(), resultProps);
                }
                this.handleRecognizedCallback(result, result.offset, this.privRequestSession.sessionId);
            }
        }
    }
    handleSpeechHypothesis(textBody) {
        const hypothesis = Exports_js_2.SpeechHypothesis.fromJSON(textBody, this.privRequestSession.currentTurnAudioOffset);
        const resultProps = new Exports_js_1.PropertyCollection();
        resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, textBody);
        const result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, Exports_js_1.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, hypothesis.Offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, hypothesis.asJson(), resultProps);
        this.privRequestSession.onHypothesis(hypothesis.Offset);
        this.handleRecognizingCallback(result, hypothesis.Duration, this.privRequestSession.sessionId);
    }
}
exports.ConversationServiceRecognizer = ConversationServiceRecognizer;

//# sourceMappingURL=ConversationServiceRecognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriberConnectionFactory.js"
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriberConnectionFactory.js ***!
  \***************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranscriberConnectionFactory = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js");
const Exports_js_4 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js");
class ConversationTranscriberConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {
    constructor() {
        super(...arguments);
        this.universalUri = "/stt/speech/universal/v2";
        this.conversationRelativeUriV1 = "/speech/recognition/conversation/cognitiveservices/v1";
    }
    async create(config, authInfo, connectionId) {
        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);
        const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, undefined);
        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);
        const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, "wss://" + region + ".stt.speech" + hostSuffix);
        const queryParams = {};
        const endpointId = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, undefined);
        const language = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);
        if (endpointId) {
            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId) === -1) {
                queryParams[QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;
            }
        }
        else if (language) {
            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.Language) === -1) {
                queryParams[QueryParameterNames_js_1.QueryParameterNames.Language] = language;
            }
        }
        if (config.autoDetectSourceLanguages !== undefined) {
            queryParams[QueryParameterNames_js_1.QueryParameterNames.EnableLanguageId] = "true";
        }
        const apiVersion = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, undefined);
        if (apiVersion === "1") {
            endpoint = `${host}${this.universalUri}`;
        }
        else {
            this.setV2UrlParams(config, queryParams, endpoint);
            if (!!endpoint) {
                const endpointUrl = new URL(endpoint);
                const pathName = endpointUrl.pathname;
                if (pathName === "" || pathName === "/") {
                    // We need to generate the path, and we need to check for a redirect.
                    endpointUrl.pathname = this.universalUri;
                    endpoint = await ConnectionFactoryBase_js_1.ConnectionFactoryBase.getRedirectUrlFromEndpoint(endpointUrl.toString());
                }
            }
            if (!endpoint) {
                endpoint = `${host}${this.conversationRelativeUriV1}`;
            }
        }
        const headers = {};
        if (authInfo.token !== undefined && authInfo.token !== "") {
            headers[authInfo.headerName] = authInfo.token;
        }
        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;
        const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
        const webSocketConnection = new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_4.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
        // Set the value of SpeechServiceConnection_Url to webSocketConnection.uri (and not to `endpoint`), since this value is the final
        // URI that was used to make the connection (including query parameters).
        const uri = webSocketConnection.uri;
        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, uri);
        return webSocketConnection;
    }
    setV2UrlParams(config, queryParams, endpoint) {
        const propertyIdToParameterMap = new Map([
            [Exports_js_2.PropertyId.Speech_SegmentationSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.SegmentationSilenceTimeoutMs],
            [Exports_js_2.PropertyId.SpeechServiceConnection_EnableAudioLogging, QueryParameterNames_js_1.QueryParameterNames.EnableAudioLogging],
            [Exports_js_2.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.EndSilenceTimeoutMs],
            [Exports_js_2.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, QueryParameterNames_js_1.QueryParameterNames.InitialSilenceTimeoutMs],
            [Exports_js_2.PropertyId.SpeechServiceResponse_PostProcessingOption, QueryParameterNames_js_1.QueryParameterNames.Postprocessing],
            [Exports_js_2.PropertyId.SpeechServiceResponse_ProfanityOption, QueryParameterNames_js_1.QueryParameterNames.Profanity],
            [Exports_js_2.PropertyId.SpeechServiceResponse_StablePartialResultThreshold, QueryParameterNames_js_1.QueryParameterNames.StableIntermediateThreshold],
        ]);
        propertyIdToParameterMap.forEach((parameterName, propertyId) => {
            this.setUrlParameter(propertyId, parameterName, config, queryParams, endpoint);
        });
        const serviceProperties = JSON.parse(config.parameters.getProperty(Exports_js_3.ServicePropertiesPropertyName, "{}"));
        Object.keys(serviceProperties).forEach((value) => {
            queryParams[value] = serviceProperties[value];
        });
    }
}
exports.ConversationTranscriberConnectionFactory = ConversationTranscriberConnectionFactory;

//# sourceMappingURL=ConversationTranscriberConnectionFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriptionServiceRecognizer.js"
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriptionServiceRecognizer.js ***!
  \*****************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranscriptionServiceRecognizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const SpeakerDiarization_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseDetection/SpeakerDiarization.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/SpeakerDiarization.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
// eslint-disable-next-line max-classes-per-file
class ConversationTranscriptionServiceRecognizer extends Exports_js_2.ServiceRecognizerBase {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationTranscriber) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, conversationTranscriber);
        this.privConversationTranscriber = conversationTranscriber;
        this.setSpeakerDiarizationJson();
    }
    setSpeakerDiarizationJson() {
        if (this.privEnableSpeakerId) {
            const phraseDetection = this.privSpeechContext.getContext().phraseDetection || {};
            phraseDetection.mode = PhraseDetectionContext_js_1.RecognitionMode.Conversation;
            const speakerDiarization = {};
            speakerDiarization.mode = SpeakerDiarization_js_1.SpeakerDiarizationMode.Anonymous;
            speakerDiarization.audioSessionId = this.privDiarizationSessionId;
            speakerDiarization.audioOffsetMs = 0;
            speakerDiarization.diarizeIntermediates = this.privRecognizerConfig.parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_DiarizeIntermediateResults, "false") === "true";
            phraseDetection.speakerDiarization = speakerDiarization;
            this.privSpeechContext.getContext().phraseDetection = phraseDetection;
        }
    }
    async processTypeSpecificMessages(connectionMessage) {
        let result;
        const resultProps = new Exports_js_1.PropertyCollection();
        resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
        let processed = false;
        switch (connectionMessage.path.toLowerCase()) {
            case "speech.hypothesis":
            case "speech.fragment":
                const hypothesis = Exports_js_2.SpeechHypothesis.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                result = new Exports_js_1.ConversationTranscriptionResult(this.privRequestSession.requestId, Exports_js_1.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, hypothesis.Offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, hypothesis.asJson(), resultProps);
                this.privRequestSession.onHypothesis(hypothesis.Offset);
                const ev = new Exports_js_1.ConversationTranscriptionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);
                if (!!this.privConversationTranscriber.transcribing) {
                    try {
                        this.privConversationTranscriber.transcribing(this.privConversationTranscriber, ev);
                        /* eslint-disable no-empty */
                    }
                    catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                    }
                }
                processed = true;
                break;
            case "speech.phrase":
                const simple = Exports_js_2.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                const resultReason = Exports_js_2.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);
                this.privRequestSession.onPhraseRecognized(simple.Offset + simple.Duration);
                if (Exports_js_1.ResultReason.Canceled === resultReason) {
                    const cancelReason = Exports_js_2.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);
                    const cancellationErrorCode = Exports_js_2.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);
                    await this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_2.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
                }
                else {
                    if (!(this.privRequestSession.isSpeechEnded && resultReason === Exports_js_1.ResultReason.NoMatch && simple.RecognitionStatus !== Exports_js_2.RecognitionStatus.InitialSilenceTimeout)) {
                        if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.OutputFormatPropertyName) === Exports_js_1.OutputFormat[Exports_js_1.OutputFormat.Simple]) {
                            result = new Exports_js_1.ConversationTranscriptionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, simple.asJson(), resultProps);
                        }
                        else {
                            const detailed = Exports_js_2.DetailedSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                            result = new Exports_js_1.ConversationTranscriptionResult(this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === Exports_js_2.RecognitionStatus.Success ? detailed.NBest[0].Display : undefined, detailed.Duration, detailed.Offset, detailed.Language, detailed.LanguageDetectionConfidence, simple.SpeakerId, undefined, detailed.asJson(), resultProps);
                        }
                        const event = new Exports_js_1.ConversationTranscriptionEventArgs(result, result.offset, this.privRequestSession.sessionId);
                        if (!!this.privConversationTranscriber.transcribed) {
                            try {
                                this.privConversationTranscriber.transcribed(this.privConversationTranscriber, event);
                                /* eslint-disable no-empty */
                            }
                            catch (error) {
                                // Not going to let errors in the event handler
                                // trip things up.
                            }
                        }
                    }
                }
                processed = true;
                break;
            default:
                break;
        }
        return processed;
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        const properties = new Exports_js_1.PropertyCollection();
        properties.setProperty(Exports_js_2.CancellationErrorCodePropertyName, Exports_js_1.CancellationErrorCode[errorCode]);
        if (!!this.privConversationTranscriber.canceled) {
            const cancelEvent = new Exports_js_1.ConversationTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
            try {
                this.privConversationTranscriber.canceled(this.privConversationTranscriber, cancelEvent);
                /* eslint-disable no-empty */
            }
            catch { }
        }
    }
}
exports.ConversationTranscriptionServiceRecognizer = ConversationTranscriptionServiceRecognizer;

//# sourceMappingURL=ConversationTranscriptionServiceRecognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogConnectorFactory.js"
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogConnectorFactory.js ***!
  \*********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DialogConnectionFactory = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js");
const Exports_js_4 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js");
class DialogConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {
    create(config, authInfo, connectionId) {
        const applicationId = config.parameters.getProperty(Exports_js_3.PropertyId.Conversation_ApplicationId, "");
        const dialogType = config.parameters.getProperty(Exports_js_3.PropertyId.Conversation_DialogType);
        const region = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Region);
        const language = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage, "en-US");
        const requestTurnStatus = config.parameters.getProperty(Exports_js_3.PropertyId.Conversation_Request_Bot_Status_Messages, "true");
        const queryParams = {};
        queryParams[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;
        queryParams[QueryParameterNames_js_1.QueryParameterNames.Format] = config.parameters.getProperty(Exports_js_2.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]).toLowerCase();
        queryParams[QueryParameterNames_js_1.QueryParameterNames.Language] = language;
        queryParams[QueryParameterNames_js_1.QueryParameterNames.RequestBotStatusMessages] = requestTurnStatus;
        if (applicationId) {
            queryParams[QueryParameterNames_js_1.QueryParameterNames.BotId] = applicationId;
            if (dialogType === Exports_js_3.DialogServiceConfig.DialogTypes.CustomCommands) {
                queryParams[HeaderNames_js_1.HeaderNames.CustomCommandsAppId] = applicationId;
            }
        }
        const resourceInfix = dialogType === Exports_js_3.DialogServiceConfig.DialogTypes.CustomCommands ? "commands/"
            : "";
        const version = dialogType === Exports_js_3.DialogServiceConfig.DialogTypes.CustomCommands ? "v1"
            : dialogType === Exports_js_3.DialogServiceConfig.DialogTypes.BotFramework ? "v3"
                : "v0";
        const headers = {};
        if (authInfo.token != null && authInfo.token !== "") {
            headers[authInfo.headerName] = authInfo.token;
        }
        // The URL used for connection is chosen in a priority order of specification:
        //  1. If a custom endpoint is provided, that URL is used verbatim.
        //  2. If a custom host is provided (e.g. "wss://my.custom.endpoint.com:1123"), a URL is constructed from it.
        //  3. If no custom connection details are provided, a URL is constructed from default values.
        let endpoint = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Endpoint, "");
        if (!endpoint) {
            const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);
            const host = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Host, `wss://${region}.${DialogConnectionFactory.BaseUrl}${hostSuffix}`);
            const standardizedHost = host.endsWith("/") ? host : host + "/";
            endpoint = `${standardizedHost}${resourceInfix}${DialogConnectionFactory.ApiKey}/${version}`;
        }
        this.setCommonUrlParams(config, queryParams, endpoint);
        const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
        return Promise.resolve(new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_4.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId));
    }
}
exports.DialogConnectionFactory = DialogConnectionFactory;
DialogConnectionFactory.ApiKey = "api";
DialogConnectionFactory.BaseUrl = "convai.speech";

//# sourceMappingURL=DialogConnectorFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceAdapter.js"
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceAdapter.js ***!
  \*******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DialogServiceAdapter = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const DialogEvents_js_1 = __webpack_require__(/*! ../common/DialogEvents.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DialogEvents.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const AudioOutputFormat_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js");
const Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const DialogServiceTurnStateManager_js_1 = __webpack_require__(/*! ./DialogServiceTurnStateManager.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnStateManager.js");
const Exports_js_4 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const ActivityResponsePayload_js_1 = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/ActivityResponsePayload.js");
const InvocationSource_js_1 = __webpack_require__(/*! ./ServiceMessages/InvocationSource.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/InvocationSource.js");
const KeywordDetection_js_1 = __webpack_require__(/*! ./ServiceMessages/KeywordDetection/KeywordDetection.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/KeywordDetection/KeywordDetection.js");
const SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js");
class DialogServiceAdapter extends Exports_js_4.ServiceRecognizerBase {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector);
        this.privEvents = new Exports_js_2.EventSource();
        this.privDialogServiceConnector = dialogServiceConnector;
        this.receiveMessageOverride = () => this.receiveDialogMessageOverride();
        this.privTurnStateManager = new DialogServiceTurnStateManager_js_1.DialogServiceTurnStateManager();
        this.recognizeOverride =
            (recoMode, successCallback, errorCallback) => this.listenOnce(recoMode, successCallback, errorCallback);
        this.postConnectImplOverride = (connection) => this.dialogConnectImpl(connection);
        this.configConnectionOverride = (connection) => this.configConnection(connection);
        this.disconnectOverride = () => this.privDisconnect();
        this.privDialogAudioSource = audioSource;
        this.agentConfigSent = false;
        this.privLastResult = null;
        this.connectionEvents.attach((connectionEvent) => {
            if (connectionEvent.name === "ConnectionClosedEvent") {
                this.terminateMessageLoop = true;
            }
        });
    }
    async sendMessage(message) {
        const interactionGuid = (0, Exports_js_2.createGuid)();
        const requestId = (0, Exports_js_2.createNoDashGuid)();
        const agentMessage = {
            context: {
                interactionId: interactionGuid
            },
            // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
            messagePayload: JSON.parse(message),
            version: 0.5
        };
        const agentMessageJson = JSON.stringify(agentMessage);
        const connection = await this.fetchConnection();
        await connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, "agent", requestId, "application/json", agentMessageJson));
    }
    async privDisconnect() {
        await this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.NoError, "Disconnecting");
        this.terminateMessageLoop = true;
        this.agentConfigSent = false;
        return;
    }
    processTypeSpecificMessages(connectionMessage) {
        const resultProps = new Exports_js_3.PropertyCollection();
        if (connectionMessage.messageType === Exports_js_2.MessageType.Text) {
            resultProps.setProperty(Exports_js_3.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
        }
        let result;
        let processed;
        switch (connectionMessage.path.toLowerCase()) {
            case "speech.phrase":
                const speechPhrase = Exports_js_4.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                this.privRequestSession.onPhraseRecognized(speechPhrase.Offset + speechPhrase.Duration);
                if (speechPhrase.RecognitionStatus !== Exports_js_4.RecognitionStatus.TooManyRequests && speechPhrase.RecognitionStatus !== Exports_js_4.RecognitionStatus.Error) {
                    const args = this.fireEventForResult(speechPhrase, resultProps);
                    this.privLastResult = args.result;
                    if (!!this.privDialogServiceConnector.recognized) {
                        try {
                            this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, args);
                            /* eslint-disable no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                }
                processed = true;
                break;
            case "speech.hypothesis":
                const hypothesis = Exports_js_4.SpeechHypothesis.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                result = new Exports_js_3.SpeechRecognitionResult(this.privRequestSession.requestId, Exports_js_3.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, hypothesis.Offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, undefined, hypothesis.asJson(), resultProps);
                this.privRequestSession.onHypothesis(hypothesis.Offset);
                const ev = new Exports_js_3.SpeechRecognitionEventArgs(result, hypothesis.Offset, this.privRequestSession.sessionId);
                if (!!this.privDialogServiceConnector.recognizing) {
                    try {
                        this.privDialogServiceConnector.recognizing(this.privDialogServiceConnector, ev);
                        /* eslint-disable no-empty */
                    }
                    catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                    }
                }
                processed = true;
                break;
            case "speech.keyword":
                const keyword = Exports_js_4.SpeechKeyword.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                result = new Exports_js_3.SpeechRecognitionResult(this.privRequestSession.requestId, keyword.Status === "Accepted" ? Exports_js_3.ResultReason.RecognizedKeyword : Exports_js_3.ResultReason.NoMatch, keyword.Text, keyword.Duration, keyword.Offset, undefined, undefined, undefined, undefined, keyword.asJson(), resultProps);
                if (keyword.Status !== "Accepted") {
                    this.privLastResult = result;
                }
                const event = new Exports_js_3.SpeechRecognitionEventArgs(result, result.duration, result.resultId);
                if (!!this.privDialogServiceConnector.recognized) {
                    try {
                        this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, event);
                        /* eslint-disable no-empty */
                    }
                    catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                    }
                }
                processed = true;
                break;
            case "audio":
                {
                    const audioRequestId = connectionMessage.requestId.toUpperCase();
                    const turn = this.privTurnStateManager.GetTurn(audioRequestId);
                    try {
                        // Empty binary message signals end of stream.
                        if (!connectionMessage.binaryBody) {
                            turn.endAudioStream();
                        }
                        else {
                            turn.audioStream.write(connectionMessage.binaryBody);
                        }
                    }
                    catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                    }
                }
                processed = true;
                break;
            case "response":
                {
                    this.handleResponseMessage(connectionMessage);
                }
                processed = true;
                break;
            default:
                break;
        }
        const defferal = new Exports_js_2.Deferred();
        defferal.resolve(processed);
        return defferal.promise;
    }
    // Cancels recognition.
    async cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        this.terminateMessageLoop = true;
        if (!!this.privRequestSession.isRecognizing) {
            await this.privRequestSession.onStopRecognizing();
        }
        if (!!this.privDialogServiceConnector.canceled) {
            const properties = new Exports_js_3.PropertyCollection();
            properties.setProperty(Exports_js_4.CancellationErrorCodePropertyName, Exports_js_3.CancellationErrorCode[errorCode]);
            const cancelEvent = new Exports_js_3.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
            try {
                this.privDialogServiceConnector.canceled(this.privDialogServiceConnector, cancelEvent);
                /* eslint-disable no-empty */
            }
            catch { }
            if (!!this.privSuccessCallback) {
                const result = new Exports_js_3.SpeechRecognitionResult(undefined, // ResultId
                Exports_js_3.ResultReason.Canceled, undefined, // Text
                undefined, // Duration
                undefined, // Offset
                undefined, // Language
                undefined, // Language Detection Confidence
                undefined, // Speaker Id
                error, undefined, // Json
                properties);
                try {
                    this.privSuccessCallback(result);
                    this.privSuccessCallback = undefined;
                    /* eslint-disable no-empty */
                }
                catch { }
            }
        }
    }
    async listenOnce(recoMode, successCallback, errorCallback) {
        this.privRecognizerConfig.recognitionMode = recoMode;
        this.privSuccessCallback = successCallback;
        this.privErrorCallback = errorCallback;
        this.privRequestSession.startNewRecognition();
        this.privRequestSession.listenForServiceTelemetry(this.privDialogAudioSource.events);
        this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);
        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
        const conPromise = this.connectImpl();
        const preAudioPromise = this.sendPreAudioMessages();
        const node = await this.privDialogAudioSource.attach(this.privRequestSession.audioNodeId);
        const format = await this.privDialogAudioSource.format;
        const deviceInfo = await this.privDialogAudioSource.deviceInfo;
        const audioNode = new Exports_js_1.ReplayableAudioNode(node, format.avgBytesPerSec);
        await this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
        this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };
        try {
            await conPromise;
            await preAudioPromise;
        }
        catch (error) {
            await this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.ConnectionFailure, error);
            return Promise.resolve();
        }
        const sessionStartEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);
        if (!!this.privRecognizer.sessionStarted) {
            this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
        }
        const audioSendPromise = this.sendAudio(audioNode);
        // /* eslint-disable no-empty */
        audioSendPromise.then(() => { }, async (error) => {
            await this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);
        });
    }
    // Establishes a websocket connection to the end point.
    dialogConnectImpl(connection) {
        this.privConnectionLoop = this.startMessageLoop();
        return connection;
    }
    receiveDialogMessageOverride() {
        // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages
        const communicationCustodian = new Exports_js_2.Deferred();
        const loop = async () => {
            try {
                const isDisposed = this.isDisposed();
                const terminateMessageLoop = (!this.isDisposed() && this.terminateMessageLoop);
                if (isDisposed || terminateMessageLoop) {
                    // We're done.
                    communicationCustodian.resolve(undefined);
                    return;
                }
                const connection = await this.fetchConnection();
                const message = await connection.read();
                if (!message) {
                    return loop();
                }
                const connectionMessage = SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage.fromConnectionMessage(message);
                switch (connectionMessage.path.toLowerCase()) {
                    case "turn.start":
                        {
                            const turnRequestId = connectionMessage.requestId.toUpperCase();
                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();
                            // turn started by the service
                            if (turnRequestId !== audioSessionReqId) {
                                this.privTurnStateManager.StartTurn(turnRequestId);
                            }
                            else {
                                this.privRequestSession.onServiceTurnStartResponse();
                            }
                        }
                        break;
                    case "speech.startdetected":
                        const speechStartDetected = Exports_js_4.SpeechDetected.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                        const speechStartEventArgs = new Exports_js_3.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);
                        if (!!this.privRecognizer.speechStartDetected) {
                            this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);
                        }
                        break;
                    case "speech.enddetected":
                        let json;
                        if (connectionMessage.textBody.length > 0) {
                            json = connectionMessage.textBody;
                        }
                        else {
                            // If the request was empty, the JSON returned is empty.
                            json = "{ Offset: 0 }";
                        }
                        const speechStopDetected = Exports_js_4.SpeechDetected.fromJSON(json, this.privRequestSession.currentTurnAudioOffset);
                        this.privRequestSession.onServiceRecognized(speechStopDetected.Offset);
                        const speechStopEventArgs = new Exports_js_3.RecognitionEventArgs(speechStopDetected.Offset, this.privRequestSession.sessionId);
                        if (!!this.privRecognizer.speechEndDetected) {
                            this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);
                        }
                        break;
                    case "turn.end":
                        {
                            const turnEndRequestId = connectionMessage.requestId.toUpperCase();
                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();
                            // turn started by the service
                            if (turnEndRequestId !== audioSessionReqId) {
                                this.privTurnStateManager.CompleteTurn(turnEndRequestId);
                            }
                            else {
                                // Audio session turn
                                const sessionStopEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);
                                await this.privRequestSession.onServiceTurnEndResponse(false);
                                if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {
                                    if (!!this.privRecognizer.sessionStopped) {
                                        this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);
                                    }
                                }
                                // report result to promise.
                                if (!!this.privSuccessCallback && this.privLastResult) {
                                    try {
                                        this.privSuccessCallback(this.privLastResult);
                                        this.privLastResult = null;
                                    }
                                    catch (e) {
                                        if (!!this.privErrorCallback) {
                                            this.privErrorCallback(e);
                                        }
                                    }
                                    // Only invoke the call back once.
                                    // and if it's successful don't invoke the
                                    // error after that.
                                    this.privSuccessCallback = undefined;
                                    this.privErrorCallback = undefined;
                                }
                            }
                        }
                        break;
                    default:
                        try {
                            const processed = await this.processTypeSpecificMessages(connectionMessage);
                            if (!processed) {
                                if (!!this.serviceEvents) {
                                    this.serviceEvents.onEvent(new Exports_js_2.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                                }
                            }
                        }
                        catch (e) {
                            //
                        }
                }
                const ret = loop();
                return ret;
            }
            catch (error) {
                this.terminateMessageLoop = true;
                communicationCustodian.resolve();
            }
        };
        loop().catch((reason) => {
            Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(reason));
        });
        return communicationCustodian.promise;
    }
    async startMessageLoop() {
        this.terminateMessageLoop = false;
        try {
            await this.receiveDialogMessageOverride();
        }
        catch (error) {
            await this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);
        }
        return Promise.resolve();
    }
    // Takes an established websocket connection to the endpoint and sends speech configuration information.
    async configConnection(connection) {
        if (this.terminateMessageLoop) {
            this.terminateMessageLoop = false;
            return Promise.reject("Connection to service terminated.");
        }
        await this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());
        await this.sendAgentConfig(connection);
        return connection;
    }
    async sendPreAudioMessages() {
        const connection = await this.fetchConnection();
        this.addKeywordContextData();
        await this.sendSpeechContext(connection, true);
        await this.sendAgentContext(connection);
        await this.sendWaveHeader(connection);
    }
    sendAgentConfig(connection) {
        if (this.agentConfig && !this.agentConfigSent) {
            if (this.privRecognizerConfig
                .parameters
                .getProperty(Exports_js_3.PropertyId.Conversation_DialogType) === Exports_js_3.DialogServiceConfig.DialogTypes.CustomCommands) {
                const config = this.agentConfig.get();
                config.botInfo.commandsCulture = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage, "en-us");
                this.agentConfig.set(config);
            }
            this.onEvent(new DialogEvents_js_1.SendingAgentContextMessageEvent(this.agentConfig));
            const agentConfigJson = this.agentConfig.toJsonString();
            // guard against sending this multiple times on one connection
            this.agentConfigSent = true;
            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, "agent.config", this.privRequestSession.requestId, "application/json", agentConfigJson));
        }
        return;
    }
    sendAgentContext(connection) {
        const guid = (0, Exports_js_2.createGuid)();
        const speechActivityTemplate = this.privDialogServiceConnector.properties.getProperty(Exports_js_3.PropertyId.Conversation_Speech_Activity_Template);
        const agentContext = {
            channelData: "",
            context: {
                interactionId: guid
            },
            messagePayload: typeof speechActivityTemplate === undefined ? undefined : speechActivityTemplate,
            version: 0.5
        };
        const agentContextJson = JSON.stringify(agentContext);
        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, "speech.agent.context", this.privRequestSession.requestId, "application/json", agentContextJson));
    }
    fireEventForResult(serviceResult, properties) {
        const resultReason = Exports_js_4.EnumTranslation.implTranslateRecognitionResult(serviceResult.RecognitionStatus);
        const result = new Exports_js_3.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, serviceResult.DisplayText, serviceResult.Duration, serviceResult.Offset, serviceResult.Language, serviceResult.LanguageDetectionConfidence, undefined, undefined, serviceResult.asJson(), properties);
        const ev = new Exports_js_3.SpeechRecognitionEventArgs(result, serviceResult.Offset, this.privRequestSession.sessionId);
        return ev;
    }
    handleResponseMessage(responseMessage) {
        // "response" messages can contain either "message" (activity) or "MessageStatus" data. Fire the appropriate
        // event according to the message type that's specified.
        const responsePayload = JSON.parse(responseMessage.textBody);
        switch (responsePayload.messageType.toLowerCase()) {
            case "message":
                const responseRequestId = responseMessage.requestId.toUpperCase();
                const activityPayload = ActivityResponsePayload_js_1.ActivityPayloadResponse.fromJSON(responseMessage.textBody);
                const turn = this.privTurnStateManager.GetTurn(responseRequestId);
                // update the conversation Id
                if (activityPayload.conversationId) {
                    const updateAgentConfig = this.agentConfig.get();
                    updateAgentConfig.botInfo.conversationId = activityPayload.conversationId;
                    this.agentConfig.set(updateAgentConfig);
                }
                const pullAudioOutputStream = turn.processActivityPayload(activityPayload, AudioOutputFormat_js_1.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(this.privDialogServiceConnector.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)));
                const activity = new Exports_js_3.ActivityReceivedEventArgs(activityPayload.messagePayload, pullAudioOutputStream);
                if (!!this.privDialogServiceConnector.activityReceived) {
                    try {
                        this.privDialogServiceConnector.activityReceived(this.privDialogServiceConnector, activity);
                        /* eslint-disable-next-line no-empty */
                    }
                    catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                    }
                }
                break;
            case "messagestatus":
                if (!!this.privDialogServiceConnector.turnStatusReceived) {
                    try {
                        this.privDialogServiceConnector.turnStatusReceived(this.privDialogServiceConnector, new Exports_js_3.TurnStatusReceivedEventArgs(responseMessage.textBody));
                        /* eslint-disable-next-line no-empty */
                    }
                    catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                    }
                }
                break;
            default:
                Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(`Unexpected response of type ${responsePayload.messageType}. Ignoring.`));
                break;
        }
    }
    onEvent(event) {
        this.privEvents.onEvent(event);
        Exports_js_2.Events.instance.onEvent(event);
    }
    addKeywordContextData() {
        const keywordPropertyValue = this.privRecognizerConfig.parameters.getProperty("SPEECH-KeywordsToDetect");
        if (keywordPropertyValue === undefined) {
            return;
        }
        const keywordOffsetPropertyValue = this.privRecognizerConfig.parameters
            .getProperty("SPEECH-KeywordsToDetect-Offsets");
        const keywordDurationPropertyValue = this.privRecognizerConfig.parameters
            .getProperty("SPEECH-KeywordsToDetect-Durations");
        const keywords = keywordPropertyValue.split(";");
        const keywordOffsets = keywordOffsetPropertyValue === undefined ? [] : keywordOffsetPropertyValue.split(";");
        const keywordDurations = keywordDurationPropertyValue === undefined ? [] : keywordDurationPropertyValue.split(";");
        const keywordDefinitionArray = [];
        for (let i = 0; i < keywords.length; i++) {
            const definition = {
                text: keywords[i]
            };
            if (i < keywordOffsets.length) {
                definition.startOffset = Number(keywordOffsets[i]);
            }
            if (i < keywordDurations.length) {
                definition.duration = Number(keywordDurations[i]);
            }
            keywordDefinitionArray.push(definition);
        }
        this.speechContext.getContext().invocationSource = InvocationSource_js_1.InvocationSource.VoiceActivationWithKeyword;
        this.speechContext.getContext().keywordDetection = [{
                clientDetectedKeywords: keywordDefinitionArray,
                onReject: { action: KeywordDetection_js_1.OnRejectAction.EndOfTurn },
                type: KeywordDetection_js_1.KeywordDetectionType.StartTrigger
            }];
    }
}
exports.DialogServiceAdapter = DialogServiceAdapter;

//# sourceMappingURL=DialogServiceAdapter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnState.js"
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnState.js ***!
  \*********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DialogServiceTurnState = void 0;
const AudioOutputFormat_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js");
const AudioOutputStream_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js");
const ActivityResponsePayload_js_1 = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/ActivityResponsePayload.js");
class DialogServiceTurnState {
    constructor(manager, requestId) {
        this.privRequestId = requestId;
        this.privIsCompleted = false;
        this.privAudioStream = null;
        this.privTurnManager = manager;
        this.resetTurnEndTimeout();
    }
    get audioStream() {
        // Called when is needed to stream.
        this.resetTurnEndTimeout();
        return this.privAudioStream;
    }
    processActivityPayload(payload, audioFormat) {
        if (payload.messageDataStreamType === ActivityResponsePayload_js_1.MessageDataStreamType.TextToSpeechAudio) {
            this.privAudioStream = AudioOutputStream_js_1.AudioOutputStream.createPullStream();
            this.privAudioStream.format = (audioFormat !== undefined) ? audioFormat : AudioOutputFormat_js_1.AudioOutputFormatImpl.getDefaultOutputFormat();
        }
        return this.privAudioStream;
    }
    endAudioStream() {
        if (this.privAudioStream !== null && !this.privAudioStream.isClosed) {
            this.privAudioStream.close();
        }
    }
    complete() {
        if (this.privTimeoutToken !== undefined) {
            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
            clearTimeout(this.privTimeoutToken);
        }
        this.endAudioStream();
    }
    resetTurnEndTimeout() {
        if (this.privTimeoutToken !== undefined) {
            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
            clearTimeout(this.privTimeoutToken);
        }
        this.privTimeoutToken = setTimeout(() => {
            this.privTurnManager.CompleteTurn(this.privRequestId);
            return;
        }, 2000);
    }
}
exports.DialogServiceTurnState = DialogServiceTurnState;

//# sourceMappingURL=DialogServiceTurnState.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnStateManager.js"
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnStateManager.js ***!
  \****************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DialogServiceTurnStateManager = void 0;
const Error_js_1 = __webpack_require__(/*! ../common/Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js");
const DialogServiceTurnState_js_1 = __webpack_require__(/*! ./DialogServiceTurnState.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceTurnState.js");
class DialogServiceTurnStateManager {
    constructor() {
        this.privTurnMap = new Map();
        return;
    }
    StartTurn(id) {
        if (this.privTurnMap.has(id)) {
            throw new Error_js_1.InvalidOperationError("Service error: There is already a turn with id:" + id);
        }
        const turnState = new DialogServiceTurnState_js_1.DialogServiceTurnState(this, id);
        this.privTurnMap.set(id, turnState);
        return this.privTurnMap.get(id);
    }
    GetTurn(id) {
        return this.privTurnMap.get(id);
    }
    CompleteTurn(id) {
        if (!this.privTurnMap.has(id)) {
            throw new Error_js_1.InvalidOperationError("Service error: Received turn end for an unknown turn id:" + id);
        }
        const turnState = this.privTurnMap.get(id);
        turnState.complete();
        this.privTurnMap.delete(id);
        return turnState;
    }
}
exports.DialogServiceTurnStateManager = DialogServiceTurnStateManager;

//# sourceMappingURL=DialogServiceTurnStateManager.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarBuilder.js"
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarBuilder.js ***!
  \********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DynamicGrammarBuilder = void 0;
const Group_js_1 = __webpack_require__(/*! ./ServiceMessages/Dgi/Group.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Dgi/Group.js");
/**
 * Responsible for building the object to be sent to the speech service to support dynamic grammars.
 * @class DynamicGrammarBuilder
 */
class DynamicGrammarBuilder {
    constructor() {
        this.privWeight = 1.0;
    }
    // Adds one more reference phrases to the dynamic grammar to send.
    // All added phrases are generic phrases.
    addPhrase(phrase) {
        if (!this.privPhrases) {
            this.privPhrases = [];
        }
        if (phrase instanceof Array) {
            this.privPhrases = this.privPhrases.concat(phrase);
        }
        else {
            this.privPhrases.push(phrase);
        }
    }
    // Clears all phrases stored in the current object.
    clearPhrases() {
        this.privPhrases = undefined;
    }
    // Adds one or more reference grammars to the current grammar.
    addReferenceGrammar(grammar) {
        if (!this.privGrammars) {
            this.privGrammars = [];
        }
        if (grammar instanceof Array) {
            this.privGrammars = this.privGrammars.concat(grammar);
        }
        else {
            this.privGrammars.push(grammar);
        }
    }
    // clears all grammars stored on the recognizer.
    clearGrammars() {
        this.privGrammars = undefined;
    }
    // Sets the weight for the dynamic grammar.
    setWeight(weight) {
        this.privWeight = weight;
    }
    // Generates an object that represents the dynamic grammar used by the Speech Service.
    // This is done by building an object with the correct layout based on the phrases and reference grammars added to this instance
    // of a DynamicGrammarBuilder
    generateGrammarObject() {
        if (this.privGrammars === undefined && this.privPhrases === undefined) {
            return undefined;
        }
        const retObj = {};
        retObj.referenceGrammars = this.privGrammars;
        if (undefined !== this.privPhrases && 0 !== this.privPhrases.length) {
            const retPhrases = [];
            this.privPhrases.forEach((value) => {
                retPhrases.push({
                    text: value,
                });
            });
            retObj.groups = [{ type: Group_js_1.GroupType.Generic, items: retPhrases }];
            retObj.bias = this.privWeight;
        }
        return retObj;
    }
}
exports.DynamicGrammarBuilder = DynamicGrammarBuilder;

//# sourceMappingURL=DynamicGrammarBuilder.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/EnumTranslation.js"
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/EnumTranslation.js ***!
  \**************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.EnumTranslation = void 0;
const Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
class EnumTranslation {
    static implTranslateRecognitionResult(recognitionStatus, expectEndOfDictation = false) {
        let reason = Exports_js_1.ResultReason.Canceled;
        switch (recognitionStatus) {
            case Exports_js_2.RecognitionStatus.Success:
                reason = Exports_js_1.ResultReason.RecognizedSpeech;
                break;
            case Exports_js_2.RecognitionStatus.EndOfDictation:
                // If we need the result in EndOfDictation (typically some session level result),
                // translate into RecognizedSpeech, otherwise NoMatch
                reason = expectEndOfDictation ? Exports_js_1.ResultReason.RecognizedSpeech : Exports_js_1.ResultReason.NoMatch;
                break;
            case Exports_js_2.RecognitionStatus.NoMatch:
            case Exports_js_2.RecognitionStatus.InitialSilenceTimeout:
            case Exports_js_2.RecognitionStatus.BabbleTimeout:
                reason = Exports_js_1.ResultReason.NoMatch;
                break;
            case Exports_js_2.RecognitionStatus.Error:
            case Exports_js_2.RecognitionStatus.BadRequest:
            case Exports_js_2.RecognitionStatus.Forbidden:
            default:
                reason = Exports_js_1.ResultReason.Canceled;
                break;
        }
        return reason;
    }
    static implTranslateCancelResult(recognitionStatus) {
        let reason = Exports_js_1.CancellationReason.EndOfStream;
        switch (recognitionStatus) {
            case Exports_js_2.RecognitionStatus.Success:
            case Exports_js_2.RecognitionStatus.EndOfDictation:
            case Exports_js_2.RecognitionStatus.NoMatch:
                reason = Exports_js_1.CancellationReason.EndOfStream;
                break;
            case Exports_js_2.RecognitionStatus.InitialSilenceTimeout:
            case Exports_js_2.RecognitionStatus.BabbleTimeout:
            case Exports_js_2.RecognitionStatus.Error:
            case Exports_js_2.RecognitionStatus.BadRequest:
            case Exports_js_2.RecognitionStatus.Forbidden:
            default:
                reason = Exports_js_1.CancellationReason.Error;
                break;
        }
        return reason;
    }
    static implTranslateCancelErrorCode(recognitionStatus) {
        let reason = Exports_js_1.CancellationErrorCode.NoError;
        switch (recognitionStatus) {
            case Exports_js_2.RecognitionStatus.Error:
                reason = Exports_js_1.CancellationErrorCode.ServiceError;
                break;
            case Exports_js_2.RecognitionStatus.TooManyRequests:
                reason = Exports_js_1.CancellationErrorCode.TooManyRequests;
                break;
            case Exports_js_2.RecognitionStatus.BadRequest:
                reason = Exports_js_1.CancellationErrorCode.BadRequestParameters;
                break;
            case Exports_js_2.RecognitionStatus.Forbidden:
                reason = Exports_js_1.CancellationErrorCode.Forbidden;
                break;
            default:
                reason = Exports_js_1.CancellationErrorCode.NoError;
                break;
        }
        return reason;
    }
    static implTranslateErrorDetails(cancellationErrorCode) {
        let errorDetails = "The speech service encountered an internal error and could not continue.";
        switch (cancellationErrorCode) {
            case Exports_js_1.CancellationErrorCode.Forbidden:
                errorDetails = "The recognizer is using a free subscription that ran out of quota.";
                break;
            case Exports_js_1.CancellationErrorCode.BadRequestParameters:
                errorDetails = "Invalid parameter or unsupported audio format in the request.";
                break;
            case Exports_js_1.CancellationErrorCode.TooManyRequests:
                errorDetails = "The number of parallel requests exceeded the number of allowed concurrent transcriptions.";
                break;
            default:
                break;
        }
        return errorDetails;
    }
}
exports.EnumTranslation = EnumTranslation;

//# sourceMappingURL=EnumTranslation.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AutoDetectSourceLanguagesOpenRangeOptionName = exports.ForceDictationPropertyName = exports.ServicePropertiesPropertyName = exports.CancellationErrorCodePropertyName = exports.OutputFormatPropertyName = exports.SpeechSynthesisAdapter = exports.AvatarSynthesisAdapter = void 0;
// Make sure not to export internal modules.
//
__exportStar(__webpack_require__(/*! ./CognitiveSubscriptionKeyAuthentication.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveSubscriptionKeyAuthentication.js"), exports);
__exportStar(__webpack_require__(/*! ./CognitiveTokenAuthentication.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/CognitiveTokenAuthentication.js"), exports);
__exportStar(__webpack_require__(/*! ./IAuthentication.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js"), exports);
__exportStar(__webpack_require__(/*! ./IConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IConnectionFactory.js"), exports);
__exportStar(__webpack_require__(/*! ./ISynthesisConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ISynthesisConnectionFactory.js"), exports);
__exportStar(__webpack_require__(/*! ./RecognitionEvents.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceRecognizerBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceRecognizerBase.js"), exports);
__exportStar(__webpack_require__(/*! ./ConversationServiceRecognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationServiceRecognizer.js"), exports);
__exportStar(__webpack_require__(/*! ./RecognizerConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognizerConfig.js"), exports);
__exportStar(__webpack_require__(/*! ./SpeechServiceInterfaces.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceInterfaces.js"), exports);
__exportStar(__webpack_require__(/*! ./WebsocketMessageFormatter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/WebsocketMessageFormatter.js"), exports);
__exportStar(__webpack_require__(/*! ./SpeechConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionFactory.js"), exports);
__exportStar(__webpack_require__(/*! ./ConversationTranscriberConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriberConnectionFactory.js"), exports);
__exportStar(__webpack_require__(/*! ./TranscriberConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriberConnectionFactory.js"), exports);
__exportStar(__webpack_require__(/*! ./TranslationConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationConnectionFactory.js"), exports);
__exportStar(__webpack_require__(/*! ./SpeechSynthesisConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisConnectionFactory.js"), exports);
__exportStar(__webpack_require__(/*! ./EnumTranslation.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/EnumTranslation.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/Enums.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Enums.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/TranslationSynthesisEnd.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/TranslationHypothesis.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationHypothesis.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/TranslationPhrase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationPhrase.js"), exports);
__exportStar(__webpack_require__(/*! ./TranslationServiceRecognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationServiceRecognizer.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/SpeechDetected.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechDetected.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/SpeechHypothesis.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechHypothesis.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/SpeechKeyword.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechKeyword.js"), exports);
__exportStar(__webpack_require__(/*! ./SpeechServiceRecognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceRecognizer.js"), exports);
__exportStar(__webpack_require__(/*! ./ConversationTranscriptionServiceRecognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConversationTranscriptionServiceRecognizer.js"), exports);
__exportStar(__webpack_require__(/*! ./TranscriptionServiceRecognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriptionServiceRecognizer.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/DetailedSpeechPhrase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/SimpleSpeechPhrase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js"), exports);
__exportStar(__webpack_require__(/*! ./RequestSession.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RequestSession.js"), exports);
__exportStar(__webpack_require__(/*! ./SpeechContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechContext.js"), exports);
__exportStar(__webpack_require__(/*! ./DynamicGrammarBuilder.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DynamicGrammarBuilder.js"), exports);
__exportStar(__webpack_require__(/*! ./DialogServiceAdapter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogServiceAdapter.js"), exports);
__exportStar(__webpack_require__(/*! ./AgentConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AgentConfig.js"), exports);
__exportStar(__webpack_require__(/*! ./Transcription/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/Exports.js"), exports);
__exportStar(__webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js"), exports);
__exportStar(__webpack_require__(/*! ./SynthesisTurn.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisTurn.js"), exports);
__exportStar(__webpack_require__(/*! ./SynthesisAdapterBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisAdapterBase.js"), exports);
var AvatarSynthesisAdapter_js_1 = __webpack_require__(/*! ./AvatarSynthesisAdapter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/AvatarSynthesisAdapter.js");
Object.defineProperty(exports, "AvatarSynthesisAdapter", ({ enumerable: true, get: function () { return AvatarSynthesisAdapter_js_1.AvatarSynthesisAdapter; } }));
var SpeechSynthesisAdapter_js_1 = __webpack_require__(/*! ./SpeechSynthesisAdapter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisAdapter.js");
Object.defineProperty(exports, "SpeechSynthesisAdapter", ({ enumerable: true, get: function () { return SpeechSynthesisAdapter_js_1.SpeechSynthesisAdapter; } }));
__exportStar(__webpack_require__(/*! ./SynthesisRestAdapter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisRestAdapter.js"), exports);
__exportStar(__webpack_require__(/*! ./SynthesizerConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesizerConfig.js"), exports);
__exportStar(__webpack_require__(/*! ./SynthesisContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js"), exports);
__exportStar(__webpack_require__(/*! ./SpeechServiceConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceConfig.js"), exports);
exports.OutputFormatPropertyName = "OutputFormat";
exports.CancellationErrorCodePropertyName = "CancellationErrorCode";
exports.ServicePropertiesPropertyName = "ServiceProperties";
exports.ForceDictationPropertyName = "ForceDictation";
exports.AutoDetectSourceLanguagesOpenRangeOptionName = "UND";

//# sourceMappingURL=Exports.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js"
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js ***!
  \**********************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.HeaderNames = void 0;
class HeaderNames {
}
exports.HeaderNames = HeaderNames;
HeaderNames.AuthKey = "Ocp-Apim-Subscription-Key";
HeaderNames.Authorization = "Authorization";
HeaderNames.SpIDAuthKey = "Apim-Subscription-Id";
HeaderNames.ConnectionId = "X-ConnectionId";
HeaderNames.ContentType = "Content-Type";
HeaderNames.CustomCommandsAppId = "X-CommandsAppId";
HeaderNames.Path = "Path";
HeaderNames.RequestId = "X-RequestId";
HeaderNames.RequestStreamId = "X-StreamId";
HeaderNames.RequestTimestamp = "X-Timestamp";

//# sourceMappingURL=HeaderNames.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js"
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IAuthentication.js ***!
  \**************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AuthInfo = void 0;
class AuthInfo {
    constructor(headerName, token) {
        this.privHeaderName = headerName;
        this.privToken = token;
    }
    get headerName() {
        return this.privHeaderName;
    }
    get token() {
        return this.privToken;
    }
}
exports.AuthInfo = AuthInfo;

//# sourceMappingURL=IAuthentication.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IConnectionFactory.js"
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/IConnectionFactory.js ***!
  \*****************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IConnectionFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ISynthesisConnectionFactory.js"
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ISynthesisConnectionFactory.js ***!
  \**************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=ISynthesisConnectionFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js"
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js ***!
  \******************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.QueryParameterNames = void 0;
class QueryParameterNames {
}
exports.QueryParameterNames = QueryParameterNames;
QueryParameterNames.BotId = "botid";
QueryParameterNames.CustomSpeechDeploymentId = "cid";
QueryParameterNames.CustomVoiceDeploymentId = "deploymentId";
QueryParameterNames.EnableAudioLogging = "storeAudio";
QueryParameterNames.EnableLanguageId = "lidEnabled";
QueryParameterNames.EnableWordLevelTimestamps = "wordLevelTimestamps";
QueryParameterNames.EndSilenceTimeoutMs = "endSilenceTimeoutMs";
QueryParameterNames.SegmentationSilenceTimeoutMs = "segmentationSilenceTimeoutMs";
QueryParameterNames.SegmentationMaximumTimeMs = "segmentationMaximumTimeMs";
QueryParameterNames.SegmentationStrategy = "segmentationStrategy";
QueryParameterNames.Format = "format";
QueryParameterNames.InitialSilenceTimeoutMs = "initialSilenceTimeoutMs";
QueryParameterNames.Language = "language";
QueryParameterNames.Profanity = "profanity";
QueryParameterNames.RequestBotStatusMessages = "enableBotMessageStatus";
QueryParameterNames.StableIntermediateThreshold = "stableIntermediateThreshold";
QueryParameterNames.StableTranslation = "stableTranslation";
QueryParameterNames.TestHooks = "testhooks";
QueryParameterNames.Postprocessing = "postprocessing";
QueryParameterNames.CtsMeetingId = "meetingId";
QueryParameterNames.CtsDeviceId = "deviceId";
QueryParameterNames.CtsIsParticipant = "isParticipant";
QueryParameterNames.EnableAvatar = "enableTalkingAvatar";

//# sourceMappingURL=QueryParameterNames.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js"
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js ***!
  \****************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RecognitionEndedEvent = exports.RecognitionCompletionStatus = exports.RecognitionStartedEvent = exports.ConnectingToServiceEvent = exports.ListeningStartedEvent = exports.RecognitionTriggeredEvent = exports.SpeechRecognitionEvent = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
class SpeechRecognitionEvent extends Exports_js_1.PlatformEvent {
    constructor(eventName, requestId, sessionId, eventType = Exports_js_1.EventType.Info) {
        super(eventName, eventType);
        this.privRequestId = requestId;
        this.privSessionId = sessionId;
    }
    get requestId() {
        return this.privRequestId;
    }
    get sessionId() {
        return this.privSessionId;
    }
}
exports.SpeechRecognitionEvent = SpeechRecognitionEvent;
class RecognitionTriggeredEvent extends SpeechRecognitionEvent {
    constructor(requestId, sessionId, audioSourceId, audioNodeId) {
        super("RecognitionTriggeredEvent", requestId, sessionId);
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
}
exports.RecognitionTriggeredEvent = RecognitionTriggeredEvent;
class ListeningStartedEvent extends SpeechRecognitionEvent {
    constructor(requestId, sessionId, audioSourceId, audioNodeId) {
        super("ListeningStartedEvent", requestId, sessionId);
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
}
exports.ListeningStartedEvent = ListeningStartedEvent;
class ConnectingToServiceEvent extends SpeechRecognitionEvent {
    constructor(requestId, authFetchEventid, sessionId) {
        super("ConnectingToServiceEvent", requestId, sessionId);
        this.privAuthFetchEventid = authFetchEventid;
    }
    get authFetchEventid() {
        return this.privAuthFetchEventid;
    }
}
exports.ConnectingToServiceEvent = ConnectingToServiceEvent;
class RecognitionStartedEvent extends SpeechRecognitionEvent {
    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId) {
        super("RecognitionStartedEvent", requestId, sessionId);
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
        this.privAuthFetchEventId = authFetchEventId;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
    get authFetchEventId() {
        return this.privAuthFetchEventId;
    }
}
exports.RecognitionStartedEvent = RecognitionStartedEvent;
var RecognitionCompletionStatus;
(function (RecognitionCompletionStatus) {
    RecognitionCompletionStatus[RecognitionCompletionStatus["Success"] = 0] = "Success";
    RecognitionCompletionStatus[RecognitionCompletionStatus["AudioSourceError"] = 1] = "AudioSourceError";
    RecognitionCompletionStatus[RecognitionCompletionStatus["AudioSourceTimeout"] = 2] = "AudioSourceTimeout";
    RecognitionCompletionStatus[RecognitionCompletionStatus["AuthTokenFetchError"] = 3] = "AuthTokenFetchError";
    RecognitionCompletionStatus[RecognitionCompletionStatus["AuthTokenFetchTimeout"] = 4] = "AuthTokenFetchTimeout";
    RecognitionCompletionStatus[RecognitionCompletionStatus["UnAuthorized"] = 5] = "UnAuthorized";
    RecognitionCompletionStatus[RecognitionCompletionStatus["ConnectTimeout"] = 6] = "ConnectTimeout";
    RecognitionCompletionStatus[RecognitionCompletionStatus["ConnectError"] = 7] = "ConnectError";
    RecognitionCompletionStatus[RecognitionCompletionStatus["ClientRecognitionActivityTimeout"] = 8] = "ClientRecognitionActivityTimeout";
    RecognitionCompletionStatus[RecognitionCompletionStatus["UnknownError"] = 9] = "UnknownError";
})(RecognitionCompletionStatus = exports.RecognitionCompletionStatus || (exports.RecognitionCompletionStatus = {}));
class RecognitionEndedEvent extends SpeechRecognitionEvent {
    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId, serviceTag, status, error) {
        super("RecognitionEndedEvent", requestId, sessionId, status === RecognitionCompletionStatus.Success ? Exports_js_1.EventType.Info : Exports_js_1.EventType.Error);
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
        this.privAuthFetchEventId = authFetchEventId;
        this.privStatus = status;
        this.privError = error;
        this.privServiceTag = serviceTag;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
    get authFetchEventId() {
        return this.privAuthFetchEventId;
    }
    get serviceTag() {
        return this.privServiceTag;
    }
    get status() {
        return this.privStatus;
    }
    get error() {
        return this.privError;
    }
}
exports.RecognitionEndedEvent = RecognitionEndedEvent;

//# sourceMappingURL=RecognitionEvents.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognizerConfig.js"
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognizerConfig.js ***!
  \***************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RecognizerConfig = exports.SpeechResultFormat = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
var SpeechResultFormat;
(function (SpeechResultFormat) {
    SpeechResultFormat[SpeechResultFormat["Simple"] = 0] = "Simple";
    SpeechResultFormat[SpeechResultFormat["Detailed"] = 1] = "Detailed";
})(SpeechResultFormat = exports.SpeechResultFormat || (exports.SpeechResultFormat = {}));
class RecognizerConfig {
    constructor(speechServiceConfig, parameters) {
        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new Exports_js_2.SpeechServiceConfig(new Exports_js_2.Context(null));
        this.privParameters = parameters;
        this.privMaxRetryCount = parseInt(parameters.getProperty("SPEECH-Error-MaxRetryCount", "4"), 10);
        this.privLanguageIdMode = parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_LanguageIdMode, undefined);
        this.privEnableSpeakerId = false;
    }
    get parameters() {
        return this.privParameters;
    }
    get recognitionMode() {
        return this.privRecognitionMode;
    }
    set recognitionMode(value) {
        this.privRecognitionMode = value;
        this.privRecognitionActivityTimeout = value === PhraseDetectionContext_js_1.RecognitionMode.Interactive ? 8000 : 25000;
        this.privSpeechServiceConfig.Recognition = PhraseDetectionContext_js_1.RecognitionMode[value];
    }
    get SpeechServiceConfig() {
        return this.privSpeechServiceConfig;
    }
    get recognitionActivityTimeout() {
        return this.privRecognitionActivityTimeout;
    }
    get isContinuousRecognition() {
        return this.privRecognitionMode !== PhraseDetectionContext_js_1.RecognitionMode.Interactive;
    }
    get languageIdMode() {
        return this.privLanguageIdMode;
    }
    get autoDetectSourceLanguages() {
        return this.parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, undefined);
    }
    get recognitionEndpointVersion() {
        return this.parameters.getProperty(Exports_js_1.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, "2");
    }
    set recognitionEndpointVersion(version) {
        this.parameters.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, version);
    }
    get sourceLanguageModels() {
        const models = [];
        let modelsExist = false;
        if (this.autoDetectSourceLanguages !== undefined) {
            for (const language of this.autoDetectSourceLanguages.split(",")) {
                const customProperty = language + Exports_js_1.PropertyId.SpeechServiceConnection_EndpointId.toString();
                const modelId = this.parameters.getProperty(customProperty, undefined);
                if (modelId !== undefined) {
                    models.push({ language, endpoint: modelId });
                    modelsExist = true;
                }
                else {
                    models.push({ language, endpoint: "" });
                }
            }
        }
        return modelsExist ? models : undefined;
    }
    get maxRetryCount() {
        return this.privMaxRetryCount;
    }
    get isSpeakerDiarizationEnabled() {
        return this.privEnableSpeakerId;
    }
    set isSpeakerDiarizationEnabled(value) {
        this.privEnableSpeakerId = value;
    }
}
exports.RecognizerConfig = RecognizerConfig;

//# sourceMappingURL=RecognizerConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RequestSession.js"
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RequestSession.js ***!
  \*************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RequestSession = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const RecognitionEvents_js_1 = __webpack_require__(/*! ./RecognitionEvents.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js");
const ServiceTelemetryListener_Internal_js_1 = __webpack_require__(/*! ./ServiceTelemetryListener.Internal.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceTelemetryListener.Internal.js");
class RequestSession {
    constructor(audioSourceId) {
        this.privIsDisposed = false;
        this.privDetachables = new Array();
        this.privIsAudioNodeDetached = false;
        this.privIsRecognizing = false;
        this.privIsSpeechEnded = false;
        this.privTurnStartAudioOffset = 0;
        this.privLastRecoOffset = 0;
        this.privHypothesisReceived = false;
        this.privBytesSent = 0;
        this.privRecognitionBytesSent = 0;
        this.privRecogNumber = 0;
        this.privInTurn = false;
        this.privConnectionAttempts = 0;
        this.privAudioSourceId = audioSourceId;
        this.privRequestId = (0, Exports_js_1.createNoDashGuid)();
        this.privAudioNodeId = (0, Exports_js_1.createNoDashGuid)();
        this.privTurnDeferral = new Exports_js_1.Deferred();
        // We're not in a turn, so resolve.
        this.privTurnDeferral.resolve();
    }
    get sessionId() {
        return this.privSessionId;
    }
    get requestId() {
        return this.privRequestId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
    get turnCompletionPromise() {
        return this.privTurnDeferral.promise;
    }
    get isSpeechEnded() {
        return this.privIsSpeechEnded;
    }
    get isRecognizing() {
        return this.privIsRecognizing;
    }
    get currentTurnAudioOffset() {
        return this.privTurnStartAudioOffset;
    }
    get recogNumber() {
        return this.privRecogNumber;
    }
    get numConnectionAttempts() {
        return this.privConnectionAttempts;
    }
    // The number of bytes sent for the current connection.
    // Counter is reset to 0 each time a connection is established.
    get bytesSent() {
        return this.privBytesSent;
    }
    // The number of bytes sent for the current recognition.
    // Counter is reset to 0 each time recognition is started.
    get recognitionBytesSent() {
        return this.privRecognitionBytesSent;
    }
    listenForServiceTelemetry(eventSource) {
        if (!!this.privServiceTelemetryListener) {
            this.privDetachables.push(eventSource.attachListener(this.privServiceTelemetryListener));
        }
    }
    startNewRecognition() {
        this.privRecognitionBytesSent = 0;
        this.privIsSpeechEnded = false;
        this.privIsRecognizing = true;
        this.privTurnStartAudioOffset = 0;
        this.privLastRecoOffset = 0;
        this.privRecogNumber++;
        this.privServiceTelemetryListener = new ServiceTelemetryListener_Internal_js_1.ServiceTelemetryListener(this.privRequestId, this.privAudioSourceId, this.privAudioNodeId);
        this.onEvent(new RecognitionEvents_js_1.RecognitionTriggeredEvent(this.requestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));
    }
    async onAudioSourceAttachCompleted(audioNode, isError) {
        this.privAudioNode = audioNode;
        this.privIsAudioNodeDetached = false;
        if (isError) {
            await this.onComplete();
        }
        else {
            this.onEvent(new RecognitionEvents_js_1.ListeningStartedEvent(this.privRequestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));
        }
    }
    onPreConnectionStart(authFetchEventId, connectionId) {
        this.privAuthFetchEventId = authFetchEventId;
        this.privSessionId = connectionId;
        this.onEvent(new RecognitionEvents_js_1.ConnectingToServiceEvent(this.privRequestId, this.privAuthFetchEventId, this.privSessionId));
    }
    async onAuthCompleted(isError) {
        if (isError) {
            await this.onComplete();
        }
    }
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    async onConnectionEstablishCompleted(statusCode, reason) {
        if (statusCode === 200) {
            this.onEvent(new RecognitionEvents_js_1.RecognitionStartedEvent(this.requestId, this.privAudioSourceId, this.privAudioNodeId, this.privAuthFetchEventId, this.privSessionId));
            if (!!this.privAudioNode) {
                this.privAudioNode.replay();
            }
            this.privTurnStartAudioOffset = this.privLastRecoOffset;
            this.privBytesSent = 0;
            return;
        }
        else if (statusCode === 403) {
            await this.onComplete();
        }
    }
    async onServiceTurnEndResponse(continuousRecognition) {
        this.privTurnDeferral.resolve();
        if (!continuousRecognition || this.isSpeechEnded) {
            await this.onComplete();
            this.privInTurn = false;
        }
        else {
            // Start a new request set.
            this.privTurnStartAudioOffset = this.privLastRecoOffset;
            this.privAudioNode.replay();
        }
    }
    onSpeechContext() {
        this.privRequestId = (0, Exports_js_1.createNoDashGuid)();
    }
    onServiceTurnStartResponse() {
        if (!!this.privTurnDeferral && !!this.privInTurn) {
            // What? How are we starting a turn with another not done?
            this.privTurnDeferral.reject("Another turn started before current completed.");
            // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited
            // eslint-disable-next-line @typescript-eslint/no-empty-function
            this.privTurnDeferral.promise.then().catch(() => { });
        }
        this.privInTurn = true;
        this.privTurnDeferral = new Exports_js_1.Deferred();
    }
    onHypothesis(offset) {
        if (!this.privHypothesisReceived) {
            this.privHypothesisReceived = true;
            this.privServiceTelemetryListener.hypothesisReceived(this.privAudioNode.findTimeAtOffset(offset));
        }
    }
    onPhraseRecognized(offset) {
        this.privServiceTelemetryListener.phraseReceived(this.privAudioNode.findTimeAtOffset(offset));
        this.onServiceRecognized(offset);
    }
    onServiceRecognized(offset) {
        this.privLastRecoOffset = offset;
        this.privHypothesisReceived = false;
        this.privAudioNode.shrinkBuffers(offset);
        this.privConnectionAttempts = 0;
    }
    onAudioSent(bytesSent) {
        this.privBytesSent += bytesSent;
        this.privRecognitionBytesSent += bytesSent;
    }
    onRetryConnection() {
        this.privConnectionAttempts++;
    }
    async dispose() {
        if (!this.privIsDisposed) {
            // we should have completed by now. If we did not its an unknown error.
            this.privIsDisposed = true;
            for (const detachable of this.privDetachables) {
                await detachable.detach();
            }
            if (!!this.privServiceTelemetryListener) {
                this.privServiceTelemetryListener.dispose();
            }
            this.privIsRecognizing = false;
        }
    }
    getTelemetry() {
        if (this.privServiceTelemetryListener.hasTelemetry) {
            return this.privServiceTelemetryListener.getTelemetry();
        }
        else {
            return null;
        }
    }
    async onStopRecognizing() {
        await this.onComplete();
    }
    // Should be called with the audioNode for this session has indicated that it is out of speech.
    onSpeechEnded() {
        this.privIsSpeechEnded = true;
    }
    onEvent(event) {
        if (!!this.privServiceTelemetryListener) {
            this.privServiceTelemetryListener.onEvent(event);
        }
        Exports_js_1.Events.instance.onEvent(event);
    }
    async onComplete() {
        if (!!this.privIsRecognizing) {
            this.privIsRecognizing = false;
            await this.detachAudioNode();
        }
    }
    async detachAudioNode() {
        if (!this.privIsAudioNodeDetached) {
            this.privIsAudioNodeDetached = true;
            if (this.privAudioNode) {
                await this.privAudioNode.detach();
            }
        }
    }
}
exports.RequestSession = RequestSession;

//# sourceMappingURL=RequestSession.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/ActivityResponsePayload.js"
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/ActivityResponsePayload.js ***!
  \**************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// response
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MessageDataStreamType = exports.ActivityPayloadResponse = void 0;
class ActivityPayloadResponse {
    constructor(json) {
        this.privActivityResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new ActivityPayloadResponse(json);
    }
    get conversationId() {
        return this.privActivityResponse.conversationId;
    }
    get messageDataStreamType() {
        return this.privActivityResponse.messageDataStreamType;
    }
    get messagePayload() {
        return this.privActivityResponse.messagePayload;
    }
    get version() {
        return this.privActivityResponse.version;
    }
}
exports.ActivityPayloadResponse = ActivityPayloadResponse;
var MessageDataStreamType;
(function (MessageDataStreamType) {
    MessageDataStreamType[MessageDataStreamType["None"] = 0] = "None";
    MessageDataStreamType[MessageDataStreamType["TextToSpeechAudio"] = 1] = "TextToSpeechAudio";
})(MessageDataStreamType = exports.MessageDataStreamType || (exports.MessageDataStreamType = {}));

//# sourceMappingURL=ActivityResponsePayload.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js"
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js ***!
  \***********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DetailedSpeechPhrase = void 0;
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
class DetailedSpeechPhrase {
    constructor(json, baseOffset) {
        this.privDetailedSpeechPhrase = JSON.parse(json);
        this.privDetailedSpeechPhrase.RecognitionStatus = this.mapRecognitionStatus(this.privDetailedSpeechPhrase.RecognitionStatus);
        this.updateOffsets(baseOffset);
    }
    static fromJSON(json, baseOffset) {
        return new DetailedSpeechPhrase(json, baseOffset);
    }
    updateOffsets(baseOffset) {
        this.privDetailedSpeechPhrase.Offset += baseOffset;
        if (!!this.privDetailedSpeechPhrase.NBest) {
            for (const phrase of this.privDetailedSpeechPhrase.NBest) {
                if (!!phrase.Words) {
                    for (const word of phrase.Words) {
                        word.Offset += baseOffset;
                    }
                }
                if (!!phrase.DisplayWords) {
                    for (const word of phrase.DisplayWords) {
                        word.Offset += baseOffset;
                    }
                }
            }
        }
    }
    asJson() {
        const jsonObj = { ...this.privDetailedSpeechPhrase };
        // Convert the enum value to its string representation for serialization purposes.
        return JSON.stringify({
            ...jsonObj,
            RecognitionStatus: Exports_js_1.RecognitionStatus[jsonObj.RecognitionStatus]
        });
    }
    get RecognitionStatus() {
        return this.privDetailedSpeechPhrase.RecognitionStatus;
    }
    get NBest() {
        return this.privDetailedSpeechPhrase.NBest;
    }
    get Duration() {
        return this.privDetailedSpeechPhrase.Duration;
    }
    get Offset() {
        return this.privDetailedSpeechPhrase.Offset;
    }
    get Language() {
        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Language;
    }
    get LanguageDetectionConfidence() {
        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Confidence;
    }
    get Text() {
        if (!!this.privDetailedSpeechPhrase.NBest && this.privDetailedSpeechPhrase.NBest[0]) {
            return this.privDetailedSpeechPhrase.NBest[0].Display || this.privDetailedSpeechPhrase.NBest[0].DisplayText;
        }
        return this.privDetailedSpeechPhrase.DisplayText;
    }
    get SpeakerId() {
        return this.privDetailedSpeechPhrase.SpeakerId;
    }
    mapRecognitionStatus(status) {
        if (typeof status === "string") {
            return Exports_js_1.RecognitionStatus[status];
        }
        else if (typeof status === "number") {
            return status;
        }
    }
}
exports.DetailedSpeechPhrase = DetailedSpeechPhrase;

//# sourceMappingURL=DetailedSpeechPhrase.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Dgi/Group.js"
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Dgi/Group.js ***!
  \************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SubstringMatchType = exports.GroupType = void 0;
/**
 * Represents the type of the Intent.
 */
var GroupType;
(function (GroupType) {
    GroupType["IntentText"] = "IntentText";
    GroupType["IntentEntity"] = "IntentEntity";
    GroupType["Generic"] = "Generic";
    GroupType["People"] = "People";
    GroupType["Place"] = "Place";
    GroupType["DynamicEntity"] = "DynamicEntity";
})(GroupType = exports.GroupType || (exports.GroupType = {}));
/**
 * Represents the type of the substring match.
 */
var SubstringMatchType;
(function (SubstringMatchType) {
    SubstringMatchType["None"] = "None";
    SubstringMatchType["LeftRooted"] = "LeftRooted";
    SubstringMatchType["PartialName"] = "PartialName";
    SubstringMatchType["MiddleOfSentence"] = "MiddleOfSentence";
})(SubstringMatchType = exports.SubstringMatchType || (exports.SubstringMatchType = {}));

//# sourceMappingURL=Group.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Enums.js"
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Enums.js ***!
  \********************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RecognitionStatus = exports.SynthesisStatus = void 0;
/**
 * @class SynthesisStatus
 * @private
 */
var SynthesisStatus;
(function (SynthesisStatus) {
    /**
     * The response contains valid audio data.
     * @member SynthesisStatus.Success
     */
    SynthesisStatus[SynthesisStatus["Success"] = 0] = "Success";
    /**
     * Indicates the end of audio data. No valid audio data is included in the message.
     * @member SynthesisStatus.SynthesisEnd
     */
    SynthesisStatus[SynthesisStatus["SynthesisEnd"] = 1] = "SynthesisEnd";
    /**
     * Indicates an error occurred during synthesis data processing.
     * @member SynthesisStatus.Error
     */
    SynthesisStatus[SynthesisStatus["Error"] = 2] = "Error";
})(SynthesisStatus = exports.SynthesisStatus || (exports.SynthesisStatus = {}));
var RecognitionStatus;
(function (RecognitionStatus) {
    RecognitionStatus[RecognitionStatus["Success"] = 0] = "Success";
    RecognitionStatus[RecognitionStatus["NoMatch"] = 1] = "NoMatch";
    RecognitionStatus[RecognitionStatus["InitialSilenceTimeout"] = 2] = "InitialSilenceTimeout";
    RecognitionStatus[RecognitionStatus["BabbleTimeout"] = 3] = "BabbleTimeout";
    RecognitionStatus[RecognitionStatus["Error"] = 4] = "Error";
    RecognitionStatus[RecognitionStatus["EndOfDictation"] = 5] = "EndOfDictation";
    RecognitionStatus[RecognitionStatus["TooManyRequests"] = 6] = "TooManyRequests";
    RecognitionStatus[RecognitionStatus["BadRequest"] = 7] = "BadRequest";
    RecognitionStatus[RecognitionStatus["Forbidden"] = 8] = "Forbidden";
})(RecognitionStatus = exports.RecognitionStatus || (exports.RecognitionStatus = {}));

//# sourceMappingURL=Enums.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/InvocationSource.js"
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/InvocationSource.js ***!
  \*******************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.InvocationSource = void 0;
/**
 * Represents the source of speech recognition invocation.
 */
var InvocationSource;
(function (InvocationSource) {
    /**
     * No invocation source specified.
     */
    InvocationSource["None"] = "None";
    /**
     * Voice activation with a keyword.
     */
    InvocationSource["VoiceActivationWithKeyword"] = "VoiceActivationWithKeyword";
})(InvocationSource = exports.InvocationSource || (exports.InvocationSource = {}));

//# sourceMappingURL=InvocationSource.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/KeywordDetection/KeywordDetection.js"
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/KeywordDetection/KeywordDetection.js ***!
  \************************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.OnRejectAction = exports.KeywordDetectionType = void 0;
/**
 * Represents the type of keyword detection.
 */
var KeywordDetectionType;
(function (KeywordDetectionType) {
    /**
     * Triggered at the start of input.
     */
    KeywordDetectionType["StartTrigger"] = "StartTrigger";
})(KeywordDetectionType = exports.KeywordDetectionType || (exports.KeywordDetectionType = {}));
/**
 * The action to take when a keyword is rejected.
 */
var OnRejectAction;
(function (OnRejectAction) {
    /**
     * End the current turn.
     */
    OnRejectAction["EndOfTurn"] = "EndOfTurn";
    /**
     * Continue processing.
     */
    OnRejectAction["Continue"] = "Continue";
})(OnRejectAction = exports.OnRejectAction || (exports.OnRejectAction = {}));

//# sourceMappingURL=KeywordDetection.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/LanguageId/LanguageIdContext.js"
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/LanguageId/LanguageIdContext.js ***!
  \*******************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.LanguageIdDetectionPriority = exports.LanguageIdDetectionMode = void 0;
/**
 * The enum that represents which mode will language detection take place
 * There is only detectAtAudioStart mode for now as language detection models are not trained for different modes
 * This enum can be extended in future to support different modes
 */
var LanguageIdDetectionMode;
(function (LanguageIdDetectionMode) {
    LanguageIdDetectionMode["DetectAtAudioStart"] = "DetectAtAudioStart";
    LanguageIdDetectionMode["DetectContinuous"] = "DetectContinuous";
    LanguageIdDetectionMode["DetectSegments"] = "DetectSegments";
})(LanguageIdDetectionMode = exports.LanguageIdDetectionMode || (exports.LanguageIdDetectionMode = {}));
/**
 * The language id detection mode, setting this will load the detection setting of MaxAudioDuration and MaxSpeechDuration
 * If the maxAudioDuration and maxSpeechDuration is set in the speech.context, then this detection mode will be ignored
 */
var LanguageIdDetectionPriority;
(function (LanguageIdDetectionPriority) {
    /**
     * default, Service decides the best mode to use.
     */
    LanguageIdDetectionPriority["Auto"] = "Auto";
    /**
     * Offers lower latency via a trade-off of accuracy.
     */
    LanguageIdDetectionPriority["PrioritizeLatency"] = "PrioritizeLatency";
    /**
     * Offers higher accuracy via a trade-off of latency.
     */
    LanguageIdDetectionPriority["PrioritizeAccuracy"] = "PrioritizeAccuracy";
})(LanguageIdDetectionPriority = exports.LanguageIdDetectionPriority || (exports.LanguageIdDetectionPriority = {}));

//# sourceMappingURL=LanguageIdContext.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/LanguageId/OnSuccess.js"
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/LanguageId/OnSuccess.js ***!
  \***********************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.NextAction = void 0;
/**
 * The action to take on successful language detection
 */
var NextAction;
(function (NextAction) {
    NextAction["Recognize"] = "Recognize";
    NextAction["None"] = "None";
})(NextAction = exports.NextAction || (exports.NextAction = {}));

//# sourceMappingURL=OnSuccess.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/LanguageId/OnUnknown.js"
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/LanguageId/OnUnknown.js ***!
  \***********************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.OnUnknownAction = void 0;
/**
 * An enum that defines actions that can be taken on unknown language detection
 */
var OnUnknownAction;
(function (OnUnknownAction) {
    OnUnknownAction["RecognizeWithDefaultLanguage"] = "RecognizeWithDefaultLanguage";
    OnUnknownAction["None"] = "None";
})(OnUnknownAction = exports.OnUnknownAction || (exports.OnUnknownAction = {}));

//# sourceMappingURL=OnUnknown.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/OnSuccess.js"
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/OnSuccess.js ***!
  \****************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.NextAction = void 0;
/**
 * The action enum when speech recognition return a final phrase result
 */
var NextAction;
(function (NextAction) {
    NextAction["None"] = "None";
    NextAction["Translate"] = "Translate";
})(NextAction = exports.NextAction || (exports.NextAction = {}));

//# sourceMappingURL=OnSuccess.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js"
/*!*****************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js ***!
  \*****************************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechStartEventSensitivity = exports.RecognitionMode = void 0;
/**
 * The Recognition modes
 */
var RecognitionMode;
(function (RecognitionMode) {
    RecognitionMode["Interactive"] = "Interactive";
    RecognitionMode["Dictation"] = "Dictation";
    RecognitionMode["Conversation"] = "Conversation";
    RecognitionMode["None"] = "None";
})(RecognitionMode = exports.RecognitionMode || (exports.RecognitionMode = {}));
/**
 * The speech start event sensitivity.
 */
var SpeechStartEventSensitivity;
(function (SpeechStartEventSensitivity) {
    SpeechStartEventSensitivity["Low"] = "low";
    SpeechStartEventSensitivity["Medium"] = "medium";
    SpeechStartEventSensitivity["High"] = "high";
})(SpeechStartEventSensitivity = exports.SpeechStartEventSensitivity || (exports.SpeechStartEventSensitivity = {}));

//# sourceMappingURL=PhraseDetectionContext.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/Segmentation.js"
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/Segmentation.js ***!
  \*******************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SegmentationMode = void 0;
/**
 * The segmentation mode.
 */
var SegmentationMode;
(function (SegmentationMode) {
    SegmentationMode["Normal"] = "Normal";
    SegmentationMode["Disabled"] = "Disabled";
    SegmentationMode["Custom"] = "Custom";
    SegmentationMode["Semantic"] = "Semantic";
})(SegmentationMode = exports.SegmentationMode || (exports.SegmentationMode = {}));

//# sourceMappingURL=Segmentation.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/SpeakerDiarization.js"
/*!*************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/SpeakerDiarization.js ***!
  \*************************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.IdentityProvider = exports.SpeakerDiarizationMode = void 0;
/**
 * The speaker diarization mode
 */
var SpeakerDiarizationMode;
(function (SpeakerDiarizationMode) {
    SpeakerDiarizationMode["None"] = "None";
    SpeakerDiarizationMode["Identity"] = "Identity";
    SpeakerDiarizationMode["Anonymous"] = "Anonymous";
})(SpeakerDiarizationMode = exports.SpeakerDiarizationMode || (exports.SpeakerDiarizationMode = {}));
/**
 * The identity provider
 */
var IdentityProvider;
(function (IdentityProvider) {
    IdentityProvider["CallCenter"] = "CallCenter";
})(IdentityProvider = exports.IdentityProvider || (exports.IdentityProvider = {}));

//# sourceMappingURL=SpeakerDiarization.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseOutput/InterimResults.js"
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseOutput/InterimResults.js ***!
  \******************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ResultType = void 0;
/**
 * The result type enum
 */
var ResultType;
(function (ResultType) {
    ResultType["Auto"] = "Auto";
    ResultType["StableFragment"] = "StableFragment";
    ResultType["Hypothesis"] = "Hypothesis";
    ResultType["None"] = "None";
})(ResultType = exports.ResultType || (exports.ResultType = {}));

//# sourceMappingURL=InterimResults.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseOutput/PhraseOutput.js"
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseOutput/PhraseOutput.js ***!
  \****************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TentativePhraseResultsOption = exports.OutputFormat = exports.PhraseExtension = exports.PhraseOption = void 0;
/**
 * The detailed output options.
 */
var PhraseOption;
(function (PhraseOption) {
    PhraseOption["WordTimings"] = "WordTimings";
    PhraseOption["SNR"] = "SNR";
    PhraseOption["Pronunciation"] = "Pronunciation";
    PhraseOption["WordPronunciation"] = "WordPronunciation";
    PhraseOption["WordConfidence"] = "WordConfidence";
    PhraseOption["Words"] = "Words";
    PhraseOption["Sentiment"] = "Sentiment";
    PhraseOption["PronunciationAssessment"] = "PronunciationAssessment";
    PhraseOption["ContentAssessment"] = "ContentAssessment";
    PhraseOption["PhraseAMScore"] = "PhraseAMScore";
    PhraseOption["PhraseLMScore"] = "PhraseLMScore";
    PhraseOption["WordAMScore"] = "WordAMScore";
    PhraseOption["WordLMScore"] = "WordLMScore";
    PhraseOption["RuleTree"] = "RuleTree";
    PhraseOption["NBestTimings"] = "NBestTimings";
    PhraseOption["DecoderDiagnostics"] = "DecoderDiagnostics";
    PhraseOption["DisplayWordTimings"] = "DisplayWordTimings";
    PhraseOption["DisplayWords"] = "DisplayWords";
})(PhraseOption = exports.PhraseOption || (exports.PhraseOption = {}));
/**
 * The detailed output extensions.
 */
var PhraseExtension;
(function (PhraseExtension) {
    PhraseExtension["Graph"] = "Graph";
    PhraseExtension["Corrections"] = "Corrections";
    PhraseExtension["Sentiment"] = "Sentiment";
})(PhraseExtension = exports.PhraseExtension || (exports.PhraseExtension = {}));
/**
 * The Recognition modes
 */
var OutputFormat;
(function (OutputFormat) {
    OutputFormat["Simple"] = "Simple";
    OutputFormat["Detailed"] = "Detailed";
})(OutputFormat = exports.OutputFormat || (exports.OutputFormat = {}));
/**
 * The Tentative Phrase Results option
 */
var TentativePhraseResultsOption;
(function (TentativePhraseResultsOption) {
    TentativePhraseResultsOption["None"] = "None";
    TentativePhraseResultsOption["Always"] = "Always";
})(TentativePhraseResultsOption = exports.TentativePhraseResultsOption || (exports.TentativePhraseResultsOption = {}));

//# sourceMappingURL=PhraseOutput.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseOutput/PhraseResults.js"
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseOutput/PhraseResults.js ***!
  \*****************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PhraseResultOutputType = void 0;
/**
 * The phrase result output type
 */
var PhraseResultOutputType;
(function (PhraseResultOutputType) {
    PhraseResultOutputType["Always"] = "Always";
    PhraseResultOutputType["None"] = "None";
})(PhraseResultOutputType = exports.PhraseResultOutputType || (exports.PhraseResultOutputType = {}));

//# sourceMappingURL=PhraseResults.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js"
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js ***!
  \*********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SimpleSpeechPhrase = void 0;
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
class SimpleSpeechPhrase {
    constructor(json, baseOffset = 0) {
        this.privSimpleSpeechPhrase = JSON.parse(json);
        this.privSimpleSpeechPhrase.RecognitionStatus = this.mapRecognitionStatus(this.privSimpleSpeechPhrase.RecognitionStatus); // RecognitionStatus[this.privSimpleSpeechPhrase.RecognitionStatus as unknown as keyof typeof RecognitionStatus];
        this.updateOffset(baseOffset);
    }
    static fromJSON(json, baseOffset) {
        return new SimpleSpeechPhrase(json, baseOffset);
    }
    updateOffset(baseOffset) {
        this.privSimpleSpeechPhrase.Offset += baseOffset;
    }
    asJson() {
        const jsonObj = { ...this.privSimpleSpeechPhrase };
        // Convert the enum value to its string representation for serialization purposes.
        return JSON.stringify({
            ...jsonObj,
            RecognitionStatus: Exports_js_1.RecognitionStatus[jsonObj.RecognitionStatus]
        });
    }
    get RecognitionStatus() {
        return this.privSimpleSpeechPhrase.RecognitionStatus;
    }
    get DisplayText() {
        return this.privSimpleSpeechPhrase.DisplayText;
    }
    get Offset() {
        return this.privSimpleSpeechPhrase.Offset;
    }
    get Duration() {
        return this.privSimpleSpeechPhrase.Duration;
    }
    get Language() {
        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Language;
    }
    get LanguageDetectionConfidence() {
        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Confidence;
    }
    get SpeakerId() {
        return this.privSimpleSpeechPhrase.SpeakerId;
    }
    mapRecognitionStatus(status) {
        if (typeof status === "string") {
            return Exports_js_1.RecognitionStatus[status];
        }
        else if (typeof status === "number") {
            return status;
        }
    }
}
exports.SimpleSpeechPhrase = SimpleSpeechPhrase;

//# sourceMappingURL=SimpleSpeechPhrase.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechDetected.js"
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechDetected.js ***!
  \*****************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechDetected = void 0;
class SpeechDetected {
    constructor(json, baseOffset) {
        this.privSpeechStartDetected = JSON.parse(json);
        this.privSpeechStartDetected.Offset += baseOffset;
    }
    static fromJSON(json, baseOffset) {
        return new SpeechDetected(json, baseOffset);
    }
    get Offset() {
        return this.privSpeechStartDetected.Offset;
    }
}
exports.SpeechDetected = SpeechDetected;

//# sourceMappingURL=SpeechDetected.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechHypothesis.js"
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechHypothesis.js ***!
  \*******************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechHypothesis = void 0;
class SpeechHypothesis {
    constructor(json, baseOffset) {
        this.privSpeechHypothesis = JSON.parse(json);
        this.updateOffset(baseOffset);
    }
    static fromJSON(json, baseOffset) {
        return new SpeechHypothesis(json, baseOffset);
    }
    updateOffset(baseOffset) {
        this.privSpeechHypothesis.Offset += baseOffset;
    }
    asJson() {
        return JSON.stringify(this.privSpeechHypothesis);
    }
    get Text() {
        return this.privSpeechHypothesis.Text;
    }
    get Offset() {
        return this.privSpeechHypothesis.Offset;
    }
    get Duration() {
        return this.privSpeechHypothesis.Duration;
    }
    get Language() {
        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Language;
    }
    get LanguageDetectionConfidence() {
        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Confidence;
    }
    get SpeakerId() {
        return this.privSpeechHypothesis.SpeakerId;
    }
}
exports.SpeechHypothesis = SpeechHypothesis;

//# sourceMappingURL=SpeechHypothesis.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechKeyword.js"
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SpeechKeyword.js ***!
  \****************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechKeyword = void 0;
class SpeechKeyword {
    constructor(json, baseOffset) {
        this.privSpeechKeyword = JSON.parse(json);
        this.privSpeechKeyword.Offset += baseOffset;
    }
    static fromJSON(json, baseOffset) {
        return new SpeechKeyword(json, baseOffset);
    }
    get Status() {
        return this.privSpeechKeyword.Status;
    }
    get Text() {
        return this.privSpeechKeyword.Text;
    }
    get Offset() {
        return this.privSpeechKeyword.Offset;
    }
    get Duration() {
        return this.privSpeechKeyword.Duration;
    }
    asJson() {
        return JSON.stringify(this.privSpeechKeyword);
    }
}
exports.SpeechKeyword = SpeechKeyword;

//# sourceMappingURL=SpeechKeyword.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js"
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js ***!
  \*************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesisAudioMetadata = exports.MetadataType = void 0;
var MetadataType;
(function (MetadataType) {
    MetadataType["WordBoundary"] = "WordBoundary";
    MetadataType["Bookmark"] = "Bookmark";
    MetadataType["Viseme"] = "Viseme";
    MetadataType["SentenceBoundary"] = "SentenceBoundary";
    MetadataType["SessionEnd"] = "SessionEnd";
    MetadataType["AvatarSignal"] = "TalkingAvatarSignal";
})(MetadataType = exports.MetadataType || (exports.MetadataType = {}));
class SynthesisAudioMetadata {
    constructor(json) {
        this.privSynthesisAudioMetadata = JSON.parse(json);
    }
    static fromJSON(json) {
        return new SynthesisAudioMetadata(json);
    }
    get Metadata() {
        return this.privSynthesisAudioMetadata.Metadata;
    }
}
exports.SynthesisAudioMetadata = SynthesisAudioMetadata;

//# sourceMappingURL=SynthesisAudioMetadata.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Translation/InterimResults.js"
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Translation/InterimResults.js ***!
  \*****************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Mode = void 0;
/**
 * Result type
 */
var Mode;
(function (Mode) {
    Mode["None"] = "None";
    Mode["Always"] = "Always";
})(Mode = exports.Mode || (exports.Mode = {}));

//# sourceMappingURL=InterimResults.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Translation/OnSuccess.js"
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Translation/OnSuccess.js ***!
  \************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.NextAction = void 0;
/**
 * The action to take on success
 */
var NextAction;
(function (NextAction) {
    NextAction["None"] = "None";
    NextAction["Synthesize"] = "Synthesize";
})(NextAction = exports.NextAction || (exports.NextAction = {}));

//# sourceMappingURL=OnSuccess.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationHypothesis.js"
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationHypothesis.js ***!
  \************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationHypothesis = void 0;
const Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const TranslationStatus_js_1 = __webpack_require__(/*! ../TranslationStatus.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js");
class TranslationHypothesis {
    constructor(hypothesis, baseOffset) {
        this.privTranslationHypothesis = hypothesis;
        this.privTranslationHypothesis.Offset += baseOffset;
        this.privTranslationHypothesis.Translation.TranslationStatus = this.mapTranslationStatus(this.privTranslationHypothesis.Translation.TranslationStatus);
    }
    static fromJSON(json, baseOffset) {
        return new TranslationHypothesis(JSON.parse(json), baseOffset);
    }
    static fromTranslationResponse(translationHypothesis, baseOffset) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(translationHypothesis, "translationHypothesis");
        const hypothesis = translationHypothesis.SpeechHypothesis;
        translationHypothesis.SpeechHypothesis = undefined;
        hypothesis.Translation = translationHypothesis;
        return new TranslationHypothesis(hypothesis, baseOffset);
    }
    get Duration() {
        return this.privTranslationHypothesis.Duration;
    }
    get Offset() {
        return this.privTranslationHypothesis.Offset;
    }
    get Text() {
        return this.privTranslationHypothesis.Text;
    }
    get Translation() {
        return this.privTranslationHypothesis.Translation;
    }
    get Language() {
        return this.privTranslationHypothesis.PrimaryLanguage?.Language;
    }
    asJson() {
        const jsonObj = { ...this.privTranslationHypothesis };
        // Convert the enum value to its string representation for serialization purposes.
        return jsonObj.Translation !== undefined ? JSON.stringify({
            ...jsonObj,
            TranslationStatus: TranslationStatus_js_1.TranslationStatus[jsonObj.Translation.TranslationStatus]
        }) : JSON.stringify(jsonObj);
    }
    mapTranslationStatus(status) {
        if (typeof status === "string") {
            return TranslationStatus_js_1.TranslationStatus[status];
        }
        else if (typeof status === "number") {
            return status;
        }
    }
}
exports.TranslationHypothesis = TranslationHypothesis;

//# sourceMappingURL=TranslationHypothesis.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationPhrase.js"
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationPhrase.js ***!
  \********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationPhrase = void 0;
const Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const TranslationStatus_js_1 = __webpack_require__(/*! ../TranslationStatus.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js");
class TranslationPhrase {
    constructor(phrase, baseOffset) {
        this.privTranslationPhrase = phrase;
        this.privTranslationPhrase.Offset += baseOffset;
        this.privTranslationPhrase.RecognitionStatus = this.mapRecognitionStatus(this.privTranslationPhrase.RecognitionStatus);
        if (this.privTranslationPhrase.Translation !== undefined) {
            this.privTranslationPhrase.Translation.TranslationStatus = this.mapTranslationStatus(this.privTranslationPhrase.Translation.TranslationStatus);
        }
    }
    static fromJSON(json, baseOffset) {
        return new TranslationPhrase(JSON.parse(json), baseOffset);
    }
    static fromTranslationResponse(translationResponse, baseOffset) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(translationResponse, "translationResponse");
        const phrase = translationResponse.SpeechPhrase;
        translationResponse.SpeechPhrase = undefined;
        phrase.Translation = translationResponse;
        phrase.Text = phrase.DisplayText;
        return new TranslationPhrase(phrase, baseOffset);
    }
    get RecognitionStatus() {
        return this.privTranslationPhrase.RecognitionStatus;
    }
    get Offset() {
        return this.privTranslationPhrase.Offset;
    }
    get Duration() {
        return this.privTranslationPhrase.Duration;
    }
    get Text() {
        return this.privTranslationPhrase.Text;
    }
    get Language() {
        return this.privTranslationPhrase.PrimaryLanguage?.Language;
    }
    get Confidence() {
        return this.privTranslationPhrase.PrimaryLanguage?.Confidence;
    }
    get Translation() {
        return this.privTranslationPhrase.Translation;
    }
    asJson() {
        const jsonObj = { ...this.privTranslationPhrase };
        // Convert the enum values to their string representations for serialization
        const serializedObj = {
            ...jsonObj,
            RecognitionStatus: Exports_js_1.RecognitionStatus[jsonObj.RecognitionStatus]
        };
        if (jsonObj.Translation) {
            // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
            serializedObj.Translation = {
                ...jsonObj.Translation,
                TranslationStatus: TranslationStatus_js_1.TranslationStatus[jsonObj.Translation.TranslationStatus]
            };
        }
        return JSON.stringify(serializedObj);
    }
    mapRecognitionStatus(status) {
        if (typeof status === "string") {
            return Exports_js_1.RecognitionStatus[status];
        }
        else if (typeof status === "number") {
            return status;
        }
    }
    mapTranslationStatus(status) {
        if (typeof status === "string") {
            return TranslationStatus_js_1.TranslationStatus[status];
        }
        else if (typeof status === "number") {
            return status;
        }
    }
}
exports.TranslationPhrase = TranslationPhrase;

//# sourceMappingURL=TranslationPhrase.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js"
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js ***!
  \**************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationSynthesisEnd = void 0;
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
class TranslationSynthesisEnd {
    constructor(json) {
        this.privSynthesisEnd = JSON.parse(json);
        if (!!this.privSynthesisEnd.SynthesisStatus) {
            this.privSynthesisEnd.SynthesisStatus = Exports_js_1.SynthesisStatus[this.privSynthesisEnd.SynthesisStatus];
        }
        if (!!this.privSynthesisEnd.Status) {
            this.privSynthesisEnd.SynthesisStatus = Exports_js_1.SynthesisStatus[this.privSynthesisEnd.Status];
        }
    }
    static fromJSON(json) {
        return new TranslationSynthesisEnd(json);
    }
    get SynthesisStatus() {
        return this.privSynthesisEnd.SynthesisStatus;
    }
    get FailureReason() {
        return this.privSynthesisEnd.FailureReason;
    }
}
exports.TranslationSynthesisEnd = TranslationSynthesisEnd;

//# sourceMappingURL=TranslationSynthesisEnd.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TurnStatusPayload.js"
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TurnStatusPayload.js ***!
  \********************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TurnStatusResponsePayload = void 0;
class TurnStatusResponsePayload {
    constructor(json) {
        this.privMessageStatusResponse = JSON.parse(json);
    }
    static fromJSON(json) {
        return new TurnStatusResponsePayload(json);
    }
    get interactionId() {
        return this.privMessageStatusResponse.interactionId;
    }
    get conversationId() {
        return this.privMessageStatusResponse.conversationId;
    }
    get statusCode() {
        // Payloads may contain a limited set of textual representations or a numeric status
        // code. The textual values are here converted into numeric ones.
        switch (this.privMessageStatusResponse.statusCode) {
            case "Success":
                return 200;
            case "Failed":
                return 400;
            case "TimedOut":
                return 429;
            default:
                // eslint-disable-next-line @typescript-eslint/no-unsafe-return
                return this.privMessageStatusResponse.statusCode;
        }
    }
}
exports.TurnStatusResponsePayload = TurnStatusResponsePayload;

//# sourceMappingURL=TurnStatusPayload.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceRecognizerBase.js"
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceRecognizerBase.js ***!
  \********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ServiceRecognizerBase = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_4 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js");
const Segmentation_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseDetection/Segmentation.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/Segmentation.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
const OnSuccess_js_1 = __webpack_require__(/*! ./ServiceMessages/Translation/OnSuccess.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Translation/OnSuccess.js");
const InterimResults_js_1 = __webpack_require__(/*! ./ServiceMessages/Translation/InterimResults.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/Translation/InterimResults.js");
const LanguageIdContext_js_1 = __webpack_require__(/*! ./ServiceMessages/LanguageId/LanguageIdContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/LanguageId/LanguageIdContext.js");
const OnSuccess_js_2 = __webpack_require__(/*! ./ServiceMessages/LanguageId/OnSuccess.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/LanguageId/OnSuccess.js");
const OnUnknown_js_1 = __webpack_require__(/*! ./ServiceMessages/LanguageId/OnUnknown.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/LanguageId/OnUnknown.js");
const InterimResults_js_2 = __webpack_require__(/*! ./ServiceMessages/PhraseOutput/InterimResults.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseOutput/InterimResults.js");
const PhraseResults_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseOutput/PhraseResults.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseOutput/PhraseResults.js");
const OnSuccess_js_3 = __webpack_require__(/*! ./ServiceMessages/PhraseDetection/OnSuccess.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/OnSuccess.js");
class ServiceRecognizerBase {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {
        // A promise for a configured connection.
        // Do not consume directly, call fetchConnection instead.
        this.privConnectionConfigurationPromise = undefined;
        // A promise for a connection, but one that has not had the speech context sent yet.
        // Do not consume directly, call fetchConnection instead.
        this.privConnectionPromise = undefined;
        this.privSetTimeout = setTimeout;
        this.privIsLiveAudio = false;
        this.privAverageBytesPerMs = 0;
        this.privEnableSpeakerId = false;
        this.privExpectContentAssessmentResponse = false;
        this.recognizeOverride = undefined;
        this.disconnectOverride = undefined;
        this.receiveMessageOverride = undefined;
        this.sendPrePayloadJSONOverride = undefined;
        this.postConnectImplOverride = undefined;
        this.configConnectionOverride = undefined;
        this.handleSpeechPhraseMessage = undefined;
        this.handleSpeechHypothesisMessage = undefined;
        if (!authentication) {
            throw new Exports_js_2.ArgumentNullError("authentication");
        }
        if (!connectionFactory) {
            throw new Exports_js_2.ArgumentNullError("connectionFactory");
        }
        if (!audioSource) {
            throw new Exports_js_2.ArgumentNullError("audioSource");
        }
        if (!recognizerConfig) {
            throw new Exports_js_2.ArgumentNullError("recognizerConfig");
        }
        this.privEnableSpeakerId = recognizerConfig.isSpeakerDiarizationEnabled;
        this.privMustReportEndOfStream = false;
        this.privAuthentication = authentication;
        this.privConnectionFactory = connectionFactory;
        this.privAudioSource = audioSource;
        this.privRecognizerConfig = recognizerConfig;
        this.privIsDisposed = false;
        this.privRecognizer = recognizer;
        this.privRequestSession = new Exports_js_4.RequestSession(this.privAudioSource.id());
        this.privConnectionEvents = new Exports_js_2.EventSource();
        this.privServiceEvents = new Exports_js_2.EventSource();
        this.privDynamicGrammar = new Exports_js_4.DynamicGrammarBuilder();
        this.privSpeechContext = new Exports_js_4.SpeechContext(this.privDynamicGrammar);
        this.privAgentConfig = new Exports_js_4.AgentConfig();
        const webWorkerLoadType = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.WebWorkerLoadType, "on").toLowerCase();
        if (webWorkerLoadType === "on" && typeof (Blob) !== "undefined" && typeof (Worker) !== "undefined") {
            this.privSetTimeout = Exports_js_2.Timeout.setTimeout;
        }
        else {
            if (typeof window !== "undefined") {
                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
                this.privSetTimeout = window.setTimeout.bind(window);
            }
            if (typeof globalThis !== "undefined") {
                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
                this.privSetTimeout = globalThis.setTimeout.bind(globalThis);
            }
        }
        this.connectionEvents.attach((connectionEvent) => {
            if (connectionEvent.name === "ConnectionClosedEvent") {
                const connectionClosedEvent = connectionEvent;
                if (connectionClosedEvent.statusCode === 1003 ||
                    connectionClosedEvent.statusCode === 1007 ||
                    connectionClosedEvent.statusCode === 1002 ||
                    connectionClosedEvent.statusCode === 4000 ||
                    this.privRequestSession.numConnectionAttempts > this.privRecognizerConfig.maxRetryCount) {
                    void this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? Exports_js_3.CancellationErrorCode.BadRequestParameters : Exports_js_3.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);
                }
            }
        });
        if (this.privEnableSpeakerId) {
            this.privDiarizationSessionId = (0, Exports_js_2.createNoDashGuid)();
        }
    }
    setTranslationJson() {
        const targetLanguages = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined);
        if (targetLanguages !== undefined) {
            const languages = targetLanguages.split(",");
            const translationVoice = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);
            const categoryId = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationCategoryId, undefined);
            const action = (translationVoice !== undefined) ? OnSuccess_js_1.NextAction.Synthesize : OnSuccess_js_1.NextAction.None;
            this.privSpeechContext.getContext().translation = {
                onPassthrough: { action },
                onSuccess: { action },
                output: {
                    includePassThroughResults: true,
                    interimResults: { mode: InterimResults_js_1.Mode.Always }
                },
                targetLanguages: languages,
            };
            // Add category if specified
            if (categoryId !== undefined) {
                this.privSpeechContext.getContext().translation.category = categoryId;
            }
            if (translationVoice !== undefined) {
                const languageToVoiceMap = {};
                for (const lang of languages) {
                    languageToVoiceMap[lang] = translationVoice;
                }
                this.privSpeechContext.getContext().synthesis = {
                    defaultVoices: languageToVoiceMap
                };
            }
            // Configure phrase detection for translation
            const phraseDetection = this.privSpeechContext.getContext().phraseDetection || {};
            phraseDetection.onSuccess = { action: OnSuccess_js_3.NextAction.Translate };
            phraseDetection.onInterim = { action: OnSuccess_js_3.NextAction.Translate };
            this.privSpeechContext.getContext().phraseDetection = phraseDetection;
        }
    }
    setSpeechSegmentationTimeoutJson() {
        const speechSegmentationSilenceTimeoutMs = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.Speech_SegmentationSilenceTimeoutMs, undefined);
        const speechSegmentationMaximumTimeMs = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.Speech_SegmentationMaximumTimeMs, undefined);
        const speechSegmentationStrategy = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.Speech_SegmentationStrategy, undefined);
        const segmentation = {
            mode: Segmentation_js_1.SegmentationMode.Normal,
        };
        let configuredSegment = false;
        if (speechSegmentationStrategy !== undefined) {
            configuredSegment = true;
            let segMode = Segmentation_js_1.SegmentationMode.Normal;
            switch (speechSegmentationStrategy.toLowerCase()) {
                case "default":
                    break;
                case "time":
                    segMode = Segmentation_js_1.SegmentationMode.Custom;
                    break;
                case "semantic":
                    segMode = Segmentation_js_1.SegmentationMode.Semantic;
                    break;
            }
            segmentation.mode = segMode;
        }
        if (speechSegmentationSilenceTimeoutMs !== undefined) {
            configuredSegment = true;
            const segmentationSilenceTimeoutMs = parseInt(speechSegmentationSilenceTimeoutMs, 10);
            segmentation.mode = Segmentation_js_1.SegmentationMode.Custom;
            segmentation.segmentationSilenceTimeoutMs = segmentationSilenceTimeoutMs;
        }
        if (speechSegmentationMaximumTimeMs !== undefined) {
            configuredSegment = true;
            const segmentationMaximumTimeMs = parseInt(speechSegmentationMaximumTimeMs, 10);
            segmentation.mode = Segmentation_js_1.SegmentationMode.Custom;
            segmentation.segmentationForcedTimeoutMs = segmentationMaximumTimeMs;
        }
        if (configuredSegment) {
            const phraseDetection = this.privSpeechContext.getContext().phraseDetection || {};
            phraseDetection.mode = this.recognitionMode;
            switch (this.recognitionMode) {
                case PhraseDetectionContext_js_1.RecognitionMode.Conversation:
                    phraseDetection.conversation = phraseDetection.conversation ?? { segmentation: {} };
                    phraseDetection.conversation.segmentation = segmentation;
                    break;
                case PhraseDetectionContext_js_1.RecognitionMode.Interactive:
                    phraseDetection.interactive = phraseDetection.interactive ?? { segmentation: {} };
                    phraseDetection.interactive.segmentation = segmentation;
                    break;
                case PhraseDetectionContext_js_1.RecognitionMode.Dictation:
                    phraseDetection.dictation = phraseDetection.dictation ?? {};
                    phraseDetection.dictation.segmentation = segmentation;
                    break;
            }
            this.privSpeechContext.getContext().phraseDetection = phraseDetection;
        }
    }
    setLanguageIdJson() {
        const phraseDetection = this.privSpeechContext.getContext().phraseDetection || {};
        if (this.privRecognizerConfig.autoDetectSourceLanguages !== undefined) {
            const sourceLanguages = this.privRecognizerConfig.autoDetectSourceLanguages.split(",");
            if (sourceLanguages.length === 1 && sourceLanguages[0] === Exports_js_4.AutoDetectSourceLanguagesOpenRangeOptionName) {
                sourceLanguages[0] = "UND";
            }
            let speechContextLidMode;
            if (this.privRecognizerConfig.languageIdMode === "Continuous") {
                speechContextLidMode = LanguageIdContext_js_1.LanguageIdDetectionMode.DetectContinuous;
            }
            else { // recognizerConfig.languageIdMode === "AtStart"
                speechContextLidMode = LanguageIdContext_js_1.LanguageIdDetectionMode.DetectAtAudioStart;
            }
            this.privSpeechContext.getContext().languageId = {
                languages: sourceLanguages,
                mode: speechContextLidMode,
                onSuccess: { action: OnSuccess_js_2.NextAction.Recognize },
                onUnknown: { action: OnUnknown_js_1.OnUnknownAction.None },
                priority: LanguageIdContext_js_1.LanguageIdDetectionPriority.PrioritizeLatency
            };
            this.privSpeechContext.getContext().phraseOutput = {
                interimResults: {
                    resultType: InterimResults_js_2.ResultType.Auto
                },
                phraseResults: {
                    resultType: PhraseResults_js_1.PhraseResultOutputType.Always
                }
            };
            const customModels = this.privRecognizerConfig.sourceLanguageModels;
            if (customModels !== undefined) {
                phraseDetection.customModels = customModels;
                phraseDetection.onInterim = { action: OnSuccess_js_3.NextAction.None };
                phraseDetection.onSuccess = { action: OnSuccess_js_3.NextAction.None };
            }
        }
        // No longer setting translation-specific configuration here
        // This is now handled in setTranslationJson and setupTranslationWithLanguageId methods
        this.privSpeechContext.getContext().phraseDetection = phraseDetection;
    }
    setOutputDetailLevelJson() {
        if (this.privEnableSpeakerId) {
            const requestWordLevelTimestamps = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "false").toLowerCase();
            if (requestWordLevelTimestamps === "true") {
                this.privSpeechContext.setWordLevelTimings();
            }
            else {
                const outputFormat = this.privRecognizerConfig.parameters.getProperty(Exports_js_4.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]).toLowerCase();
                if (outputFormat === Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Detailed].toLocaleLowerCase()) {
                    this.privSpeechContext.setDetailedOutputFormat();
                }
            }
        }
    }
    setSpeechStartEventSensitivityJson() {
        const sensitivity = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.Speech_StartEventSensitivity, undefined);
        if (sensitivity !== undefined) {
            let configuredSensitivity = false;
            switch (sensitivity.toLowerCase()) {
                case PhraseDetectionContext_js_1.SpeechStartEventSensitivity.Low:
                case PhraseDetectionContext_js_1.SpeechStartEventSensitivity.Medium:
                case PhraseDetectionContext_js_1.SpeechStartEventSensitivity.High:
                    configuredSensitivity = true;
                    break;
            }
            if (configuredSensitivity) {
                const phraseDetection = this.privSpeechContext.getContext().phraseDetection || {};
                phraseDetection.voiceOnsetSensitivity = sensitivity.toLowerCase();
                this.privSpeechContext.getContext().phraseDetection = phraseDetection;
            }
        }
    }
    get isSpeakerDiarizationEnabled() {
        return this.privEnableSpeakerId;
    }
    get audioSource() {
        return this.privAudioSource;
    }
    get speechContext() {
        return this.privSpeechContext;
    }
    get dynamicGrammar() {
        return this.privDynamicGrammar;
    }
    get agentConfig() {
        return this.privAgentConfig;
    }
    set conversationTranslatorToken(token) {
        this.privRecognizerConfig.parameters.setProperty(Exports_js_3.PropertyId.ConversationTranslator_Token, token);
    }
    set authentication(auth) {
        this.privAuthentication = auth;
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    async dispose(reason) {
        this.privIsDisposed = true;
        if (this.privConnectionPromise !== undefined) {
            try {
                const connection = await this.privConnectionPromise;
                await connection.dispose(reason);
            }
            catch (error) {
                // The connection is in a bad state. But we're trying to kill it, so...
                return;
            }
        }
    }
    get connectionEvents() {
        return this.privConnectionEvents;
    }
    get serviceEvents() {
        return this.privServiceEvents;
    }
    get recognitionMode() {
        return this.privRecognizerConfig.recognitionMode;
    }
    async recognize(recoMode, successCallback, errorCallBack) {
        if (this.recognizeOverride !== undefined) {
            await this.recognizeOverride(recoMode, successCallback, errorCallBack);
            return;
        }
        // Clear the existing configuration promise to force a re-transmission of config and context.
        this.privConnectionConfigurationPromise = undefined;
        this.privRecognizerConfig.recognitionMode = recoMode;
        if (this.privRecognizerConfig.recognitionEndpointVersion === "2") {
            const phraseDetection = this.privSpeechContext.getContext().phraseDetection || {};
            phraseDetection.mode = recoMode;
            this.privSpeechContext.getContext().phraseDetection = phraseDetection;
        }
        // Set language ID (if configured)
        this.setLanguageIdJson();
        // Then set translation (if configured)
        this.setTranslationJson();
        // Configure the integration between language ID and translation (if both are used)
        if (this.privRecognizerConfig.autoDetectSourceLanguages !== undefined &&
            this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
            this.setupTranslationWithLanguageId();
        }
        this.setSpeechSegmentationTimeoutJson();
        this.setOutputDetailLevelJson();
        this.setSpeechStartEventSensitivityJson();
        this.privSuccessCallback = successCallback;
        this.privErrorCallback = errorCallBack;
        this.privRequestSession.startNewRecognition();
        this.privRequestSession.listenForServiceTelemetry(this.privAudioSource.events);
        // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().
        const conPromise = this.connectImpl();
        let audioNode;
        try {
            const audioStreamNode = await this.audioSource.attach(this.privRequestSession.audioNodeId);
            const format = await this.audioSource.format;
            const deviceInfo = await this.audioSource.deviceInfo;
            this.privIsLiveAudio = deviceInfo.type && deviceInfo.type === Exports_js_4.type.Microphones;
            audioNode = new Exports_js_1.ReplayableAudioNode(audioStreamNode, format.avgBytesPerSec);
            await this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);
            this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };
        }
        catch (error) {
            await this.privRequestSession.onStopRecognizing();
            throw error;
        }
        try {
            await conPromise;
        }
        catch (error) {
            await this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.ConnectionFailure, error);
            return;
        }
        const sessionStartEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);
        if (!!this.privRecognizer.sessionStarted) {
            this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);
        }
        void this.receiveMessage();
        const audioSendPromise = this.sendAudio(audioNode);
        audioSendPromise.catch(async (error) => {
            await this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.RuntimeError, error);
        });
        return;
    }
    async stopRecognizing() {
        if (this.privRequestSession.isRecognizing) {
            try {
                await this.audioSource.turnOff();
                await this.sendFinalAudio();
                await this.privRequestSession.onStopRecognizing();
                await this.privRequestSession.turnCompletionPromise;
            }
            finally {
                await this.privRequestSession.dispose();
            }
        }
        return;
    }
    async connect() {
        await this.connectImpl();
        return Promise.resolve();
    }
    connectAsync(cb, err) {
        this.connectImpl().then(() => {
            try {
                if (!!cb) {
                    cb();
                }
            }
            catch (e) {
                if (!!err) {
                    err(e);
                }
            }
        }, (reason) => {
            try {
                if (!!err) {
                    err(reason);
                }
                /* eslint-disable no-empty */
            }
            catch (error) {
            }
        });
    }
    async disconnect() {
        await this.cancelRecognitionLocal(Exports_js_3.CancellationReason.Error, Exports_js_3.CancellationErrorCode.NoError, "Disconnecting");
        if (this.disconnectOverride !== undefined) {
            await this.disconnectOverride();
        }
        if (this.privConnectionPromise !== undefined) {
            try {
                await (await this.privConnectionPromise).dispose();
            }
            catch (error) {
            }
        }
        this.privConnectionPromise = undefined;
    }
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    sendMessage(message) {
        return;
    }
    async sendNetworkMessage(path, payload) {
        const type = typeof payload === "string" ? Exports_js_2.MessageType.Text : Exports_js_2.MessageType.Binary;
        const contentType = typeof payload === "string" ? "application/json" : "";
        const connection = await this.fetchConnection();
        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(type, path, this.privRequestSession.requestId, contentType, payload));
    }
    set activityTemplate(messagePayload) {
        this.privActivityTemplate = messagePayload;
    }
    get activityTemplate() {
        return this.privActivityTemplate;
    }
    set expectContentAssessmentResponse(value) {
        this.privExpectContentAssessmentResponse = value;
    }
    async sendTelemetryData() {
        const telemetryData = this.privRequestSession.getTelemetry();
        if (ServiceRecognizerBase.telemetryDataEnabled !== true ||
            this.privIsDisposed ||
            null === telemetryData) {
            return;
        }
        if (!!ServiceRecognizerBase.telemetryData) {
            try {
                ServiceRecognizerBase.telemetryData(telemetryData);
                /* eslint-disable no-empty */
            }
            catch { }
        }
        const connection = await this.fetchConnection();
        await connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, "telemetry", this.privRequestSession.requestId, "application/json", telemetryData));
    }
    // Cancels recognition.
    async cancelRecognitionLocal(cancellationReason, errorCode, error) {
        if (!!this.privRequestSession.isRecognizing) {
            await this.privRequestSession.onStopRecognizing();
            this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, cancellationReason, errorCode, error);
        }
    }
    async receiveMessage() {
        try {
            if (this.privIsDisposed) {
                // We're done.
                return;
            }
            let connection = await this.fetchConnection();
            const message = await connection.read();
            if (this.receiveMessageOverride !== undefined) {
                return this.receiveMessageOverride();
            }
            // indicates we are draining the queue and it came with no message;
            if (!message) {
                return this.receiveMessage();
            }
            this.privServiceHasSentMessage = true;
            const connectionMessage = SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage.fromConnectionMessage(message);
            if (connectionMessage.requestId.toLowerCase() === this.privRequestSession.requestId.toLowerCase()) {
                switch (connectionMessage.path.toLowerCase()) {
                    case "turn.start":
                        this.privMustReportEndOfStream = true;
                        this.privRequestSession.onServiceTurnStartResponse();
                        break;
                    case "speech.startdetected":
                        const speechStartDetected = Exports_js_4.SpeechDetected.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                        const speechStartEventArgs = new Exports_js_3.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);
                        if (!!this.privRecognizer.speechStartDetected) {
                            this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);
                        }
                        break;
                    case "speech.enddetected":
                        let json;
                        if (connectionMessage.textBody.length > 0) {
                            json = connectionMessage.textBody;
                        }
                        else {
                            // If the request was empty, the JSON returned is empty.
                            json = "{ Offset: 0 }";
                        }
                        const speechStopDetected = Exports_js_4.SpeechDetected.fromJSON(json, this.privRequestSession.currentTurnAudioOffset);
                        const speechStopEventArgs = new Exports_js_3.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);
                        if (!!this.privRecognizer.speechEndDetected) {
                            this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);
                        }
                        break;
                    case "turn.end":
                        await this.sendTelemetryData();
                        if (this.privRequestSession.isSpeechEnded && this.privMustReportEndOfStream) {
                            this.privMustReportEndOfStream = false;
                            await this.cancelRecognitionLocal(Exports_js_3.CancellationReason.EndOfStream, Exports_js_3.CancellationErrorCode.NoError, undefined);
                        }
                        const sessionStopEventArgs = new Exports_js_3.SessionEventArgs(this.privRequestSession.sessionId);
                        await this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition);
                        if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {
                            if (!!this.privRecognizer.sessionStopped) {
                                this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);
                            }
                            return;
                        }
                        else {
                            connection = await this.fetchConnection();
                            await this.sendPrePayloadJSON(connection);
                        }
                        break;
                    default:
                        if (!await this.processTypeSpecificMessages(connectionMessage)) {
                            // here are some messages that the derived class has not processed, dispatch them to connect class
                            if (!!this.privServiceEvents) {
                                this.serviceEvents.onEvent(new Exports_js_2.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                            }
                        }
                }
            }
            return this.receiveMessage();
        }
        catch (error) {
            return null;
        }
    }
    updateSpeakerDiarizationAudioOffset() {
        const bytesSent = this.privRequestSession.recognitionBytesSent;
        const audioOffsetMs = this.privAverageBytesPerMs !== 0 ? bytesSent / this.privAverageBytesPerMs : 0;
        this.privSpeechContext.setSpeakerDiarizationAudioOffsetMs(audioOffsetMs);
    }
    sendSpeechContext(connection, generateNewRequestId) {
        if (this.privEnableSpeakerId) {
            this.updateSpeakerDiarizationAudioOffset();
        }
        const speechContextJson = this.speechContext.toJSON();
        if (generateNewRequestId) {
            this.privRequestSession.onSpeechContext();
        }
        if (speechContextJson) {
            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, "speech.context", this.privRequestSession.requestId, "application/json", speechContextJson));
        }
        return;
    }
    setupTranslationWithLanguageId() {
        const targetLanguages = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined);
        const hasLanguageId = this.privRecognizerConfig.autoDetectSourceLanguages !== undefined;
        if (targetLanguages !== undefined && hasLanguageId) {
            // Configure phraseOutput for translation + language ID scenario
            this.privSpeechContext.getContext().phraseOutput = {
                interimResults: {
                    resultType: InterimResults_js_2.ResultType.None
                },
                phraseResults: {
                    resultType: PhraseResults_js_1.PhraseResultOutputType.None
                }
            };
            // Handle custom language models and voice mapping
            const translationContext = this.privSpeechContext.getContext().translation;
            if (translationContext) {
                const customModels = this.privRecognizerConfig.sourceLanguageModels;
                if (customModels !== undefined && customModels.length > 0) {
                    const phraseDetection = this.privSpeechContext.getContext().phraseDetection || {};
                    phraseDetection.customModels = customModels;
                    this.privSpeechContext.getContext().phraseDetection = phraseDetection;
                }
                const translationVoice = this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);
                if (translationVoice !== undefined) {
                    // Update translation actions for synthesis
                    translationContext.onSuccess = { action: OnSuccess_js_1.NextAction.Synthesize };
                    translationContext.onPassthrough = { action: OnSuccess_js_1.NextAction.Synthesize };
                }
            }
        }
    }
    noOp() {
        // operation not supported
        return;
    }
    // Encapsulated for derived service recognizers that need to send additional JSON
    async sendPrePayloadJSON(connection, generateNewRequestId = true) {
        if (this.sendPrePayloadJSONOverride !== undefined) {
            return this.sendPrePayloadJSONOverride(connection);
        }
        await this.sendSpeechContext(connection, generateNewRequestId);
        await this.sendWaveHeader(connection);
        return;
    }
    async sendWaveHeader(connection) {
        const format = await this.audioSource.format;
        // this.writeBufferToConsole(format.header);
        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Binary, "audio", this.privRequestSession.requestId, "audio/x-wav", format.header));
    }
    // Establishes a websocket connection to the end point.
    connectImpl() {
        if (this.privConnectionPromise !== undefined) {
            return this.privConnectionPromise.then((connection) => {
                if (connection.state() === Exports_js_2.ConnectionState.Disconnected) {
                    this.privConnectionId = null;
                    this.privConnectionPromise = undefined;
                    this.privServiceHasSentMessage = false;
                    return this.connectImpl();
                }
                return this.privConnectionPromise;
            }, () => {
                this.privConnectionId = null;
                this.privConnectionPromise = undefined;
                this.privServiceHasSentMessage = false;
                return this.connectImpl();
            });
        }
        this.privConnectionPromise = this.retryableConnect();
        // Attach an empty handler to allow the promise to run in the background while
        // other startup events happen. It'll eventually be awaited on.
        // eslint-disable-next-line @typescript-eslint/no-empty-function
        this.privConnectionPromise.catch(() => { });
        if (this.postConnectImplOverride !== undefined) {
            return this.postConnectImplOverride(this.privConnectionPromise);
        }
        return this.privConnectionPromise;
    }
    sendSpeechServiceConfig(connection, requestSession, SpeechServiceConfigJson) {
        requestSession.onSpeechContext();
        // filter out anything that is not required for the service to work.
        if (ServiceRecognizerBase.telemetryDataEnabled !== true) {
            const withTelemetry = JSON.parse(SpeechServiceConfigJson);
            const replacement = {
                context: {
                    system: withTelemetry.context.system,
                },
            };
            SpeechServiceConfigJson = JSON.stringify(replacement);
        }
        if (this.privRecognizerConfig.parameters.getProperty("f0f5debc-f8c9-4892-ac4b-90a7ab359fd2", "false").toLowerCase() === "true") {
            const json = JSON.parse(SpeechServiceConfigJson);
            json.context.DisableReferenceChannel = "True";
            json.context.MicSpec = "1_0_0";
            SpeechServiceConfigJson = JSON.stringify(json);
        }
        if (SpeechServiceConfigJson) {
            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Text, "speech.config", requestSession.requestId, "application/json", SpeechServiceConfigJson));
        }
        return;
    }
    async fetchConnection() {
        if (this.privConnectionConfigurationPromise !== undefined) {
            return this.privConnectionConfigurationPromise.then((connection) => {
                if (connection.state() === Exports_js_2.ConnectionState.Disconnected) {
                    this.privConnectionId = null;
                    this.privConnectionConfigurationPromise = undefined;
                    this.privServiceHasSentMessage = false;
                    return this.fetchConnection();
                }
                return this.privConnectionConfigurationPromise;
            }, () => {
                this.privConnectionId = null;
                this.privConnectionConfigurationPromise = undefined;
                this.privServiceHasSentMessage = false;
                return this.fetchConnection();
            });
        }
        this.privConnectionConfigurationPromise = this.configureConnection();
        return await this.privConnectionConfigurationPromise;
    }
    async sendAudio(audioStreamNode) {
        const audioFormat = await this.audioSource.format;
        this.privAverageBytesPerMs = audioFormat.avgBytesPerSec / 1000;
        // The time we last sent data to the service.
        let nextSendTime = Date.now();
        // Max amount to send before we start to throttle
        const fastLaneSizeMs = this.privRecognizerConfig.parameters.getProperty("SPEECH-TransmitLengthBeforThrottleMs", "5000");
        const maxSendUnthrottledBytes = audioFormat.avgBytesPerSec / 1000 * parseInt(fastLaneSizeMs, 10);
        const startRecogNumber = this.privRequestSession.recogNumber;
        const readAndUploadCycle = async () => {
            // If speech is done, stop sending audio.
            if (!this.privIsDisposed &&
                !this.privRequestSession.isSpeechEnded &&
                this.privRequestSession.isRecognizing &&
                this.privRequestSession.recogNumber === startRecogNumber) {
                const connection = await this.fetchConnection();
                const audioStreamChunk = await audioStreamNode.read();
                // we have a new audio chunk to upload.
                if (this.privRequestSession.isSpeechEnded) {
                    // If service already recognized audio end then don't send any more audio
                    return;
                }
                let payload;
                let sendDelay;
                if (!audioStreamChunk || audioStreamChunk.isEnd) {
                    payload = null;
                    sendDelay = 0;
                }
                else {
                    payload = audioStreamChunk.buffer;
                    this.privRequestSession.onAudioSent(payload.byteLength);
                    if (maxSendUnthrottledBytes >= this.privRequestSession.bytesSent) {
                        sendDelay = 0;
                    }
                    else {
                        sendDelay = Math.max(0, nextSendTime - Date.now());
                    }
                }
                if (0 !== sendDelay) {
                    await this.delay(sendDelay);
                }
                if (payload !== null) {
                    nextSendTime = Date.now() + (payload.byteLength * 1000 / (audioFormat.avgBytesPerSec * 2));
                }
                // Are we still alive?
                if (!this.privIsDisposed &&
                    !this.privRequestSession.isSpeechEnded &&
                    this.privRequestSession.isRecognizing &&
                    this.privRequestSession.recogNumber === startRecogNumber) {
                    connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Binary, "audio", this.privRequestSession.requestId, null, payload)).catch(() => {
                        // eslint-disable-next-line @typescript-eslint/no-empty-function
                        this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition).catch(() => { });
                    });
                    if (!audioStreamChunk?.isEnd) {
                        // this.writeBufferToConsole(payload);
                        // Regardless of success or failure, schedule the next upload.
                        // If the underlying connection was broken, the next cycle will
                        // get a new connection and re-transmit missing audio automatically.
                        return readAndUploadCycle();
                    }
                    else {
                        // the audio stream has been closed, no need to schedule next
                        // read-upload cycle.
                        if (!this.privIsLiveAudio) {
                            this.privRequestSession.onSpeechEnded();
                        }
                    }
                }
            }
        };
        return readAndUploadCycle();
    }
    async retryableConnect() {
        let isUnAuthorized = false;
        this.privAuthFetchEventId = (0, Exports_js_2.createNoDashGuid)();
        const sessionId = this.privRequestSession.sessionId;
        this.privConnectionId = (sessionId !== undefined) ? sessionId : (0, Exports_js_2.createNoDashGuid)();
        this.privRequestSession.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);
        let lastStatusCode = 0;
        let lastReason = "";
        while (this.privRequestSession.numConnectionAttempts <= this.privRecognizerConfig.maxRetryCount) {
            this.privRequestSession.onRetryConnection();
            // Get the auth information for the connection. This is a bit of overkill for the current API surface, but leaving the plumbing in place to be able to raise a developer-customer
            // facing event when a connection fails to let them try and provide new auth information.
            const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);
            const auth = await authPromise;
            await this.privRequestSession.onAuthCompleted(false);
            // Create the connection
            const connection = await this.privConnectionFactory.create(this.privRecognizerConfig, auth, this.privConnectionId);
            // Attach the telemetry handlers.
            this.privRequestSession.listenForServiceTelemetry(connection.events);
            // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,
            // it'll stop sending events.
            connection.events.attach((event) => {
                this.connectionEvents.onEvent(event);
            });
            const response = await connection.open();
            // 200 == everything is fine.
            if (response.statusCode === 200) {
                await this.privRequestSession.onConnectionEstablishCompleted(response.statusCode);
                return Promise.resolve(connection);
            }
            else if (response.statusCode === 1006) {
                isUnAuthorized = true;
            }
            lastStatusCode = response.statusCode;
            lastReason = response.reason;
        }
        await this.privRequestSession.onConnectionEstablishCompleted(lastStatusCode, lastReason);
        return Promise.reject(`Unable to contact server. StatusCode: ${lastStatusCode}, ${this.privRecognizerConfig.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${lastReason}`);
    }
    delay(delayMs) {
        return new Promise((resolve) => this.privSetTimeout(resolve, delayMs));
    }
    writeBufferToConsole(buffer) {
        let out = "Buffer Size: ";
        if (null === buffer) {
            out += "null";
        }
        else {
            const readView = new Uint8Array(buffer);
            out += `${buffer.byteLength}\r\n`;
            for (let i = 0; i < buffer.byteLength; i++) {
                out += readView[i].toString(16).padStart(2, "0") + " ";
                if (((i + 1) % 16) === 0) {
                    // eslint-disable-next-line no-console
                    console.info(out);
                    out = "";
                }
            }
        }
        // eslint-disable-next-line no-console
        console.info(out);
    }
    async sendFinalAudio() {
        const connection = await this.fetchConnection();
        await connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_2.MessageType.Binary, "audio", this.privRequestSession.requestId, null, null));
        return;
    }
    // Takes an established websocket connection to the endpoint and sends speech configuration information.
    async configureConnection() {
        const connection = await this.connectImpl();
        if (this.configConnectionOverride !== undefined) {
            return this.configConnectionOverride(connection);
        }
        await this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());
        await this.sendPrePayloadJSON(connection, false);
        return connection;
    }
}
exports.ServiceRecognizerBase = ServiceRecognizerBase;
ServiceRecognizerBase.telemetryDataEnabled = true;

//# sourceMappingURL=ServiceRecognizerBase.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceTelemetryListener.Internal.js"
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceTelemetryListener.Internal.js ***!
  \********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ServiceTelemetryListener = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const RecognitionEvents_js_1 = __webpack_require__(/*! ./RecognitionEvents.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/RecognitionEvents.js");
class ServiceTelemetryListener {
    constructor(requestId, audioSourceId, audioNodeId) {
        this.privIsDisposed = false;
        this.privListeningTriggerMetric = null;
        this.privMicMetric = null;
        this.privConnectionEstablishMetric = null;
        this.privRequestId = requestId;
        this.privAudioSourceId = audioSourceId;
        this.privAudioNodeId = audioNodeId;
        this.privReceivedMessages = {};
        this.privPhraseLatencies = [];
        this.privHypothesisLatencies = [];
    }
    phraseReceived(audioReceivedTime) {
        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.
            this.privPhraseLatencies.push(Date.now() - audioReceivedTime);
        }
    }
    hypothesisReceived(audioReceivedTime) {
        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.
            this.privHypothesisLatencies.push(Date.now() - audioReceivedTime);
        }
    }
    onEvent(e) {
        if (this.privIsDisposed) {
            return;
        }
        if (e instanceof RecognitionEvents_js_1.RecognitionTriggeredEvent && e.requestId === this.privRequestId) {
            this.privListeningTriggerMetric = {
                End: e.eventTime,
                Name: "ListeningTrigger",
                Start: e.eventTime,
            };
        }
        if (e instanceof Exports_js_1.AudioStreamNodeAttachingEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
            this.privMicStartTime = e.eventTime;
        }
        if (e instanceof Exports_js_1.AudioStreamNodeAttachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
            this.privMicStartTime = e.eventTime;
        }
        if (e instanceof Exports_js_1.AudioSourceErrorEvent && e.audioSourceId === this.privAudioSourceId) {
            if (!this.privMicMetric) {
                this.privMicMetric = {
                    End: e.eventTime,
                    Error: e.error,
                    Name: "Microphone",
                    Start: this.privMicStartTime,
                };
            }
        }
        if (e instanceof Exports_js_1.AudioStreamNodeErrorEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
            if (!this.privMicMetric) {
                this.privMicMetric = {
                    End: e.eventTime,
                    Error: e.error,
                    Name: "Microphone",
                    Start: this.privMicStartTime,
                };
            }
        }
        if (e instanceof Exports_js_1.AudioStreamNodeDetachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {
            if (!this.privMicMetric) {
                this.privMicMetric = {
                    End: e.eventTime,
                    Name: "Microphone",
                    Start: this.privMicStartTime,
                };
            }
        }
        if (e instanceof RecognitionEvents_js_1.ConnectingToServiceEvent && e.requestId === this.privRequestId) {
            this.privConnectionId = e.sessionId;
        }
        if (e instanceof Exports_js_1.ConnectionStartEvent && e.connectionId === this.privConnectionId) {
            this.privConnectionStartTime = e.eventTime;
        }
        if (e instanceof Exports_js_1.ConnectionEstablishedEvent && e.connectionId === this.privConnectionId) {
            if (!this.privConnectionEstablishMetric) {
                this.privConnectionEstablishMetric = {
                    End: e.eventTime,
                    Id: this.privConnectionId,
                    Name: "Connection",
                    Start: this.privConnectionStartTime,
                };
            }
        }
        if (e instanceof Exports_js_1.ConnectionEstablishErrorEvent && e.connectionId === this.privConnectionId) {
            if (!this.privConnectionEstablishMetric) {
                this.privConnectionEstablishMetric = {
                    End: e.eventTime,
                    Error: this.getConnectionError(e.statusCode),
                    Id: this.privConnectionId,
                    Name: "Connection",
                    Start: this.privConnectionStartTime,
                };
            }
        }
        if (e instanceof Exports_js_1.ConnectionMessageReceivedEvent && e.connectionId === this.privConnectionId) {
            if (e.message && e.message.headers && e.message.headers.path) {
                if (!this.privReceivedMessages[e.message.headers.path]) {
                    this.privReceivedMessages[e.message.headers.path] = new Array();
                }
                const maxMessagesToSend = 50;
                if (this.privReceivedMessages[e.message.headers.path].length < maxMessagesToSend) {
                    this.privReceivedMessages[e.message.headers.path].push(e.networkReceivedTime);
                }
            }
        }
    }
    getTelemetry() {
        const metrics = new Array();
        if (this.privListeningTriggerMetric) {
            metrics.push(this.privListeningTriggerMetric);
        }
        if (this.privMicMetric) {
            metrics.push(this.privMicMetric);
        }
        if (this.privConnectionEstablishMetric) {
            metrics.push(this.privConnectionEstablishMetric);
        }
        if (this.privPhraseLatencies.length > 0) {
            metrics.push({
                PhraseLatencyMs: this.privPhraseLatencies,
            });
        }
        if (this.privHypothesisLatencies.length > 0) {
            metrics.push({
                FirstHypothesisLatencyMs: this.privHypothesisLatencies,
            });
        }
        const telemetry = {
            Metrics: metrics,
            ReceivedMessages: this.privReceivedMessages,
        };
        const json = JSON.stringify(telemetry);
        // We dont want to send the same telemetry again. So clean those out.
        this.privReceivedMessages = {};
        this.privListeningTriggerMetric = null;
        this.privMicMetric = null;
        this.privConnectionEstablishMetric = null;
        this.privPhraseLatencies = [];
        this.privHypothesisLatencies = [];
        return json;
    }
    // Determines if there are any telemetry events to send to the service.
    get hasTelemetry() {
        return (Object.keys(this.privReceivedMessages).length !== 0 ||
            this.privListeningTriggerMetric !== null ||
            this.privMicMetric !== null ||
            this.privConnectionEstablishMetric !== null ||
            this.privPhraseLatencies.length !== 0 ||
            this.privHypothesisLatencies.length !== 0);
    }
    dispose() {
        this.privIsDisposed = true;
    }
    getConnectionError(statusCode) {
        /*
        -- Websocket status codes --
        NormalClosure = 1000,
        EndpointUnavailable = 1001,
        ProtocolError = 1002,
        InvalidMessageType = 1003,
        Empty = 1005,
        InvalidPayloadData = 1007,
        PolicyViolation = 1008,
        MessageTooBig = 1009,
        MandatoryExtension = 1010,
        InternalServerError = 1011
        */
        switch (statusCode) {
            case 400:
            case 1002:
            case 1003:
            case 1005:
            case 1007:
            case 1008:
            case 1009: return "BadRequest";
            case 401: return "Unauthorized";
            case 403: return "Forbidden";
            case 503:
            case 1001: return "ServerUnavailable";
            case 500:
            case 1011: return "ServerError";
            case 408:
            case 504: return "Timeout";
            default: return "statuscode:" + statusCode.toString();
        }
    }
}
exports.ServiceTelemetryListener = ServiceTelemetryListener;

//# sourceMappingURL=ServiceTelemetryListener.Internal.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionFactory.js"
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionFactory.js ***!
  \**********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechConnectionFactory = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js");
const Exports_js_4 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
class SpeechConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {
    constructor() {
        super(...arguments);
        this.interactiveRelativeUri = "/speech/recognition/interactive/cognitiveservices/v1";
        this.conversationRelativeUri = "/speech/recognition/conversation/cognitiveservices/v1";
        this.dictationRelativeUri = "/speech/recognition/dictation/cognitiveservices/v1";
        this.universalUri = "/stt/speech/universal/v";
    }
    async create(config, authInfo, connectionId) {
        let endpoint = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Endpoint, undefined);
        const region = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Region, undefined);
        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);
        const host = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Host, "wss://" + region + ".stt.speech" + hostSuffix);
        const queryParams = {};
        const endpointId = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_EndpointId, undefined);
        const language = config.parameters.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);
        if (endpointId) {
            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId) === -1) {
                queryParams[QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;
            }
        }
        else if (language) {
            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.Language) === -1) {
                queryParams[QueryParameterNames_js_1.QueryParameterNames.Language] = language;
            }
        }
        if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.Format) === -1) {
            queryParams[QueryParameterNames_js_1.QueryParameterNames.Format] = config.parameters.getProperty(Exports_js_2.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]).toLowerCase();
        }
        if (config.autoDetectSourceLanguages !== undefined) {
            queryParams[QueryParameterNames_js_1.QueryParameterNames.EnableLanguageId] = "true";
        }
        this.setCommonUrlParams(config, queryParams, endpoint);
        if (!!endpoint) {
            const endpointUrl = new URL(endpoint);
            const pathName = endpointUrl.pathname;
            if (pathName === "" || pathName === "/") {
                // We need to generate the path, and we need to check for a redirect.
                endpointUrl.pathname = this.universalUri + config.recognitionEndpointVersion;
                endpoint = await ConnectionFactoryBase_js_1.ConnectionFactoryBase.getRedirectUrlFromEndpoint(endpointUrl.toString());
            }
        }
        if (!endpoint) {
            switch (config.recognitionMode) {
                case PhraseDetectionContext_js_1.RecognitionMode.Conversation:
                    if (config.parameters.getProperty(Exports_js_2.ForceDictationPropertyName, "false") === "true") {
                        endpoint = host + this.dictationRelativeUri;
                    }
                    else {
                        if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {
                            endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;
                        }
                        else {
                            endpoint = host + this.conversationRelativeUri;
                        }
                    }
                    break;
                case PhraseDetectionContext_js_1.RecognitionMode.Dictation:
                    endpoint = host + this.dictationRelativeUri;
                    break;
                default:
                    if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {
                        endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;
                    }
                    else {
                        endpoint = host + this.interactiveRelativeUri; // default is interactive
                    }
                    break;
            }
        }
        const headers = {};
        if (authInfo.token !== undefined && authInfo.token !== "") {
            headers[authInfo.headerName] = authInfo.token;
        }
        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;
        headers.connectionId = connectionId;
        const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
        const webSocketConnection = new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_4.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
        // Set the value of SpeechServiceConnection_Url to webSocketConnection.uri (and not to `endpoint`), since this value is the final
        // URI that was used to make the connection (including query parameters).
        const uri = webSocketConnection.uri;
        config.parameters.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Url, uri);
        return webSocketConnection;
    }
}
exports.SpeechConnectionFactory = SpeechConnectionFactory;

//# sourceMappingURL=SpeechConnectionFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js"
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js ***!
  \*******************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechConnectionMessage = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
class SpeechConnectionMessage extends Exports_js_1.ConnectionMessage {
    constructor(messageType, path, requestId, contentType, body, streamId, additionalHeaders, id) {
        if (!path) {
            throw new Exports_js_1.ArgumentNullError("path");
        }
        if (!requestId) {
            throw new Exports_js_1.ArgumentNullError("requestId");
        }
        const headers = {};
        headers[HeaderNames_js_1.HeaderNames.Path] = path;
        headers[HeaderNames_js_1.HeaderNames.RequestId] = requestId;
        headers[HeaderNames_js_1.HeaderNames.RequestTimestamp] = new Date().toISOString();
        if (contentType) {
            headers[HeaderNames_js_1.HeaderNames.ContentType] = contentType;
        }
        if (streamId) {
            headers[HeaderNames_js_1.HeaderNames.RequestStreamId] = streamId;
        }
        if (additionalHeaders) {
            for (const headerName in additionalHeaders) {
                if (headerName) {
                    headers[headerName] = additionalHeaders[headerName];
                }
            }
        }
        if (id) {
            super(messageType, body, headers, id);
        }
        else {
            super(messageType, body, headers);
        }
        this.privPath = path;
        this.privRequestId = requestId;
        this.privContentType = contentType;
        this.privStreamId = streamId;
        this.privAdditionalHeaders = additionalHeaders;
    }
    get path() {
        return this.privPath;
    }
    get requestId() {
        return this.privRequestId;
    }
    get contentType() {
        return this.privContentType;
    }
    get streamId() {
        return this.privStreamId;
    }
    get additionalHeaders() {
        return this.privAdditionalHeaders;
    }
    static fromConnectionMessage(message) {
        let path = null;
        let requestId = null;
        let contentType = null;
        // let requestTimestamp = null;
        let streamId = null;
        const additionalHeaders = {};
        if (message.headers) {
            for (const headerName in message.headers) {
                if (headerName) {
                    if (headerName.toLowerCase() === HeaderNames_js_1.HeaderNames.Path.toLowerCase()) {
                        path = message.headers[headerName];
                    }
                    else if (headerName.toLowerCase() === HeaderNames_js_1.HeaderNames.RequestId.toLowerCase()) {
                        requestId = message.headers[headerName];
                        // } else if (headerName.toLowerCase() === HeaderNames.RequestTimestamp.toLowerCase()) {
                        //  requestTimestamp = message.headers[headerName];
                    }
                    else if (headerName.toLowerCase() === HeaderNames_js_1.HeaderNames.ContentType.toLowerCase()) {
                        contentType = message.headers[headerName];
                    }
                    else if (headerName.toLowerCase() === HeaderNames_js_1.HeaderNames.RequestStreamId.toLowerCase()) {
                        streamId = message.headers[headerName];
                    }
                    else {
                        additionalHeaders[headerName] = message.headers[headerName];
                    }
                }
            }
        }
        return new SpeechConnectionMessage(message.messageType, path, requestId, contentType, message.body, streamId, additionalHeaders, message.id);
    }
}
exports.SpeechConnectionMessage = SpeechConnectionMessage;

//# sourceMappingURL=SpeechConnectionMessage.Internal.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechContext.js"
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechContext.js ***!
  \************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechContext = void 0;
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
const PhraseOutput_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseOutput/PhraseOutput.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseOutput/PhraseOutput.js");
/**
 * Represents the JSON used in the speech.context message sent to the speech service.
 * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.
 */
class SpeechContext {
    constructor(dynamicGrammar) {
        this.privContext = {};
        this.privDynamicGrammar = dynamicGrammar;
    }
    getContext() {
        return this.privContext;
    }
    /**
     * @Internal
     * This is only used by pronunciation assessment config.
     * Do not use externally, object returned will change without warning or notice.
     */
    setPronunciationAssessmentParams(params, isSpeakerDiarizationEnabled = false) {
        if (this.privContext.phraseDetection === undefined) {
            this.privContext.phraseDetection = {
                enrichment: {
                    pronunciationAssessment: {}
                }
            };
        }
        if (this.privContext.phraseDetection.enrichment === undefined) {
            this.privContext.phraseDetection.enrichment = {
                pronunciationAssessment: {}
            };
        }
        this.privContext.phraseDetection.enrichment.pronunciationAssessment = JSON.parse(params) || {};
        if (isSpeakerDiarizationEnabled) {
            this.privContext.phraseDetection.mode = PhraseDetectionContext_js_1.RecognitionMode.Conversation;
        }
        this.setWordLevelTimings();
        this.privContext.phraseOutput.detailed.options.push(PhraseOutput_js_1.PhraseOption.PronunciationAssessment);
        if (this.privContext.phraseOutput.detailed.options.indexOf(PhraseOutput_js_1.PhraseOption.SNR) === -1) {
            this.privContext.phraseOutput.detailed.options.push(PhraseOutput_js_1.PhraseOption.SNR);
        }
    }
    setDetailedOutputFormat() {
        if (this.privContext.phraseOutput === undefined) {
            this.privContext.phraseOutput = {
                detailed: {
                    options: []
                }
            };
        }
        if (this.privContext.phraseOutput.detailed === undefined) {
            this.privContext.phraseOutput.detailed = {
                options: []
            };
        }
        this.privContext.phraseOutput.format = PhraseOutput_js_1.OutputFormat.Detailed;
    }
    setWordLevelTimings() {
        if (this.privContext.phraseOutput === undefined) {
            this.privContext.phraseOutput = {
                detailed: {
                    options: []
                }
            };
        }
        if (this.privContext.phraseOutput.detailed === undefined) {
            this.privContext.phraseOutput.detailed = {
                options: []
            };
        }
        this.privContext.phraseOutput.format = PhraseOutput_js_1.OutputFormat.Detailed;
        if (this.privContext.phraseOutput.detailed.options.indexOf(PhraseOutput_js_1.PhraseOption.WordTimings) === -1) {
            this.privContext.phraseOutput.detailed.options.push(PhraseOutput_js_1.PhraseOption.WordTimings);
        }
    }
    setSpeakerDiarizationAudioOffsetMs(audioOffsetMs) {
        this.privContext.phraseDetection.speakerDiarization.audioOffsetMs = audioOffsetMs;
    }
    toJSON() {
        const dgi = this.privDynamicGrammar.generateGrammarObject();
        this.privContext.dgi = dgi;
        const ret = JSON.stringify(this.privContext);
        return ret;
    }
}
exports.SpeechContext = SpeechContext;

//# sourceMappingURL=SpeechContext.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceConfig.js"
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceConfig.js ***!
  \******************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.type = exports.connectivity = exports.Device = exports.OS = exports.System = exports.Context = exports.SpeechServiceConfig = void 0;
/* eslint-disable max-classes-per-file */
// The config is serialized and sent as the Speech.Config
class SpeechServiceConfig {
    constructor(context) {
        this.context = context;
    }
    serialize() {
        return JSON.stringify(this, (key, value) => {
            if (value && typeof value === "object" && !Array.isArray(value)) {
                const replacement = {};
                for (const k in value) {
                    if (Object.hasOwnProperty.call(value, k)) {
                        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
                        replacement[k && k.charAt(0).toLowerCase() + k.substring(1)] = value[k];
                    }
                }
                return replacement;
            }
            return value;
        });
    }
    get Context() {
        return this.context;
    }
    get Recognition() {
        return this.recognition;
    }
    set Recognition(value) {
        this.recognition = value.toLowerCase();
    }
}
exports.SpeechServiceConfig = SpeechServiceConfig;
class Context {
    constructor(os) {
        this.system = new System();
        this.os = os;
    }
}
exports.Context = Context;
class System {
    constructor() {
        // Note: below will be patched for official builds.
        const SPEECHSDK_CLIENTSDK_VERSION = "1.47.0";
        this.name = "SpeechSDK";
        this.version = SPEECHSDK_CLIENTSDK_VERSION;
        this.build = "JavaScript";
        this.lang = "JavaScript";
    }
}
exports.System = System;
class OS {
    constructor(platform, name, version) {
        this.platform = platform;
        this.name = name;
        this.version = version;
    }
}
exports.OS = OS;
class Device {
    constructor(manufacturer, model, version) {
        this.manufacturer = manufacturer;
        this.model = model;
        this.version = version;
    }
}
exports.Device = Device;
var connectivity;
(function (connectivity) {
    connectivity["Bluetooth"] = "Bluetooth";
    connectivity["Wired"] = "Wired";
    connectivity["WiFi"] = "WiFi";
    connectivity["Cellular"] = "Cellular";
    connectivity["InBuilt"] = "InBuilt";
    connectivity["Unknown"] = "Unknown";
})(connectivity = exports.connectivity || (exports.connectivity = {}));
var type;
(function (type) {
    type["Phone"] = "Phone";
    type["Speaker"] = "Speaker";
    type["Car"] = "Car";
    type["Headset"] = "Headset";
    type["Thermostat"] = "Thermostat";
    type["Microphones"] = "Microphones";
    type["Deskphone"] = "Deskphone";
    type["RemoteControl"] = "RemoteControl";
    type["Unknown"] = "Unknown";
    type["File"] = "File";
    type["Stream"] = "Stream";
})(type = exports.type || (exports.type = {}));

//# sourceMappingURL=SpeechServiceConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceInterfaces.js"
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceInterfaces.js ***!
  \**********************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=SpeechServiceInterfaces.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceRecognizer.js"
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechServiceRecognizer.js ***!
  \**********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechServiceRecognizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
// eslint-disable-next-line max-classes-per-file
class SpeechServiceRecognizer extends Exports_js_2.ServiceRecognizerBase {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer);
        this.privSpeechRecognizer = speechRecognizer;
    }
    async processTypeSpecificMessages(connectionMessage) {
        let result;
        const resultProps = new Exports_js_1.PropertyCollection();
        let processed = false;
        switch (connectionMessage.path.toLowerCase()) {
            case "speech.hypothesis":
            case "speech.fragment":
                const hypothesis = Exports_js_2.SpeechHypothesis.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, hypothesis.asJson());
                result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, Exports_js_1.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, hypothesis.Offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, // Speaker Id
                undefined, hypothesis.asJson(), resultProps);
                this.privRequestSession.onHypothesis(hypothesis.Offset);
                const ev = new Exports_js_1.SpeechRecognitionEventArgs(result, hypothesis.Offset, this.privRequestSession.sessionId);
                if (!!this.privSpeechRecognizer.recognizing) {
                    try {
                        this.privSpeechRecognizer.recognizing(this.privSpeechRecognizer, ev);
                        /* eslint-disable no-empty */
                    }
                    catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                    }
                }
                processed = true;
                break;
            case "speech.phrase":
                const simple = Exports_js_2.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, simple.asJson());
                const resultReason = Exports_js_2.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus, this.privExpectContentAssessmentResponse);
                this.privRequestSession.onPhraseRecognized(simple.Offset + simple.Duration);
                if (Exports_js_1.ResultReason.Canceled === resultReason) {
                    const cancelReason = Exports_js_2.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);
                    const cancellationErrorCode = Exports_js_2.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);
                    await this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_2.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
                }
                else {
                    // Like the native SDK's, don't event / return an EndOfDictation message.
                    if (simple.RecognitionStatus === Exports_js_2.RecognitionStatus.EndOfDictation) {
                        break;
                    }
                    if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.OutputFormatPropertyName) === Exports_js_1.OutputFormat[Exports_js_1.OutputFormat.Simple]) {
                        result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset, simple.Language, simple.LanguageDetectionConfidence, undefined, // Speaker Id
                        undefined, simple.asJson(), resultProps);
                    }
                    else {
                        const detailed = Exports_js_2.DetailedSpeechPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset);
                        resultProps.setProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult, detailed.asJson());
                        result = new Exports_js_1.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === Exports_js_2.RecognitionStatus.Success ? detailed.NBest[0].Display : "", detailed.Duration, detailed.Offset, detailed.Language, detailed.LanguageDetectionConfidence, undefined, // Speaker Id
                        undefined, detailed.asJson(), resultProps);
                    }
                    const event = new Exports_js_1.SpeechRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);
                    if (!!this.privSpeechRecognizer.recognized) {
                        try {
                            this.privSpeechRecognizer.recognized(this.privSpeechRecognizer, event);
                            /* eslint-disable no-empty */
                        }
                        catch (error) {
                            // Not going to let errors in the event handler
                            // trip things up.
                        }
                    }
                    if (!!this.privSuccessCallback) {
                        try {
                            this.privSuccessCallback(result);
                        }
                        catch (e) {
                            if (!!this.privErrorCallback) {
                                this.privErrorCallback(e);
                            }
                        }
                        // Only invoke the call back once.
                        // and if it's successful don't invoke the
                        // error after that.
                        this.privSuccessCallback = undefined;
                        this.privErrorCallback = undefined;
                    }
                }
                processed = true;
                break;
            default:
                break;
        }
        return processed;
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        const properties = new Exports_js_1.PropertyCollection();
        properties.setProperty(Exports_js_2.CancellationErrorCodePropertyName, Exports_js_1.CancellationErrorCode[errorCode]);
        if (!!this.privSpeechRecognizer.canceled) {
            const cancelEvent = new Exports_js_1.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
            try {
                this.privSpeechRecognizer.canceled(this.privSpeechRecognizer, cancelEvent);
                /* eslint-disable no-empty */
            }
            catch { }
        }
        if (!!this.privSuccessCallback) {
            const result = new Exports_js_1.SpeechRecognitionResult(requestId, Exports_js_1.ResultReason.Canceled, undefined, // Text
            undefined, // Duration
            undefined, // Offset
            undefined, // Language
            undefined, // Language Detection Confidence
            undefined, // Speaker Id
            error, undefined, // Json
            properties);
            try {
                this.privSuccessCallback(result);
                this.privSuccessCallback = undefined;
                /* eslint-disable no-empty */
            }
            catch { }
        }
    }
}
exports.SpeechServiceRecognizer = SpeechServiceRecognizer;

//# sourceMappingURL=SpeechServiceRecognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisAdapter.js"
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisAdapter.js ***!
  \*********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesisAdapter = void 0;
const Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
class SpeechSynthesisAdapter extends Exports_js_2.SynthesisAdapterBase {
    constructor(authentication, connectionFactory, synthesizerConfig, speechSynthesizer, audioDestination) {
        super(authentication, connectionFactory, synthesizerConfig, audioDestination);
        this.privSpeechSynthesizer = speechSynthesizer;
        this.privSynthesizer = speechSynthesizer;
    }
    setSynthesisContextSynthesisSection() {
        this.privSynthesisContext.setSynthesisSection(this.privSpeechSynthesizer);
    }
    onSynthesisStarted(requestId) {
        const synthesisStartEventArgs = new Exports_js_1.SpeechSynthesisEventArgs(new Exports_js_1.SpeechSynthesisResult(requestId, Exports_js_1.ResultReason.SynthesizingAudioStarted));
        if (!!this.privSpeechSynthesizer.synthesisStarted) {
            this.privSpeechSynthesizer.synthesisStarted(this.privSpeechSynthesizer, synthesisStartEventArgs);
        }
    }
    onSynthesizing(audio) {
        if (!!this.privSpeechSynthesizer.synthesizing) {
            try {
                const audioWithHeader = this.privSynthesisTurn.audioOutputFormat.addHeader(audio);
                const ev = new Exports_js_1.SpeechSynthesisEventArgs(new Exports_js_1.SpeechSynthesisResult(this.privSynthesisTurn.requestId, Exports_js_1.ResultReason.SynthesizingAudio, audioWithHeader));
                this.privSpeechSynthesizer.synthesizing(this.privSpeechSynthesizer, ev);
            }
            catch (error) {
                // Not going to let errors in the event handler
                // trip things up.
            }
        }
    }
    onSynthesisCancelled(result) {
        if (!!this.privSpeechSynthesizer.SynthesisCanceled) {
            const cancelEvent = new Exports_js_1.SpeechSynthesisEventArgs(result);
            try {
                this.privSpeechSynthesizer.SynthesisCanceled(this.privSpeechSynthesizer, cancelEvent);
                /* eslint-disable no-empty */
            }
            catch { }
        }
    }
    onSynthesisCompleted(result) {
        if (this.privSpeechSynthesizer.synthesisCompleted) {
            try {
                this.privSpeechSynthesizer.synthesisCompleted(this.privSpeechSynthesizer, new Exports_js_1.SpeechSynthesisEventArgs(result));
            }
            catch (e) {
                // Not going to let errors in the event handler
                // trip things up.
            }
        }
    }
    onWordBoundary(wordBoundaryEventArgs) {
        if (!!this.privSpeechSynthesizer.wordBoundary) {
            try {
                this.privSpeechSynthesizer.wordBoundary(this.privSpeechSynthesizer, wordBoundaryEventArgs);
            }
            catch (error) {
                // Not going to let errors in the event handler
                // trip things up.
            }
        }
    }
    onVisemeReceived(visemeEventArgs) {
        if (!!this.privSpeechSynthesizer.visemeReceived) {
            try {
                this.privSpeechSynthesizer.visemeReceived(this.privSpeechSynthesizer, visemeEventArgs);
            }
            catch (error) {
                // Not going to let errors in the event handler
                // trip things up.
            }
        }
    }
    onBookmarkReached(bookmarkEventArgs) {
        if (!!this.privSpeechSynthesizer.bookmarkReached) {
            try {
                this.privSpeechSynthesizer.bookmarkReached(this.privSpeechSynthesizer, bookmarkEventArgs);
            }
            catch (error) {
                // Not going to let errors in the event handler
                // trip things up.
            }
        }
    }
}
exports.SpeechSynthesisAdapter = SpeechSynthesisAdapter;

//# sourceMappingURL=SpeechSynthesisAdapter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisConnectionFactory.js"
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisConnectionFactory.js ***!
  \*******************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesisConnectionFactory = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js");
class SpeechSynthesisConnectionFactory {
    constructor() {
        this.synthesisUri = "/tts/cognitiveservices/websocket/v1";
    }
    async create(config, authInfo, connectionId) {
        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);
        const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, undefined);
        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);
        const endpointId = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, undefined);
        const hostPrefix = (endpointId === undefined) ? "tts" : "voice";
        const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, "wss://" + region + "." + hostPrefix + ".speech" + hostSuffix);
        const queryParams = {};
        const headers = {};
        if (authInfo.token !== undefined && authInfo.token !== "") {
            headers[authInfo.headerName] = authInfo.token;
        }
        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;
        if (endpointId !== undefined && endpointId !== "") {
            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.CustomVoiceDeploymentId) === -1) {
                queryParams[QueryParameterNames_js_1.QueryParameterNames.CustomVoiceDeploymentId] = endpointId;
            }
        }
        if (config.avatarEnabled) {
            if (!endpoint || endpoint.search(QueryParameterNames_js_1.QueryParameterNames.EnableAvatar) === -1) {
                queryParams[QueryParameterNames_js_1.QueryParameterNames.EnableAvatar] = "true";
            }
        }
        if (!!endpoint) {
            const endpointUrl = new URL(endpoint);
            const pathName = endpointUrl.pathname;
            if (pathName === "" || pathName === "/") {
                // We need to generate the path, and we need to check for a redirect.
                endpointUrl.pathname = this.synthesisUri;
                endpoint = await ConnectionFactoryBase_js_1.ConnectionFactoryBase.getRedirectUrlFromEndpoint(endpointUrl.toString());
            }
        }
        if (!endpoint) {
            endpoint = host + this.synthesisUri;
        }
        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, endpoint);
        const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
        return new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromParameters(config.parameters), enableCompression, connectionId);
    }
}
exports.SpeechSynthesisConnectionFactory = SpeechSynthesisConnectionFactory;

//# sourceMappingURL=SpeechSynthesisConnectionFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisAdapterBase.js"
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisAdapterBase.js ***!
  \*******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesisAdapterBase = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js");
class SynthesisAdapterBase {
    constructor(authentication, connectionFactory, synthesizerConfig, audioDestination) {
        this.speakOverride = undefined;
        this.receiveMessageOverride = undefined;
        this.connectImplOverride = undefined;
        this.configConnectionOverride = undefined;
        // A promise for a configured connection.
        // Do not consume directly, call fetchConnection instead.
        this.privConnectionConfigurationPromise = undefined;
        if (!authentication) {
            throw new Exports_js_1.ArgumentNullError("authentication");
        }
        if (!connectionFactory) {
            throw new Exports_js_1.ArgumentNullError("connectionFactory");
        }
        if (!synthesizerConfig) {
            throw new Exports_js_1.ArgumentNullError("synthesizerConfig");
        }
        this.privAuthentication = authentication;
        this.privConnectionFactory = connectionFactory;
        this.privSynthesizerConfig = synthesizerConfig;
        this.privIsDisposed = false;
        this.privSessionAudioDestination = audioDestination;
        this.privSynthesisTurn = new Exports_js_3.SynthesisTurn();
        this.privConnectionEvents = new Exports_js_1.EventSource();
        this.privServiceEvents = new Exports_js_1.EventSource();
        this.privSynthesisContext = new Exports_js_3.SynthesisContext();
        this.privAgentConfig = new Exports_js_3.AgentConfig();
        this.connectionEvents.attach((connectionEvent) => {
            if (connectionEvent.name === "ConnectionClosedEvent") {
                const connectionClosedEvent = connectionEvent;
                if (connectionClosedEvent.statusCode !== 1000) {
                    this.cancelSynthesisLocal(Exports_js_2.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? Exports_js_2.CancellationErrorCode.BadRequestParameters : Exports_js_2.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);
                }
            }
        });
    }
    get synthesizerConfig() {
        return this.privSynthesizerConfig;
    }
    get synthesisContext() {
        return this.privSynthesisContext;
    }
    get agentConfig() {
        return this.privAgentConfig;
    }
    get connectionEvents() {
        return this.privConnectionEvents;
    }
    get serviceEvents() {
        return this.privServiceEvents;
    }
    set activityTemplate(messagePayload) {
        this.privActivityTemplate = messagePayload;
    }
    get activityTemplate() {
        return this.privActivityTemplate;
    }
    set audioOutputFormat(format) {
        this.privAudioOutputFormat = format;
        this.privSynthesisTurn.audioOutputFormat = format;
        if (this.privSessionAudioDestination !== undefined) {
            this.privSessionAudioDestination.format = format;
        }
        if (this.synthesisContext !== undefined) {
            this.synthesisContext.audioOutputFormat = format;
        }
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    async dispose(reason) {
        this.privIsDisposed = true;
        if (this.privSessionAudioDestination !== undefined) {
            this.privSessionAudioDestination.close();
        }
        if (this.privConnectionConfigurationPromise !== undefined) {
            const connection = await this.privConnectionConfigurationPromise;
            await connection.dispose(reason);
        }
    }
    async connect() {
        await this.connectImpl();
    }
    async sendNetworkMessage(path, payload) {
        const type = typeof payload === "string" ? Exports_js_1.MessageType.Text : Exports_js_1.MessageType.Binary;
        const contentType = typeof payload === "string" ? "application/json" : "";
        const connection = await this.fetchConnection();
        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(type, path, this.privSynthesisTurn.requestId, contentType, payload));
    }
    async Speak(text, isSSML, requestId, successCallback, errorCallBack, audioDestination) {
        let ssml;
        if (isSSML) {
            ssml = text;
        }
        else {
            ssml = this.privSynthesizer.buildSsml(text);
        }
        if (this.speakOverride !== undefined) {
            return this.speakOverride(ssml, requestId, successCallback, errorCallBack);
        }
        this.privSuccessCallback = successCallback;
        this.privErrorCallback = errorCallBack;
        this.privSynthesisTurn.startNewSynthesis(requestId, text, isSSML, audioDestination);
        try {
            await this.connectImpl();
            const connection = await this.fetchConnection();
            await this.sendSynthesisContext(connection);
            await this.sendSsmlMessage(connection, ssml, requestId);
            this.onSynthesisStarted(requestId);
            void this.receiveMessage();
        }
        catch (e) {
            this.cancelSynthesisLocal(Exports_js_2.CancellationReason.Error, Exports_js_2.CancellationErrorCode.ConnectionFailure, e);
            return Promise.reject(e);
        }
    }
    async stopSpeaking() {
        await this.connectImpl();
        const connection = await this.fetchConnection();
        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, "synthesis.control", this.privSynthesisTurn.requestId, "application/json", JSON.stringify({
            action: "stop"
        })));
    }
    // Cancels synthesis.
    cancelSynthesis(requestId, _cancellationReason, errorCode, error) {
        const properties = new Exports_js_2.PropertyCollection();
        properties.setProperty(Exports_js_3.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[errorCode]);
        const result = new Exports_js_2.SpeechSynthesisResult(requestId, Exports_js_2.ResultReason.Canceled, undefined, error, properties);
        this.onSynthesisCancelled(result);
        if (!!this.privSuccessCallback) {
            try {
                this.privSuccessCallback(result);
                /* eslint-disable no-empty */
            }
            catch { }
        }
    }
    // Cancels synthesis.
    cancelSynthesisLocal(cancellationReason, errorCode, error) {
        if (!!this.privSynthesisTurn.isSynthesizing) {
            this.privSynthesisTurn.onStopSynthesizing();
            this.cancelSynthesis(this.privSynthesisTurn.requestId, cancellationReason, errorCode, error);
        }
    }
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    processTypeSpecificMessages(_connectionMessage) {
        return true;
    }
    async receiveMessage() {
        try {
            const connection = await this.fetchConnection();
            const message = await connection.read();
            if (this.receiveMessageOverride !== undefined) {
                return this.receiveMessageOverride();
            }
            if (this.privIsDisposed) {
                // We're done.
                return;
            }
            // indicates we are draining the queue and it came with no message;
            if (!message) {
                if (!this.privSynthesisTurn.isSynthesizing) {
                    return;
                }
                else {
                    return this.receiveMessage();
                }
            }
            const connectionMessage = SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage.fromConnectionMessage(message);
            if (connectionMessage.requestId.toLowerCase() === this.privSynthesisTurn.requestId.toLowerCase()) {
                switch (connectionMessage.path.toLowerCase()) {
                    case "turn.start":
                        this.privSynthesisTurn.onServiceTurnStartResponse(connectionMessage.textBody);
                        break;
                    case "response":
                        this.privSynthesisTurn.onServiceResponseMessage(connectionMessage.textBody);
                        break;
                    case "audio":
                        if (this.privSynthesisTurn.streamId.toLowerCase() === connectionMessage.streamId.toLowerCase()
                            && !!connectionMessage.binaryBody) {
                            this.privSynthesisTurn.onAudioChunkReceived(connectionMessage.binaryBody);
                            this.onSynthesizing(connectionMessage.binaryBody);
                            if (this.privSessionAudioDestination !== undefined) {
                                this.privSessionAudioDestination.write(connectionMessage.binaryBody);
                            }
                        }
                        break;
                    case "audio.metadata":
                        const metadataList = Exports_js_3.SynthesisAudioMetadata.fromJSON(connectionMessage.textBody).Metadata;
                        for (const metadata of metadataList) {
                            switch (metadata.Type) {
                                case Exports_js_3.MetadataType.WordBoundary:
                                case Exports_js_3.MetadataType.SentenceBoundary:
                                    this.privSynthesisTurn.onTextBoundaryEvent(metadata);
                                    const wordBoundaryEventArgs = new Exports_js_2.SpeechSynthesisWordBoundaryEventArgs(metadata.Data.Offset, metadata.Data.Duration, metadata.Data.text.Text, metadata.Data.text.Length, metadata.Type === Exports_js_3.MetadataType.WordBoundary
                                        ? this.privSynthesisTurn.currentTextOffset : this.privSynthesisTurn.currentSentenceOffset, metadata.Data.text.BoundaryType);
                                    this.onWordBoundary(wordBoundaryEventArgs);
                                    break;
                                case Exports_js_3.MetadataType.Bookmark:
                                    const bookmarkEventArgs = new Exports_js_2.SpeechSynthesisBookmarkEventArgs(metadata.Data.Offset, metadata.Data.Bookmark);
                                    this.onBookmarkReached(bookmarkEventArgs);
                                    break;
                                case Exports_js_3.MetadataType.Viseme:
                                    this.privSynthesisTurn.onVisemeMetadataReceived(metadata);
                                    if (metadata.Data.IsLastAnimation) {
                                        const visemeEventArgs = new Exports_js_2.SpeechSynthesisVisemeEventArgs(metadata.Data.Offset, metadata.Data.VisemeId, this.privSynthesisTurn.getAndClearVisemeAnimation());
                                        this.onVisemeReceived(visemeEventArgs);
                                    }
                                    break;
                                case Exports_js_3.MetadataType.AvatarSignal:
                                    this.onAvatarEvent(metadata);
                                    break;
                                case Exports_js_3.MetadataType.SessionEnd:
                                    this.privSynthesisTurn.onSessionEnd(metadata);
                                    break;
                            }
                        }
                        break;
                    case "turn.end":
                        this.privSynthesisTurn.onServiceTurnEndResponse();
                        let result;
                        try {
                            result = await this.privSynthesisTurn.constructSynthesisResult();
                            if (!!this.privSuccessCallback) {
                                this.privSuccessCallback(result);
                            }
                        }
                        catch (error) {
                            if (!!this.privErrorCallback) {
                                this.privErrorCallback(error);
                            }
                        }
                        this.onSynthesisCompleted(result);
                        break;
                    default:
                        if (!this.processTypeSpecificMessages(connectionMessage)) {
                            // here are some messages that the derived class has not processed, dispatch them to connect class
                            if (!!this.privServiceEvents) {
                                this.serviceEvents.onEvent(new Exports_js_1.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));
                            }
                        }
                }
            }
            return this.receiveMessage();
        }
        catch (e) {
            // TODO: What goes here?
        }
    }
    sendSynthesisContext(connection) {
        this.setSynthesisContextSynthesisSection();
        const synthesisContextJson = this.synthesisContext.toJSON();
        if (synthesisContextJson) {
            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, "synthesis.context", this.privSynthesisTurn.requestId, "application/json", synthesisContextJson));
        }
        return;
    }
    setSpeechConfigSynthesisSection() {
        return;
    }
    connectImpl(isUnAuthorized = false) {
        if (this.privConnectionPromise != null) {
            return this.privConnectionPromise.then((connection) => {
                if (connection.state() === Exports_js_1.ConnectionState.Disconnected) {
                    this.privConnectionId = null;
                    this.privConnectionPromise = null;
                    return this.connectImpl();
                }
                return this.privConnectionPromise;
            }, () => {
                this.privConnectionId = null;
                this.privConnectionPromise = null;
                return this.connectImpl();
            });
        }
        this.privAuthFetchEventId = (0, Exports_js_1.createNoDashGuid)();
        this.privConnectionId = (0, Exports_js_1.createNoDashGuid)();
        this.privSynthesisTurn.onPreConnectionStart(this.privAuthFetchEventId);
        const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);
        this.privConnectionPromise = authPromise.then(async (result) => {
            this.privSynthesisTurn.onAuthCompleted(false);
            const connection = await this.privConnectionFactory.create(this.privSynthesizerConfig, result, this.privConnectionId);
            // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,
            // it'll stop sending events.
            connection.events.attach((event) => {
                this.connectionEvents.onEvent(event);
            });
            const response = await connection.open();
            if (response.statusCode === 200) {
                this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);
                return Promise.resolve(connection);
            }
            else if (response.statusCode === 403 && !isUnAuthorized) {
                return this.connectImpl(true);
            }
            else {
                this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);
                return Promise.reject(`Unable to contact server. StatusCode: ${response.statusCode},
                    ${this.privSynthesizerConfig.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url)} Reason: ${response.reason}`);
            }
        }, (error) => {
            this.privSynthesisTurn.onAuthCompleted(true);
            throw new Error(error);
        });
        // Attach an empty handler to allow the promise to run in the background while
        // other startup events happen. It'll eventually be awaited on.
        // eslint-disable-next-line @typescript-eslint/no-empty-function
        this.privConnectionPromise.catch(() => { });
        return this.privConnectionPromise;
    }
    sendSpeechServiceConfig(connection, SpeechServiceConfigJson) {
        if (SpeechServiceConfigJson) {
            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, "speech.config", this.privSynthesisTurn.requestId, "application/json", SpeechServiceConfigJson));
        }
    }
    sendSsmlMessage(connection, ssml, requestId) {
        return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, "ssml", requestId, "application/ssml+xml", ssml));
    }
    async fetchConnection() {
        if (this.privConnectionConfigurationPromise !== undefined) {
            return this.privConnectionConfigurationPromise.then((connection) => {
                if (connection.state() === Exports_js_1.ConnectionState.Disconnected) {
                    this.privConnectionId = null;
                    this.privConnectionConfigurationPromise = undefined;
                    return this.fetchConnection();
                }
                return this.privConnectionConfigurationPromise;
            }, () => {
                this.privConnectionId = null;
                this.privConnectionConfigurationPromise = undefined;
                return this.fetchConnection();
            });
        }
        this.privConnectionConfigurationPromise = this.configureConnection();
        return await this.privConnectionConfigurationPromise;
    }
    // Takes an established websocket connection to the endpoint and sends speech configuration information.
    async configureConnection() {
        const connection = await this.connectImpl();
        if (this.configConnectionOverride !== undefined) {
            return this.configConnectionOverride(connection);
        }
        this.setSpeechConfigSynthesisSection();
        await this.sendSpeechServiceConfig(connection, this.privSynthesizerConfig.SpeechServiceConfig.serialize());
        return connection;
    }
    onAvatarEvent(_metadata) {
        return;
    }
    onSynthesisStarted(_requestId) {
        return;
    }
    onSynthesizing(_audio) {
        return;
    }
    onSynthesisCancelled(_result) {
        return;
    }
    onSynthesisCompleted(_result) {
        return;
    }
    onWordBoundary(_wordBoundaryEventArgs) {
        return;
    }
    onVisemeReceived(_visemeEventArgs) {
        return;
    }
    onBookmarkReached(_bookmarkEventArgs) {
        return;
    }
}
exports.SynthesisAdapterBase = SynthesisAdapterBase;
SynthesisAdapterBase.telemetryDataEnabled = true;

//# sourceMappingURL=SynthesisAdapterBase.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js"
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js ***!
  \***************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesisContext = void 0;
const Exports_js_1 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Represents the JSON used in the synthesis.context message sent to the speech service.
 * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.
 */
class SynthesisContext {
    constructor() {
        this.privContext = {};
    }
    /**
     * Adds a section to the synthesis.context object.
     * @param sectionName Name of the section to add.
     * @param value JSON serializable object that represents the value.
     */
    setSection(sectionName, value) {
        this.privContext[sectionName] = value;
    }
    /**
     * Sets the audio output format for synthesis context generation.
     * @param format {AudioOutputFormatImpl} the output format
     */
    set audioOutputFormat(format) {
        this.privAudioOutputFormat = format;
    }
    toJSON() {
        return JSON.stringify(this.privContext);
    }
    setSynthesisSection(speechSynthesizer) {
        const synthesisSection = this.buildSynthesisContext(speechSynthesizer);
        this.setSection("synthesis", synthesisSection);
    }
    buildSynthesisContext(speechSynthesizer) {
        return {
            audio: {
                metadataOptions: {
                    bookmarkEnabled: (!!speechSynthesizer?.bookmarkReached),
                    punctuationBoundaryEnabled: speechSynthesizer?.properties.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, (!!speechSynthesizer?.wordBoundary)),
                    sentenceBoundaryEnabled: speechSynthesizer?.properties.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),
                    sessionEndEnabled: true,
                    visemeEnabled: (!!speechSynthesizer?.visemeReceived),
                    wordBoundaryEnabled: speechSynthesizer?.properties.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_RequestWordBoundary, (!!speechSynthesizer?.wordBoundary)),
                },
                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,
            },
            language: {
                autoDetection: speechSynthesizer?.autoDetectSourceLanguage
            }
        };
    }
}
exports.SynthesisContext = SynthesisContext;

//# sourceMappingURL=SynthesisContext.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisEvents.js"
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisEvents.js ***!
  \**************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesisStartedEvent = exports.ConnectingToSynthesisServiceEvent = exports.SynthesisTriggeredEvent = exports.SpeechSynthesisEvent = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
class SpeechSynthesisEvent extends Exports_js_1.PlatformEvent {
    constructor(eventName, requestId, eventType = Exports_js_1.EventType.Info) {
        super(eventName, eventType);
        this.privRequestId = requestId;
    }
    get requestId() {
        return this.privRequestId;
    }
}
exports.SpeechSynthesisEvent = SpeechSynthesisEvent;
class SynthesisTriggeredEvent extends SpeechSynthesisEvent {
    constructor(requestId, sessionAudioDestinationId, turnAudioDestinationId) {
        super("SynthesisTriggeredEvent", requestId);
        this.privSessionAudioDestinationId = sessionAudioDestinationId;
        this.privTurnAudioDestinationId = turnAudioDestinationId;
    }
    get audioSessionDestinationId() {
        return this.privSessionAudioDestinationId;
    }
    get audioTurnDestinationId() {
        return this.privTurnAudioDestinationId;
    }
}
exports.SynthesisTriggeredEvent = SynthesisTriggeredEvent;
class ConnectingToSynthesisServiceEvent extends SpeechSynthesisEvent {
    constructor(requestId, authFetchEventId) {
        super("ConnectingToSynthesisServiceEvent", requestId);
        this.privAuthFetchEventId = authFetchEventId;
    }
    get authFetchEventId() {
        return this.privAuthFetchEventId;
    }
}
exports.ConnectingToSynthesisServiceEvent = ConnectingToSynthesisServiceEvent;
class SynthesisStartedEvent extends SpeechSynthesisEvent {
    constructor(requestId, authFetchEventId) {
        super("SynthesisStartedEvent", requestId);
        this.privAuthFetchEventId = authFetchEventId;
    }
    get authFetchEventId() {
        return this.privAuthFetchEventId;
    }
}
exports.SynthesisStartedEvent = SynthesisStartedEvent;

//# sourceMappingURL=SynthesisEvents.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisRestAdapter.js"
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisRestAdapter.js ***!
  \*******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesisRestAdapter = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
/**
 * Implements methods for speech synthesis classes, sending requests to endpoint
 * and parsing response into expected format
 * @class SynthesisRestAdapter
 */
class SynthesisRestAdapter {
    constructor(config, authentication) {
        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);
        if (!endpoint) {
            const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, "westus");
            const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);
            endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, `https://${region}.tts.speech${hostSuffix}`);
        }
        this.privUri = `${endpoint}/cognitiveservices/voices/list`;
        const options = Exports_js_1.RestConfigBase.requestOptions;
        this.privRestAdapter = new Exports_js_1.RestMessageAdapter(options);
        this.privAuthentication = authentication;
    }
    /**
     * Sends list voices request to endpoint.
     * @function
     * @public
     * @param connectionId - guid for connectionId
     * @returns {Promise<IRestResponse>} rest response to status request
     */
    getVoicesList(connectionId) {
        this.privRestAdapter.setHeaders(HeaderNames_js_1.HeaderNames.ConnectionId, connectionId);
        return this.privAuthentication.fetch(connectionId).then((authInfo) => {
            this.privRestAdapter.setHeaders(authInfo.headerName, authInfo.token);
            return this.privRestAdapter.request(Exports_js_1.RestRequestType.Get, this.privUri);
        });
    }
}
exports.SynthesisRestAdapter = SynthesisRestAdapter;

//# sourceMappingURL=SynthesisRestAdapter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisTurn.js"
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisTurn.js ***!
  \************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesisTurn = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const AudioOutputStream_js_1 = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js");
const Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const SynthesisAudioMetadata_js_1 = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js");
const SynthesisEvents_js_1 = __webpack_require__(/*! ./SynthesisEvents.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisEvents.js");
class SynthesisTurn {
    constructor() {
        this.privIsDisposed = false;
        this.privIsSynthesizing = false;
        this.privIsSynthesisEnded = false;
        this.privBytesReceived = 0;
        this.privInTurn = false;
        this.privTextOffset = 0;
        this.privNextSearchTextIndex = 0;
        this.privSentenceOffset = 0;
        this.privNextSearchSentenceIndex = 0;
        this.privRequestId = (0, Exports_js_1.createNoDashGuid)();
        this.privTurnDeferral = new Exports_js_1.Deferred();
        // We're not in a turn, so resolve.
        this.privTurnDeferral.resolve();
    }
    get requestId() {
        return this.privRequestId;
    }
    get streamId() {
        return this.privStreamId;
    }
    set streamId(value) {
        this.privStreamId = value;
    }
    get audioOutputFormat() {
        return this.privAudioOutputFormat;
    }
    set audioOutputFormat(format) {
        this.privAudioOutputFormat = format;
    }
    get turnCompletionPromise() {
        return this.privTurnDeferral.promise;
    }
    get isSynthesisEnded() {
        return this.privIsSynthesisEnded;
    }
    get isSynthesizing() {
        return this.privIsSynthesizing;
    }
    get currentTextOffset() {
        return this.privTextOffset;
    }
    get currentSentenceOffset() {
        return this.privSentenceOffset;
    }
    // The number of bytes received for current turn
    get bytesReceived() {
        return this.privBytesReceived;
    }
    get audioDuration() {
        return this.privAudioDuration;
    }
    get extraProperties() {
        if (!!this.privWebRTCSDP) {
            const properties = new Exports_js_2.PropertyCollection();
            properties.setProperty(Exports_js_2.PropertyId.TalkingAvatarService_WebRTC_SDP, this.privWebRTCSDP);
            return properties;
        }
        return undefined;
    }
    async getAllReceivedAudio() {
        if (!!this.privReceivedAudio) {
            return Promise.resolve(this.privReceivedAudio);
        }
        if (!this.privIsSynthesisEnded) {
            return null;
        }
        await this.readAllAudioFromStream();
        return Promise.resolve(this.privReceivedAudio);
    }
    async getAllReceivedAudioWithHeader() {
        if (!!this.privReceivedAudioWithHeader) {
            return this.privReceivedAudioWithHeader;
        }
        if (!this.privIsSynthesisEnded) {
            return null;
        }
        if (this.audioOutputFormat.hasHeader) {
            const audio = await this.getAllReceivedAudio();
            this.privReceivedAudioWithHeader = this.audioOutputFormat.addHeader(audio);
            return this.privReceivedAudioWithHeader;
        }
        else {
            return this.getAllReceivedAudio();
        }
    }
    startNewSynthesis(requestId, rawText, isSSML, audioDestination) {
        this.privIsSynthesisEnded = false;
        this.privIsSynthesizing = true;
        this.privRequestId = requestId;
        this.privRawText = rawText;
        this.privIsSSML = isSSML;
        this.privAudioOutputStream = new AudioOutputStream_js_1.PullAudioOutputStreamImpl();
        this.privAudioOutputStream.format = this.privAudioOutputFormat;
        this.privReceivedAudio = null;
        this.privReceivedAudioWithHeader = null;
        this.privBytesReceived = 0;
        this.privTextOffset = 0;
        this.privNextSearchTextIndex = 0;
        this.privSentenceOffset = 0;
        this.privNextSearchSentenceIndex = 0;
        this.privPartialVisemeAnimation = "";
        this.privWebRTCSDP = "";
        if (audioDestination !== undefined) {
            this.privTurnAudioDestination = audioDestination;
            this.privTurnAudioDestination.format = this.privAudioOutputFormat;
        }
        this.onEvent(new SynthesisEvents_js_1.SynthesisTriggeredEvent(this.requestId, undefined, audioDestination === undefined ? undefined : audioDestination.id()));
    }
    onPreConnectionStart(authFetchEventId) {
        this.privAuthFetchEventId = authFetchEventId;
        this.onEvent(new SynthesisEvents_js_1.ConnectingToSynthesisServiceEvent(this.privRequestId, this.privAuthFetchEventId));
    }
    onAuthCompleted(isError) {
        if (isError) {
            this.onComplete();
        }
    }
    onConnectionEstablishCompleted(statusCode) {
        if (statusCode === 200) {
            this.onEvent(new SynthesisEvents_js_1.SynthesisStartedEvent(this.requestId, this.privAuthFetchEventId));
            this.privBytesReceived = 0;
            return;
        }
        else if (statusCode === 403) {
            this.onComplete();
        }
    }
    onServiceResponseMessage(responseJson) {
        const response = JSON.parse(responseJson);
        this.streamId = response.audio.streamId;
    }
    onServiceTurnEndResponse() {
        this.privInTurn = false;
        this.privTurnDeferral.resolve();
        this.onComplete();
    }
    onServiceTurnStartResponse(responseJson) {
        if (!!this.privTurnDeferral && !!this.privInTurn) {
            // What? How are we starting a turn with another not done?
            this.privTurnDeferral.reject("Another turn started before current completed.");
            // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited
            // eslint-disable-next-line @typescript-eslint/no-empty-function
            this.privTurnDeferral.promise.then().catch(() => { });
        }
        this.privInTurn = true;
        this.privTurnDeferral = new Exports_js_1.Deferred();
        const response = JSON.parse(responseJson);
        if (!!response.webrtc) {
            this.privWebRTCSDP = response.webrtc.connectionString;
        }
    }
    onAudioChunkReceived(data) {
        if (this.isSynthesizing) {
            this.privAudioOutputStream.write(data);
            this.privBytesReceived += data.byteLength;
            if (this.privTurnAudioDestination !== undefined) {
                this.privTurnAudioDestination.write(data);
            }
        }
    }
    onTextBoundaryEvent(metadata) {
        this.updateTextOffset(metadata.Data.text.Text, metadata.Type);
    }
    onVisemeMetadataReceived(metadata) {
        if (metadata.Data.AnimationChunk !== undefined) {
            this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;
        }
    }
    onSessionEnd(metadata) {
        this.privAudioDuration = metadata.Data.Offset;
    }
    async constructSynthesisResult() {
        const audioBuffer = await this.getAllReceivedAudioWithHeader();
        return new Exports_js_2.SpeechSynthesisResult(this.requestId, Exports_js_2.ResultReason.SynthesizingAudioCompleted, audioBuffer, undefined, this.extraProperties, this.audioDuration);
    }
    dispose() {
        if (!this.privIsDisposed) {
            // we should have completed by now. If we did not its an unknown error.
            this.privIsDisposed = true;
        }
    }
    onStopSynthesizing() {
        this.onComplete();
    }
    /**
     * Gets the viseme animation string (merged from animation chunk), and clears the internal
     * partial animation.
     */
    getAndClearVisemeAnimation() {
        const animation = this.privPartialVisemeAnimation;
        this.privPartialVisemeAnimation = "";
        return animation;
    }
    onEvent(event) {
        Exports_js_1.Events.instance.onEvent(event);
    }
    /**
     * Check if the text is an XML(SSML) tag
     * @param text
     * @private
     */
    static isXmlTag(text) {
        return text.length >= 2 && text[0] === "<" && text[text.length - 1] === ">";
    }
    updateTextOffset(text, type) {
        if (type === SynthesisAudioMetadata_js_1.MetadataType.WordBoundary) {
            this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);
            if (this.privTextOffset >= 0) {
                this.privNextSearchTextIndex = this.privTextOffset + text.length;
                if (this.privIsSSML) {
                    if (this.withinXmlTag(this.privTextOffset) && !SynthesisTurn.isXmlTag(text)) {
                        this.updateTextOffset(text, type);
                    }
                }
            }
        }
        else {
            this.privSentenceOffset = this.privRawText.indexOf(text, this.privNextSearchSentenceIndex);
            if (this.privSentenceOffset >= 0) {
                this.privNextSearchSentenceIndex = this.privSentenceOffset + text.length;
                if (this.privIsSSML) {
                    if (this.withinXmlTag(this.privSentenceOffset) && !SynthesisTurn.isXmlTag(text)) {
                        this.updateTextOffset(text, type);
                    }
                }
            }
        }
    }
    onComplete() {
        if (this.privIsSynthesizing) {
            this.privIsSynthesizing = false;
            this.privIsSynthesisEnded = true;
            this.privAudioOutputStream.close();
            this.privInTurn = false;
            if (this.privTurnAudioDestination !== undefined) {
                this.privTurnAudioDestination.close();
                this.privTurnAudioDestination = undefined;
            }
        }
    }
    async readAllAudioFromStream() {
        if (this.privIsSynthesisEnded) {
            this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);
            try {
                await this.privAudioOutputStream.read(this.privReceivedAudio);
            }
            catch (e) {
                this.privReceivedAudio = new ArrayBuffer(0);
            }
        }
    }
    /**
     * Check if current idx is in XML(SSML) tag
     * @param idx
     * @private
     */
    withinXmlTag(idx) {
        return this.privRawText.indexOf("<", idx + 1) > this.privRawText.indexOf(">", idx + 1);
    }
}
exports.SynthesisTurn = SynthesisTurn;

//# sourceMappingURL=SynthesisTurn.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesizerConfig.js"
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesizerConfig.js ***!
  \****************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesizerConfig = exports.SynthesisServiceType = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
var SynthesisServiceType;
(function (SynthesisServiceType) {
    SynthesisServiceType[SynthesisServiceType["Standard"] = 0] = "Standard";
    SynthesisServiceType[SynthesisServiceType["Custom"] = 1] = "Custom";
})(SynthesisServiceType = exports.SynthesisServiceType || (exports.SynthesisServiceType = {}));
class SynthesizerConfig {
    constructor(speechServiceConfig, parameters) {
        this.privSynthesisServiceType = SynthesisServiceType.Standard;
        this.avatarEnabled = false;
        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new Exports_js_1.SpeechServiceConfig(new Exports_js_1.Context(null));
        this.privParameters = parameters;
    }
    get parameters() {
        return this.privParameters;
    }
    get synthesisServiceType() {
        return this.privSynthesisServiceType;
    }
    set synthesisServiceType(value) {
        this.privSynthesisServiceType = value;
    }
    set synthesisVideoSection(value) {
        this.privSpeechServiceConfig.Context.synthesis = {
            video: value
        };
    }
    get SpeechServiceConfig() {
        return this.privSpeechServiceConfig;
    }
    setContextFromJson(contextJson) {
        const context = JSON.parse(contextJson);
        if (context.system) {
            this.privSpeechServiceConfig.Context.system = context.system;
        }
        if (context.os) {
            this.privSpeechServiceConfig.Context.os = context.os;
        }
        if (context.audio) {
            this.privSpeechServiceConfig.Context.audio = context.audio;
        }
        if (context.synthesis) {
            this.privSpeechServiceConfig.Context.synthesis = context.synthesis;
        }
    }
}
exports.SynthesizerConfig = SynthesizerConfig;

//# sourceMappingURL=SynthesizerConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriberConnectionFactory.js"
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriberConnectionFactory.js ***!
  \***************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranscriberConnectionFactory = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js");
class TranscriberConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {
    constructor() {
        super(...arguments);
        this.multiaudioRelativeUri = "/speech/recognition/multiaudio";
    }
    create(config, authInfo, connectionId) {
        let endpoint = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);
        const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, "centralus");
        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);
        const hostDefault = "wss://transcribe." + region + ".cts.speech" + hostSuffix + this.multiaudioRelativeUri;
        const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, hostDefault);
        const queryParams = {};
        this.setQueryParams(queryParams, config, endpoint);
        if (!endpoint) {
            endpoint = host;
        }
        const headers = {};
        if (authInfo.token !== undefined && authInfo.token !== "") {
            headers[authInfo.headerName] = authInfo.token;
        }
        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;
        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, endpoint);
        const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
        return Promise.resolve(new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId));
    }
    setQueryParams(queryParams, config, endpointUrl) {
        const endpointId = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, undefined);
        const language = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);
        if (endpointId && !(QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId in queryParams)) {
            queryParams[QueryParameterNames_js_1.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;
        }
        if (language && !(QueryParameterNames_js_1.QueryParameterNames.Language in queryParams)) {
            queryParams[QueryParameterNames_js_1.QueryParameterNames.Language] = language;
        }
        const wordLevelTimings = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "false").toLowerCase() === "true";
        const detailed = config.parameters.getProperty(Exports_js_3.OutputFormatPropertyName, Exports_js_2.OutputFormat[Exports_js_2.OutputFormat.Simple]) !== Exports_js_2.OutputFormat[Exports_js_2.OutputFormat.Simple];
        if (wordLevelTimings || detailed) {
            queryParams[QueryParameterNames_js_1.QueryParameterNames.Format] = Exports_js_2.OutputFormat[Exports_js_2.OutputFormat.Detailed].toLowerCase();
        }
        this.setCommonUrlParams(config, queryParams, endpointUrl);
    }
}
exports.TranscriberConnectionFactory = TranscriberConnectionFactory;

//# sourceMappingURL=TranscriberConnectionFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js"
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js ***!
  \*****************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationConnectionConfig = void 0;
const RestConfigBase_js_1 = __webpack_require__(/*! ../../common.browser/RestConfigBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/RestConfigBase.js");
class ConversationConnectionConfig extends RestConfigBase_js_1.RestConfigBase {
    static get host() {
        return ConversationConnectionConfig.privHost;
    }
    static get apiVersion() {
        return ConversationConnectionConfig.privApiVersion;
    }
    static get clientAppId() {
        return ConversationConnectionConfig.privClientAppId;
    }
    static get defaultLanguageCode() {
        return ConversationConnectionConfig.privDefaultLanguageCode;
    }
    static get restPath() {
        return ConversationConnectionConfig.privRestPath;
    }
    static get webSocketPath() {
        return ConversationConnectionConfig.privWebSocketPath;
    }
    static get transcriptionEventKeys() {
        return ConversationConnectionConfig.privTranscriptionEventKeys;
    }
}
exports.ConversationConnectionConfig = ConversationConnectionConfig;
ConversationConnectionConfig.privHost = "dev.microsofttranslator.com";
ConversationConnectionConfig.privRestPath = "/capito/room";
ConversationConnectionConfig.privApiVersion = "2.0";
ConversationConnectionConfig.privDefaultLanguageCode = "en-US";
ConversationConnectionConfig.privClientAppId = "FC539C22-1767-4F1F-84BC-B4D811114F15";
ConversationConnectionConfig.privWebSocketPath = "/capito/translate";
ConversationConnectionConfig.privTranscriptionEventKeys = ["iCalUid", "callId", "organizer", "FLAC", "MTUri", "DifferentiateGuestSpeakers", "audiorecording", "Threadid", "OrganizerMri", "OrganizerTenantId", "UserToken"];

//# sourceMappingURL=ConversationConnectionConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionFactory.js"
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionFactory.js ***!
  \******************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationConnectionFactory = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ../../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const ConnectionFactoryBase_js_1 = __webpack_require__(/*! ../ConnectionFactoryBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js");
const ConversationConnectionConfig_js_1 = __webpack_require__(/*! ./ConversationConnectionConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js");
const ConversationWebsocketMessageFormatter_js_1 = __webpack_require__(/*! ./ConversationWebsocketMessageFormatter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js");
/**
 * Create a connection to the Conversation Translator websocket for sending instant messages and commands, and for receiving translated messages.
 * The conversation must already have been started or joined.
 */
class ConversationConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {
    create(config, authInfo, connectionId) {
        const endpointHost = config.parameters.getProperty(Exports_js_3.PropertyId.ConversationTranslator_Host, ConversationConnectionConfig_js_1.ConversationConnectionConfig.host);
        const correlationId = config.parameters.getProperty(Exports_js_3.PropertyId.ConversationTranslator_CorrelationId, (0, Exports_js_2.createGuid)());
        const endpoint = `wss://${endpointHost}${ConversationConnectionConfig_js_1.ConversationConnectionConfig.webSocketPath}`;
        const token = config.parameters.getProperty(Exports_js_3.PropertyId.ConversationTranslator_Token, undefined);
        Contracts_js_1.Contracts.throwIfNullOrUndefined(token, "token");
        const queryParams = {};
        queryParams[ConversationConnectionConfig_js_1.ConversationConnectionConfig.configParams.apiVersion] = ConversationConnectionConfig_js_1.ConversationConnectionConfig.apiVersion;
        queryParams[ConversationConnectionConfig_js_1.ConversationConnectionConfig.configParams.token] = token;
        queryParams[ConversationConnectionConfig_js_1.ConversationConnectionConfig.configParams.correlationId] = correlationId;
        const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
        return Promise.resolve(new Exports_js_1.WebsocketConnection(endpoint, queryParams, {}, new ConversationWebsocketMessageFormatter_js_1.ConversationWebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId));
    }
}
exports.ConversationConnectionFactory = ConversationConnectionFactory;

//# sourceMappingURL=ConversationConnectionFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionMessage.js"
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionMessage.js ***!
  \******************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationConnectionMessage = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
class ConversationConnectionMessage extends Exports_js_1.ConnectionMessage {
    constructor(messageType, body, headers, id) {
        super(messageType, body, headers, id);
        const json = JSON.parse(this.textBody);
        if (json.type !== undefined) {
            this.privConversationMessageType = json.type;
        }
    }
    get conversationMessageType() {
        return this.privConversationMessageType;
    }
}
exports.ConversationConnectionMessage = ConversationConnectionMessage;

//# sourceMappingURL=ConversationConnectionMessage.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationManager.js"
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationManager.js ***!
  \********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationManager = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_2 = __webpack_require__(/*! ../../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const ConversationConnectionConfig_js_1 = __webpack_require__(/*! ./ConversationConnectionConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js");
class ConversationManager {
    constructor() {
        //
        this.privRequestParams = ConversationConnectionConfig_js_1.ConversationConnectionConfig.configParams;
        this.privErrors = ConversationConnectionConfig_js_1.ConversationConnectionConfig.restErrors;
        this.privHost = ConversationConnectionConfig_js_1.ConversationConnectionConfig.host;
        this.privApiVersion = ConversationConnectionConfig_js_1.ConversationConnectionConfig.apiVersion;
        this.privRestPath = ConversationConnectionConfig_js_1.ConversationConnectionConfig.restPath;
        this.privRestAdapter = new Exports_js_1.RestMessageAdapter({});
    }
    /**
     * Make a POST request to the Conversation Manager service endpoint to create or join a conversation.
     * @param args
     * @param conversationCode
     * @param callback
     * @param errorCallback
     */
    createOrJoin(args, conversationCode, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfNullOrUndefined(args, "args");
            const languageCode = args.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, ConversationConnectionConfig_js_1.ConversationConnectionConfig.defaultLanguageCode);
            const nickname = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_Name, "conversation_host");
            const endpointHost = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_Host, this.privHost);
            const correlationId = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_CorrelationId);
            const subscriptionKey = args.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key);
            const subscriptionRegion = args.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region);
            const authToken = args.getProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token);
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(languageCode, "languageCode");
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, "nickname");
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(endpointHost, "endpointHost");
            const queryParams = {};
            queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;
            queryParams[this.privRequestParams.languageCode] = languageCode;
            queryParams[this.privRequestParams.nickname] = nickname;
            const headers = {};
            if (correlationId) {
                headers[this.privRequestParams.correlationId] = correlationId;
            }
            headers[this.privRequestParams.clientAppId] = ConversationConnectionConfig_js_1.ConversationConnectionConfig.clientAppId;
            if (conversationCode !== undefined) {
                queryParams[this.privRequestParams.roomId] = conversationCode;
            }
            else {
                Contracts_js_1.Contracts.throwIfNullOrUndefined(subscriptionRegion, this.privErrors.authInvalidSubscriptionRegion);
                headers[this.privRequestParams.subscriptionRegion] = subscriptionRegion;
                if (subscriptionKey) {
                    headers[this.privRequestParams.subscriptionKey] = subscriptionKey;
                }
                else if (authToken) {
                    headers[this.privRequestParams.authorization] = `Bearer ${authToken}`;
                }
                else {
                    Contracts_js_1.Contracts.throwIfNullOrUndefined(subscriptionKey, this.privErrors.authInvalidSubscriptionKey);
                }
            }
            const config = {};
            config.headers = headers;
            this.privRestAdapter.options = config;
            const endpoint = `https://${endpointHost}${this.privRestPath}`;
            // TODO: support a proxy and certificate validation
            this.privRestAdapter.request(Exports_js_1.RestRequestType.Post, endpoint, queryParams, null).then((response) => {
                const requestId = Exports_js_1.RestMessageAdapter.extractHeaderValue(this.privRequestParams.requestId, response.headers);
                if (!response.ok) {
                    if (!!err) {
                        // get the error
                        let errorMessage = this.privErrors.invalidCreateJoinConversationResponse.replace("{status}", response.status.toString());
                        let errMessageRaw;
                        try {
                            errMessageRaw = JSON.parse(response.data);
                            errorMessage += ` [${errMessageRaw.error.code}: ${errMessageRaw.error.message}]`;
                        }
                        catch (e) {
                            errorMessage += ` [${response.data}]`;
                        }
                        if (requestId) {
                            errorMessage += ` ${requestId}`;
                        }
                        err(errorMessage);
                    }
                    return;
                }
                const conversation = JSON.parse(response.data);
                if (conversation) {
                    conversation.requestId = requestId;
                }
                if (!!cb) {
                    try {
                        cb(conversation);
                    }
                    catch (e) {
                        if (!!err) {
                            err(e);
                        }
                    }
                    cb = undefined;
                }
                // eslint-disable-next-line @typescript-eslint/no-empty-function
            }).catch(() => { });
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
        }
    }
    /**
     * Make a DELETE request to the Conversation Manager service endpoint to leave the conversation.
     * @param args
     * @param sessionToken
     * @param callback
     */
    leave(args, sessionToken) {
        return new Promise((resolve, reject) => {
            try {
                Contracts_js_1.Contracts.throwIfNullOrUndefined(args, this.privErrors.invalidArgs.replace("{arg}", "config"));
                Contracts_js_1.Contracts.throwIfNullOrWhitespace(sessionToken, this.privErrors.invalidArgs.replace("{arg}", "token"));
                const endpointHost = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_Host, this.privHost);
                const correlationId = args.getProperty(Exports_js_2.PropertyId.ConversationTranslator_CorrelationId);
                const queryParams = {};
                queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;
                queryParams[this.privRequestParams.sessionToken] = sessionToken;
                const headers = {};
                if (correlationId) {
                    headers[this.privRequestParams.correlationId] = correlationId;
                }
                const config = {};
                config.headers = headers;
                this.privRestAdapter.options = config;
                const endpoint = `https://${endpointHost}${this.privRestPath}`;
                // TODO: support a proxy and certificate validation
                this.privRestAdapter.request(Exports_js_1.RestRequestType.Delete, endpoint, queryParams, null).then((response) => {
                    if (!response.ok) {
                        // ignore errors on delete
                    }
                    resolve();
                    // eslint-disable-next-line @typescript-eslint/no-empty-function
                }).catch(() => { });
            }
            catch (error) {
                if (error instanceof Error) {
                    const typedError = error;
                    reject(typedError.name + ": " + typedError.message);
                }
                else {
                    reject(error);
                }
            }
        });
    }
}
exports.ConversationManager = ConversationManager;

//# sourceMappingURL=ConversationManager.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationRequestSession.js"
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationRequestSession.js ***!
  \***************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationRequestSession = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
/**
 * Placeholder class for the Conversation Request Session. Based off RequestSession.
 * TODO: define what telemetry is required.
 */
class ConversationRequestSession {
    constructor(sessionId) {
        this.privIsDisposed = false;
        this.privDetachables = new Array();
        this.privSessionId = sessionId;
        this.privRequestId = (0, Exports_js_1.createNoDashGuid)();
        this.privRequestCompletionDeferral = new Exports_js_1.Deferred();
    }
    get sessionId() {
        return this.privSessionId;
    }
    get requestId() {
        return this.privRequestId;
    }
    get completionPromise() {
        return this.privRequestCompletionDeferral.promise;
    }
    onPreConnectionStart(authFetchEventId, connectionId) {
        this.privSessionId = connectionId;
    }
    onAuthCompleted(isError) {
        if (isError) {
            this.onComplete();
        }
    }
    onConnectionEstablishCompleted(statusCode) {
        if (statusCode === 200) {
            return;
        }
        else if (statusCode === 403) {
            this.onComplete();
        }
    }
    onServiceTurnEndResponse(continuousRecognition) {
        if (!continuousRecognition) {
            this.onComplete();
        }
        else {
            this.privRequestId = (0, Exports_js_1.createNoDashGuid)();
        }
    }
    async dispose() {
        if (!this.privIsDisposed) {
            // we should have completed by now. If we did not its an unknown error.
            this.privIsDisposed = true;
            for (const detachable of this.privDetachables) {
                await detachable.detach();
            }
        }
    }
    onComplete() {
        //
    }
}
exports.ConversationRequestSession = ConversationRequestSession;

//# sourceMappingURL=ConversationRequestSession.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationServiceAdapter.js"
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationServiceAdapter.js ***!
  \***************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationServiceAdapter = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const ConversationConnectionMessage_js_1 = __webpack_require__(/*! ./ConversationConnectionMessage.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionMessage.js");
const ConversationRequestSession_js_1 = __webpack_require__(/*! ./ConversationRequestSession.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationRequestSession.js");
const ConversationTranslatorEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranslatorEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorEventArgs.js");
const ConversationTranslatorInterfaces_js_1 = __webpack_require__(/*! ./ConversationTranslatorInterfaces.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorInterfaces.js");
const Exports_js_4 = __webpack_require__(/*! ./ServiceMessages/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/Exports.js");
/**
 * The service adapter handles sending and receiving messages to the Conversation Translator websocket.
 */
class ConversationServiceAdapter extends Exports_js_3.ServiceRecognizerBase {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector);
        this.privConnectionConfigPromise = undefined;
        this.privLastPartialUtteranceId = "";
        this.privConversationServiceConnector = conversationServiceConnector;
        this.privConversationAuthentication = authentication;
        this.receiveMessageOverride = () => this.receiveConversationMessageOverride();
        this.recognizeOverride = () => this.noOp();
        this.postConnectImplOverride = (connection) => this.conversationConnectImpl(connection);
        this.configConnectionOverride = () => this.configConnection();
        this.disconnectOverride = () => this.privDisconnect();
        this.privConversationRequestSession = new ConversationRequestSession_js_1.ConversationRequestSession((0, Exports_js_1.createNoDashGuid)());
        this.privConversationConnectionFactory = connectionFactory;
        this.privConversationIsDisposed = false;
    }
    isDisposed() {
        return super.isDisposed() || this.privConversationIsDisposed;
    }
    async dispose(reason) {
        this.privConversationIsDisposed = true;
        if (this.privConnectionConfigPromise !== undefined) {
            const connection = await this.privConnectionConfigPromise;
            await connection.dispose(reason);
        }
        await super.dispose(reason);
    }
    async sendMessage(message) {
        const connection = await this.fetchConnection();
        return connection.send(new ConversationConnectionMessage_js_1.ConversationConnectionMessage(Exports_js_1.MessageType.Text, message));
    }
    async sendMessageAsync(message) {
        const connection = await this.fetchConnection();
        await connection.send(new ConversationConnectionMessage_js_1.ConversationConnectionMessage(Exports_js_1.MessageType.Text, message));
    }
    privDisconnect() {
        if (this.terminateMessageLoop) {
            return;
        }
        this.cancelRecognition(this.privConversationRequestSession.sessionId, this.privConversationRequestSession.requestId, Exports_js_2.CancellationReason.Error, Exports_js_2.CancellationErrorCode.NoError, "Disconnecting");
        this.terminateMessageLoop = true;
        return Promise.resolve();
    }
    // eslint-disable-next-line @typescript-eslint/require-await
    async processTypeSpecificMessages() {
        return true;
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        this.terminateMessageLoop = true;
        const cancelEvent = new Exports_js_2.ConversationTranslationCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
        try {
            if (!!this.privConversationServiceConnector.canceled) {
                this.privConversationServiceConnector.canceled(this.privConversationServiceConnector, cancelEvent);
            }
        }
        catch {
            // continue on error
        }
    }
    /**
     * Establishes a websocket connection to the end point.
     */
    async conversationConnectImpl(connection) {
        this.privConnectionLoop = this.startMessageLoop();
        return connection;
    }
    /**
     * Process incoming websocket messages
     */
    async receiveConversationMessageOverride() {
        if (this.isDisposed() || this.terminateMessageLoop) {
            return Promise.resolve();
        }
        // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages
        const communicationCustodian = new Exports_js_1.Deferred();
        try {
            const connection = await this.fetchConnection();
            const message = await connection.read();
            if (this.isDisposed() || this.terminateMessageLoop) {
                // We're done.
                communicationCustodian.resolve();
                return Promise.resolve();
            }
            if (!message) {
                return this.receiveConversationMessageOverride();
            }
            const sessionId = this.privConversationRequestSession.sessionId;
            const conversationMessageType = message.conversationMessageType.toLowerCase();
            let sendFinal = false;
            try {
                switch (conversationMessageType) {
                    case "info":
                    case "participant_command":
                    case "command":
                        const commandPayload = Exports_js_4.CommandResponsePayload.fromJSON(message.textBody);
                        switch (commandPayload.command.toLowerCase()) {
                            /**
                             * 'ParticpantList' is the first message sent to the user after the websocket connection has opened.
                             * The consuming client must wait for this message to arrive
                             * before starting to send their own data.
                             */
                            case "participantlist":
                                const participantsPayload = Exports_js_4.ParticipantsListPayloadResponse.fromJSON(message.textBody);
                                const participantsResult = participantsPayload.participants.map((p) => {
                                    const participant = {
                                        avatar: p.avatar,
                                        displayName: p.nickname,
                                        id: p.participantId,
                                        isHost: p.ishost,
                                        isMuted: p.ismuted,
                                        isUsingTts: p.usetts,
                                        preferredLanguage: p.locale
                                    };
                                    return participant;
                                });
                                if (!!this.privConversationServiceConnector.participantsListReceived) {
                                    this.privConversationServiceConnector.participantsListReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantsListEventArgs(participantsPayload.roomid, participantsPayload.token, participantsPayload.translateTo, participantsPayload.profanityFilter, participantsPayload.roomProfanityFilter, participantsPayload.roomLocked, participantsPayload.muteAll, participantsResult, sessionId));
                                }
                                break;
                            /**
                             * 'SetTranslateToLanguages' represents the list of languages being used in the Conversation by all users(?).
                             * This is sent at the start of the Conversation
                             */
                            case "settranslatetolanguages":
                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages, commandPayload.value, sessionId));
                                }
                                break;
                            /**
                             * 'SetProfanityFiltering' lets the client set the level of profanity filtering.
                             * If sent by the participant the setting will effect only their own profanity level.
                             * If sent by the host, the setting will effect all participants including the host.
                             * Note: the profanity filters differ from Speech Service (?): 'marked', 'raw', 'removed', 'tagged'
                             */
                            case "setprofanityfiltering":
                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.setProfanityFiltering, commandPayload.value, sessionId));
                                }
                                break;
                            /**
                             * 'SetMute' is sent if the participant has been muted by the host.
                             * Check the 'participantId' to determine if the current user has been muted.
                             */
                            case "setmute":
                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.setMute, commandPayload.value, sessionId));
                                }
                                break;
                            /**
                             * 'SetMuteAll' is sent if the Conversation has been muted by the host.
                             */
                            case "setmuteall":
                                if (!!this.privConversationServiceConnector.muteAllCommandReceived) {
                                    this.privConversationServiceConnector.muteAllCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.MuteAllEventArgs(commandPayload.value, sessionId));
                                }
                                break;
                            /**
                             * 'RoomExpirationWarning' is sent towards the end of the Conversation session to give a timeout warning.
                             */
                            case "roomexpirationwarning":
                                if (!!this.privConversationServiceConnector.conversationExpiration) {
                                    this.privConversationServiceConnector.conversationExpiration(this.privConversationServiceConnector, new Exports_js_2.ConversationExpirationEventArgs(commandPayload.value, this.privConversationRequestSession.sessionId));
                                }
                                break;
                            /**
                             * 'SetUseTts' is sent as a confirmation if the user requests TTS to be turned on or off.
                             */
                            case "setusetts":
                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.setUseTTS, commandPayload.value, sessionId));
                                }
                                break;
                            /**
                             * 'SetLockState' is set if the host has locked or unlocked the Conversation.
                             */
                            case "setlockstate":
                                if (!!this.privConversationServiceConnector.lockRoomCommandReceived) {
                                    this.privConversationServiceConnector.lockRoomCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.LockRoomEventArgs(commandPayload.value, sessionId));
                                }
                                break;
                            /**
                             * 'ChangeNickname' is received if a user changes their display name.
                             * Any cached particpiants list should be updated to reflect the display name.
                             */
                            case "changenickname":
                                if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {
                                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs(commandPayload.participantId, ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes.changeNickname, commandPayload.value, sessionId));
                                }
                                break;
                            /**
                             * 'JoinSession' is sent when a user joins the Conversation.
                             */
                            case "joinsession":
                                const joinParticipantPayload = Exports_js_4.ParticipantPayloadResponse.fromJSON(message.textBody);
                                const joiningParticipant = {
                                    avatar: joinParticipantPayload.avatar,
                                    displayName: joinParticipantPayload.nickname,
                                    id: joinParticipantPayload.participantId,
                                    isHost: joinParticipantPayload.ishost,
                                    isMuted: joinParticipantPayload.ismuted,
                                    isUsingTts: joinParticipantPayload.usetts,
                                    preferredLanguage: joinParticipantPayload.locale,
                                };
                                if (!!this.privConversationServiceConnector.participantJoinCommandReceived) {
                                    this.privConversationServiceConnector.participantJoinCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantEventArgs(joiningParticipant, sessionId));
                                }
                                break;
                            /**
                             * 'LeaveSession' is sent when a user leaves the Conversation'.
                             */
                            case "leavesession":
                                const leavingParticipant = {
                                    id: commandPayload.participantId
                                };
                                if (!!this.privConversationServiceConnector.participantLeaveCommandReceived) {
                                    this.privConversationServiceConnector.participantLeaveCommandReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ParticipantEventArgs(leavingParticipant, sessionId));
                                }
                                break;
                            /**
                             * 'DisconnectSession' is sent when a user is disconnected from the session (e.g. network problem).
                             * Check the 'ParticipantId' to check whether the message is for the current user.
                             */
                            case "disconnectsession":
                                // eslint-disable-next-line @typescript-eslint/no-unused-vars
                                const disconnectParticipant = {
                                    id: commandPayload.participantId
                                };
                                break;
                            case "token":
                                const token = new Exports_js_3.CognitiveTokenAuthentication(() => {
                                    const authorizationToken = commandPayload.token;
                                    return Promise.resolve(authorizationToken);
                                }, () => {
                                    const authorizationToken = commandPayload.token;
                                    return Promise.resolve(authorizationToken);
                                });
                                this.authentication = token;
                                this.privConversationServiceConnector.onToken(token);
                                break;
                            /**
                             * Message not recognized.
                             */
                            default:
                                break;
                        }
                        break;
                    /**
                     * 'partial' (or 'hypothesis') represents a unfinalized speech message.
                     */
                    case "partial":
                    /**
                     * 'final' (or 'phrase') represents a finalized speech message.
                     */
                    case "final":
                        const speechPayload = Exports_js_4.SpeechResponsePayload.fromJSON(message.textBody);
                        const conversationResultReason = (conversationMessageType === "final") ? Exports_js_2.ResultReason.TranslatedParticipantSpeech : Exports_js_2.ResultReason.TranslatingParticipantSpeech;
                        const speechResult = new Exports_js_2.ConversationTranslationResult(speechPayload.participantId, this.getTranslations(speechPayload.translations), speechPayload.language, speechPayload.id, conversationResultReason, speechPayload.recognition, undefined, undefined, message.textBody, undefined);
                        if (speechPayload.isFinal) {
                            // check the length, sometimes empty finals are returned
                            if (speechResult.text !== undefined && speechResult.text.length > 0) {
                                sendFinal = true;
                            }
                            else if (speechPayload.id === this.privLastPartialUtteranceId) {
                                // send final as normal. We had a non-empty partial for this same utterance
                                // so sending the empty final is important
                                sendFinal = true;
                            }
                            else {
                                // suppress unneeded final
                            }
                            if (sendFinal) {
                                if (!!this.privConversationServiceConnector.translationReceived) {
                                    this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ConversationReceivedTranslationEventArgs(ConversationTranslatorInterfaces_js_1.ConversationTranslatorMessageTypes.final, speechResult, sessionId));
                                }
                            }
                        }
                        else if (speechResult.text !== undefined) {
                            this.privLastPartialUtteranceId = speechPayload.id;
                            if (!!this.privConversationServiceConnector.translationReceived) {
                                this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ConversationReceivedTranslationEventArgs(ConversationTranslatorInterfaces_js_1.ConversationTranslatorMessageTypes.partial, speechResult, sessionId));
                            }
                        }
                        break;
                    /**
                     * "translated_message" is a text message or instant message (IM).
                     */
                    case "translated_message":
                        const textPayload = Exports_js_4.TextResponsePayload.fromJSON(message.textBody);
                        // TODO: (Native parity) a result reason should be set based whether the participantId is ours or not
                        const textResult = new Exports_js_2.ConversationTranslationResult(textPayload.participantId, this.getTranslations(textPayload.translations), textPayload.language, undefined, undefined, textPayload.originalText, undefined, undefined, undefined, message.textBody, undefined);
                        if (!!this.privConversationServiceConnector.translationReceived) {
                            this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new ConversationTranslatorEventArgs_js_1.ConversationReceivedTranslationEventArgs(ConversationTranslatorInterfaces_js_1.ConversationTranslatorMessageTypes.instantMessage, textResult, sessionId));
                        }
                        break;
                    default:
                        // ignore any unsupported message types
                        break;
                }
            }
            catch (e) {
                // continue
            }
            return this.receiveConversationMessageOverride();
        }
        catch (e) {
            this.terminateMessageLoop = true;
        }
        return communicationCustodian.promise;
    }
    async startMessageLoop() {
        if (this.isDisposed()) {
            return Promise.resolve();
        }
        this.terminateMessageLoop = false;
        const messageRetrievalPromise = this.receiveConversationMessageOverride();
        try {
            const r = await messageRetrievalPromise;
            return r;
        }
        catch (error) {
            this.cancelRecognition(this.privRequestSession ? this.privRequestSession.sessionId : "", this.privRequestSession ? this.privRequestSession.requestId : "", Exports_js_2.CancellationReason.Error, Exports_js_2.CancellationErrorCode.RuntimeError, error);
            return null;
        }
    }
    // Takes an established websocket connection to the endpoint
    configConnection() {
        if (this.isDisposed()) {
            return Promise.resolve(undefined);
        }
        if (this.privConnectionConfigPromise !== undefined) {
            return this.privConnectionConfigPromise.then((connection) => {
                if (connection.state() === Exports_js_1.ConnectionState.Disconnected) {
                    this.privConnectionId = null;
                    this.privConnectionConfigPromise = undefined;
                    return this.configConnection();
                }
                return this.privConnectionConfigPromise;
            }, () => {
                this.privConnectionId = null;
                this.privConnectionConfigPromise = undefined;
                return this.configConnection();
            });
        }
        if (this.terminateMessageLoop) {
            return Promise.resolve(undefined);
        }
        this.privConnectionConfigPromise = this.connectImpl().then((connection) => connection);
        return this.privConnectionConfigPromise;
    }
    getTranslations(serviceResultTranslations) {
        let translations;
        if (undefined !== serviceResultTranslations) {
            translations = new Exports_js_2.Translations();
            for (const translation of serviceResultTranslations) {
                translations.set(translation.lang, translation.translation);
            }
        }
        return translations;
    }
}
exports.ConversationServiceAdapter = ConversationServiceAdapter;

//# sourceMappingURL=ConversationServiceAdapter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js"
/*!****************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js ***!
  \****************************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranslatorConnectionFactory = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const StringUtils_js_1 = __webpack_require__(/*! ../../common/StringUtils.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/StringUtils.js");
const Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_2 = __webpack_require__(/*! ../../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const HeaderNames_js_1 = __webpack_require__(/*! ../HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const QueryParameterNames_js_1 = __webpack_require__(/*! ../QueryParameterNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js");
const ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./../ConnectionFactoryBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js");
const Exports_js_3 = __webpack_require__(/*! ./../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
/**
 * Connection factory for the conversation translator. Handles connecting to the regular translator endpoint,
 * as well as the virtual microphone array transcription endpoint
 */
class ConversationTranslatorConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {
    constructor(convGetter) {
        super();
        Contracts_js_1.Contracts.throwIfNullOrUndefined(convGetter, "convGetter");
        this.privConvGetter = convGetter;
    }
    create(config, authInfo, connectionId) {
        const isVirtMicArrayEndpoint = config.parameters.getProperty("ConversationTranslator_MultiChannelAudio", "").toUpperCase() === "TRUE";
        const convInfo = this.privConvGetter().room;
        const region = convInfo.cognitiveSpeechRegion || config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, "");
        const replacementValues = {
            hostSuffix: ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region),
            path: ConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH,
            region: encodeURIComponent(region)
        };
        replacementValues[QueryParameterNames_js_1.QueryParameterNames.Language] = encodeURIComponent(config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, ""));
        replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsMeetingId] = encodeURIComponent(convInfo.roomId);
        replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsDeviceId] = encodeURIComponent(convInfo.participantId);
        replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsIsParticipant] = convInfo.isHost ? "" : ("&" + QueryParameterNames_js_1.QueryParameterNames.CtsIsParticipant);
        let endpointUrl = "";
        const queryParams = {};
        const headers = {};
        if (isVirtMicArrayEndpoint) {
            // connecting to the conversation transcription virtual microphone array endpoint
            endpointUrl = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint);
            if (!endpointUrl) {
                const hostName = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, "transcribe.{region}.cts.speech{hostSuffix}");
                endpointUrl = "wss://" + hostName + "{path}";
            }
            // because the region can change during a session, we support being passed a format string which we can then
            // replace with the correct information.
            endpointUrl = StringUtils_js_1.StringUtils.formatString(endpointUrl, replacementValues);
            const parsedUrl = new URL(endpointUrl);
            parsedUrl.searchParams.forEach((val, key) => {
                queryParams[key] = val;
            });
            const connFactory = new Exports_js_3.TranscriberConnectionFactory();
            connFactory.setQueryParams(queryParams, config, endpointUrl);
            // Some query parameters are required for the CTS endpoint, let's explicity set them here
            queryParams[QueryParameterNames_js_1.QueryParameterNames.CtsMeetingId] = replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsMeetingId];
            queryParams[QueryParameterNames_js_1.QueryParameterNames.CtsDeviceId] = replacementValues[QueryParameterNames_js_1.QueryParameterNames.CtsDeviceId];
            if (!convInfo.isHost) {
                queryParams[QueryParameterNames_js_1.QueryParameterNames.CtsIsParticipant] = ""; // this doesn't have a value so set to an empty string
            }
            if (!(QueryParameterNames_js_1.QueryParameterNames.Format in queryParams)) {
                queryParams[QueryParameterNames_js_1.QueryParameterNames.Format] = "simple";
            }
            parsedUrl.searchParams.forEach((val, key) => {
                parsedUrl.searchParams.set(key, queryParams[key]);
                delete queryParams[key];
            });
            endpointUrl = parsedUrl.toString();
        }
        else {
            // connecting to regular translation endpoint
            const connFactory = new Exports_js_3.TranslationConnectionFactory();
            endpointUrl = connFactory.getEndpointUrl(config, true);
            endpointUrl = StringUtils_js_1.StringUtils.formatString(endpointUrl, replacementValues);
            connFactory.setQueryParams(queryParams, config, endpointUrl);
        }
        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;
        headers[Exports_js_1.RestConfigBase.configParams.token] = convInfo.token;
        if (!!authInfo.token) {
            headers[authInfo.headerName] = authInfo.token;
        }
        const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "").toUpperCase() === "TRUE";
        return Promise.resolve(new Exports_js_1.WebsocketConnection(endpointUrl, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId));
    }
}
exports.ConversationTranslatorConnectionFactory = ConversationTranslatorConnectionFactory;
ConversationTranslatorConnectionFactory.CTS_VIRT_MIC_PATH = "/speech/recognition/dynamicaudio";

//# sourceMappingURL=ConversationTranslatorConnectionFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorEventArgs.js"
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorEventArgs.js ***!
  \********************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationReceivedTranslationEventArgs = exports.ParticipantsListEventArgs = exports.ParticipantAttributeEventArgs = exports.ParticipantEventArgs = exports.LockRoomEventArgs = exports.MuteAllEventArgs = void 0;
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
class MuteAllEventArgs extends Exports_js_1.SessionEventArgs {
    constructor(isMuted, sessionId) {
        super(sessionId);
        this.privIsMuted = isMuted;
    }
    get isMuted() {
        return this.privIsMuted;
    }
}
exports.MuteAllEventArgs = MuteAllEventArgs;
class LockRoomEventArgs extends Exports_js_1.SessionEventArgs {
    constructor(isLocked, sessionId) {
        super(sessionId);
        this.privIsLocked = isLocked;
    }
    get isMuted() {
        return this.privIsLocked;
    }
}
exports.LockRoomEventArgs = LockRoomEventArgs;
class ParticipantEventArgs extends Exports_js_1.SessionEventArgs {
    constructor(participant, sessionId) {
        super(sessionId);
        this.privParticipant = participant;
    }
    get participant() {
        return this.privParticipant;
    }
}
exports.ParticipantEventArgs = ParticipantEventArgs;
class ParticipantAttributeEventArgs extends Exports_js_1.SessionEventArgs {
    constructor(participantId, key, value, sessionId) {
        super(sessionId);
        this.privKey = key;
        this.privValue = value;
        this.privParticipantId = participantId;
    }
    get value() {
        return this.privValue;
    }
    get key() {
        return this.privKey;
    }
    get id() {
        return this.privParticipantId;
    }
}
exports.ParticipantAttributeEventArgs = ParticipantAttributeEventArgs;
class ParticipantsListEventArgs extends Exports_js_1.SessionEventArgs {
    constructor(conversationId, token, translateTo, profanityFilter, roomProfanityFilter, isRoomLocked, isMuteAll, participants, sessionId) {
        super(sessionId);
        this.privRoomId = conversationId;
        this.privSessionToken = token;
        this.privTranslateTo = translateTo;
        this.privProfanityFilter = profanityFilter;
        this.privRoomProfanityFilter = roomProfanityFilter;
        this.privIsRoomLocked = isRoomLocked;
        this.privIsRoomLocked = isMuteAll;
        this.privParticipants = participants;
    }
    get sessionToken() {
        return this.privSessionToken;
    }
    get conversationId() {
        return this.privRoomId;
    }
    get translateTo() {
        return this.privTranslateTo;
    }
    get profanityFilter() {
        return this.privProfanityFilter;
    }
    get roomProfanityFilter() {
        return this.privRoomProfanityFilter;
    }
    get isRoomLocked() {
        return this.privIsRoomLocked;
    }
    get isMuteAll() {
        return this.privIsMuteAll;
    }
    get participants() {
        return this.privParticipants;
    }
}
exports.ParticipantsListEventArgs = ParticipantsListEventArgs;
class ConversationReceivedTranslationEventArgs {
    constructor(command, payload, sessionId) {
        this.privPayload = payload;
        this.privCommand = command;
        this.privSessionId = sessionId;
    }
    get payload() {
        return this.privPayload;
    }
    get command() {
        return this.privCommand;
    }
    get sessionId() {
        return this.privSessionId;
    }
}
exports.ConversationReceivedTranslationEventArgs = ConversationReceivedTranslationEventArgs;

//# sourceMappingURL=ConversationTranslatorEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorInterfaces.js"
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorInterfaces.js ***!
  \*********************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranslatorCommandTypes = exports.ConversationTranslatorMessageTypes = exports.InternalParticipants = void 0;
/** Users participating in the conversation */
class InternalParticipants {
    constructor(participants = [], meId) {
        this.participants = participants;
        this.meId = meId;
    }
    /**
     * Add or update a participant
     * @param value
     */
    addOrUpdateParticipant(value) {
        if (value === undefined) {
            return;
        }
        const exists = this.getParticipantIndex(value.id);
        if (exists > -1) {
            this.participants.splice(exists, 1, value);
        }
        else {
            this.participants.push(value);
        }
        // ensure it was added ok
        return this.getParticipant(value.id);
    }
    /**
     * Find the participant's position in the participants list.
     * @param id
     */
    getParticipantIndex(id) {
        return this.participants.findIndex((p) => p.id === id);
    }
    /**
     * Find the participant by id.
     * @param id
     */
    getParticipant(id) {
        return this.participants.find((p) => p.id === id);
    }
    /**
     * Remove a participant from the participants list.
     */
    deleteParticipant(id) {
        this.participants = this.participants.filter((p) => p.id !== id);
    }
    /**
     * Helper to return the conversation host.
     */
    get host() {
        return this.participants.find((p) => p.isHost === true);
    }
    /**
     * Helper to return the current user.
     */
    get me() {
        return this.getParticipant(this.meId);
    }
}
exports.InternalParticipants = InternalParticipants;
/**
 * List of command message types
 */
exports.ConversationTranslatorMessageTypes = {
    command: "command",
    final: "final",
    info: "info",
    instantMessage: "instant_message",
    keepAlive: "keep_alive",
    partial: "partial",
    participantCommand: "participant_command",
    translatedMessage: "translated_message"
};
/**
 * List of command types
 */
exports.ConversationTranslatorCommandTypes = {
    changeNickname: "ChangeNickname",
    disconnectSession: "DisconnectSession",
    ejectParticipant: "EjectParticipant",
    instant_message: "instant_message",
    joinSession: "JoinSession",
    leaveSession: "LeaveSession",
    participantList: "ParticipantList",
    roomExpirationWarning: "RoomExpirationWarning",
    setLockState: "SetLockState",
    setMute: "SetMute",
    setMuteAll: "SetMuteAll",
    setProfanityFiltering: "SetProfanityFiltering",
    setTranslateToLanguages: "SetTranslateToLanguages",
    setUseTTS: "SetUseTTS"
};

//# sourceMappingURL=ConversationTranslatorInterfaces.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorRecognizer.js"
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorRecognizer.js ***!
  \*********************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranslatorRecognizer = exports.ConversationRecognizerFactory = void 0;
// eslint-disable-next-line max-classes-per-file
const Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ../../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const ConversationConnectionFactory_js_1 = __webpack_require__(/*! ./ConversationConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionFactory.js");
const ConversationServiceAdapter_js_1 = __webpack_require__(/*! ./ConversationServiceAdapter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationServiceAdapter.js");
class ConversationRecognizerFactory {
    static fromConfig(conversation, speechConfig, audioConfig) {
        return new ConversationTranslatorRecognizer(conversation, speechConfig, audioConfig);
    }
}
exports.ConversationRecognizerFactory = ConversationRecognizerFactory;
/**
 * Sends messages to the Conversation Translator websocket and listens for incoming events containing websocket messages.
 * Based off the recognizers in the SDK folder.
 */
class ConversationTranslatorRecognizer extends Exports_js_3.Recognizer {
    constructor(conversation, speechConfig, audioConfig) {
        const serviceConfigImpl = speechConfig;
        Contracts_js_1.Contracts.throwIfNull(serviceConfigImpl, "speechConfig");
        const conversationImpl = conversation;
        Contracts_js_1.Contracts.throwIfNull(conversationImpl, "conversationImpl");
        super(audioConfig, serviceConfigImpl.properties, new ConversationConnectionFactory_js_1.ConversationConnectionFactory());
        this.privConversation = conversationImpl;
        this.privIsDisposed = false;
        this.privProperties = serviceConfigImpl.properties.clone();
        this.privConnection = Exports_js_3.Connection.fromRecognizer(this);
        const webWorkerLoadType = this.privProperties.getProperty(Exports_js_3.PropertyId.WebWorkerLoadType, "on").toLowerCase();
        if (webWorkerLoadType === "on" && typeof (Blob) !== "undefined" && typeof (Worker) !== "undefined") {
            this.privSetTimeout = Exports_js_2.Timeout.setTimeout;
            this.privClearTimeout = Exports_js_2.Timeout.clearTimeout;
        }
        else {
            if (typeof window !== "undefined") {
                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
                this.privSetTimeout = window.setTimeout.bind(window);
                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
                this.privClearTimeout = window.clearTimeout.bind(window);
            }
            else {
                this.privSetTimeout = setTimeout;
                this.privClearTimeout = clearTimeout;
            }
        }
    }
    set connected(cb) {
        this.privConnection.connected = cb;
    }
    set disconnected(cb) {
        this.privConnection.disconnected = cb;
    }
    /**
     * Return the speech language used by the recognizer
     */
    get speechRecognitionLanguage() {
        return this.privSpeechRecognitionLanguage;
    }
    /**
     * Return the properties for the recognizer
     */
    get properties() {
        return this.privProperties;
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    /**
     * Connect to the recognizer
     * @param token
     */
    connect(token, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, "token");
            this.privReco.conversationTranslatorToken = token;
            this.resetConversationTimeout();
            this.privReco.connectAsync(cb, err);
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
        }
    }
    /**
     * Disconnect from the recognizer
     */
    disconnect(cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            if (this.privTimeoutToken !== undefined) {
                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
                this.privClearTimeout(this.privTimeoutToken);
            }
            this.privReco.disconnect().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
            // Destroy the recognizer.
            this.dispose(true).catch((reason) => {
                Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(reason));
            });
        }
    }
    /**
     * Send the mute all participants command to the websocket
     * @param conversationId
     * @param participantId
     * @param isMuted
     */
    sendRequest(command, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            this.sendMessage(command, cb, err);
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
            // Destroy the recognizer.
            this.dispose(true).catch((reason) => {
                Exports_js_2.Events.instance.onEvent(new Exports_js_2.BackgroundEvent(reason));
            });
        }
    }
    /**
     * Handle update of service auth token (#694)
     */
    onToken(token) {
        this.privConversation.onToken(token);
    }
    /**
     * Close and dispose the recognizer
     */
    async close() {
        if (!this.privIsDisposed) {
            if (!!this.privConnection) {
                this.privConnection.closeConnection();
                this.privConnection.close();
            }
            this.privConnection = undefined;
            await this.dispose(true);
        }
    }
    /**
     * Dispose the recognizer
     * @param disposing
     */
    async dispose(disposing) {
        if (this.privIsDisposed) {
            return;
        }
        if (disposing) {
            if (this.privTimeoutToken !== undefined) {
                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
                this.privClearTimeout(this.privTimeoutToken);
            }
            this.privIsDisposed = true;
            if (!!this.privConnection) {
                this.privConnection.closeConnection();
                this.privConnection.close();
                this.privConnection = undefined;
            }
            await super.dispose(disposing);
        }
    }
    /**
     * Create the config for the recognizer
     * @param speechConfig
     */
    createRecognizerConfig(speechConfig) {
        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);
    }
    /**
     * Create the service recognizer.
     * The audio source is redundnant here but is required by the implementation.
     * @param authentication
     * @param connectionFactory
     * @param audioConfig
     * @param recognizerConfig
     */
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const audioSource = audioConfig;
        return new ConversationServiceAdapter_js_1.ConversationServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);
    }
    sendMessage(msg, cb, err) {
        const withAsync = this.privReco;
        const PromiseToEmptyCallback = (promise, cb, err) => {
            if (promise !== undefined) {
                promise.then(() => {
                    try {
                        if (!!cb) {
                            cb();
                        }
                    }
                    catch (e) {
                        if (!!err) {
                            err(`'Unhandled error on promise callback: ${e}'`);
                        }
                    }
                }, (reason) => {
                    try {
                        if (!!err) {
                            err(reason);
                        }
                        // eslint-disable-next-line no-empty
                    }
                    catch (error) { }
                });
            }
            else {
                if (!!err) {
                    err("Null promise");
                }
            }
        };
        PromiseToEmptyCallback(withAsync.sendMessageAsync(msg), cb, err);
        this.resetConversationTimeout();
    }
    resetConversationTimeout() {
        if (this.privTimeoutToken !== undefined) {
            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
            this.privClearTimeout(this.privTimeoutToken);
        }
        this.privTimeoutToken = this.privSetTimeout(() => {
            this.sendRequest(this.privConversation.getKeepAlive());
        }, 60000);
    }
}
exports.ConversationTranslatorRecognizer = ConversationTranslatorRecognizer;

//# sourceMappingURL=ConversationTranslatorRecognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js"
/*!**************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js ***!
  \**************************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationWebsocketMessageFormatter = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const ConversationConnectionMessage_js_1 = __webpack_require__(/*! ./ConversationConnectionMessage.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionMessage.js");
/**
 * Based off WebsocketMessageFormatter. The messages for Conversation Translator have some variations from the Speech messages.
 */
class ConversationWebsocketMessageFormatter {
    /**
     * Format incoming messages: text (speech partial/final, IM) or binary (tts)
     */
    toConnectionMessage(message) {
        const deferral = new Exports_js_1.Deferred();
        try {
            if (message.messageType === Exports_js_1.MessageType.Text) {
                const incomingMessage = new ConversationConnectionMessage_js_1.ConversationConnectionMessage(message.messageType, message.textContent, {}, message.id);
                deferral.resolve(incomingMessage);
            }
            else if (message.messageType === Exports_js_1.MessageType.Binary) {
                deferral.resolve(new ConversationConnectionMessage_js_1.ConversationConnectionMessage(message.messageType, message.binaryContent, undefined, message.id));
            }
        }
        catch (e) {
            deferral.reject(`Error formatting the message. Error: ${e}`);
        }
        return deferral.promise;
    }
    /**
     * Format outgoing messages: text (commands or IM)
     */
    fromConnectionMessage(message) {
        const deferral = new Exports_js_1.Deferred();
        try {
            if (message.messageType === Exports_js_1.MessageType.Text) {
                const payload = `${message.textBody ? message.textBody : ""}`;
                deferral.resolve(new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Text, payload, message.id));
            }
        }
        catch (e) {
            deferral.reject(`Error formatting the message. ${e}`);
        }
        return deferral.promise;
    }
}
exports.ConversationWebsocketMessageFormatter = ConversationWebsocketMessageFormatter;

//# sourceMappingURL=ConversationWebsocketMessageFormatter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/Exports.js"
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/Exports.js ***!
  \********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.InternalParticipants = exports.ConversationTranslatorMessageTypes = exports.ConversationTranslatorCommandTypes = exports.ParticipantsListEventArgs = exports.ParticipantEventArgs = exports.ParticipantAttributeEventArgs = exports.MuteAllEventArgs = exports.LockRoomEventArgs = exports.ConversationReceivedTranslationEventArgs = exports.TranscriberRecognizer = exports.ConversationRecognizerFactory = exports.ConversationConnectionConfig = exports.ConversationManager = void 0;
var ConversationManager_js_1 = __webpack_require__(/*! ./ConversationManager.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationManager.js");
Object.defineProperty(exports, "ConversationManager", ({ enumerable: true, get: function () { return ConversationManager_js_1.ConversationManager; } }));
var ConversationConnectionConfig_js_1 = __webpack_require__(/*! ./ConversationConnectionConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationConnectionConfig.js");
Object.defineProperty(exports, "ConversationConnectionConfig", ({ enumerable: true, get: function () { return ConversationConnectionConfig_js_1.ConversationConnectionConfig; } }));
var ConversationTranslatorRecognizer_js_1 = __webpack_require__(/*! ./ConversationTranslatorRecognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorRecognizer.js");
Object.defineProperty(exports, "ConversationRecognizerFactory", ({ enumerable: true, get: function () { return ConversationTranslatorRecognizer_js_1.ConversationRecognizerFactory; } }));
var TranscriberRecognizer_js_1 = __webpack_require__(/*! ./TranscriberRecognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/TranscriberRecognizer.js");
Object.defineProperty(exports, "TranscriberRecognizer", ({ enumerable: true, get: function () { return TranscriberRecognizer_js_1.TranscriberRecognizer; } }));
var ConversationTranslatorEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranslatorEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorEventArgs.js");
Object.defineProperty(exports, "ConversationReceivedTranslationEventArgs", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.ConversationReceivedTranslationEventArgs; } }));
Object.defineProperty(exports, "LockRoomEventArgs", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.LockRoomEventArgs; } }));
Object.defineProperty(exports, "MuteAllEventArgs", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.MuteAllEventArgs; } }));
Object.defineProperty(exports, "ParticipantAttributeEventArgs", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.ParticipantAttributeEventArgs; } }));
Object.defineProperty(exports, "ParticipantEventArgs", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.ParticipantEventArgs; } }));
Object.defineProperty(exports, "ParticipantsListEventArgs", ({ enumerable: true, get: function () { return ConversationTranslatorEventArgs_js_1.ParticipantsListEventArgs; } }));
var ConversationTranslatorInterfaces_js_1 = __webpack_require__(/*! ./ConversationTranslatorInterfaces.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorInterfaces.js");
Object.defineProperty(exports, "ConversationTranslatorCommandTypes", ({ enumerable: true, get: function () { return ConversationTranslatorInterfaces_js_1.ConversationTranslatorCommandTypes; } }));
Object.defineProperty(exports, "ConversationTranslatorMessageTypes", ({ enumerable: true, get: function () { return ConversationTranslatorInterfaces_js_1.ConversationTranslatorMessageTypes; } }));
Object.defineProperty(exports, "InternalParticipants", ({ enumerable: true, get: function () { return ConversationTranslatorInterfaces_js_1.InternalParticipants; } }));

//# sourceMappingURL=Exports.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js"
/*!***************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js ***!
  \***************************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CommandResponsePayload = void 0;
const parseCommandResponse = (json) => JSON.parse(json);
class CommandResponsePayload {
    constructor(json) {
        this.privCommandResponse = parseCommandResponse(json);
    }
    get type() {
        return this.privCommandResponse.type;
    }
    get command() {
        return this.privCommandResponse.command;
    }
    get id() {
        return this.privCommandResponse.id;
    }
    get nickname() {
        return this.privCommandResponse.nickname;
    }
    get participantId() {
        return this.privCommandResponse.participantId;
    }
    get roomid() {
        return this.privCommandResponse.roomid;
    }
    get value() {
        return this.privCommandResponse.value;
    }
    get token() {
        return this.privCommandResponse.token;
    }
    static fromJSON(json) {
        return new CommandResponsePayload(json);
    }
}
exports.CommandResponsePayload = CommandResponsePayload;

//# sourceMappingURL=CommandResponsePayload.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/Exports.js"
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/Exports.js ***!
  \************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextResponsePayload = exports.SpeechResponsePayload = exports.ParticipantPayloadResponse = exports.ParticipantsListPayloadResponse = exports.CommandResponsePayload = void 0;
var CommandResponsePayload_js_1 = __webpack_require__(/*! ./CommandResponsePayload.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js");
Object.defineProperty(exports, "CommandResponsePayload", ({ enumerable: true, get: function () { return CommandResponsePayload_js_1.CommandResponsePayload; } }));
var ParticipantResponsePayload_js_1 = __webpack_require__(/*! ./ParticipantResponsePayload.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js");
Object.defineProperty(exports, "ParticipantsListPayloadResponse", ({ enumerable: true, get: function () { return ParticipantResponsePayload_js_1.ParticipantsListPayloadResponse; } }));
Object.defineProperty(exports, "ParticipantPayloadResponse", ({ enumerable: true, get: function () { return ParticipantResponsePayload_js_1.ParticipantPayloadResponse; } }));
var TranslationResponsePayload_js_1 = __webpack_require__(/*! ./TranslationResponsePayload.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js");
Object.defineProperty(exports, "SpeechResponsePayload", ({ enumerable: true, get: function () { return TranslationResponsePayload_js_1.SpeechResponsePayload; } }));
Object.defineProperty(exports, "TextResponsePayload", ({ enumerable: true, get: function () { return TranslationResponsePayload_js_1.TextResponsePayload; } }));

//# sourceMappingURL=Exports.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js"
/*!*******************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js ***!
  \*******************************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ParticipantPayloadResponse = exports.ParticipantsListPayloadResponse = void 0;
const parseListResponse = (json) => JSON.parse(json);
const parseParticipantResponse = (json) => JSON.parse(json);
class ParticipantsListPayloadResponse {
    constructor(json) {
        this.privParticipantsPayloadResponse = parseListResponse(json);
    }
    get roomid() {
        return this.privParticipantsPayloadResponse.roomid;
    }
    get id() {
        return this.privParticipantsPayloadResponse.id;
    }
    get command() {
        return this.privParticipantsPayloadResponse.command;
    }
    get participants() {
        return this.privParticipantsPayloadResponse.participants;
    }
    get token() {
        return this.privParticipantsPayloadResponse.token;
    }
    get translateTo() {
        return this.privParticipantsPayloadResponse.translateTo;
    }
    get profanityFilter() {
        return this.privParticipantsPayloadResponse.profanityFilter;
    }
    get roomProfanityFilter() {
        return this.privParticipantsPayloadResponse.roomProfanityFilter;
    }
    get roomLocked() {
        return this.privParticipantsPayloadResponse.roomLocked;
    }
    get muteAll() {
        return this.privParticipantsPayloadResponse.muteAll;
    }
    get type() {
        return this.privParticipantsPayloadResponse.type;
    }
    static fromJSON(json) {
        return new ParticipantsListPayloadResponse(json);
    }
}
exports.ParticipantsListPayloadResponse = ParticipantsListPayloadResponse;
class ParticipantPayloadResponse {
    constructor(json) {
        this.privParticipantPayloadResponse = parseParticipantResponse(json);
    }
    get nickname() {
        return this.privParticipantPayloadResponse.nickname;
    }
    get locale() {
        return this.privParticipantPayloadResponse.locale;
    }
    get usetts() {
        return this.privParticipantPayloadResponse.usetts;
    }
    get ismuted() {
        return this.privParticipantPayloadResponse.ismuted;
    }
    get ishost() {
        return this.privParticipantPayloadResponse.ishost;
    }
    get participantId() {
        return this.privParticipantPayloadResponse.participantId;
    }
    get avatar() {
        return this.privParticipantPayloadResponse.avatar;
    }
    static fromJSON(json) {
        return new ParticipantPayloadResponse(json);
    }
}
exports.ParticipantPayloadResponse = ParticipantPayloadResponse;

//# sourceMappingURL=ParticipantResponsePayload.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js"
/*!*******************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js ***!
  \*******************************************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TextResponsePayload = exports.SpeechResponsePayload = void 0;
const parseSpeechResponse = (json) => JSON.parse(json);
const parseTextResponse = (json) => JSON.parse(json);
class SpeechResponsePayload {
    constructor(json) {
        this.privSpeechResponse = parseSpeechResponse(json);
    }
    get recognition() {
        return this.privSpeechResponse.recognition;
    }
    get translations() {
        return this.privSpeechResponse.translations;
    }
    get id() {
        return this.privSpeechResponse.id;
    }
    get language() {
        return this.privSpeechResponse.language;
    }
    get nickname() {
        return this.privSpeechResponse.nickname;
    }
    get participantId() {
        return this.privSpeechResponse.participantId;
    }
    get roomid() {
        return this.privSpeechResponse.roomid;
    }
    get timestamp() {
        return this.privSpeechResponse.timestamp;
    }
    get type() {
        return this.privSpeechResponse.type;
    }
    get isFinal() {
        return this.privSpeechResponse.type === "final";
    }
    static fromJSON(json) {
        return new SpeechResponsePayload(json);
    }
}
exports.SpeechResponsePayload = SpeechResponsePayload;
class TextResponsePayload {
    constructor(json) {
        this.privTextResponse = parseTextResponse(json);
    }
    get originalText() {
        return this.privTextResponse.originalText;
    }
    get translations() {
        return this.privTextResponse.translations;
    }
    get id() {
        return this.privTextResponse.id;
    }
    get language() {
        return this.privTextResponse.language;
    }
    get nickname() {
        return this.privTextResponse.nickname;
    }
    get participantId() {
        return this.privTextResponse.participantId;
    }
    get roomid() {
        return this.privTextResponse.roomid;
    }
    get timestamp() {
        return this.privTextResponse.timestamp;
    }
    get type() {
        return this.privTextResponse.type;
    }
    static fromJSON(json) {
        return new TextResponsePayload(json);
    }
}
exports.TextResponsePayload = TextResponsePayload;

//# sourceMappingURL=TranslationResponsePayload.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/TranscriberRecognizer.js"
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/TranscriberRecognizer.js ***!
  \**********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranscriberRecognizer = void 0;
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
const Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../../sdk/Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_2 = __webpack_require__(/*! ../../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ../ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
class TranscriberRecognizer extends Exports_js_2.Recognizer {
    /**
     * TranscriberRecognizer constructor.
     * @constructor
     * @param {SpeechTranslationConfig} speechTranslationConfig - Non-audio configuration associated with the recognizer
     * @param {AudioConfig} audioConfig - An audio configuration associated with the recognizer
     */
    constructor(speechTranslationConfig, audioConfig) {
        const speechTranslationConfigImpl = speechTranslationConfig;
        Contracts_js_1.Contracts.throwIfNull(speechTranslationConfigImpl, "speechTranslationConfig");
        const audioConfigImpl = audioConfig;
        Contracts_js_1.Contracts.throwIfNull(audioConfigImpl, "audioConfigImpl");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(speechTranslationConfigImpl.speechRecognitionLanguage, Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage]);
        super(audioConfig, speechTranslationConfigImpl.properties, new Exports_js_3.TranscriberConnectionFactory());
        this.privDisposedRecognizer = false;
        this.isMeetingRecognizer = false;
    }
    get speechRecognitionLanguage() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage);
    }
    get properties() {
        return this.privProperties;
    }
    get authorizationToken() {
        return this.properties.getProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token);
    }
    set authorizationToken(token) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, token);
    }
    set conversation(c) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(c, "Conversation");
        this.isMeetingRecognizer = false;
        this.privConversation = c;
    }
    getConversationInfo() {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation, "Conversation");
        return this.privConversation.conversationInfo;
    }
    set meeting(m) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(m, "Meeting");
        this.isMeetingRecognizer = true;
        this.privMeeting = m;
    }
    getMeetingInfo() {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privMeeting, "Meeting");
        return this.privMeeting.meetingInfo;
    }
    IsMeetingRecognizer() {
        return this.isMeetingRecognizer;
    }
    startContinuousRecognitionAsync(cb, err) {
        (0, Exports_js_1.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(PhraseDetectionContext_js_1.RecognitionMode.Conversation), cb, err);
    }
    stopContinuousRecognitionAsync(cb, err) {
        (0, Exports_js_1.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);
    }
    async close() {
        if (!this.privDisposedRecognizer) {
            await this.dispose(true);
        }
    }
    // Push async join/leave conversation message via serviceRecognizer
    async pushConversationEvent(conversationInfo, command) {
        const reco = (this.privReco);
        Contracts_js_1.Contracts.throwIfNullOrUndefined(reco, "serviceRecognizer");
        await reco.sendSpeechEventAsync(conversationInfo, command);
    }
    // Push async join/leave meeting message via serviceRecognizer
    async pushMeetingEvent(meetingInfo, command) {
        const reco = (this.privReco);
        Contracts_js_1.Contracts.throwIfNullOrUndefined(reco, "serviceRecognizer");
        await reco.sendMeetingSpeechEventAsync(meetingInfo, command);
    }
    async enforceAudioGating() {
        const audioConfigImpl = this.audioConfig;
        const format = await audioConfigImpl.format;
        const channels = format.channels;
        if (channels === 1) {
            if (this.properties.getProperty("f0f5debc-f8c9-4892-ac4b-90a7ab359fd2", "false").toLowerCase() !== "true") {
                throw new Error("Single channel audio configuration for MeetingTranscriber is currently under private preview, please contact diarizationrequest@microsoft.com for more details");
            }
        }
        else if (channels !== 8) {
            throw new Error(`Unsupported audio configuration: Detected ${channels}-channel audio`);
        }
        return;
    }
    connectMeetingCallbacks(transcriber) {
        this.isMeetingRecognizer = true;
        this.canceled = (s, e) => {
            if (!!transcriber.canceled) {
                transcriber.canceled(transcriber, e);
            }
        };
        this.recognizing = (s, e) => {
            if (!!transcriber.transcribing) {
                transcriber.transcribing(transcriber, e);
            }
        };
        this.recognized = (s, e) => {
            if (!!transcriber.transcribed) {
                transcriber.transcribed(transcriber, e);
            }
        };
        this.sessionStarted = (s, e) => {
            if (!!transcriber.sessionStarted) {
                transcriber.sessionStarted(transcriber, e);
            }
        };
        this.sessionStopped = (s, e) => {
            if (!!transcriber.sessionStopped) {
                transcriber.sessionStopped(transcriber, e);
            }
        };
    }
    disconnectCallbacks() {
        this.canceled = undefined;
        this.recognizing = undefined;
        this.recognized = undefined;
        this.sessionStarted = undefined;
        this.sessionStopped = undefined;
    }
    /**
     * Disposes any resources held by the object.
     * @member ConversationTranscriber.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - true if disposing the object.
     */
    async dispose(disposing) {
        if (this.privDisposedRecognizer) {
            return;
        }
        if (disposing) {
            this.privDisposedRecognizer = true;
            await this.implRecognizerStop();
        }
        await super.dispose(disposing);
    }
    createRecognizerConfig(speechConfig) {
        return new Exports_js_3.RecognizerConfig(speechConfig, this.properties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const configImpl = audioConfig;
        return new Exports_js_3.TranscriptionServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
    }
}
exports.TranscriberRecognizer = TranscriberRecognizer;

//# sourceMappingURL=TranscriberRecognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriptionServiceRecognizer.js"
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranscriptionServiceRecognizer.js ***!
  \*****************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranscriptionServiceRecognizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const SpeechConnectionMessage_Internal_js_1 = __webpack_require__(/*! ./SpeechConnectionMessage.Internal.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechConnectionMessage.Internal.js");
// eslint-disable-next-line max-classes-per-file
class TranscriptionServiceRecognizer extends Exports_js_3.ConversationServiceRecognizer {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, transcriber) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, transcriber);
        this.privTranscriberRecognizer = transcriber;
        this.sendPrePayloadJSONOverride = (connection) => this.sendTranscriptionStartJSON(connection);
        if (this.privRecognizerConfig.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps) === "true") {
            this.privSpeechContext.setWordLevelTimings();
        }
    }
    async sendSpeechEventAsync(info, command) {
        if (!!this.privRequestSession.isRecognizing) {
            const connection = await this.fetchConnection();
            await this.sendSpeechEvent(connection, this.createSpeechEventPayload(info, command));
        }
    }
    async sendMeetingSpeechEventAsync(info, command) {
        if (!!this.privRequestSession.isRecognizing) {
            const connection = await this.fetchConnection();
            await this.sendSpeechEvent(connection, this.createMeetingSpeechEventPayload(info, command));
        }
    }
    processTypeSpecificMessages(connectionMessage) {
        return this.processSpeechMessages(connectionMessage);
    }
    handleRecognizedCallback(result, offset, sessionId) {
        try {
            const event = new Exports_js_2.SpeechRecognitionEventArgs(result, offset, sessionId);
            this.privTranscriberRecognizer.recognized(this.privTranscriberRecognizer, event);
            if (!!this.privSuccessCallback) {
                try {
                    this.privSuccessCallback(result);
                }
                catch (e) {
                    if (!!this.privErrorCallback) {
                        this.privErrorCallback(e);
                    }
                }
                // Only invoke the call back once.
                // and if it's successful don't invoke the
                // error after that.
                this.privSuccessCallback = undefined;
                this.privErrorCallback = undefined;
            }
            /* eslint-disable no-empty */
        }
        catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
        }
    }
    handleRecognizingCallback(result, duration, sessionId) {
        try {
            const ev = new Exports_js_2.SpeechRecognitionEventArgs(result, duration, sessionId);
            this.privTranscriberRecognizer.recognizing(this.privTranscriberRecognizer, ev);
            /* eslint-disable no-empty */
        }
        catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
        }
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        const properties = new Exports_js_2.PropertyCollection();
        properties.setProperty(Exports_js_3.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[errorCode]);
        if (this.privTranscriberRecognizer.IsMeetingRecognizer()) {
            if (!!this.privTranscriberRecognizer.canceled) {
                const cancelEvent = new Exports_js_2.MeetingTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
                try {
                    this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);
                    /* eslint-disable no-empty */
                }
                catch { }
            }
        }
        else {
            if (!!this.privTranscriberRecognizer.canceled) {
                const cancelEvent = new Exports_js_2.ConversationTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);
                try {
                    this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);
                    /* eslint-disable no-empty */
                }
                catch { }
            }
        }
        if (!!this.privSuccessCallback) {
            const result = new Exports_js_2.SpeechRecognitionResult(requestId, Exports_js_2.ResultReason.Canceled, undefined, // Text
            undefined, // Duration
            undefined, // Offset
            undefined, // Language
            undefined, // Language Detection Confidence
            undefined, // Speaker Id
            error, undefined, // Json
            properties);
            try {
                this.privSuccessCallback(result);
                this.privSuccessCallback = undefined;
                /* eslint-disable no-empty */
            }
            catch { }
        }
    }
    // Encapsulated for derived service recognizers that need to send additional JSON
    async sendTranscriptionStartJSON(connection) {
        await this.sendSpeechContext(connection, true);
        if (this.privTranscriberRecognizer.IsMeetingRecognizer()) {
            const info = this.privTranscriberRecognizer.getMeetingInfo();
            const payload = this.createMeetingSpeechEventPayload(info, "start");
            await this.sendSpeechEvent(connection, payload);
        }
        else {
            const info = this.privTranscriberRecognizer.getConversationInfo();
            const payload = this.createSpeechEventPayload(info, "start");
            await this.sendSpeechEvent(connection, payload);
        }
        await this.sendWaveHeader(connection);
        return;
    }
    sendSpeechEvent(connection, payload) {
        const speechEventJson = JSON.stringify(payload);
        if (speechEventJson) {
            return connection.send(new SpeechConnectionMessage_Internal_js_1.SpeechConnectionMessage(Exports_js_1.MessageType.Text, "speech.event", this.privRequestSession.requestId, "application/json", speechEventJson));
        }
        return;
    }
    createSpeechEventPayload(info, command) {
        const eventDict = { id: "meeting", name: command, meeting: info.conversationProperties };
        eventDict.meeting.id = info.id;
        eventDict.meeting.attendees = info.participants;
        return eventDict;
    }
    createMeetingSpeechEventPayload(info, command) {
        const eventDict = { id: "meeting", name: command, meeting: info.meetingProperties };
        eventDict.meeting.id = info.id;
        eventDict.meeting.attendees = info.participants;
        return eventDict;
    }
}
exports.TranscriptionServiceRecognizer = TranscriptionServiceRecognizer;

//# sourceMappingURL=TranscriptionServiceRecognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationConnectionFactory.js"
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationConnectionFactory.js ***!
  \***************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationConnectionFactory = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const StringUtils_js_1 = __webpack_require__(/*! ../common/StringUtils.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/StringUtils.js");
const Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const ConnectionFactoryBase_js_1 = __webpack_require__(/*! ./ConnectionFactoryBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ConnectionFactoryBase.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const HeaderNames_js_1 = __webpack_require__(/*! ./HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const QueryParameterNames_js_1 = __webpack_require__(/*! ./QueryParameterNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/QueryParameterNames.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ./ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
class TranslationConnectionFactory extends ConnectionFactoryBase_js_1.ConnectionFactoryBase {
    constructor() {
        super(...arguments);
        this.universalUri = "/stt/speech/universal/v2";
        this.translationV1Uri = "/speech/translation/cognitiveservices/v1";
    }
    async create(config, authInfo, connectionId) {
        let endpoint = this.getEndpointUrl(config);
        const queryParams = {};
        // Determine if we're using V1 or V2 endpoint
        this.setQueryParams(queryParams, config, endpoint);
        if (!!endpoint) {
            const endpointUrl = new URL(endpoint);
            const pathName = endpointUrl.pathname;
            if (pathName === "" || pathName === "/") {
                // We need to generate the path, and we need to check for a redirect.
                endpointUrl.pathname = this.universalUri;
                endpoint = await ConnectionFactoryBase_js_1.ConnectionFactoryBase.getRedirectUrlFromEndpoint(endpointUrl.toString());
            }
        }
        const headers = {};
        if (authInfo.token !== undefined && authInfo.token !== "") {
            headers[authInfo.headerName] = authInfo.token;
        }
        headers[HeaderNames_js_1.HeaderNames.ConnectionId] = connectionId;
        config.parameters.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Url, endpoint);
        const enableCompression = config.parameters.getProperty("SPEECH-EnableWebsocketCompression", "false") === "true";
        const webSocketConnection = new Exports_js_1.WebsocketConnection(endpoint, queryParams, headers, new Exports_js_3.WebsocketMessageFormatter(), Exports_js_1.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);
        return webSocketConnection;
    }
    getEndpointUrl(config, returnRegionPlaceholder) {
        const region = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region);
        const hostSuffix = ConnectionFactoryBase_js_1.ConnectionFactoryBase.getHostSuffix(region);
        // First check for an explicitly specified endpoint
        let endpointUrl = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, undefined);
        // If an explicit endpoint is provided, use it
        if (endpointUrl) {
            if (returnRegionPlaceholder === true) {
                return endpointUrl;
            }
            return StringUtils_js_1.StringUtils.formatString(endpointUrl, { region });
        }
        // Check if V1 endpoint is explicitly requested
        const forceV1Endpoint = config.parameters.getProperty("SPEECH-ForceV1Endpoint", "false") === "true";
        if (forceV1Endpoint) {
            // Use V1 endpoint with s2s.speech host
            const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, "wss://{region}.s2s.speech" + hostSuffix);
            endpointUrl = host + this.translationV1Uri;
        }
        else {
            // Default to V2 endpoint with stt.speech host
            const host = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, "wss://{region}.stt.speech" + hostSuffix);
            endpointUrl = host + this.universalUri;
        }
        if (returnRegionPlaceholder === true) {
            return endpointUrl;
        }
        return StringUtils_js_1.StringUtils.formatString(endpointUrl, { region });
    }
    setQueryParams(queryParams, config, endpointUrl) {
        // Common parameters for both V1 and V2 endpoints
        queryParams.from = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage);
        queryParams.to = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationToLanguages);
        queryParams.scenario = config.recognitionMode === PhraseDetectionContext_js_1.RecognitionMode.Interactive ? "interactive" :
            config.recognitionMode === PhraseDetectionContext_js_1.RecognitionMode.Conversation ? "conversation" : "";
        // Set common parameters
        this.setCommonUrlParams(config, queryParams, endpointUrl);
        this.setUrlParameter(Exports_js_2.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult, QueryParameterNames_js_1.QueryParameterNames.StableTranslation, config, queryParams, endpointUrl);
        // Handle translation voice if specified
        const translationVoice = config.parameters.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);
        if (translationVoice !== undefined) {
            queryParams.voice = translationVoice;
            // Updated to match C++ implementation
            queryParams.features = "requireVoice";
        }
    }
}
exports.TranslationConnectionFactory = TranslationConnectionFactory;

//# sourceMappingURL=TranslationConnectionFactory.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationServiceRecognizer.js"
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationServiceRecognizer.js ***!
  \***************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationServiceRecognizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../sdk/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
// eslint-disable-next-line max-classes-per-file
class TranslationServiceRecognizer extends Exports_js_3.ConversationServiceRecognizer {
    constructor(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer) {
        super(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer);
        this.privTranslationRecognizer = translationRecognizer;
        this.connectionEvents.attach((connectionEvent) => {
            if (connectionEvent.name === "ConnectionEstablishedEvent") {
                this.privTranslationRecognizer.onConnection();
            }
        });
    }
    async processTypeSpecificMessages(connectionMessage) {
        const resultProps = new Exports_js_2.PropertyCollection();
        let processed = await this.processSpeechMessages(connectionMessage);
        if (processed) {
            return true;
        }
        const handleTranslationPhrase = async (translatedPhrase) => {
            resultProps.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_JsonResult, translatedPhrase.asJson());
            this.privRequestSession.onPhraseRecognized(translatedPhrase.Offset + translatedPhrase.Duration);
            if (translatedPhrase.RecognitionStatus === Exports_js_3.RecognitionStatus.Success) {
                // OK, the recognition was successful. How'd the translation do?
                const result = this.fireEventForResult(translatedPhrase, resultProps);
                if (!!this.privTranslationRecognizer.recognized) {
                    try {
                        this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, result);
                        /* eslint-disable no-empty */
                    }
                    catch (error) {
                        // Not going to let errors in the event handler
                        // trip things up.
                    }
                }
                // report result to promise.
                if (!!this.privSuccessCallback) {
                    try {
                        this.privSuccessCallback(result.result);
                    }
                    catch (e) {
                        if (!!this.privErrorCallback) {
                            this.privErrorCallback(e);
                        }
                    }
                    // Only invoke the call back once.
                    // and if it's successful don't invoke the
                    // error after that.
                    this.privSuccessCallback = undefined;
                    this.privErrorCallback = undefined;
                }
            }
            else {
                const reason = Exports_js_3.EnumTranslation.implTranslateRecognitionResult(translatedPhrase.RecognitionStatus);
                const result = new Exports_js_2.TranslationRecognitionResult(undefined, this.privRequestSession.requestId, reason, translatedPhrase.Text, translatedPhrase.Duration, translatedPhrase.Offset, translatedPhrase.Language, translatedPhrase.Confidence, undefined, translatedPhrase.asJson(), resultProps);
                if (reason === Exports_js_2.ResultReason.Canceled) {
                    const cancelReason = Exports_js_3.EnumTranslation.implTranslateCancelResult(translatedPhrase.RecognitionStatus);
                    const cancellationErrorCode = Exports_js_3.EnumTranslation.implTranslateCancelErrorCode(translatedPhrase.RecognitionStatus);
                    await this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, Exports_js_3.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));
                }
                else {
                    if (translatedPhrase.RecognitionStatus !== Exports_js_3.RecognitionStatus.EndOfDictation) {
                        const ev = new Exports_js_2.TranslationRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);
                        if (!!this.privTranslationRecognizer.recognized) {
                            try {
                                this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);
                                /* eslint-disable no-empty */
                            }
                            catch (error) {
                                // Not going to let errors in the event handler
                                // trip things up.
                            }
                        }
                        // report result to promise.
                        if (!!this.privSuccessCallback) {
                            try {
                                this.privSuccessCallback(result);
                            }
                            catch (e) {
                                if (!!this.privErrorCallback) {
                                    this.privErrorCallback(e);
                                }
                            }
                            // Only invoke the call back once.
                            // and if it's successful don't invoke the
                            // error after that.
                            this.privSuccessCallback = undefined;
                            this.privErrorCallback = undefined;
                        }
                    }
                }
                processed = true;
            }
        };
        const handleTranslationHypothesis = (hypothesis) => {
            resultProps.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_JsonResult, hypothesis.asJson());
            const result = this.fireEventForResult(hypothesis, resultProps);
            this.privRequestSession.onHypothesis(result.offset);
            if (!!this.privTranslationRecognizer.recognizing) {
                try {
                    this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, result);
                    /* eslint-disable no-empty */
                }
                catch (error) {
                    // Not going to let errors in the event handler
                    // trip things up.
                }
            }
            processed = true;
        };
        if (connectionMessage.messageType === Exports_js_1.MessageType.Text) {
            resultProps.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);
        }
        switch (connectionMessage.path.toLowerCase()) {
            case "translation.hypothesis":
                handleTranslationHypothesis(Exports_js_3.TranslationHypothesis.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset));
                break;
            case "translation.response":
                const phrase = JSON.parse(connectionMessage.textBody);
                if (!!phrase.SpeechPhrase) {
                    await handleTranslationPhrase(Exports_js_3.TranslationPhrase.fromTranslationResponse(phrase, this.privRequestSession.currentTurnAudioOffset));
                }
                else {
                    const hypothesis = JSON.parse(connectionMessage.textBody);
                    if (!!hypothesis.SpeechHypothesis) {
                        handleTranslationHypothesis(Exports_js_3.TranslationHypothesis.fromTranslationResponse(hypothesis, this.privRequestSession.currentTurnAudioOffset));
                    }
                }
                break;
            case "translation.phrase":
                await handleTranslationPhrase(Exports_js_3.TranslationPhrase.fromJSON(connectionMessage.textBody, this.privRequestSession.currentTurnAudioOffset));
                break;
            case "translation.synthesis":
            case "audio":
                this.sendSynthesisAudio(connectionMessage.binaryBody, this.privRequestSession.sessionId);
                processed = true;
                break;
            case "audio.end":
            case "translation.synthesis.end":
                const synthEnd = Exports_js_3.TranslationSynthesisEnd.fromJSON(connectionMessage.textBody);
                switch (synthEnd.SynthesisStatus) {
                    case Exports_js_3.SynthesisStatus.Error:
                        if (!!this.privTranslationRecognizer.synthesizing) {
                            const result = new Exports_js_2.TranslationSynthesisResult(Exports_js_2.ResultReason.Canceled, undefined);
                            const retEvent = new Exports_js_2.TranslationSynthesisEventArgs(result, this.privRequestSession.sessionId);
                            try {
                                this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);
                                /* eslint-disable no-empty */
                            }
                            catch (error) {
                                // Not going to let errors in the event handler
                                // trip things up.
                            }
                        }
                        if (!!this.privTranslationRecognizer.canceled) {
                            // And raise a canceled event to send the rich(er) error message back.
                            const canceledResult = new Exports_js_2.TranslationRecognitionCanceledEventArgs(this.privRequestSession.sessionId, Exports_js_2.CancellationReason.Error, synthEnd.FailureReason, Exports_js_2.CancellationErrorCode.ServiceError, null);
                            try {
                                this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, canceledResult);
                                /* eslint-disable no-empty */
                            }
                            catch (error) {
                                // Not going to let errors in the event handler
                                // trip things up.
                            }
                        }
                        break;
                    case Exports_js_3.SynthesisStatus.Success:
                        this.sendSynthesisAudio(undefined, this.privRequestSession.sessionId);
                        break;
                    default:
                        break;
                }
                processed = true;
                break;
            default:
                break;
        }
        return processed;
    }
    // Cancels recognition.
    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {
        const properties = new Exports_js_2.PropertyCollection();
        properties.setProperty(Exports_js_3.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[errorCode]);
        if (!!this.privTranslationRecognizer.canceled) {
            const cancelEvent = new Exports_js_2.TranslationRecognitionCanceledEventArgs(sessionId, cancellationReason, error, errorCode, undefined);
            try {
                this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, cancelEvent);
                /* eslint-disable no-empty */
            }
            catch { }
        }
        if (!!this.privSuccessCallback) {
            const result = new Exports_js_2.TranslationRecognitionResult(undefined, // Translations
            requestId, Exports_js_2.ResultReason.Canceled, undefined, // Text
            undefined, // Druation
            undefined, // Offset
            undefined, // Language
            undefined, // LanguageDetectionConfidence
            error, undefined, // Json
            properties);
            try {
                this.privSuccessCallback(result);
                /* eslint-disable no-empty */
                this.privSuccessCallback = undefined;
            }
            catch { }
        }
    }
    handleRecognizingCallback(result, offset, sessionId) {
        try {
            const ev = new Exports_js_2.TranslationRecognitionEventArgs(Exports_js_2.TranslationRecognitionResult.fromSpeechRecognitionResult(result), offset, sessionId);
            this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, ev);
            /* eslint-disable no-empty */
        }
        catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
        }
    }
    handleRecognizedCallback(result, offset, sessionId) {
        try {
            const ev = new Exports_js_2.TranslationRecognitionEventArgs(Exports_js_2.TranslationRecognitionResult.fromSpeechRecognitionResult(result), offset, sessionId);
            this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);
        }
        catch (error) {
            // Not going to let errors in the event handler
            // trip things up.
        }
    }
    fireEventForResult(serviceResult, properties) {
        let translations;
        if (undefined !== serviceResult.Translation.Translations) {
            translations = new Exports_js_2.Translations();
            for (const translation of serviceResult.Translation.Translations) {
                translations.set(translation.Language, translation.Text || translation.DisplayText);
            }
        }
        let resultReason;
        let confidence;
        if (serviceResult instanceof Exports_js_3.TranslationPhrase) {
            if (!!serviceResult.Translation && serviceResult.Translation.TranslationStatus === Exports_js_1.TranslationStatus.Success) {
                resultReason = Exports_js_2.ResultReason.TranslatedSpeech;
            }
            else {
                resultReason = Exports_js_2.ResultReason.RecognizedSpeech;
            }
            confidence = serviceResult.Confidence;
        }
        else {
            resultReason = Exports_js_2.ResultReason.TranslatingSpeech;
        }
        const language = serviceResult.Language;
        const result = new Exports_js_2.TranslationRecognitionResult(translations, this.privRequestSession.requestId, resultReason, serviceResult.Text, serviceResult.Duration, serviceResult.Offset, language, confidence, serviceResult.Translation.FailureReason, serviceResult.asJson(), properties);
        const ev = new Exports_js_2.TranslationRecognitionEventArgs(result, serviceResult.Offset, this.privRequestSession.sessionId);
        return ev;
    }
    sendSynthesisAudio(audio, sessionId) {
        const reason = (undefined === audio) ? Exports_js_2.ResultReason.SynthesizingAudioCompleted : Exports_js_2.ResultReason.SynthesizingAudio;
        const result = new Exports_js_2.TranslationSynthesisResult(reason, audio);
        const retEvent = new Exports_js_2.TranslationSynthesisEventArgs(result, sessionId);
        if (!!this.privTranslationRecognizer.synthesizing) {
            try {
                this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);
                /* eslint-disable no-empty */
            }
            catch (error) {
                // Not going to let errors in the event handler
                // trip things up.
            }
        }
    }
}
exports.TranslationServiceRecognizer = TranslationServiceRecognizer;

//# sourceMappingURL=TranslationServiceRecognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js"
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js ***!
  \****************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationStatus = void 0;
/**
 * Defines translation status.
 * @class TranslationStatus
 */
var TranslationStatus;
(function (TranslationStatus) {
    /**
     * @member TranslationStatus.Success
     */
    TranslationStatus[TranslationStatus["Success"] = 0] = "Success";
    /**
     * @member TranslationStatus.Error
     */
    TranslationStatus[TranslationStatus["Error"] = 1] = "Error";
})(TranslationStatus = exports.TranslationStatus || (exports.TranslationStatus = {}));

//# sourceMappingURL=TranslationStatus.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/WebsocketMessageFormatter.js"
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/WebsocketMessageFormatter.js ***!
  \************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.WebsocketMessageFormatter = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const CRLF = "\r\n";
class WebsocketMessageFormatter {
    toConnectionMessage(message) {
        const deferral = new Exports_js_1.Deferred();
        try {
            if (message.messageType === Exports_js_1.MessageType.Text) {
                const textMessage = message.textContent;
                let headers = {};
                let body = null;
                if (textMessage) {
                    const headerBodySplit = textMessage.split("\r\n\r\n");
                    if (headerBodySplit && headerBodySplit.length > 0) {
                        headers = this.parseHeaders(headerBodySplit[0]);
                        if (headerBodySplit.length > 1) {
                            body = headerBodySplit[1];
                        }
                    }
                }
                deferral.resolve(new Exports_js_1.ConnectionMessage(message.messageType, body, headers, message.id));
            }
            else if (message.messageType === Exports_js_1.MessageType.Binary) {
                const binaryMessage = message.binaryContent;
                let headers = {};
                let body = null;
                if (!binaryMessage || binaryMessage.byteLength < 2) {
                    throw new Error("Invalid binary message format. Header length missing.");
                }
                const dataView = new DataView(binaryMessage);
                const headerLength = dataView.getInt16(0);
                if (binaryMessage.byteLength < headerLength + 2) {
                    throw new Error("Invalid binary message format. Header content missing.");
                }
                let headersString = "";
                for (let i = 0; i < headerLength; i++) {
                    headersString += String.fromCharCode((dataView).getInt8(i + 2));
                }
                headers = this.parseHeaders(headersString);
                if (binaryMessage.byteLength > headerLength + 2) {
                    body = binaryMessage.slice(2 + headerLength);
                }
                deferral.resolve(new Exports_js_1.ConnectionMessage(message.messageType, body, headers, message.id));
            }
        }
        catch (e) {
            deferral.reject(`Error formatting the message. Error: ${e}`);
        }
        return deferral.promise;
    }
    fromConnectionMessage(message) {
        const deferral = new Exports_js_1.Deferred();
        try {
            if (message.messageType === Exports_js_1.MessageType.Text) {
                const payload = `${this.makeHeaders(message)}${CRLF}${message.textBody ? message.textBody : ""}`;
                deferral.resolve(new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Text, payload, message.id));
            }
            else if (message.messageType === Exports_js_1.MessageType.Binary) {
                const headersString = this.makeHeaders(message);
                const content = message.binaryBody;
                const headerBuffer = this.stringToArrayBuffer(headersString);
                const headerInt8Array = new Int8Array(headerBuffer);
                const headerLength = headerInt8Array.byteLength;
                const payloadInt8Array = new Int8Array(2 + headerLength + (content ? content.byteLength : 0));
                payloadInt8Array[0] = ((headerLength >> 8) & 0xff);
                payloadInt8Array[1] = headerLength & 0xff;
                payloadInt8Array.set(headerInt8Array, 2);
                if (content) {
                    const bodyInt8Array = new Int8Array(content);
                    payloadInt8Array.set(bodyInt8Array, 2 + headerLength);
                }
                const payload = payloadInt8Array.buffer;
                deferral.resolve(new Exports_js_1.RawWebsocketMessage(Exports_js_1.MessageType.Binary, payload, message.id));
            }
        }
        catch (e) {
            deferral.reject(`Error formatting the message. ${e}`);
        }
        return deferral.promise;
    }
    makeHeaders(message) {
        let headersString = "";
        if (message.headers) {
            for (const header in message.headers) {
                if (header) {
                    headersString += `${header}: ${message.headers[header]}${CRLF}`;
                }
            }
        }
        return headersString;
    }
    parseHeaders(headersString) {
        const headers = {};
        if (headersString) {
            const headerMatches = headersString.match(/[^\r\n]+/g);
            if (headers) {
                for (const header of headerMatches) {
                    if (header) {
                        const separatorIndex = header.indexOf(":");
                        const headerName = separatorIndex > 0 ? header.substr(0, separatorIndex).trim().toLowerCase() : header;
                        const headerValue = separatorIndex > 0 && header.length > (separatorIndex + 1) ?
                            header.substr(separatorIndex + 1).trim() :
                            "";
                        headers[headerName] = headerValue;
                    }
                }
            }
        }
        return headers;
    }
    stringToArrayBuffer(str) {
        const buffer = new ArrayBuffer(str.length);
        const view = new DataView(buffer);
        for (let i = 0; i < str.length; i++) {
            view.setUint8(i, str.charCodeAt(i));
        }
        return buffer;
    }
}
exports.WebsocketMessageFormatter = WebsocketMessageFormatter;

//# sourceMappingURL=WebsocketMessageFormatter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/AudioSourceEvents.js"
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/AudioSourceEvents.js ***!
  \*********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AudioStreamNodeErrorEvent = exports.AudioStreamNodeDetachedEvent = exports.AudioStreamNodeAttachedEvent = exports.AudioStreamNodeAttachingEvent = exports.AudioStreamNodeEvent = exports.AudioSourceErrorEvent = exports.AudioSourceOffEvent = exports.AudioSourceReadyEvent = exports.AudioSourceInitializingEvent = exports.AudioSourceEvent = void 0;
/* eslint-disable max-classes-per-file */
const PlatformEvent_js_1 = __webpack_require__(/*! ./PlatformEvent.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js");
class AudioSourceEvent extends PlatformEvent_js_1.PlatformEvent {
    constructor(eventName, audioSourceId, eventType = PlatformEvent_js_1.EventType.Info) {
        super(eventName, eventType);
        this.privAudioSourceId = audioSourceId;
    }
    get audioSourceId() {
        return this.privAudioSourceId;
    }
}
exports.AudioSourceEvent = AudioSourceEvent;
class AudioSourceInitializingEvent extends AudioSourceEvent {
    constructor(audioSourceId) {
        super("AudioSourceInitializingEvent", audioSourceId);
    }
}
exports.AudioSourceInitializingEvent = AudioSourceInitializingEvent;
class AudioSourceReadyEvent extends AudioSourceEvent {
    constructor(audioSourceId) {
        super("AudioSourceReadyEvent", audioSourceId);
    }
}
exports.AudioSourceReadyEvent = AudioSourceReadyEvent;
class AudioSourceOffEvent extends AudioSourceEvent {
    constructor(audioSourceId) {
        super("AudioSourceOffEvent", audioSourceId);
    }
}
exports.AudioSourceOffEvent = AudioSourceOffEvent;
class AudioSourceErrorEvent extends AudioSourceEvent {
    constructor(audioSourceId, error) {
        super("AudioSourceErrorEvent", audioSourceId, PlatformEvent_js_1.EventType.Error);
        this.privError = error;
    }
    get error() {
        return this.privError;
    }
}
exports.AudioSourceErrorEvent = AudioSourceErrorEvent;
class AudioStreamNodeEvent extends AudioSourceEvent {
    constructor(eventName, audioSourceId, audioNodeId) {
        super(eventName, audioSourceId);
        this.privAudioNodeId = audioNodeId;
    }
    get audioNodeId() {
        return this.privAudioNodeId;
    }
}
exports.AudioStreamNodeEvent = AudioStreamNodeEvent;
class AudioStreamNodeAttachingEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId, audioNodeId) {
        super("AudioStreamNodeAttachingEvent", audioSourceId, audioNodeId);
    }
}
exports.AudioStreamNodeAttachingEvent = AudioStreamNodeAttachingEvent;
class AudioStreamNodeAttachedEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId, audioNodeId) {
        super("AudioStreamNodeAttachedEvent", audioSourceId, audioNodeId);
    }
}
exports.AudioStreamNodeAttachedEvent = AudioStreamNodeAttachedEvent;
class AudioStreamNodeDetachedEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId, audioNodeId) {
        super("AudioStreamNodeDetachedEvent", audioSourceId, audioNodeId);
    }
}
exports.AudioStreamNodeDetachedEvent = AudioStreamNodeDetachedEvent;
class AudioStreamNodeErrorEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId, audioNodeId, error) {
        super("AudioStreamNodeErrorEvent", audioSourceId, audioNodeId);
        this.privError = error;
    }
    get error() {
        return this.privError;
    }
}
exports.AudioStreamNodeErrorEvent = AudioStreamNodeErrorEvent;

//# sourceMappingURL=AudioSourceEvents.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/BackgroundError.js"
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/BackgroundError.js ***!
  \*******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.BackgroundEvent = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
class BackgroundEvent extends Exports_js_1.PlatformEvent {
    constructor(error) {
        super("BackgroundEvent", Exports_js_1.EventType.Error);
        this.privError = error;
    }
    get error() {
        return this.privError;
    }
}
exports.BackgroundEvent = BackgroundEvent;

//# sourceMappingURL=BackgroundError.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ChunkedArrayBufferStream.js"
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ChunkedArrayBufferStream.js ***!
  \****************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ChunkedArrayBufferStream = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
class ChunkedArrayBufferStream extends Exports_js_1.Stream {
    constructor(targetChunkSize, streamId) {
        super(streamId);
        this.privTargetChunkSize = Math.round(targetChunkSize);
        this.privNextBufferReadyBytes = 0;
    }
    writeStreamChunk(chunk) {
        // No pending write, and the buffer is the right size so write it.
        if (chunk.isEnd ||
            (0 === this.privNextBufferReadyBytes && chunk.buffer.byteLength === this.privTargetChunkSize)) {
            super.writeStreamChunk(chunk);
            return;
        }
        let bytesCopiedFromBuffer = 0;
        while (bytesCopiedFromBuffer < chunk.buffer.byteLength) {
            // Fill the next buffer.
            if (undefined === this.privNextBufferToWrite) {
                this.privNextBufferToWrite = new ArrayBuffer(this.privTargetChunkSize);
                this.privNextBufferStartTime = chunk.timeReceived;
            }
            // Find out how many bytes we can copy into the read buffer.
            const bytesToCopy = Math.min(chunk.buffer.byteLength - bytesCopiedFromBuffer, this.privTargetChunkSize - this.privNextBufferReadyBytes);
            const targetView = new Uint8Array(this.privNextBufferToWrite);
            const sourceView = new Uint8Array(chunk.buffer.slice(bytesCopiedFromBuffer, bytesToCopy + bytesCopiedFromBuffer));
            targetView.set(sourceView, this.privNextBufferReadyBytes);
            this.privNextBufferReadyBytes += bytesToCopy;
            bytesCopiedFromBuffer += bytesToCopy;
            // Are we ready to write?
            if (this.privNextBufferReadyBytes === this.privTargetChunkSize) {
                super.writeStreamChunk({
                    buffer: this.privNextBufferToWrite,
                    isEnd: false,
                    timeReceived: this.privNextBufferStartTime,
                });
                this.privNextBufferReadyBytes = 0;
                this.privNextBufferToWrite = undefined;
            }
        }
    }
    close() {
        // Send whatever is pending, then close the base class.
        if (0 !== this.privNextBufferReadyBytes && !this.isClosed) {
            super.writeStreamChunk({
                buffer: this.privNextBufferToWrite.slice(0, this.privNextBufferReadyBytes),
                isEnd: false,
                timeReceived: this.privNextBufferStartTime,
            });
        }
        super.close();
    }
}
exports.ChunkedArrayBufferStream = ChunkedArrayBufferStream;

//# sourceMappingURL=ChunkedArrayBufferStream.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionEvents.js"
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionEvents.js ***!
  \********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConnectionRedirectEvent = exports.ConnectionMessageSentEvent = exports.ConnectionMessageReceivedEvent = exports.ConnectionEstablishErrorEvent = exports.ConnectionErrorEvent = exports.ConnectionClosedEvent = exports.ConnectionEstablishedEvent = exports.ConnectionStartEvent = exports.ConnectionEvent = exports.ServiceEvent = void 0;
const PlatformEvent_js_1 = __webpack_require__(/*! ./PlatformEvent.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js");
class ServiceEvent extends PlatformEvent_js_1.PlatformEvent {
    constructor(eventName, jsonstring, eventType = PlatformEvent_js_1.EventType.Info) {
        super(eventName, eventType);
        this.privJsonResult = jsonstring;
    }
    get jsonString() {
        return this.privJsonResult;
    }
}
exports.ServiceEvent = ServiceEvent;
class ConnectionEvent extends PlatformEvent_js_1.PlatformEvent {
    constructor(eventName, connectionId, eventType = PlatformEvent_js_1.EventType.Info) {
        super(eventName, eventType);
        this.privConnectionId = connectionId;
    }
    get connectionId() {
        return this.privConnectionId;
    }
}
exports.ConnectionEvent = ConnectionEvent;
class ConnectionStartEvent extends ConnectionEvent {
    constructor(connectionId, uri, headers) {
        super("ConnectionStartEvent", connectionId);
        this.privUri = uri;
        this.privHeaders = headers;
    }
    get uri() {
        return this.privUri;
    }
    get headers() {
        return this.privHeaders;
    }
}
exports.ConnectionStartEvent = ConnectionStartEvent;
class ConnectionEstablishedEvent extends ConnectionEvent {
    constructor(connectionId) {
        super("ConnectionEstablishedEvent", connectionId);
    }
}
exports.ConnectionEstablishedEvent = ConnectionEstablishedEvent;
class ConnectionClosedEvent extends ConnectionEvent {
    constructor(connectionId, statusCode, reason) {
        super("ConnectionClosedEvent", connectionId, PlatformEvent_js_1.EventType.Debug);
        this.privReason = reason;
        this.privStatusCode = statusCode;
    }
    get reason() {
        return this.privReason;
    }
    get statusCode() {
        return this.privStatusCode;
    }
}
exports.ConnectionClosedEvent = ConnectionClosedEvent;
class ConnectionErrorEvent extends ConnectionEvent {
    constructor(connectionId, message, type) {
        super("ConnectionErrorEvent", connectionId, PlatformEvent_js_1.EventType.Debug);
        this.privMessage = message;
        this.privType = type;
    }
    get message() {
        return this.privMessage;
    }
    get type() {
        return this.privType;
    }
}
exports.ConnectionErrorEvent = ConnectionErrorEvent;
class ConnectionEstablishErrorEvent extends ConnectionEvent {
    constructor(connectionId, statuscode, reason) {
        super("ConnectionEstablishErrorEvent", connectionId, PlatformEvent_js_1.EventType.Error);
        this.privStatusCode = statuscode;
        this.privReason = reason;
    }
    get reason() {
        return this.privReason;
    }
    get statusCode() {
        return this.privStatusCode;
    }
}
exports.ConnectionEstablishErrorEvent = ConnectionEstablishErrorEvent;
class ConnectionMessageReceivedEvent extends ConnectionEvent {
    constructor(connectionId, networkReceivedTimeISO, message) {
        super("ConnectionMessageReceivedEvent", connectionId);
        this.privNetworkReceivedTime = networkReceivedTimeISO;
        this.privMessage = message;
    }
    get networkReceivedTime() {
        return this.privNetworkReceivedTime;
    }
    get message() {
        return this.privMessage;
    }
}
exports.ConnectionMessageReceivedEvent = ConnectionMessageReceivedEvent;
class ConnectionMessageSentEvent extends ConnectionEvent {
    constructor(connectionId, networkSentTimeISO, message) {
        super("ConnectionMessageSentEvent", connectionId);
        this.privNetworkSentTime = networkSentTimeISO;
        this.privMessage = message;
    }
    get networkSentTime() {
        return this.privNetworkSentTime;
    }
    get message() {
        return this.privMessage;
    }
}
exports.ConnectionMessageSentEvent = ConnectionMessageSentEvent;
class ConnectionRedirectEvent extends ConnectionEvent {
    constructor(connectionId, redirectUrl, originalUrl, context) {
        super("ConnectionRedirectEvent", connectionId, PlatformEvent_js_1.EventType.Info);
        this.privRedirectUrl = redirectUrl;
        this.privOriginalUrl = originalUrl;
        this.privContext = context;
    }
    get redirectUrl() {
        return this.privRedirectUrl;
    }
    get originalUrl() {
        return this.privOriginalUrl;
    }
    get context() {
        return this.privContext;
    }
}
exports.ConnectionRedirectEvent = ConnectionRedirectEvent;

//# sourceMappingURL=ConnectionEvents.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionMessage.js"
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionMessage.js ***!
  \*********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

/* eslint-disable @typescript-eslint/no-unsafe-return */
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConnectionMessage = exports.MessageType = void 0;
const Error_js_1 = __webpack_require__(/*! ./Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js");
const Guid_js_1 = __webpack_require__(/*! ./Guid.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js");
var MessageType;
(function (MessageType) {
    MessageType[MessageType["Text"] = 0] = "Text";
    MessageType[MessageType["Binary"] = 1] = "Binary";
})(MessageType = exports.MessageType || (exports.MessageType = {}));
class ConnectionMessage {
    constructor(messageType, body, headers, id) {
        this.privBody = null;
        if (messageType === MessageType.Text && body && !(typeof (body) === "string")) {
            throw new Error_js_1.InvalidOperationError("Payload must be a string");
        }
        if (messageType === MessageType.Binary && body && !(body instanceof ArrayBuffer)) {
            throw new Error_js_1.InvalidOperationError("Payload must be ArrayBuffer");
        }
        this.privMessageType = messageType;
        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
        this.privBody = body;
        this.privHeaders = headers ? headers : {};
        this.privId = id ? id : (0, Guid_js_1.createNoDashGuid)();
        switch (this.messageType) {
            case MessageType.Binary:
                this.privSize = this.binaryBody !== null ? this.binaryBody.byteLength : 0;
                break;
            case MessageType.Text:
                this.privSize = this.textBody.length;
        }
    }
    get messageType() {
        return this.privMessageType;
    }
    get headers() {
        return this.privHeaders;
    }
    get body() {
        return this.privBody;
    }
    get textBody() {
        if (this.privMessageType === MessageType.Binary) {
            throw new Error_js_1.InvalidOperationError("Not supported for binary message");
        }
        return this.privBody;
    }
    get binaryBody() {
        if (this.privMessageType === MessageType.Text) {
            throw new Error_js_1.InvalidOperationError("Not supported for text message");
        }
        return this.privBody;
    }
    get id() {
        return this.privId;
    }
}
exports.ConnectionMessage = ConnectionMessage;

//# sourceMappingURL=ConnectionMessage.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionOpenResponse.js"
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionOpenResponse.js ***!
  \**************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConnectionOpenResponse = void 0;
class ConnectionOpenResponse {
    constructor(statusCode, reason) {
        this.privStatusCode = statusCode;
        this.privReason = reason;
    }
    get statusCode() {
        return this.privStatusCode;
    }
    get reason() {
        return this.privReason;
    }
}
exports.ConnectionOpenResponse = ConnectionOpenResponse;

//# sourceMappingURL=ConnectionOpenResponse.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DeferralMap.js"
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DeferralMap.js ***!
  \***************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DeferralMap = void 0;
/**
 * The error that is thrown when an argument passed in is null.
 *
 * @export
 * @class DefferalMap
 */
class DeferralMap {
    constructor() {
        this.privMap = {};
    }
    add(id, deferral) {
        this.privMap[id] = deferral;
    }
    getId(id) {
        return this.privMap[id];
    }
    complete(id, result) {
        try {
            this.privMap[id].resolve(result);
        }
        catch (error) {
            this.privMap[id].reject(error);
        }
        finally {
            this.privMap[id] = undefined;
        }
    }
}
exports.DeferralMap = DeferralMap;

//# sourceMappingURL=DeferralMap.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DialogEvents.js"
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DialogEvents.js ***!
  \****************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SendingAgentContextMessageEvent = exports.DialogEvent = void 0;
const PlatformEvent_js_1 = __webpack_require__(/*! ./PlatformEvent.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js");
class DialogEvent extends PlatformEvent_js_1.PlatformEvent {
    constructor(eventName, eventType = PlatformEvent_js_1.EventType.Info) {
        super(eventName, eventType);
    }
}
exports.DialogEvent = DialogEvent;
class SendingAgentContextMessageEvent extends DialogEvent {
    constructor(agentConfig) {
        super("SendingAgentContextMessageEvent");
        this.privAgentConfig = agentConfig;
    }
    get agentConfig() {
        return this.privAgentConfig;
    }
}
exports.SendingAgentContextMessageEvent = SendingAgentContextMessageEvent;

//# sourceMappingURL=DialogEvents.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js"
/*!*********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js ***!
  \*********************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ObjectDisposedError = exports.InvalidOperationError = exports.ArgumentNullError = void 0;
/* eslint-disable max-classes-per-file */
/**
 * The error that is thrown when an argument passed in is null.
 *
 * @export
 * @class ArgumentNullError
 * @extends {Error}
 */
class ArgumentNullError extends Error {
    /**
     * Creates an instance of ArgumentNullError.
     *
     * @param {string} argumentName - Name of the argument that is null
     *
     * @memberOf ArgumentNullError
     */
    constructor(argumentName) {
        super(argumentName);
        this.name = "ArgumentNull";
        this.message = argumentName;
    }
}
exports.ArgumentNullError = ArgumentNullError;
/**
 * The error that is thrown when an invalid operation is performed in the code.
 *
 * @export
 * @class InvalidOperationError
 * @extends {Error}
 */
class InvalidOperationError extends Error {
    /**
     * Creates an instance of InvalidOperationError.
     *
     * @param {string} error - The error
     *
     * @memberOf InvalidOperationError
     */
    constructor(error) {
        super(error);
        this.name = "InvalidOperation";
        this.message = error;
    }
}
exports.InvalidOperationError = InvalidOperationError;
/**
 * The error that is thrown when an object is disposed.
 *
 * @export
 * @class ObjectDisposedError
 * @extends {Error}
 */
class ObjectDisposedError extends Error {
    /**
     * Creates an instance of ObjectDisposedError.
     *
     * @param {string} objectName - The object that is disposed
     * @param {string} error - The error
     *
     * @memberOf ObjectDisposedError
     */
    constructor(objectName, error) {
        super(error);
        this.name = objectName + "ObjectDisposed";
        this.message = error;
    }
}
exports.ObjectDisposedError = ObjectDisposedError;

//# sourceMappingURL=Error.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/EventSource.js"
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/EventSource.js ***!
  \***************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.EventSource = void 0;
const Error_js_1 = __webpack_require__(/*! ./Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js");
const Guid_js_1 = __webpack_require__(/*! ./Guid.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js");
class EventSource {
    constructor(metadata) {
        this.privEventListeners = {};
        this.privIsDisposed = false;
        this.privConsoleListener = undefined;
        this.privMetadata = metadata;
    }
    onEvent(event) {
        if (this.isDisposed()) {
            throw (new Error_js_1.ObjectDisposedError("EventSource"));
        }
        if (this.metadata) {
            for (const paramName in this.metadata) {
                if (paramName) {
                    if (event.metadata) {
                        if (!event.metadata[paramName]) {
                            event.metadata[paramName] = this.metadata[paramName];
                        }
                    }
                }
            }
        }
        for (const eventId in this.privEventListeners) {
            if (eventId && this.privEventListeners[eventId]) {
                this.privEventListeners[eventId](event);
            }
        }
    }
    attach(onEventCallback) {
        const id = (0, Guid_js_1.createNoDashGuid)();
        this.privEventListeners[id] = onEventCallback;
        return {
            detach: () => {
                delete this.privEventListeners[id];
                return Promise.resolve();
            },
        };
    }
    attachListener(listener) {
        return this.attach((e) => listener.onEvent(e));
    }
    attachConsoleListener(listener) {
        if (!!this.privConsoleListener) {
            void this.privConsoleListener.detach(); // Detach implementation for eventListeners is synchronous
        }
        this.privConsoleListener = this.attach((e) => listener.onEvent(e));
        return this.privConsoleListener;
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    dispose() {
        this.privEventListeners = null;
        this.privIsDisposed = true;
    }
    get metadata() {
        return this.privMetadata;
    }
}
exports.EventSource = EventSource;

//# sourceMappingURL=EventSource.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Events.js"
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Events.js ***!
  \**********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Events = void 0;
const Error_js_1 = __webpack_require__(/*! ./Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js");
const EventSource_js_1 = __webpack_require__(/*! ./EventSource.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/EventSource.js");
class Events {
    static setEventSource(eventSource) {
        if (!eventSource) {
            throw new Error_js_1.ArgumentNullError("eventSource");
        }
        Events.privInstance = eventSource;
    }
    static get instance() {
        return Events.privInstance;
    }
}
exports.Events = Events;
Events.privInstance = new EventSource_js_1.EventSource();

//# sourceMappingURL=Events.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js"
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js ***!
  \***********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __exportStar = (this && this.__exportStar) || function(m, exports) {
    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationStatus = void 0;
__exportStar(__webpack_require__(/*! ./AudioSourceEvents.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/AudioSourceEvents.js"), exports);
__exportStar(__webpack_require__(/*! ./ConnectionEvents.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionEvents.js"), exports);
__exportStar(__webpack_require__(/*! ./ConnectionMessage.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionMessage.js"), exports);
__exportStar(__webpack_require__(/*! ./ConnectionOpenResponse.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionOpenResponse.js"), exports);
__exportStar(__webpack_require__(/*! ./DeferralMap.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DeferralMap.js"), exports);
__exportStar(__webpack_require__(/*! ./DialogEvents.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/DialogEvents.js"), exports);
__exportStar(__webpack_require__(/*! ./Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js"), exports);
__exportStar(__webpack_require__(/*! ./Events.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Events.js"), exports);
__exportStar(__webpack_require__(/*! ./EventSource.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/EventSource.js"), exports);
__exportStar(__webpack_require__(/*! ./Guid.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js"), exports);
__exportStar(__webpack_require__(/*! ./IAudioSource.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioSource.js"), exports);
__exportStar(__webpack_require__(/*! ./IConnection.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IConnection.js"), exports);
__exportStar(__webpack_require__(/*! ./IDetachable.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDetachable.js"), exports);
__exportStar(__webpack_require__(/*! ./IDictionary.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDictionary.js"), exports);
__exportStar(__webpack_require__(/*! ./IDisposable.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDisposable.js"), exports);
__exportStar(__webpack_require__(/*! ./IEventListener.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventListener.js"), exports);
__exportStar(__webpack_require__(/*! ./IEventSource.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventSource.js"), exports);
__exportStar(__webpack_require__(/*! ./IErrorMessages.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IErrorMessages.js"), exports);
__exportStar(__webpack_require__(/*! ./ITimer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ITimer.js"), exports);
__exportStar(__webpack_require__(/*! ./IWebsocketMessageFormatter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IWebsocketMessageFormatter.js"), exports);
__exportStar(__webpack_require__(/*! ./List.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/List.js"), exports);
__exportStar(__webpack_require__(/*! ./PlatformEvent.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js"), exports);
__exportStar(__webpack_require__(/*! ./Promise.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Promise.js"), exports);
__exportStar(__webpack_require__(/*! ./Queue.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Queue.js"), exports);
__exportStar(__webpack_require__(/*! ./RawWebsocketMessage.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RawWebsocketMessage.js"), exports);
__exportStar(__webpack_require__(/*! ./RiffPcmEncoder.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RiffPcmEncoder.js"), exports);
__exportStar(__webpack_require__(/*! ./Stream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Stream.js"), exports);
var TranslationStatus_js_1 = __webpack_require__(/*! ../common.speech/TranslationStatus.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/TranslationStatus.js");
Object.defineProperty(exports, "TranslationStatus", ({ enumerable: true, get: function () { return TranslationStatus_js_1.TranslationStatus; } }));
__exportStar(__webpack_require__(/*! ./ChunkedArrayBufferStream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ChunkedArrayBufferStream.js"), exports);
__exportStar(__webpack_require__(/*! ./IAudioDestination.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioDestination.js"), exports);
__exportStar(__webpack_require__(/*! ./Timeout.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Timeout.js"), exports);
__exportStar(__webpack_require__(/*! ./OCSPEvents.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/OCSPEvents.js"), exports);
__exportStar(__webpack_require__(/*! ./BackgroundError.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/BackgroundError.js"), exports);

//# sourceMappingURL=Exports.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js"
/*!********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js ***!
  \********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.createNoDashGuid = exports.createGuid = void 0;
const uuid_1 = __webpack_require__(/*! uuid */ "./node_modules/uuid/dist/commonjs-browser/index.js");
const createGuid = () => (0, uuid_1.v4)();
exports.createGuid = createGuid;
const createNoDashGuid = () => createGuid().replace(new RegExp("-", "g"), "").toUpperCase();
exports.createNoDashGuid = createNoDashGuid;

//# sourceMappingURL=Guid.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioDestination.js"
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioDestination.js ***!
  \*********************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IAudioDestination.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioSource.js"
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IAudioSource.js ***!
  \****************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IAudioSource.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IConnection.js"
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IConnection.js ***!
  \***************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConnectionState = void 0;
var ConnectionState;
(function (ConnectionState) {
    ConnectionState[ConnectionState["None"] = 0] = "None";
    ConnectionState[ConnectionState["Connected"] = 1] = "Connected";
    ConnectionState[ConnectionState["Connecting"] = 2] = "Connecting";
    ConnectionState[ConnectionState["Disconnected"] = 3] = "Disconnected";
})(ConnectionState = exports.ConnectionState || (exports.ConnectionState = {}));

//# sourceMappingURL=IConnection.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDetachable.js"
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDetachable.js ***!
  \***************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IDetachable.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDictionary.js"
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDictionary.js ***!
  \***************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IDictionary.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDisposable.js"
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IDisposable.js ***!
  \***************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IDisposable.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IErrorMessages.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IErrorMessages.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IErrorMessages.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventListener.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventListener.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IEventListener.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventSource.js"
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IEventSource.js ***!
  \****************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IEventSource.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ITimer.js"
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ITimer.js ***!
  \**********************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=ITimer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IWebsocketMessageFormatter.js"
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/IWebsocketMessageFormatter.js ***!
  \******************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));

//# sourceMappingURL=IWebsocketMessageFormatter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/List.js"
/*!********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/List.js ***!
  \********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.List = void 0;
const Error_js_1 = __webpack_require__(/*! ./Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js");
class List {
    constructor(list) {
        this.privSubscriptionIdCounter = 0;
        this.privAddSubscriptions = {};
        this.privRemoveSubscriptions = {};
        this.privDisposedSubscriptions = {};
        this.privDisposeReason = null;
        this.privList = [];
        // copy the list rather than taking as is.
        if (list) {
            for (const item of list) {
                this.privList.push(item);
            }
        }
    }
    get(itemIndex) {
        this.throwIfDisposed();
        return this.privList[itemIndex];
    }
    first() {
        return this.get(0);
    }
    last() {
        return this.get(this.length() - 1);
    }
    add(item) {
        this.throwIfDisposed();
        this.insertAt(this.privList.length, item);
    }
    insertAt(index, item) {
        this.throwIfDisposed();
        if (index === 0) {
            this.privList.unshift(item);
        }
        else if (index === this.privList.length) {
            this.privList.push(item);
        }
        else {
            this.privList.splice(index, 0, item);
        }
        this.triggerSubscriptions(this.privAddSubscriptions);
    }
    removeFirst() {
        this.throwIfDisposed();
        return this.removeAt(0);
    }
    removeLast() {
        this.throwIfDisposed();
        return this.removeAt(this.length() - 1);
    }
    removeAt(index) {
        this.throwIfDisposed();
        return this.remove(index, 1)[0];
    }
    remove(index, count) {
        this.throwIfDisposed();
        const removedElements = this.privList.splice(index, count);
        this.triggerSubscriptions(this.privRemoveSubscriptions);
        return removedElements;
    }
    clear() {
        this.throwIfDisposed();
        this.remove(0, this.length());
    }
    length() {
        this.throwIfDisposed();
        return this.privList.length;
    }
    onAdded(addedCallback) {
        this.throwIfDisposed();
        const subscriptionId = this.privSubscriptionIdCounter++;
        this.privAddSubscriptions[subscriptionId] = addedCallback;
        return {
            detach: () => {
                delete this.privAddSubscriptions[subscriptionId];
                return Promise.resolve();
            },
        };
    }
    onRemoved(removedCallback) {
        this.throwIfDisposed();
        const subscriptionId = this.privSubscriptionIdCounter++;
        this.privRemoveSubscriptions[subscriptionId] = removedCallback;
        return {
            detach: () => {
                delete this.privRemoveSubscriptions[subscriptionId];
                return Promise.resolve();
            },
        };
    }
    onDisposed(disposedCallback) {
        this.throwIfDisposed();
        const subscriptionId = this.privSubscriptionIdCounter++;
        this.privDisposedSubscriptions[subscriptionId] = disposedCallback;
        return {
            detach: () => {
                delete this.privDisposedSubscriptions[subscriptionId];
                return Promise.resolve();
            },
        };
    }
    join(seperator) {
        this.throwIfDisposed();
        return this.privList.join(seperator);
    }
    toArray() {
        const cloneCopy = Array();
        this.privList.forEach((val) => {
            cloneCopy.push(val);
        });
        return cloneCopy;
    }
    any(callback) {
        this.throwIfDisposed();
        if (callback) {
            return this.where(callback).length() > 0;
        }
        else {
            return this.length() > 0;
        }
    }
    all(callback) {
        this.throwIfDisposed();
        return this.where(callback).length() === this.length();
    }
    forEach(callback) {
        this.throwIfDisposed();
        for (let i = 0; i < this.length(); i++) {
            callback(this.privList[i], i);
        }
    }
    select(callback) {
        this.throwIfDisposed();
        const selectList = [];
        for (let i = 0; i < this.privList.length; i++) {
            selectList.push(callback(this.privList[i], i));
        }
        return new List(selectList);
    }
    where(callback) {
        this.throwIfDisposed();
        const filteredList = new List();
        for (let i = 0; i < this.privList.length; i++) {
            if (callback(this.privList[i], i)) {
                filteredList.add(this.privList[i]);
            }
        }
        return filteredList;
    }
    orderBy(compareFn) {
        this.throwIfDisposed();
        const clonedArray = this.toArray();
        const orderedArray = clonedArray.sort(compareFn);
        return new List(orderedArray);
    }
    orderByDesc(compareFn) {
        this.throwIfDisposed();
        return this.orderBy((a, b) => compareFn(b, a));
    }
    clone() {
        this.throwIfDisposed();
        return new List(this.toArray());
    }
    concat(list) {
        this.throwIfDisposed();
        return new List(this.privList.concat(list.toArray()));
    }
    concatArray(array) {
        this.throwIfDisposed();
        return new List(this.privList.concat(array));
    }
    isDisposed() {
        return this.privList == null;
    }
    dispose(reason) {
        if (!this.isDisposed()) {
            this.privDisposeReason = reason;
            this.privList = null;
            this.privAddSubscriptions = null;
            this.privRemoveSubscriptions = null;
            this.triggerSubscriptions(this.privDisposedSubscriptions);
        }
    }
    throwIfDisposed() {
        if (this.isDisposed()) {
            throw new Error_js_1.ObjectDisposedError("List", this.privDisposeReason);
        }
    }
    triggerSubscriptions(subscriptions) {
        if (subscriptions) {
            for (const subscriptionId in subscriptions) {
                if (subscriptionId) {
                    subscriptions[subscriptionId]();
                }
            }
        }
    }
}
exports.List = List;

//# sourceMappingURL=List.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/OCSPEvents.js"
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/OCSPEvents.js ***!
  \**************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.OCSPCacheUpdateErrorEvent = exports.OCSPResponseRetrievedEvent = exports.OCSPCacheFetchErrorEvent = exports.OCSPVerificationFailedEvent = exports.OCSPCacheHitEvent = exports.OCSPCacheEntryNeedsRefreshEvent = exports.OCSPCacheEntryExpiredEvent = exports.OCSPWSUpgradeStartedEvent = exports.OCSPStapleReceivedEvent = exports.OCSPCacheUpdateCompleteEvent = exports.OCSPDiskCacheStoreEvent = exports.OCSPMemoryCacheStoreEvent = exports.OCSPCacheUpdateNeededEvent = exports.OCSPDiskCacheHitEvent = exports.OCSPCacheMissEvent = exports.OCSPMemoryCacheHitEvent = exports.OCSPEvent = void 0;
/* eslint-disable max-classes-per-file */
const PlatformEvent_js_1 = __webpack_require__(/*! ./PlatformEvent.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js");
class OCSPEvent extends PlatformEvent_js_1.PlatformEvent {
    constructor(eventName, eventType, signature) {
        super(eventName, eventType);
        this.privSignature = signature;
    }
}
exports.OCSPEvent = OCSPEvent;
class OCSPMemoryCacheHitEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPMemoryCacheHitEvent", PlatformEvent_js_1.EventType.Debug, signature);
    }
}
exports.OCSPMemoryCacheHitEvent = OCSPMemoryCacheHitEvent;
class OCSPCacheMissEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPCacheMissEvent", PlatformEvent_js_1.EventType.Debug, signature);
    }
}
exports.OCSPCacheMissEvent = OCSPCacheMissEvent;
class OCSPDiskCacheHitEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPDiskCacheHitEvent", PlatformEvent_js_1.EventType.Debug, signature);
    }
}
exports.OCSPDiskCacheHitEvent = OCSPDiskCacheHitEvent;
class OCSPCacheUpdateNeededEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPCacheUpdateNeededEvent", PlatformEvent_js_1.EventType.Debug, signature);
    }
}
exports.OCSPCacheUpdateNeededEvent = OCSPCacheUpdateNeededEvent;
class OCSPMemoryCacheStoreEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPMemoryCacheStoreEvent", PlatformEvent_js_1.EventType.Debug, signature);
    }
}
exports.OCSPMemoryCacheStoreEvent = OCSPMemoryCacheStoreEvent;
class OCSPDiskCacheStoreEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPDiskCacheStoreEvent", PlatformEvent_js_1.EventType.Debug, signature);
    }
}
exports.OCSPDiskCacheStoreEvent = OCSPDiskCacheStoreEvent;
class OCSPCacheUpdateCompleteEvent extends OCSPEvent {
    constructor(signature) {
        super("OCSPCacheUpdateCompleteEvent", PlatformEvent_js_1.EventType.Debug, signature);
    }
}
exports.OCSPCacheUpdateCompleteEvent = OCSPCacheUpdateCompleteEvent;
class OCSPStapleReceivedEvent extends OCSPEvent {
    constructor() {
        super("OCSPStapleReceivedEvent", PlatformEvent_js_1.EventType.Debug, "");
    }
}
exports.OCSPStapleReceivedEvent = OCSPStapleReceivedEvent;
class OCSPWSUpgradeStartedEvent extends OCSPEvent {
    constructor(serialNumber) {
        super("OCSPWSUpgradeStartedEvent", PlatformEvent_js_1.EventType.Debug, serialNumber);
    }
}
exports.OCSPWSUpgradeStartedEvent = OCSPWSUpgradeStartedEvent;
class OCSPCacheEntryExpiredEvent extends OCSPEvent {
    constructor(serialNumber, expireTime) {
        super("OCSPCacheEntryExpiredEvent", PlatformEvent_js_1.EventType.Debug, serialNumber);
        this.privExpireTime = expireTime;
    }
}
exports.OCSPCacheEntryExpiredEvent = OCSPCacheEntryExpiredEvent;
class OCSPCacheEntryNeedsRefreshEvent extends OCSPEvent {
    constructor(serialNumber, startTime, expireTime) {
        super("OCSPCacheEntryNeedsRefreshEvent", PlatformEvent_js_1.EventType.Debug, serialNumber);
        this.privExpireTime = expireTime;
        this.privStartTime = startTime;
    }
}
exports.OCSPCacheEntryNeedsRefreshEvent = OCSPCacheEntryNeedsRefreshEvent;
class OCSPCacheHitEvent extends OCSPEvent {
    constructor(serialNumber, startTime, expireTime) {
        super("OCSPCacheHitEvent", PlatformEvent_js_1.EventType.Debug, serialNumber);
        this.privExpireTime = expireTime;
        this.privExpireTimeString = new Date(expireTime).toLocaleDateString();
        this.privStartTime = startTime;
        this.privStartTimeString = new Date(startTime).toLocaleTimeString();
    }
}
exports.OCSPCacheHitEvent = OCSPCacheHitEvent;
class OCSPVerificationFailedEvent extends OCSPEvent {
    constructor(serialNumber, error) {
        super("OCSPVerificationFailedEvent", PlatformEvent_js_1.EventType.Debug, serialNumber);
        this.privError = error;
    }
}
exports.OCSPVerificationFailedEvent = OCSPVerificationFailedEvent;
class OCSPCacheFetchErrorEvent extends OCSPEvent {
    constructor(serialNumber, error) {
        super("OCSPCacheFetchErrorEvent", PlatformEvent_js_1.EventType.Debug, serialNumber);
        this.privError = error;
    }
}
exports.OCSPCacheFetchErrorEvent = OCSPCacheFetchErrorEvent;
class OCSPResponseRetrievedEvent extends OCSPEvent {
    constructor(serialNumber) {
        super("OCSPResponseRetrievedEvent", PlatformEvent_js_1.EventType.Debug, serialNumber);
    }
}
exports.OCSPResponseRetrievedEvent = OCSPResponseRetrievedEvent;
class OCSPCacheUpdateErrorEvent extends OCSPEvent {
    constructor(serialNumber, error) {
        super("OCSPCacheUpdateErrorEvent", PlatformEvent_js_1.EventType.Debug, serialNumber);
        this.privError = error;
    }
}
exports.OCSPCacheUpdateErrorEvent = OCSPCacheUpdateErrorEvent;

//# sourceMappingURL=OCSPEvents.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js"
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/PlatformEvent.js ***!
  \*****************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PlatformEvent = exports.EventType = void 0;
const Guid_js_1 = __webpack_require__(/*! ./Guid.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js");
var EventType;
(function (EventType) {
    EventType[EventType["Debug"] = 0] = "Debug";
    EventType[EventType["Info"] = 1] = "Info";
    EventType[EventType["Warning"] = 2] = "Warning";
    EventType[EventType["Error"] = 3] = "Error";
    EventType[EventType["None"] = 4] = "None";
})(EventType = exports.EventType || (exports.EventType = {}));
class PlatformEvent {
    constructor(eventName, eventType) {
        this.privName = eventName;
        this.privEventId = (0, Guid_js_1.createNoDashGuid)();
        this.privEventTime = new Date().toISOString();
        this.privEventType = eventType;
        this.privMetadata = {};
    }
    get name() {
        return this.privName;
    }
    get eventId() {
        return this.privEventId;
    }
    get eventTime() {
        return this.privEventTime;
    }
    get eventType() {
        return this.privEventType;
    }
    get metadata() {
        return this.privMetadata;
    }
}
exports.PlatformEvent = PlatformEvent;

//# sourceMappingURL=PlatformEvent.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Promise.js"
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Promise.js ***!
  \***********************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.marshalPromiseToCallbacks = exports.Sink = exports.Deferred = exports.PromiseResultEventSource = exports.PromiseResult = exports.PromiseState = void 0;
/* eslint-disable max-classes-per-file, @typescript-eslint/typedef */
var PromiseState;
(function (PromiseState) {
    PromiseState[PromiseState["None"] = 0] = "None";
    PromiseState[PromiseState["Resolved"] = 1] = "Resolved";
    PromiseState[PromiseState["Rejected"] = 2] = "Rejected";
})(PromiseState = exports.PromiseState || (exports.PromiseState = {}));
class PromiseResult {
    constructor(promiseResultEventSource) {
        this.throwIfError = () => {
            if (this.isError) {
                throw this.error;
            }
        };
        promiseResultEventSource.on((result) => {
            if (!this.privIsCompleted) {
                this.privIsCompleted = true;
                this.privIsError = false;
                this.privResult = result;
            }
        }, (error) => {
            if (!this.privIsCompleted) {
                this.privIsCompleted = true;
                this.privIsError = true;
                this.privError = error;
            }
        });
    }
    get isCompleted() {
        return this.privIsCompleted;
    }
    get isError() {
        return this.privIsError;
    }
    get error() {
        return this.privError;
    }
    get result() {
        return this.privResult;
    }
}
exports.PromiseResult = PromiseResult;
class PromiseResultEventSource {
    constructor() {
        this.setResult = (result) => {
            this.privOnSetResult(result);
        };
        this.setError = (error) => {
            this.privOnSetError(error);
        };
        this.on = (onSetResult, onSetError) => {
            this.privOnSetResult = onSetResult;
            this.privOnSetError = onSetError;
        };
    }
}
exports.PromiseResultEventSource = PromiseResultEventSource;
class Deferred {
    constructor() {
        this.resolve = (result) => {
            this.privResolve(result);
            return this;
        };
        this.reject = (error) => {
            this.privReject(error);
            return this;
        };
        // eslint-disable-next-line @typescript-eslint/explicit-function-return-type
        this.privPromise = new Promise((resolve, reject) => {
            this.privResolve = resolve;
            this.privReject = reject;
        });
    }
    get promise() {
        return this.privPromise;
    }
}
exports.Deferred = Deferred;
class Sink {
    constructor() {
        this.privState = PromiseState.None;
        this.privPromiseResult = null;
        this.privPromiseResultEvents = null;
        this.privSuccessHandlers = [];
        this.privErrorHandlers = [];
        this.privPromiseResultEvents = new PromiseResultEventSource();
        this.privPromiseResult = new PromiseResult(this.privPromiseResultEvents);
    }
    get state() {
        return this.privState;
    }
    get result() {
        return this.privPromiseResult;
    }
    resolve(result) {
        if (this.privState !== PromiseState.None) {
            throw new Error("'Cannot resolve a completed promise'");
        }
        this.privState = PromiseState.Resolved;
        this.privPromiseResultEvents.setResult(result);
        for (let i = 0; i < this.privSuccessHandlers.length; i++) {
            this.executeSuccessCallback(result, this.privSuccessHandlers[i], this.privErrorHandlers[i]);
        }
        this.detachHandlers();
    }
    reject(error) {
        if (this.privState !== PromiseState.None) {
            throw new Error("'Cannot reject a completed promise'");
        }
        this.privState = PromiseState.Rejected;
        this.privPromiseResultEvents.setError(error);
        for (const errorHandler of this.privErrorHandlers) {
            this.executeErrorCallback(error, errorHandler);
        }
        this.detachHandlers();
    }
    on(successCallback, errorCallback) {
        if (successCallback == null) {
            // eslint-disable-next-line @typescript-eslint/no-empty-function
            successCallback = () => { };
        }
        if (this.privState === PromiseState.None) {
            this.privSuccessHandlers.push(successCallback);
            this.privErrorHandlers.push(errorCallback);
        }
        else {
            if (this.privState === PromiseState.Resolved) {
                this.executeSuccessCallback(this.privPromiseResult.result, successCallback, errorCallback);
            }
            else if (this.privState === PromiseState.Rejected) {
                this.executeErrorCallback(this.privPromiseResult.error, errorCallback);
            }
            this.detachHandlers();
        }
    }
    executeSuccessCallback(result, successCallback, errorCallback) {
        try {
            successCallback(result);
        }
        catch (e) {
            this.executeErrorCallback(`'Unhandled callback error: ${e}'`, errorCallback);
        }
    }
    executeErrorCallback(error, errorCallback) {
        if (errorCallback) {
            try {
                errorCallback(error);
            }
            catch (e) {
                throw new Error(`'Unhandled callback error: ${e}. InnerError: ${error}'`);
            }
        }
        else {
            throw new Error(`'Unhandled error: ${error}'`);
        }
    }
    detachHandlers() {
        this.privErrorHandlers = [];
        this.privSuccessHandlers = [];
    }
}
exports.Sink = Sink;
// eslint-disable-next-line prefer-arrow/prefer-arrow-functions
function marshalPromiseToCallbacks(promise, cb, err) {
    promise.then((val) => {
        try {
            if (!!cb) {
                cb(val);
            }
        }
        catch (error) {
            if (!!err) {
                try {
                    if (error instanceof Error) {
                        const typedError = error;
                        err(typedError.name + ": " + typedError.message);
                    }
                    else {
                        err(error);
                    }
                    // eslint-disable-next-line no-empty
                }
                catch (error) { }
            }
        }
    }, (error) => {
        if (!!err) {
            try {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
                // eslint-disable-next-line no-empty
            }
            catch (error) { }
        }
    });
}
exports.marshalPromiseToCallbacks = marshalPromiseToCallbacks;

//# sourceMappingURL=Promise.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Queue.js"
/*!*********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Queue.js ***!
  \*********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Queue = void 0;
const Error_js_1 = __webpack_require__(/*! ./Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js");
const List_js_1 = __webpack_require__(/*! ./List.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/List.js");
const Promise_js_1 = __webpack_require__(/*! ./Promise.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Promise.js");
var SubscriberType;
(function (SubscriberType) {
    SubscriberType[SubscriberType["Dequeue"] = 0] = "Dequeue";
    SubscriberType[SubscriberType["Peek"] = 1] = "Peek";
})(SubscriberType || (SubscriberType = {}));
class Queue {
    constructor(list) {
        this.privPromiseStore = new List_js_1.List();
        this.privIsDrainInProgress = false;
        this.privIsDisposing = false;
        this.privDisposeReason = null;
        this.privList = list ? list : new List_js_1.List();
        this.privDetachables = [];
        this.privSubscribers = new List_js_1.List();
        this.privDetachables.push(this.privList.onAdded(() => this.drain()));
    }
    enqueue(item) {
        this.throwIfDispose();
        this.enqueueFromPromise(new Promise((resolve) => resolve(item)));
    }
    enqueueFromPromise(promise) {
        this.throwIfDispose();
        promise.then((val) => {
            this.privList.add(val);
            // eslint-disable-next-line @typescript-eslint/no-empty-function
        }, () => { });
    }
    dequeue() {
        this.throwIfDispose();
        const deferredSubscriber = new Promise_js_1.Deferred();
        if (this.privSubscribers) {
            this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Dequeue });
            this.drain();
        }
        return deferredSubscriber.promise;
    }
    peek() {
        this.throwIfDispose();
        const deferredSubscriber = new Promise_js_1.Deferred();
        const subs = this.privSubscribers;
        if (subs) {
            this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Peek });
            this.drain();
        }
        return deferredSubscriber.promise;
    }
    length() {
        this.throwIfDispose();
        return this.privList.length();
    }
    isDisposed() {
        return this.privSubscribers == null;
    }
    async drainAndDispose(pendingItemProcessor, reason) {
        if (!this.isDisposed() && !this.privIsDisposing) {
            this.privDisposeReason = reason;
            this.privIsDisposing = true;
            const subs = this.privSubscribers;
            if (subs) {
                while (subs.length() > 0) {
                    const subscriber = subs.removeFirst();
                    // TODO: this needs work (Resolve(null) instead?).
                    subscriber.deferral.resolve(undefined);
                    // subscriber.deferral.reject("Disposed");
                }
                // note: this block assumes cooperative multitasking, i.e.,
                // between the if-statement and the assignment there are no
                // thread switches.
                // Reason is that between the initial const = this.; and this
                // point there is the derral.resolve() operation that might have
                // caused recursive calls to the Queue, especially, calling
                // Dispose() on the queue alredy (which would reset the var
                // here to null!).
                // That should generally hold true for javascript...
                if (this.privSubscribers === subs) {
                    this.privSubscribers = subs;
                }
            }
            for (const detachable of this.privDetachables) {
                await detachable.detach();
            }
            if (this.privPromiseStore.length() > 0 && pendingItemProcessor) {
                const promiseArray = [];
                this.privPromiseStore.toArray().forEach((wrapper) => {
                    promiseArray.push(wrapper);
                });
                return Promise.all(promiseArray).finally(() => {
                    this.privSubscribers = null;
                    this.privList.forEach((item) => {
                        pendingItemProcessor(item);
                    });
                    this.privList = null;
                    return;
                }).then();
            }
            else {
                this.privSubscribers = null;
                this.privList = null;
            }
        }
    }
    async dispose(reason) {
        await this.drainAndDispose(null, reason);
    }
    drain() {
        if (!this.privIsDrainInProgress && !this.privIsDisposing) {
            this.privIsDrainInProgress = true;
            const subs = this.privSubscribers;
            const lists = this.privList;
            if (subs && lists) {
                while (lists.length() > 0 && subs.length() > 0 && !this.privIsDisposing) {
                    const subscriber = subs.removeFirst();
                    if (subscriber.type === SubscriberType.Peek) {
                        subscriber.deferral.resolve(lists.first());
                    }
                    else {
                        const dequeuedItem = lists.removeFirst();
                        subscriber.deferral.resolve(dequeuedItem);
                    }
                }
                // note: this block assumes cooperative multitasking, i.e.,
                // between the if-statement and the assignment there are no
                // thread switches.
                // Reason is that between the initial const = this.; and this
                // point there is the derral.resolve() operation that might have
                // caused recursive calls to the Queue, especially, calling
                // Dispose() on the queue alredy (which would reset the var
                // here to null!).
                // That should generally hold true for javascript...
                if (this.privSubscribers === subs) {
                    this.privSubscribers = subs;
                }
                // note: this block assumes cooperative multitasking, i.e.,
                // between the if-statement and the assignment there are no
                // thread switches.
                // Reason is that between the initial const = this.; and this
                // point there is the derral.resolve() operation that might have
                // caused recursive calls to the Queue, especially, calling
                // Dispose() on the queue alredy (which would reset the var
                // here to null!).
                // That should generally hold true for javascript...
                if (this.privList === lists) {
                    this.privList = lists;
                }
            }
            this.privIsDrainInProgress = false;
        }
    }
    throwIfDispose() {
        if (this.isDisposed()) {
            if (this.privDisposeReason) {
                throw new Error_js_1.InvalidOperationError(this.privDisposeReason);
            }
            throw new Error_js_1.ObjectDisposedError("Queue");
        }
        else if (this.privIsDisposing) {
            throw new Error_js_1.InvalidOperationError("Queue disposing");
        }
    }
}
exports.Queue = Queue;

//# sourceMappingURL=Queue.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RawWebsocketMessage.js"
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RawWebsocketMessage.js ***!
  \***********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

/* eslint-disable @typescript-eslint/no-unsafe-assignment */
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RawWebsocketMessage = void 0;
const ConnectionMessage_js_1 = __webpack_require__(/*! ./ConnectionMessage.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/ConnectionMessage.js");
const Error_js_1 = __webpack_require__(/*! ./Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js");
const Guid_js_1 = __webpack_require__(/*! ./Guid.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js");
class RawWebsocketMessage {
    constructor(messageType, payload, id) {
        this.privPayload = null;
        if (!payload) {
            throw new Error_js_1.ArgumentNullError("payload");
        }
        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
        if (messageType === ConnectionMessage_js_1.MessageType.Binary && Object.getPrototypeOf(payload).constructor.name !== "ArrayBuffer") {
            throw new Error_js_1.InvalidOperationError("Payload must be ArrayBuffer");
        }
        if (messageType === ConnectionMessage_js_1.MessageType.Text && !(typeof (payload) === "string")) {
            throw new Error_js_1.InvalidOperationError("Payload must be a string");
        }
        this.privMessageType = messageType;
        this.privPayload = payload;
        this.privId = id ? id : (0, Guid_js_1.createNoDashGuid)();
    }
    get messageType() {
        return this.privMessageType;
    }
    get payload() {
        // eslint-disable-next-line @typescript-eslint/no-unsafe-return
        return this.privPayload;
    }
    get textContent() {
        if (this.privMessageType === ConnectionMessage_js_1.MessageType.Binary) {
            throw new Error_js_1.InvalidOperationError("Not supported for binary message");
        }
        return this.privPayload;
    }
    get binaryContent() {
        if (this.privMessageType === ConnectionMessage_js_1.MessageType.Text) {
            throw new Error_js_1.InvalidOperationError("Not supported for text message");
        }
        return this.privPayload;
    }
    get id() {
        return this.privId;
    }
}
exports.RawWebsocketMessage = RawWebsocketMessage;

//# sourceMappingURL=RawWebsocketMessage.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RiffPcmEncoder.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/RiffPcmEncoder.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RiffPcmEncoder = void 0;
class RiffPcmEncoder {
    constructor(actualSampleRate, desiredSampleRate) {
        this.privActualSampleRate = actualSampleRate;
        this.privDesiredSampleRate = desiredSampleRate;
    }
    encode(actualAudioFrame) {
        const audioFrame = this.downSampleAudioFrame(actualAudioFrame, this.privActualSampleRate, this.privDesiredSampleRate);
        if (!audioFrame) {
            return null;
        }
        const audioLength = audioFrame.length * 2;
        const buffer = new ArrayBuffer(audioLength);
        const view = new DataView(buffer);
        this.floatTo16BitPCM(view, 0, audioFrame);
        return buffer;
    }
    setString(view, offset, str) {
        for (let i = 0; i < str.length; i++) {
            view.setUint8(offset + i, str.charCodeAt(i));
        }
    }
    floatTo16BitPCM(view, offset, input) {
        for (let i = 0; i < input.length; i++, offset += 2) {
            const s = Math.max(-1, Math.min(1, input[i]));
            view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
        }
    }
    downSampleAudioFrame(srcFrame, srcRate, dstRate) {
        if (!srcFrame) {
            return null;
        }
        if (dstRate === srcRate || dstRate > srcRate) {
            return srcFrame;
        }
        const ratio = srcRate / dstRate;
        const dstLength = Math.round(srcFrame.length / ratio);
        const dstFrame = new Float32Array(dstLength);
        let srcOffset = 0;
        let dstOffset = 0;
        while (dstOffset < dstLength) {
            const nextSrcOffset = Math.round((dstOffset + 1) * ratio);
            let accum = 0;
            let count = 0;
            while (srcOffset < nextSrcOffset && srcOffset < srcFrame.length) {
                accum += srcFrame[srcOffset++];
                count++;
            }
            dstFrame[dstOffset++] = accum / count;
        }
        return dstFrame;
    }
}
exports.RiffPcmEncoder = RiffPcmEncoder;

//# sourceMappingURL=RiffPcmEncoder.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Stream.js"
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Stream.js ***!
  \**********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Stream = void 0;
const Error_js_1 = __webpack_require__(/*! ./Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js");
const Guid_js_1 = __webpack_require__(/*! ./Guid.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js");
const Queue_js_1 = __webpack_require__(/*! ./Queue.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Queue.js");
class Stream {
    constructor(streamId) {
        this.privIsWriteEnded = false;
        this.privIsReadEnded = false;
        this.privId = streamId ? streamId : (0, Guid_js_1.createNoDashGuid)();
        this.privReaderQueue = new Queue_js_1.Queue();
    }
    get isClosed() {
        return this.privIsWriteEnded;
    }
    get isReadEnded() {
        return this.privIsReadEnded;
    }
    get id() {
        return this.privId;
    }
    close() {
        if (!this.privIsWriteEnded) {
            this.writeStreamChunk({
                buffer: null,
                isEnd: true,
                timeReceived: Date.now(),
            });
            this.privIsWriteEnded = true;
        }
    }
    writeStreamChunk(streamChunk) {
        this.throwIfClosed();
        if (!this.privReaderQueue.isDisposed()) {
            try {
                this.privReaderQueue.enqueue(streamChunk);
            }
            catch (e) {
                // Do nothing
            }
        }
    }
    read() {
        if (this.privIsReadEnded) {
            throw new Error_js_1.InvalidOperationError("Stream read has already finished");
        }
        return this.privReaderQueue
            .dequeue()
            .then(async (streamChunk) => {
            if (streamChunk === undefined || streamChunk.isEnd) {
                await this.privReaderQueue.dispose("End of stream reached");
            }
            return streamChunk;
        });
    }
    readEnded() {
        if (!this.privIsReadEnded) {
            this.privIsReadEnded = true;
            this.privReaderQueue = new Queue_js_1.Queue();
        }
    }
    throwIfClosed() {
        if (this.privIsWriteEnded) {
            throw new Error_js_1.InvalidOperationError("Stream closed");
        }
    }
}
exports.Stream = Stream;

//# sourceMappingURL=Stream.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/StringUtils.js"
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/StringUtils.js ***!
  \***************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.StringUtils = void 0;
/**
 * String helper functions
 */
class StringUtils {
    /**
     * Formats a string by replacing the named {keys} in the string with the values contained in the replacement dictionary.
     * @param format The format string that contains the parts to replace surrounded by {}. For example: "wss://{region}.cts.speech.microsoft.com".
     * If your string needs to contain a { or } you can use the {{ and }} escape sequences respectively.
     * @param replacements The dictionary of replacements. If a replacement is not found, it is replaced with an empty string
     * @returns The formatted string. If you pass in a null or undefined format string, an empty string will be returned
     */
    static formatString(format, replacements) {
        if (!format) {
            return "";
        }
        if (!replacements) {
            return format;
        }
        let formatted = "";
        let key = "";
        const appendToFormatted = (str) => {
            formatted += str;
        };
        const appendToKey = (str) => {
            key += str;
        };
        let appendFunc = appendToFormatted;
        for (let i = 0; i < format.length; i++) {
            const c = format[i];
            const next = i + 1 < format.length ? format[i + 1] : "";
            switch (c) {
                case "{":
                    if (next === "{") {
                        appendFunc("{");
                        i++;
                    }
                    else {
                        appendFunc = appendToKey;
                    }
                    break;
                case "}":
                    if (next === "}") {
                        appendFunc("}");
                        i++;
                    }
                    else {
                        if (replacements.hasOwnProperty(key)) {
                            formatted += replacements[key];
                        }
                        appendFunc = appendToFormatted;
                        key = "";
                    }
                    break;
                default:
                    appendFunc(c);
                    break;
            }
        }
        return formatted;
    }
}
exports.StringUtils = StringUtils;

//# sourceMappingURL=StringUtils.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Timeout.js"
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Timeout.js ***!
  \***********************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Timeout = void 0;
class Timeout {
    static load() {
        // Prefilling the Maps with a function indexed by zero is necessary to be compliant with the specification.
        const scheduledTimeoutFunctions = new Map([[0, () => { }]]); // eslint-disable-line @typescript-eslint/no-empty-function
        const unhandledRequests = new Map();
        // eslint-disable-next-line
        const workerScript = `!function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,"a",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p="",n(n.s=14)}([function(e,t,n){"use strict";n.d(t,"a",(function(){return i})),n.d(t,"b",(function(){return u})),n.d(t,"c",(function(){return a})),n.d(t,"d",(function(){return d}));const r=new Map,o=new Map,i=e=>{const t=r.get(e);if(void 0===t)throw new Error('There is no interval scheduled with the given id "'.concat(e,'".'));clearTimeout(t),r.delete(e)},u=e=>{const t=o.get(e);if(void 0===t)throw new Error('There is no timeout scheduled with the given id "'.concat(e,'".'));clearTimeout(t),o.delete(e)},f=(e,t)=>{let n,r;if("performance"in self){const o=performance.now();n=o,r=e-Math.max(0,o-t)}else n=Date.now(),r=e;return{expected:n+r,remainingDelay:r}},c=(e,t,n,r)=>{const o="performance"in self?performance.now():Date.now();o>n?postMessage({id:null,method:"call",params:{timerId:t}}):e.set(t,setTimeout(c,n-o,e,t,n))},a=(e,t,n)=>{const{expected:o,remainingDelay:i}=f(e,n);r.set(t,setTimeout(c,i,r,t,o))},d=(e,t,n)=>{const{expected:r,remainingDelay:i}=f(e,n);o.set(t,setTimeout(c,i,o,t,r))}},function(e,t,n){"use strict";n.r(t);var r=n(2);for(var o in r)"default"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(3);for(var o in i)"default"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(4);for(var o in u)"default"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o);var f=n(5);for(var o in f)"default"!==o&&function(e){n.d(t,e,(function(){return f[e]}))}(o);var c=n(6);for(var o in c)"default"!==o&&function(e){n.d(t,e,(function(){return c[e]}))}(o);var a=n(7);for(var o in a)"default"!==o&&function(e){n.d(t,e,(function(){return a[e]}))}(o);var d=n(8);for(var o in d)"default"!==o&&function(e){n.d(t,e,(function(){return d[e]}))}(o);var s=n(9);for(var o in s)"default"!==o&&function(e){n.d(t,e,(function(){return s[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){"use strict";n.r(t);var r=n(11);for(var o in r)"default"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(12);for(var o in i)"default"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(13);for(var o in u)"default"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){"use strict";n.r(t);var r=n(0),o=n(1);for(var i in o)"default"!==i&&function(e){n.d(t,e,(function(){return o[e]}))}(i);var u=n(10);for(var i in u)"default"!==i&&function(e){n.d(t,e,(function(){return u[e]}))}(i);addEventListener("message",({data:e})=>{try{if("clear"===e.method){const{id:t,params:{timerId:n}}=e;Object(r.b)(n),postMessage({error:null,id:t})}else{if("set"!==e.method)throw new Error('The given method "'.concat(e.method,'" is not supported'));{const{params:{delay:t,now:n,timerId:o}}=e;Object(r.d)(t,o,n)}}}catch(t){postMessage({error:{message:t.message},id:e.id,result:null})}})}]);`;
        const workerUrl = "data:text/javascript;base64," + btoa(workerScript);
        const worker = new Worker(workerUrl);
        worker.addEventListener("message", ({ data }) => {
            if (Timeout.isCallNotification(data)) {
                const { params: { timerId } } = data;
                const idOrFunc = scheduledTimeoutFunctions.get(timerId);
                if (typeof idOrFunc === "number") {
                    const unhandledTimerId = unhandledRequests.get(idOrFunc);
                    if (unhandledTimerId === undefined ||
                        unhandledTimerId !== timerId) {
                        throw new Error("The timer is in an undefined state.");
                    }
                }
                else if (typeof idOrFunc !== "undefined") {
                    idOrFunc();
                    // A timeout can be safely deleted because it is only called once.
                    scheduledTimeoutFunctions.delete(timerId);
                }
                else {
                    throw new Error("The timer is in an undefined state.");
                }
            }
            else if (Timeout.isClearResponse(data)) {
                const { id } = data;
                const unhandledTimerId = unhandledRequests.get(id);
                if (unhandledTimerId === undefined) {
                    throw new Error("The timer is in an undefined state.");
                }
                unhandledRequests.delete(id);
                scheduledTimeoutFunctions.delete(unhandledTimerId);
            }
            else {
                const { error: { message } } = data;
                throw new Error(message);
            }
        });
        const clearTimeout = (timerId) => {
            const id = Math.random();
            unhandledRequests.set(id, timerId);
            scheduledTimeoutFunctions.set(timerId, id);
            worker.postMessage({
                id,
                method: "clear",
                params: { timerId }
            });
        };
        const setTimeout = (func, delay) => {
            const timerId = Math.random();
            scheduledTimeoutFunctions.set(timerId, func);
            worker.postMessage({
                id: null,
                method: "set",
                params: {
                    delay,
                    now: performance.now(),
                    timerId
                }
            });
            return timerId;
        };
        return {
            clearTimeout,
            setTimeout
        };
    }
    static loadWorkerTimers() {
        return () => {
            if (Timeout.workerTimers !== null) {
                return Timeout.workerTimers;
            }
            Timeout.workerTimers = Timeout.load();
            return Timeout.workerTimers;
        };
    }
    static isCallNotification(message) {
        return message.method !== undefined && message.method === "call";
    }
    static isClearResponse(message) {
        return message.error === null && typeof message.id === "number";
    }
}
exports.Timeout = Timeout;
Timeout.workerTimers = null;
Timeout.clearTimeout = (timerId) => Timeout.timers().clearTimeout(timerId);
Timeout.setTimeout = (func, delay) => Timeout.timers().setTimeout(func, delay);
Timeout.timers = Timeout.loadWorkerTimers();

//# sourceMappingURL=Timeout.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ActivityReceivedEventArgs.js"
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ActivityReceivedEventArgs.js ***!
  \**************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ActivityReceivedEventArgs = void 0;
/**
 * Defines contents of received message/events.
 * @class ActivityReceivedEventArgs
 */
class ActivityReceivedEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {any} activity - The activity..
     */
    constructor(activity, audioStream) {
        this.privActivity = activity;
        this.privAudioStream = audioStream;
    }
    /**
     * Gets the received activity
     * @member ActivityReceivedEventArgs.prototype.activity
     * @function
     * @public
     * @returns {any} the received activity.
     */
    get activity() {
        return this.privActivity;
    }
    get audioStream() {
        return this.privAudioStream;
    }
}
exports.ActivityReceivedEventArgs = ActivityReceivedEventArgs;

//# sourceMappingURL=ActivityReceivedEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AudioOutputConfigImpl = exports.AudioConfigImpl = exports.AudioConfig = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_2 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const AudioFileWriter_js_1 = __webpack_require__(/*! ./AudioFileWriter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioFileWriter.js");
const AudioInputStream_js_1 = __webpack_require__(/*! ./AudioInputStream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioInputStream.js");
const AudioOutputStream_js_1 = __webpack_require__(/*! ./AudioOutputStream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js");
/**
 * Represents audio input configuration used for specifying what type of input to use (microphone, file, stream).
 * @class AudioConfig
 * Updated in version 1.11.0
 */
class AudioConfig {
    /**
     * Creates an AudioConfig object representing the default microphone on the system.
     * @member AudioConfig.fromDefaultMicrophoneInput
     * @function
     * @public
     * @returns {AudioConfig} The audio input configuration being created.
     */
    static fromDefaultMicrophoneInput() {
        const pcmRecorder = new Exports_js_1.PcmRecorder(true);
        return new AudioConfigImpl(new Exports_js_1.MicAudioSource(pcmRecorder));
    }
    /**
     * Creates an AudioConfig object representing a microphone with the specified device ID.
     * @member AudioConfig.fromMicrophoneInput
     * @function
     * @public
     * @param {string | undefined} deviceId - Specifies the device ID of the microphone to be used.
     * Default microphone is used the value is omitted.
     * @returns {AudioConfig} The audio input configuration being created.
     */
    static fromMicrophoneInput(deviceId) {
        const pcmRecorder = new Exports_js_1.PcmRecorder(true);
        return new AudioConfigImpl(new Exports_js_1.MicAudioSource(pcmRecorder, deviceId));
    }
    /**
     * Creates an AudioConfig object representing the specified file.
     * @member AudioConfig.fromWavFileInput
     * @function
     * @public
     * @param {File} fileName - Specifies the audio input file. Currently, only WAV / PCM is supported.
     * @returns {AudioConfig} The audio input configuration being created.
     */
    static fromWavFileInput(file, name = "unnamedBuffer.wav") {
        return new AudioConfigImpl(new Exports_js_1.FileAudioSource(file, name));
    }
    /**
     * Creates an AudioConfig object representing the specified stream.
     * @member AudioConfig.fromStreamInput
     * @function
     * @public
     * @param {AudioInputStream | PullAudioInputStreamCallback | MediaStream} audioStream - Specifies the custom audio input
     * stream. Currently, only WAV / PCM is supported.
     * @returns {AudioConfig} The audio input configuration being created.
     */
    static fromStreamInput(audioStream) {
        if (audioStream instanceof Exports_js_2.PullAudioInputStreamCallback) {
            return new AudioConfigImpl(new AudioInputStream_js_1.PullAudioInputStreamImpl(audioStream));
        }
        if (audioStream instanceof Exports_js_2.AudioInputStream) {
            return new AudioConfigImpl(audioStream);
        }
        if (typeof MediaStream !== "undefined" && audioStream instanceof MediaStream) {
            const pcmRecorder = new Exports_js_1.PcmRecorder(false);
            return new AudioConfigImpl(new Exports_js_1.MicAudioSource(pcmRecorder, null, null, audioStream));
        }
        throw new Error("Not Supported Type");
    }
    /**
     * Creates an AudioConfig object representing the default speaker.
     * @member AudioConfig.fromDefaultSpeakerOutput
     * @function
     * @public
     * @returns {AudioConfig} The audio output configuration being created.
     * Added in version 1.11.0
     */
    static fromDefaultSpeakerOutput() {
        return new AudioOutputConfigImpl(new Exports_js_2.SpeakerAudioDestination());
    }
    /**
     * Creates an AudioConfig object representing the custom IPlayer object.
     * You can use the IPlayer object to control pause, resume, etc.
     * @member AudioConfig.fromSpeakerOutput
     * @function
     * @public
     * @param {IPlayer} player - the IPlayer object for playback.
     * @returns {AudioConfig} The audio output configuration being created.
     * Added in version 1.12.0
     */
    static fromSpeakerOutput(player) {
        if (player === undefined) {
            return AudioConfig.fromDefaultSpeakerOutput();
        }
        if (player instanceof Exports_js_2.SpeakerAudioDestination) {
            return new AudioOutputConfigImpl(player);
        }
        throw new Error("Not Supported Type");
    }
    /**
     * Creates an AudioConfig object representing a specified output audio file
     * @member AudioConfig.fromAudioFileOutput
     * @function
     * @public
     * @param {PathLike} filename - the filename of the output audio file
     * @returns {AudioConfig} The audio output configuration being created.
     * Added in version 1.11.0
     */
    static fromAudioFileOutput(filename) {
        return new AudioOutputConfigImpl(new AudioFileWriter_js_1.AudioFileWriter(filename));
    }
    /**
     * Creates an AudioConfig object representing a specified audio output stream
     * @member AudioConfig.fromStreamOutput
     * @function
     * @public
     * @param {AudioOutputStream | PushAudioOutputStreamCallback} audioStream - Specifies the custom audio output
     * stream.
     * @returns {AudioConfig} The audio output configuration being created.
     * Added in version 1.11.0
     */
    static fromStreamOutput(audioStream) {
        if (audioStream instanceof Exports_js_2.PushAudioOutputStreamCallback) {
            return new AudioOutputConfigImpl(new AudioOutputStream_js_1.PushAudioOutputStreamImpl(audioStream));
        }
        if (audioStream instanceof Exports_js_2.PushAudioOutputStream) {
            return new AudioOutputConfigImpl(audioStream);
        }
        if (audioStream instanceof Exports_js_2.PullAudioOutputStream) {
            return new AudioOutputConfigImpl(audioStream);
        }
        throw new Error("Not Supported Type");
    }
}
exports.AudioConfig = AudioConfig;
/**
 * Represents audio input stream used for custom audio input configurations.
 * @private
 * @class AudioConfigImpl
 */
class AudioConfigImpl extends AudioConfig {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {IAudioSource} source - An audio source.
     */
    constructor(source) {
        super();
        this.privSource = source;
    }
    /**
     * Format information for the audio
     */
    get format() {
        return this.privSource.format;
    }
    /**
     * @member AudioConfigImpl.prototype.close
     * @function
     * @public
     */
    close(cb, err) {
        this.privSource.turnOff().then(() => {
            if (!!cb) {
                cb();
            }
        }, (error) => {
            if (!!err) {
                err(error);
            }
        });
    }
    /**
     * @member AudioConfigImpl.prototype.id
     * @function
     * @public
     */
    id() {
        return this.privSource.id();
    }
    /**
     * @member AudioConfigImpl.prototype.turnOn
     * @function
     * @public
     * @returns {Promise<void>} A promise.
     */
    turnOn() {
        return this.privSource.turnOn();
    }
    /**
     * @member AudioConfigImpl.prototype.attach
     * @function
     * @public
     * @param {string} audioNodeId - The audio node id.
     * @returns {Promise<IAudioStreamNode>} A promise.
     */
    attach(audioNodeId) {
        return this.privSource.attach(audioNodeId);
    }
    /**
     * @member AudioConfigImpl.prototype.detach
     * @function
     * @public
     * @param {string} audioNodeId - The audio node id.
     */
    detach(audioNodeId) {
        return this.privSource.detach(audioNodeId);
    }
    /**
     * @member AudioConfigImpl.prototype.turnOff
     * @function
     * @public
     * @returns {Promise<void>} A promise.
     */
    turnOff() {
        return this.privSource.turnOff();
    }
    /**
     * @member AudioConfigImpl.prototype.events
     * @function
     * @public
     * @returns {EventSource<AudioSourceEvent>} An event source for audio events.
     */
    get events() {
        return this.privSource.events;
    }
    setProperty(name, value) {
        Contracts_js_1.Contracts.throwIfNull(value, "value");
        if (undefined !== this.privSource.setProperty) {
            this.privSource.setProperty(name, value);
        }
        else {
            throw new Error("This AudioConfig instance does not support setting properties.");
        }
    }
    getProperty(name, def) {
        if (undefined !== this.privSource.getProperty) {
            return this.privSource.getProperty(name, def);
        }
        else {
            throw new Error("This AudioConfig instance does not support getting properties.");
        }
        // removed by dead control flow

    }
    get deviceInfo() {
        return this.privSource.deviceInfo;
    }
}
exports.AudioConfigImpl = AudioConfigImpl;
class AudioOutputConfigImpl extends AudioConfig {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {IAudioDestination} destination - An audio destination.
     */
    constructor(destination) {
        super();
        this.privDestination = destination;
    }
    set format(format) {
        this.privDestination.format = format;
    }
    write(buffer) {
        this.privDestination.write(buffer);
    }
    close() {
        this.privDestination.close();
    }
    id() {
        return this.privDestination.id();
    }
    setProperty() {
        throw new Error("This AudioConfig instance does not support setting properties.");
    }
    getProperty() {
        throw new Error("This AudioConfig instance does not support getting properties.");
    }
}
exports.AudioOutputConfigImpl = AudioOutputConfigImpl;

//# sourceMappingURL=AudioConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioFileWriter.js"
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioFileWriter.js ***!
  \**********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AudioFileWriter = void 0;
const fs = __importStar(__webpack_require__(/*! fs */ "?c417"));
const Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
class AudioFileWriter {
    constructor(filename) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(fs.openSync, "\nFile System access not available, please use Push or PullAudioOutputStream");
        this.privFd = fs.openSync(filename, "w");
    }
    set format(format) {
        Contracts_js_1.Contracts.throwIfNotUndefined(this.privAudioFormat, "format is already set");
        this.privAudioFormat = format;
        let headerOffset = 0;
        if (this.privAudioFormat.hasHeader) {
            headerOffset = this.privAudioFormat.header.byteLength;
        }
        if (this.privFd !== undefined) {
            this.privWriteStream = fs.createWriteStream("", { fd: this.privFd, start: headerOffset, autoClose: false });
        }
    }
    write(buffer) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privAudioFormat, "must set format before writing.");
        if (this.privWriteStream !== undefined) {
            this.privWriteStream.write(new Uint8Array(buffer.slice(0)));
        }
    }
    close() {
        if (this.privFd !== undefined) {
            this.privWriteStream.on("finish", () => {
                if (this.privAudioFormat.hasHeader) {
                    this.privAudioFormat.updateHeader(this.privWriteStream.bytesWritten);
                    fs.writeSync(this.privFd, new Int8Array(this.privAudioFormat.header), 0, this.privAudioFormat.header.byteLength, 0);
                }
                fs.closeSync(this.privFd);
                this.privFd = undefined;
            });
            this.privWriteStream.end();
        }
    }
    id() {
        return this.privId;
    }
}
exports.AudioFileWriter = AudioFileWriter;

//# sourceMappingURL=AudioFileWriter.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioInputStream.js"
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioInputStream.js ***!
  \***********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PullAudioInputStreamImpl = exports.PullAudioInputStream = exports.PushAudioInputStreamImpl = exports.PushAudioInputStream = exports.AudioInputStream = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Guid_js_1 = __webpack_require__(/*! ../../common/Guid.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Guid.js");
const Exports_js_3 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const AudioStreamFormat_js_1 = __webpack_require__(/*! ./AudioStreamFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js");
/**
 * Represents audio input stream used for custom audio input configurations.
 * @class AudioInputStream
 */
class AudioInputStream {
    /**
     * Creates and initializes an instance.
     * @constructor
     */
    constructor() {
        return;
    }
    /**
     * Creates a memory backed PushAudioInputStream with the specified audio format.
     * @member AudioInputStream.createPushStream
     * @function
     * @public
     * @param {AudioStreamFormat} format - The audio data format in which audio will be
     * written to the push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).
     * @returns {PushAudioInputStream} The audio input stream being created.
     */
    static createPushStream(format) {
        return PushAudioInputStream.create(format);
    }
    /**
     * Creates a PullAudioInputStream that delegates to the specified callback interface for read()
     * and close() methods.
     * @member AudioInputStream.createPullStream
     * @function
     * @public
     * @param {PullAudioInputStreamCallback} callback - The custom audio input object, derived from
     * PullAudioInputStreamCallback
     * @param {AudioStreamFormat} format - The audio data format in which audio will be returned from
     * the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
     * @returns {PullAudioInputStream} The audio input stream being created.
     */
    static createPullStream(callback, format) {
        return PullAudioInputStream.create(callback, format);
        // throw new Error("Oops");
    }
}
exports.AudioInputStream = AudioInputStream;
/**
 * Represents memory backed push audio input stream used for custom audio input configurations.
 * @class PushAudioInputStream
 */
class PushAudioInputStream extends AudioInputStream {
    /**
     * Creates a memory backed PushAudioInputStream with the specified audio format.
     * @member PushAudioInputStream.create
     * @function
     * @public
     * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the
     * push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).
     * @returns {PushAudioInputStream} The push audio input stream being created.
     */
    static create(format) {
        return new PushAudioInputStreamImpl(format);
    }
}
exports.PushAudioInputStream = PushAudioInputStream;
/**
 * Represents memory backed push audio input stream used for custom audio input configurations.
 * @private
 * @class PushAudioInputStreamImpl
 */
class PushAudioInputStreamImpl extends PushAudioInputStream {
    /**
     * Creates and initalizes an instance with the given values.
     * @constructor
     * @param {AudioStreamFormat} format - The audio stream format.
     */
    constructor(format) {
        super();
        if (format === undefined) {
            this.privFormat = AudioStreamFormat_js_1.AudioStreamFormatImpl.getDefaultInputFormat();
        }
        else {
            this.privFormat = format;
        }
        this.privEvents = new Exports_js_2.EventSource();
        this.privId = (0, Guid_js_1.createNoDashGuid)();
        this.privStream = new Exports_js_2.ChunkedArrayBufferStream(this.privFormat.avgBytesPerSec / 10);
    }
    /**
     * Format information for the audio
     */
    get format() {
        return Promise.resolve(this.privFormat);
    }
    /**
     * Writes the audio data specified by making an internal copy of the data.
     * @member PushAudioInputStreamImpl.prototype.write
     * @function
     * @public
     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
     */
    write(dataBuffer) {
        this.privStream.writeStreamChunk({
            buffer: dataBuffer,
            isEnd: false,
            timeReceived: Date.now()
        });
    }
    /**
     * Closes the stream.
     * @member PushAudioInputStreamImpl.prototype.close
     * @function
     * @public
     */
    close() {
        this.privStream.close();
    }
    id() {
        return this.privId;
    }
    turnOn() {
        this.onEvent(new Exports_js_2.AudioSourceInitializingEvent(this.privId)); // no stream id
        this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));
        return;
    }
    async attach(audioNodeId) {
        this.onEvent(new Exports_js_2.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
        await this.turnOn();
        const stream = this.privStream;
        this.onEvent(new Exports_js_2.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
        return {
            detach: async () => {
                this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
                return this.turnOff();
            },
            id: () => audioNodeId,
            read: () => stream.read(),
        };
    }
    detach(audioNodeId) {
        this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
    }
    turnOff() {
        return;
    }
    get events() {
        return this.privEvents;
    }
    get deviceInfo() {
        return Promise.resolve({
            bitspersample: this.privFormat.bitsPerSample,
            channelcount: this.privFormat.channels,
            connectivity: Exports_js_1.connectivity.Unknown,
            manufacturer: "Speech SDK",
            model: "PushStream",
            samplerate: this.privFormat.samplesPerSec,
            type: Exports_js_1.type.Stream,
        });
    }
    onEvent(event) {
        this.privEvents.onEvent(event);
        Exports_js_2.Events.instance.onEvent(event);
    }
    toBuffer(arrayBuffer) {
        const buf = Buffer.alloc(arrayBuffer.byteLength);
        const view = new Uint8Array(arrayBuffer);
        for (let i = 0; i < buf.length; ++i) {
            buf[i] = view[i];
        }
        return buf;
    }
}
exports.PushAudioInputStreamImpl = PushAudioInputStreamImpl;
/*
 * Represents audio input stream used for custom audio input configurations.
 * @class PullAudioInputStream
 */
class PullAudioInputStream extends AudioInputStream {
    /**
     * Creates and initializes and instance.
     * @constructor
     */
    constructor() {
        super();
    }
    /**
     * Creates a PullAudioInputStream that delegates to the specified callback interface for
     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
     * @member PullAudioInputStream.create
     * @function
     * @public
     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
     * derived from PullAudioInputStreamCustomCallback
     * @param {AudioStreamFormat} format - The audio data format in which audio will be
     * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
     * @returns {PullAudioInputStream} The push audio input stream being created.
     */
    static create(callback, format) {
        return new PullAudioInputStreamImpl(callback, format);
    }
}
exports.PullAudioInputStream = PullAudioInputStream;
/**
 * Represents audio input stream used for custom audio input configurations.
 * @private
 * @class PullAudioInputStreamImpl
 */
class PullAudioInputStreamImpl extends PullAudioInputStream {
    /**
     * Creates a PullAudioInputStream that delegates to the specified callback interface for
     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
     * @constructor
     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
     * derived from PullAudioInputStreamCustomCallback
     * @param {AudioStreamFormat} format - The audio data format in which audio will be
     * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).
     */
    constructor(callback, format) {
        super();
        if (undefined === format) {
            this.privFormat = Exports_js_3.AudioStreamFormat.getDefaultInputFormat();
        }
        else {
            this.privFormat = format;
        }
        this.privEvents = new Exports_js_2.EventSource();
        this.privId = (0, Guid_js_1.createNoDashGuid)();
        this.privCallback = callback;
        this.privIsClosed = false;
        this.privBufferSize = this.privFormat.avgBytesPerSec / 10;
    }
    /**
     * Format information for the audio
     */
    get format() {
        return Promise.resolve(this.privFormat);
    }
    /**
     * Closes the stream.
     * @member PullAudioInputStreamImpl.prototype.close
     * @function
     * @public
     */
    close() {
        this.privIsClosed = true;
        this.privCallback.close();
    }
    id() {
        return this.privId;
    }
    turnOn() {
        this.onEvent(new Exports_js_2.AudioSourceInitializingEvent(this.privId)); // no stream id
        this.onEvent(new Exports_js_2.AudioSourceReadyEvent(this.privId));
        return;
    }
    async attach(audioNodeId) {
        this.onEvent(new Exports_js_2.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));
        await this.turnOn();
        this.onEvent(new Exports_js_2.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));
        return {
            detach: () => {
                this.privCallback.close();
                this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
                return this.turnOff();
            },
            id: () => audioNodeId,
            read: () => {
                let totalBytes = 0;
                let transmitBuff;
                // Until we have the minimum number of bytes to send in a transmission, keep asking for more.
                while (totalBytes < this.privBufferSize) {
                    // Sizing the read buffer to the delta between the perfect size and what's left means we won't ever get too much
                    // data back.
                    const readBuff = new ArrayBuffer(this.privBufferSize - totalBytes);
                    const pulledBytes = this.privCallback.read(readBuff);
                    // If there is no return buffer yet defined, set the return buffer to the that was just populated.
                    // This was, if we have enough data there's no copy penalty, but if we don't we have a buffer that's the
                    // preferred size allocated.
                    if (undefined === transmitBuff) {
                        transmitBuff = readBuff;
                    }
                    else {
                        // Not the first bite at the apple, so fill the return buffer with the data we got back.
                        const intView = new Int8Array(transmitBuff);
                        intView.set(new Int8Array(readBuff), totalBytes);
                    }
                    // If there are no bytes to read, just break out and be done.
                    if (0 === pulledBytes) {
                        break;
                    }
                    totalBytes += pulledBytes;
                }
                return Promise.resolve({
                    buffer: transmitBuff.slice(0, totalBytes),
                    isEnd: this.privIsClosed || totalBytes === 0,
                    timeReceived: Date.now(),
                });
            },
        };
    }
    detach(audioNodeId) {
        this.onEvent(new Exports_js_2.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));
    }
    turnOff() {
        return;
    }
    get events() {
        return this.privEvents;
    }
    get deviceInfo() {
        return Promise.resolve({
            bitspersample: this.privFormat.bitsPerSample,
            channelcount: this.privFormat.channels,
            connectivity: Exports_js_1.connectivity.Unknown,
            manufacturer: "Speech SDK",
            model: "PullStream",
            samplerate: this.privFormat.samplesPerSec,
            type: Exports_js_1.type.Stream,
        });
    }
    onEvent(event) {
        this.privEvents.onEvent(event);
        Exports_js_2.Events.instance.onEvent(event);
    }
}
exports.PullAudioInputStreamImpl = PullAudioInputStreamImpl;

//# sourceMappingURL=AudioInputStream.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js"
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js ***!
  \************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AudioOutputFormatImpl = void 0;
const SpeechSynthesisOutputFormat_js_1 = __webpack_require__(/*! ../SpeechSynthesisOutputFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisOutputFormat.js");
const AudioStreamFormat_js_1 = __webpack_require__(/*! ./AudioStreamFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js");
/**
 * @private
 * @class AudioOutputFormatImpl
 * Updated in version 1.17.0
 */
// eslint-disable-next-line max-classes-per-file
class AudioOutputFormatImpl extends AudioStreamFormat_js_1.AudioStreamFormatImpl {
    /**
     * Creates an instance with the given values.
     * @constructor
     * @param formatTag
     * @param {number} channels - Number of channels.
     * @param {number} samplesPerSec - Samples per second.
     * @param {number} avgBytesPerSec - Average bytes per second.
     * @param {number} blockAlign - Block alignment.
     * @param {number} bitsPerSample - Bits per sample.
     * @param {string} audioFormatString - Audio format string
     * @param {string} requestAudioFormatString - Audio format string sent to service.
     * @param {boolean} hasHeader - If the format has header or not.
     */
    constructor(formatTag, channels, samplesPerSec, avgBytesPerSec, blockAlign, bitsPerSample, audioFormatString, requestAudioFormatString, hasHeader) {
        super(samplesPerSec, bitsPerSample, channels, formatTag);
        this.formatTag = formatTag;
        this.avgBytesPerSec = avgBytesPerSec;
        this.blockAlign = blockAlign;
        this.priAudioFormatString = audioFormatString;
        this.priRequestAudioFormatString = requestAudioFormatString;
        this.priHasHeader = hasHeader;
    }
    static fromSpeechSynthesisOutputFormat(speechSynthesisOutputFormat) {
        if (speechSynthesisOutputFormat === undefined) {
            return AudioOutputFormatImpl.getDefaultOutputFormat();
        }
        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString[speechSynthesisOutputFormat]);
    }
    static fromSpeechSynthesisOutputFormatString(speechSynthesisOutputFormatString) {
        switch (speechSynthesisOutputFormatString) {
            case "raw-8khz-8bit-mono-mulaw":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "riff-16khz-16kbps-mono-siren":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, "audio-16khz-16kbps-mono-siren", true);
            case "audio-16khz-16kbps-mono-siren":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-16khz-32kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 16000, 32 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-16khz-128kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 16000, 128 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-16khz-64kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 16000, 64 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-24khz-48kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 24000, 48 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-24khz-96kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 24000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-24khz-160kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 24000, 160 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "raw-16khz-16bit-mono-truesilk":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.SILKSkype, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "riff-8khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, "raw-8khz-16bit-mono-pcm", true);
            case "riff-24khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, "raw-24khz-16bit-mono-pcm", true);
            case "riff-8khz-8bit-mono-mulaw":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, "raw-8khz-8bit-mono-mulaw", true);
            case "raw-16khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, "raw-16khz-16bit-mono-pcm", false);
            case "raw-24khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, "raw-24khz-16bit-mono-pcm", false);
            case "raw-8khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, "raw-8khz-16bit-mono-pcm", false);
            case "ogg-16khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OGG_OPUS, 1, 16000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "ogg-24khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OGG_OPUS, 1, 24000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "raw-48khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, "raw-48khz-16bit-mono-pcm", false);
            case "riff-48khz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, "raw-48khz-16bit-mono-pcm", true);
            case "audio-48khz-96kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 48000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-48khz-192kbitrate-mono-mp3":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.MP3, 1, 48000, 192 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "ogg-48khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OGG_OPUS, 1, 48000, 12000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "webm-16khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.WEBM_OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "webm-24khz-16bit-mono-opus":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.WEBM_OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "webm-24khz-16bit-24kbps-mono-opus":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.WEBM_OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-16khz-16bit-32kbps-mono-opus":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-24khz-16bit-48kbps-mono-opus":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-24khz-16bit-24kbps-mono-opus":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-24khz-16bit-mono-flac":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.FLAC, 1, 24000, 24000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "audio-48khz-16bit-mono-flac":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.FLAC, 1, 48000, 30000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "raw-24khz-16bit-mono-truesilk":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.SILKSkype, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "raw-8khz-8bit-mono-alaw":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "riff-8khz-8bit-mono-alaw":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, "raw-8khz-8bit-mono-alaw", true);
            case "raw-22050hz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "riff-22050hz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, "raw-22050hz-16bit-mono-pcm", true);
            case "raw-44100hz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "riff-44100hz-16bit-mono-pcm":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, "raw-44100hz-16bit-mono-pcm", true);
            case "amr-wb-16000h":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.AMR_WB, 1, 16000, 3052, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "g722-16khz-64kbps":
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.G722, 1, 16000, 8000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);
            case "riff-16khz-16bit-mono-pcm":
            default:
                return new AudioOutputFormatImpl(AudioStreamFormat_js_1.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, "riff-16khz-16bit-mono-pcm", "raw-16khz-16bit-mono-pcm", true);
        }
    }
    static getDefaultOutputFormat() {
        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString((typeof window !== "undefined") ? "audio-24khz-48kbitrate-mono-mp3" : "riff-16khz-16bit-mono-pcm");
    }
    /**
     * Specifies if this audio output format has a header
     * @boolean AudioOutputFormatImpl.prototype.hasHeader
     * @function
     * @public
     */
    get hasHeader() {
        return this.priHasHeader;
    }
    /**
     * Specifies the header of this format
     * @ArrayBuffer AudioOutputFormatImpl.prototype.header
     * @function
     * @public
     */
    get header() {
        if (this.hasHeader) {
            return this.privHeader;
        }
        return undefined;
    }
    /**
     * Updates the header based on the audio length
     * @member AudioOutputFormatImpl.updateHeader
     * @function
     * @public
     * @param {number} audioLength - the audio length
     */
    updateHeader(audioLength) {
        if (this.priHasHeader) {
            const view = new DataView(this.privHeader);
            view.setUint32(4, audioLength + this.privHeader.byteLength - 8, true);
            view.setUint32(40, audioLength, true);
        }
    }
    /**
     * Specifies the audio format string to be sent to the service
     * @string AudioOutputFormatImpl.prototype.requestAudioFormatString
     * @function
     * @public
     */
    get requestAudioFormatString() {
        return this.priRequestAudioFormatString;
    }
    /**
     * Adds audio header
     * @param audio the raw audio without header
     * @returns the audio with header if applicable
     */
    addHeader(audio) {
        if (!this.hasHeader) {
            return audio;
        }
        this.updateHeader(audio.byteLength);
        const tmp = new Uint8Array(audio.byteLength + this.header.byteLength);
        tmp.set(new Uint8Array(this.header), 0);
        tmp.set(new Uint8Array(audio), this.header.byteLength);
        return tmp.buffer;
    }
}
exports.AudioOutputFormatImpl = AudioOutputFormatImpl;
AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString = {
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw]: "raw-8khz-8bit-mono-mulaw",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren]: "riff-16khz-16kbps-mono-siren",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren]: "audio-16khz-16kbps-mono-siren",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3]: "audio-16khz-32kbitrate-mono-mp3",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3]: "audio-16khz-128kbitrate-mono-mp3",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3]: "audio-16khz-64kbitrate-mono-mp3",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3]: "audio-24khz-48kbitrate-mono-mp3",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3]: "audio-24khz-96kbitrate-mono-mp3",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3]: "audio-24khz-160kbitrate-mono-mp3",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk]: "raw-16khz-16bit-mono-truesilk",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm]: "riff-16khz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm]: "riff-8khz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm]: "riff-24khz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw]: "riff-8khz-8bit-mono-mulaw",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm]: "raw-16khz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm]: "raw-24khz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm]: "raw-8khz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus]: "ogg-16khz-16bit-mono-opus",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus]: "ogg-24khz-16bit-mono-opus",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm]: "raw-48khz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm]: "riff-48khz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3]: "audio-48khz-96kbitrate-mono-mp3",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3]: "audio-48khz-192kbitrate-mono-mp3",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus]: "ogg-48khz-16bit-mono-opus",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus]: "webm-16khz-16bit-mono-opus",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus]: "webm-24khz-16bit-mono-opus",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus]: "webm-24khz-16bit-24kbps-mono-opus",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk]: "raw-24khz-16bit-mono-truesilk",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw]: "raw-8khz-8bit-mono-alaw",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw]: "riff-8khz-8bit-mono-alaw",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus]: "audio-16khz-16bit-32kbps-mono-opus",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus]: "audio-24khz-16bit-48kbps-mono-opus",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus]: "audio-24khz-16bit-24kbps-mono-opus",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm]: "raw-22050hz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm]: "riff-22050hz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm]: "raw-44100hz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm]: "riff-44100hz-16bit-mono-pcm",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.AmrWb16000Hz]: "amr-wb-16000hz",
    [SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat.G72216Khz64Kbps]: "g722-16khz-64kbps",
};

//# sourceMappingURL=AudioOutputFormat.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js"
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js ***!
  \************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PushAudioOutputStreamImpl = exports.PushAudioOutputStream = exports.PullAudioOutputStreamImpl = exports.PullAudioOutputStream = exports.AudioOutputStream = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const AudioOutputFormat_js_1 = __webpack_require__(/*! ./AudioOutputFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js");
/**
 * Represents audio output stream used for custom audio output configurations.
 * @class AudioOutputStream
 */
class AudioOutputStream {
    /**
     * Creates and initializes an instance.
     * @constructor
     */
    constructor() {
        return;
    }
    /**
     * Creates a memory backed PullAudioOutputStream with the specified audio format.
     * @member AudioOutputStream.createPullStream
     * @function
     * @public
     * @returns {PullAudioOutputStream} The audio output stream being created.
     */
    static createPullStream() {
        return PullAudioOutputStream.create();
    }
}
exports.AudioOutputStream = AudioOutputStream;
/**
 * Represents memory backed push audio output stream used for custom audio output configurations.
 * @class PullAudioOutputStream
 */
class PullAudioOutputStream extends AudioOutputStream {
    /**
     * Creates a memory backed PullAudioOutputStream with the specified audio format.
     * @member PullAudioOutputStream.create
     * @function
     * @public
     * @returns {PullAudioOutputStream} The push audio output stream being created.
     */
    static create() {
        return new PullAudioOutputStreamImpl();
    }
}
exports.PullAudioOutputStream = PullAudioOutputStream;
/**
 * Represents memory backed push audio output stream used for custom audio output configurations.
 * @private
 * @class PullAudioOutputStreamImpl
 */
class PullAudioOutputStreamImpl extends PullAudioOutputStream {
    /**
     * Creates and initializes an instance with the given values.
     * @constructor
     */
    constructor() {
        super();
        this.privId = (0, Exports_js_1.createNoDashGuid)();
        this.privStream = new Exports_js_1.Stream();
    }
    /**
     * Sets the format information to the stream. For internal use only.
     * @param {AudioStreamFormat} format - the format to be set.
     */
    set format(format) {
        if (format === undefined || format === null) {
            this.privFormat = AudioOutputFormat_js_1.AudioOutputFormatImpl.getDefaultOutputFormat();
        }
        this.privFormat = format;
    }
    /**
     * Format information for the audio
     */
    get format() {
        return this.privFormat;
    }
    /**
     * Checks if the stream is closed
     * @member PullAudioOutputStreamImpl.prototype.isClosed
     * @property
     * @public
     */
    get isClosed() {
        return this.privStream.isClosed;
    }
    /**
     * Gets the id of the stream
     * @member PullAudioOutputStreamImpl.prototype.id
     * @property
     * @public
     */
    id() {
        return this.privId;
    }
    /**
     * Reads audio data from the internal buffer.
     * @member PullAudioOutputStreamImpl.prototype.read
     * @function
     * @public
     * @param {ArrayBuffer} dataBuffer - An ArrayBuffer to store the read data.
     * @returns {Promise<number>} - Audio buffer length has been read.
     */
    async read(dataBuffer) {
        const intView = new Int8Array(dataBuffer);
        let totalBytes = 0;
        if (this.privLastChunkView !== undefined) {
            if (this.privLastChunkView.length > dataBuffer.byteLength) {
                intView.set(this.privLastChunkView.slice(0, dataBuffer.byteLength));
                this.privLastChunkView = this.privLastChunkView.slice(dataBuffer.byteLength);
                return Promise.resolve(dataBuffer.byteLength);
            }
            intView.set(this.privLastChunkView);
            totalBytes = this.privLastChunkView.length;
            this.privLastChunkView = undefined;
        }
        // Until we have the minimum number of bytes to send in a transmission, keep asking for more.
        while (totalBytes < dataBuffer.byteLength && !this.privStream.isReadEnded) {
            const chunk = await this.privStream.read();
            if (chunk !== undefined && !chunk.isEnd) {
                let tmpBuffer;
                if (chunk.buffer.byteLength > dataBuffer.byteLength - totalBytes) {
                    tmpBuffer = chunk.buffer.slice(0, dataBuffer.byteLength - totalBytes);
                    this.privLastChunkView = new Int8Array(chunk.buffer.slice(dataBuffer.byteLength - totalBytes));
                }
                else {
                    tmpBuffer = chunk.buffer;
                }
                intView.set(new Int8Array(tmpBuffer), totalBytes);
                totalBytes += tmpBuffer.byteLength;
            }
            else {
                this.privStream.readEnded();
            }
        }
        return totalBytes;
    }
    /**
     * Writes the audio data specified by making an internal copy of the data.
     * @member PullAudioOutputStreamImpl.prototype.write
     * @function
     * @public
     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
     */
    write(dataBuffer) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privStream, "must set format before writing");
        this.privStream.writeStreamChunk({
            buffer: dataBuffer,
            isEnd: false,
            timeReceived: Date.now()
        });
    }
    /**
     * Closes the stream.
     * @member PullAudioOutputStreamImpl.prototype.close
     * @function
     * @public
     */
    close() {
        this.privStream.close();
    }
}
exports.PullAudioOutputStreamImpl = PullAudioOutputStreamImpl;
/*
 * Represents audio output stream used for custom audio output configurations.
 * @class PushAudioOutputStream
 */
class PushAudioOutputStream extends AudioOutputStream {
    /**
     * Creates and initializes and instance.
     * @constructor
     */
    constructor() {
        super();
    }
    /**
     * Creates a PushAudioOutputStream that delegates to the specified callback interface for
     * write() and close() methods.
     * @member PushAudioOutputStream.create
     * @function
     * @public
     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,
     * derived from PushAudioOutputStreamCallback
     * @returns {PushAudioOutputStream} The push audio output stream being created.
     */
    static create(callback) {
        return new PushAudioOutputStreamImpl(callback);
    }
}
exports.PushAudioOutputStream = PushAudioOutputStream;
/**
 * Represents audio output stream used for custom audio output configurations.
 * @private
 * @class PushAudioOutputStreamImpl
 */
class PushAudioOutputStreamImpl extends PushAudioOutputStream {
    /**
     * Creates a PushAudioOutputStream that delegates to the specified callback interface for
     * read() and close() methods.
     * @constructor
     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,
     * derived from PushAudioOutputStreamCallback
     */
    constructor(callback) {
        super();
        this.privId = (0, Exports_js_1.createNoDashGuid)();
        this.privCallback = callback;
    }
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    set format(format) { }
    write(buffer) {
        if (!!this.privCallback.write) {
            this.privCallback.write(buffer);
        }
    }
    close() {
        if (!!this.privCallback.close) {
            this.privCallback.close();
        }
    }
    id() {
        return this.privId;
    }
}
exports.PushAudioOutputStreamImpl = PushAudioOutputStreamImpl;

//# sourceMappingURL=AudioOutputStream.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js"
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js ***!
  \************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AudioStreamFormatImpl = exports.AudioStreamFormat = exports.AudioFormatTag = void 0;
// eslint-disable-next-line max-classes-per-file
var AudioFormatTag;
(function (AudioFormatTag) {
    AudioFormatTag[AudioFormatTag["PCM"] = 1] = "PCM";
    AudioFormatTag[AudioFormatTag["MuLaw"] = 2] = "MuLaw";
    AudioFormatTag[AudioFormatTag["Siren"] = 3] = "Siren";
    AudioFormatTag[AudioFormatTag["MP3"] = 4] = "MP3";
    AudioFormatTag[AudioFormatTag["SILKSkype"] = 5] = "SILKSkype";
    AudioFormatTag[AudioFormatTag["OGG_OPUS"] = 6] = "OGG_OPUS";
    AudioFormatTag[AudioFormatTag["WEBM_OPUS"] = 7] = "WEBM_OPUS";
    AudioFormatTag[AudioFormatTag["ALaw"] = 8] = "ALaw";
    AudioFormatTag[AudioFormatTag["FLAC"] = 9] = "FLAC";
    AudioFormatTag[AudioFormatTag["OPUS"] = 10] = "OPUS";
    AudioFormatTag[AudioFormatTag["AMR_WB"] = 11] = "AMR_WB";
    AudioFormatTag[AudioFormatTag["G722"] = 12] = "G722";
})(AudioFormatTag = exports.AudioFormatTag || (exports.AudioFormatTag = {}));
/**
 * Represents audio stream format used for custom audio input configurations.
 * @class AudioStreamFormat
 */
class AudioStreamFormat {
    /**
     * Creates an audio stream format object representing the default audio stream
     * format (16KHz 16bit mono PCM).
     * @member AudioStreamFormat.getDefaultInputFormat
     * @function
     * @public
     * @returns {AudioStreamFormat} The audio stream format being created.
     */
    static getDefaultInputFormat() {
        return AudioStreamFormatImpl.getDefaultInputFormat();
    }
    /**
     * Creates an audio stream format object with the specified format characteristics.
     * @member AudioStreamFormat.getWaveFormat
     * @function
     * @public
     * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).
     * @param {number} bitsPerSample - Bits per sample, typically 16.
     * @param {number} channels - Number of channels in the waveform-audio data. Monaural data
     * uses one channel and stereo data uses two channels.
     * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).
     * @returns {AudioStreamFormat} The audio stream format being created.
     */
    static getWaveFormat(samplesPerSecond, bitsPerSample, channels, format) {
        return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels, format);
    }
    /**
     * Creates an audio stream format object with the specified pcm waveformat characteristics.
     * @member AudioStreamFormat.getWaveFormatPCM
     * @function
     * @public
     * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).
     * @param {number} bitsPerSample - Bits per sample, typically 16.
     * @param {number} channels - Number of channels in the waveform-audio data. Monaural data
     * uses one channel and stereo data uses two channels.
     * @returns {AudioStreamFormat} The audio stream format being created.
     */
    static getWaveFormatPCM(samplesPerSecond, bitsPerSample, channels) {
        return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels);
    }
}
exports.AudioStreamFormat = AudioStreamFormat;
/**
 * @private
 * @class AudioStreamFormatImpl
 */
class AudioStreamFormatImpl extends AudioStreamFormat {
    /**
     * Creates an instance with the given values.
     * @constructor
     * @param {number} samplesPerSec - Samples per second.
     * @param {number} bitsPerSample - Bits per sample.
     * @param {number} channels - Number of channels.
     * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).
     */
    constructor(samplesPerSec = 16000, bitsPerSample = 16, channels = 1, format = AudioFormatTag.PCM) {
        super();
        let isWavFormat = true;
        /* 1 for PCM; 6 for alaw; 7 for mulaw */
        switch (format) {
            case AudioFormatTag.PCM:
                this.formatTag = 1;
                break;
            case AudioFormatTag.ALaw:
                this.formatTag = 6;
                break;
            case AudioFormatTag.MuLaw:
                this.formatTag = 7;
                break;
            default:
                isWavFormat = false;
        }
        this.bitsPerSample = bitsPerSample;
        this.samplesPerSec = samplesPerSec;
        this.channels = channels;
        this.avgBytesPerSec = this.samplesPerSec * this.channels * (this.bitsPerSample / 8);
        this.blockAlign = this.channels * Math.max(this.bitsPerSample, 8);
        if (isWavFormat) {
            this.privHeader = new ArrayBuffer(44);
            // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView
            const view = new DataView(this.privHeader);
            /* RIFF identifier */
            this.setString(view, 0, "RIFF");
            /* file length */
            view.setUint32(4, 0, true);
            /* RIFF type & Format */
            this.setString(view, 8, "WAVEfmt ");
            /* format chunk length */
            view.setUint32(16, 16, true);
            /* audio format */
            view.setUint16(20, this.formatTag, true);
            /* channel count */
            view.setUint16(22, this.channels, true);
            /* sample rate */
            view.setUint32(24, this.samplesPerSec, true);
            /* byte rate (sample rate * block align) */
            view.setUint32(28, this.avgBytesPerSec, true);
            /* block align (channel count * bytes per sample) */
            view.setUint16(32, this.channels * (this.bitsPerSample / 8), true);
            /* bits per sample */
            view.setUint16(34, this.bitsPerSample, true);
            /* data chunk identifier */
            this.setString(view, 36, "data");
            /* data chunk length */
            view.setUint32(40, 0, true);
        }
    }
    /**
     * Retrieves the default input format.
     * @member AudioStreamFormatImpl.getDefaultInputFormat
     * @function
     * @public
     * @returns {AudioStreamFormatImpl} The default input format.
     */
    static getDefaultInputFormat() {
        return new AudioStreamFormatImpl();
    }
    /**
     * Creates an audio context appropriate to current browser
     * @member AudioStreamFormatImpl.getAudioContext
     * @function
     * @public
     * @returns {AudioContext} An audio context instance
     */
    /* eslint-disable */
    static getAudioContext(sampleRate) {
        // Workaround for Speech SDK bug in Safari.
        const AudioContext = window.AudioContext // our preferred impl
            || window.webkitAudioContext // fallback, mostly when on Safari
            || false; // could not find.
        // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext
        if (!!AudioContext) {
            if (sampleRate !== undefined && navigator.mediaDevices.getSupportedConstraints().sampleRate) {
                return new AudioContext({ sampleRate });
            }
            else {
                return new AudioContext();
            }
        }
        else {
            throw new Error("Browser does not support Web Audio API (AudioContext is not available).");
        }
    }
    /* eslint-enable */
    /**
     * Closes the configuration object.
     * @member AudioStreamFormatImpl.prototype.close
     * @function
     * @public
     */
    close() {
        return;
    }
    get header() {
        return this.privHeader;
    }
    setString(view, offset, str) {
        for (let i = 0; i < str.length; i++) {
            view.setUint8(offset + i, str.charCodeAt(i));
        }
    }
}
exports.AudioStreamFormatImpl = AudioStreamFormatImpl;

//# sourceMappingURL=AudioStreamFormat.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/BaseAudioPlayer.js"
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/BaseAudioPlayer.js ***!
  \**********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.BaseAudioPlayer = void 0;
const Error_js_1 = __webpack_require__(/*! ../../common/Error.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Error.js");
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const AudioStreamFormat_js_1 = __webpack_require__(/*! ./AudioStreamFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js");
/**
 * Base audio player class
 * TODO: Plays only PCM for now.
 * @class
 */
class BaseAudioPlayer {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {AudioStreamFormat} audioFormat audio stream format recognized by the player.
     */
    constructor(audioFormat) {
        this.audioContext = null;
        this.gainNode = null;
        this.autoUpdateBufferTimer = 0;
        if (audioFormat === undefined) {
            audioFormat = Exports_js_1.AudioStreamFormat.getDefaultInputFormat();
        }
        this.init(audioFormat);
    }
    /**
     * play Audio sample
     * @param newAudioData audio data to be played.
     */
    playAudioSample(newAudioData, cb, err) {
        try {
            this.ensureInitializedContext();
            const audioData = this.formatAudioData(newAudioData);
            const newSamplesData = new Float32Array(this.samples.length + audioData.length);
            newSamplesData.set(this.samples, 0);
            newSamplesData.set(audioData, this.samples.length);
            this.samples = newSamplesData;
            if (!!cb) {
                cb();
            }
        }
        catch (e) {
            if (!!err) {
                err(e);
            }
        }
    }
    /**
     * stops audio and clears the buffers
     */
    stopAudio(cb, err) {
        if (this.audioContext !== null) {
            this.samples = new Float32Array();
            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument
            clearInterval(this.autoUpdateBufferTimer);
            this.audioContext.close().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
            this.audioContext = null;
        }
    }
    init(audioFormat) {
        this.audioFormat = audioFormat;
        this.samples = new Float32Array();
    }
    ensureInitializedContext() {
        if (this.audioContext === null) {
            this.createAudioContext();
            const timerPeriod = 200;
            this.autoUpdateBufferTimer = setInterval(() => {
                this.updateAudioBuffer();
            }, timerPeriod);
        }
    }
    createAudioContext() {
        // new ((window as any).AudioContext || (window as any).webkitAudioContext)();
        this.audioContext = AudioStreamFormat_js_1.AudioStreamFormatImpl.getAudioContext();
        // TODO: Various examples shows this gain node, it does not seem to be needed unless we plan
        // to control the volume, not likely
        this.gainNode = this.audioContext.createGain();
        this.gainNode.gain.value = 1;
        this.gainNode.connect(this.audioContext.destination);
        this.startTime = this.audioContext.currentTime;
    }
    formatAudioData(audioData) {
        switch (this.audioFormat.bitsPerSample) {
            case 8:
                return this.formatArrayBuffer(new Int8Array(audioData), 128);
            case 16:
                return this.formatArrayBuffer(new Int16Array(audioData), 32768);
            case 32:
                return this.formatArrayBuffer(new Int32Array(audioData), 2147483648);
            default:
                throw new Error_js_1.InvalidOperationError("Only WAVE_FORMAT_PCM (8/16/32 bps) format supported at this time");
        }
    }
    formatArrayBuffer(audioData, maxValue) {
        const float32Data = new Float32Array(audioData.length);
        for (let i = 0; i < audioData.length; i++) {
            float32Data[i] = audioData[i] / maxValue;
        }
        return float32Data;
    }
    updateAudioBuffer() {
        if (this.samples.length === 0) {
            return;
        }
        const channelCount = this.audioFormat.channels;
        const bufferSource = this.audioContext.createBufferSource();
        const frameCount = this.samples.length / channelCount;
        const audioBuffer = this.audioContext.createBuffer(channelCount, frameCount, this.audioFormat.samplesPerSec);
        // TODO: Should we do the conversion in the pushAudioSample instead?
        for (let channel = 0; channel < channelCount; channel++) {
            // Fill in individual channel data
            let channelOffset = channel;
            const audioData = audioBuffer.getChannelData(channel);
            for (let i = 0; i < this.samples.length; i++, channelOffset += channelCount) {
                audioData[i] = this.samples[channelOffset];
            }
        }
        if (this.startTime < this.audioContext.currentTime) {
            this.startTime = this.audioContext.currentTime;
        }
        bufferSource.buffer = audioBuffer;
        bufferSource.connect(this.gainNode);
        bufferSource.start(this.startTime);
        // Make sure we play the next sample after the current one.
        this.startTime += audioBuffer.duration;
        // Clear the samples for the next pushed data.
        this.samples = new Float32Array();
    }
    async playAudio(audioData) {
        if (this.audioContext === null) {
            this.createAudioContext();
        }
        const source = this.audioContext.createBufferSource();
        const destination = this.audioContext.destination;
        await this.audioContext.decodeAudioData(audioData, (newBuffer) => {
            source.buffer = newBuffer;
            source.connect(destination);
            source.start(0);
        });
    }
}
exports.BaseAudioPlayer = BaseAudioPlayer;

//# sourceMappingURL=BaseAudioPlayer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PullAudioInputStreamCallback.js"
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PullAudioInputStreamCallback.js ***!
  \***********************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PullAudioInputStreamCallback = void 0;
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * An abstract base class that defines callback methods (read() and close()) for
 * custom audio input streams).
 * @class PullAudioInputStreamCallback
 */
class PullAudioInputStreamCallback {
}
exports.PullAudioInputStreamCallback = PullAudioInputStreamCallback;

//# sourceMappingURL=PullAudioInputStreamCallback.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PushAudioOutputStreamCallback.js"
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PushAudioOutputStreamCallback.js ***!
  \************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PushAudioOutputStreamCallback = void 0;
// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/**
 * An abstract base class that defines callback methods (write() and close()) for
 * custom audio output streams).
 * @class PushAudioOutputStreamCallback
 */
class PushAudioOutputStreamCallback {
}
exports.PushAudioOutputStreamCallback = PushAudioOutputStreamCallback;

//# sourceMappingURL=PushAudioOutputStreamCallback.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/SpeakerAudioDestination.js"
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/SpeakerAudioDestination.js ***!
  \******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeakerAudioDestination = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const AudioOutputStream_js_1 = __webpack_require__(/*! ./AudioOutputStream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js");
const AudioStreamFormat_js_1 = __webpack_require__(/*! ./AudioStreamFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js");
const MediaDurationPlaceholderSeconds = 60 * 30;
const AudioFormatToMimeType = {
    [AudioStreamFormat_js_1.AudioFormatTag.PCM]: "audio/wav",
    [AudioStreamFormat_js_1.AudioFormatTag.MuLaw]: "audio/x-wav",
    [AudioStreamFormat_js_1.AudioFormatTag.MP3]: "audio/mpeg",
    [AudioStreamFormat_js_1.AudioFormatTag.OGG_OPUS]: "audio/ogg",
    [AudioStreamFormat_js_1.AudioFormatTag.WEBM_OPUS]: "audio/webm; codecs=opus",
    [AudioStreamFormat_js_1.AudioFormatTag.ALaw]: "audio/x-wav",
    [AudioStreamFormat_js_1.AudioFormatTag.FLAC]: "audio/flac",
    [AudioStreamFormat_js_1.AudioFormatTag.AMR_WB]: "audio/amr-wb",
    [AudioStreamFormat_js_1.AudioFormatTag.G722]: "audio/G722",
};
/**
 * Represents the speaker playback audio destination, which only works in browser.
 * Note: the SDK will try to use <a href="https://www.w3.org/TR/media-source/">Media Source Extensions</a> to play audio.
 * Mp3 format has better supports on Microsoft Edge, Chrome and Safari (desktop), so, it's better to specify mp3 format for playback.
 * @class SpeakerAudioDestination
 * Updated in version 1.17.0
 */
class SpeakerAudioDestination {
    constructor(audioDestinationId) {
        this.privPlaybackStarted = false;
        this.privAppendingToBuffer = false;
        this.privMediaSourceOpened = false;
        this.privBytesReceived = 0;
        this.privId = audioDestinationId ? audioDestinationId : (0, Exports_js_1.createNoDashGuid)();
        this.privIsPaused = false;
        this.privIsClosed = false;
    }
    id() {
        return this.privId;
    }
    write(buffer, cb, err) {
        if (this.privAudioBuffer !== undefined) {
            this.privAudioBuffer.push(buffer);
            this.updateSourceBuffer().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
        }
        else if (this.privAudioOutputStream !== undefined) {
            this.privAudioOutputStream.write(buffer);
            this.privBytesReceived += buffer.byteLength;
        }
    }
    close(cb, err) {
        this.privIsClosed = true;
        if (this.privSourceBuffer !== undefined) {
            this.handleSourceBufferUpdateEnd().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
        }
        else if (this.privAudioOutputStream !== undefined && typeof window !== "undefined") {
            if ((this.privFormat.formatTag === AudioStreamFormat_js_1.AudioFormatTag.PCM || this.privFormat.formatTag === AudioStreamFormat_js_1.AudioFormatTag.MuLaw
                || this.privFormat.formatTag === AudioStreamFormat_js_1.AudioFormatTag.ALaw) && this.privFormat.hasHeader === false) {
                // eslint-disable-next-line no-console
                console.warn("Play back is not supported for raw PCM, mulaw or alaw format without header.");
                if (!!this.onAudioEnd) {
                    this.onAudioEnd(this);
                }
            }
            else {
                let receivedAudio = new ArrayBuffer(this.privBytesReceived);
                this.privAudioOutputStream.read(receivedAudio).then(() => {
                    receivedAudio = this.privFormat.addHeader(receivedAudio);
                    const audioBlob = new Blob([receivedAudio], { type: AudioFormatToMimeType[this.privFormat.formatTag] });
                    this.privAudio.src = window.URL.createObjectURL(audioBlob);
                    this.notifyPlayback().then(() => {
                        if (!!cb) {
                            cb();
                        }
                    }, (error) => {
                        if (!!err) {
                            err(error);
                        }
                    });
                }, (error) => {
                    if (!!err) {
                        err(error);
                    }
                });
            }
        }
        else {
            // unsupported format, call onAudioEnd directly.
            if (!!this.onAudioEnd) {
                this.onAudioEnd(this);
            }
        }
    }
    set format(format) {
        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
        if (typeof (AudioContext) !== "undefined" || (typeof (window) !== "undefined" && typeof (window.webkitAudioContext) !== "undefined")) {
            this.privFormat = format;
            const mimeType = AudioFormatToMimeType[this.privFormat.formatTag];
            if (mimeType === undefined) {
                // eslint-disable-next-line no-console
                console.warn(`Unknown mimeType for format ${AudioStreamFormat_js_1.AudioFormatTag[this.privFormat.formatTag]}; playback is not supported.`);
            }
            else if (typeof (MediaSource) !== "undefined" && MediaSource.isTypeSupported(mimeType)) {
                this.privAudio = new Audio();
                this.privAudioBuffer = [];
                this.privMediaSource = new MediaSource();
                this.privAudio.src = URL.createObjectURL(this.privMediaSource);
                this.privAudio.load();
                this.privMediaSource.onsourceopen = () => {
                    this.privMediaSourceOpened = true;
                    this.privMediaSource.duration = MediaDurationPlaceholderSeconds;
                    this.privSourceBuffer = this.privMediaSource.addSourceBuffer(mimeType);
                    this.privSourceBuffer.onupdate = () => {
                        this.updateSourceBuffer().catch((reason) => {
                            Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));
                        });
                    };
                    this.privSourceBuffer.onupdateend = () => {
                        this.handleSourceBufferUpdateEnd().catch((reason) => {
                            Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));
                        });
                    };
                    this.privSourceBuffer.onupdatestart = () => {
                        this.privAppendingToBuffer = false;
                    };
                };
                this.updateSourceBuffer().catch((reason) => {
                    Exports_js_1.Events.instance.onEvent(new Exports_js_1.BackgroundEvent(reason));
                });
            }
            else {
                // eslint-disable-next-line no-console
                console.warn(`Format ${AudioStreamFormat_js_1.AudioFormatTag[this.privFormat.formatTag]} could not be played by MSE, streaming playback is not enabled.`);
                this.privAudioOutputStream = new AudioOutputStream_js_1.PullAudioOutputStreamImpl();
                this.privAudioOutputStream.format = this.privFormat;
                this.privAudio = new Audio();
            }
        }
    }
    get volume() {
        return this.privAudio?.volume ?? -1;
    }
    set volume(volume) {
        if (!!this.privAudio) {
            this.privAudio.volume = volume;
        }
    }
    mute() {
        if (!!this.privAudio) {
            this.privAudio.muted = true;
        }
    }
    unmute() {
        if (!!this.privAudio) {
            this.privAudio.muted = false;
        }
    }
    get isClosed() {
        return this.privIsClosed;
    }
    get currentTime() {
        if (this.privAudio !== undefined) {
            return this.privAudio.currentTime;
        }
        return -1;
    }
    pause() {
        if (!this.privIsPaused && this.privAudio !== undefined) {
            this.privAudio.pause();
            this.privIsPaused = true;
        }
    }
    resume(cb, err) {
        if (this.privIsPaused && this.privAudio !== undefined) {
            this.privAudio.play().then(() => {
                if (!!cb) {
                    cb();
                }
            }, (error) => {
                if (!!err) {
                    err(error);
                }
            });
            this.privIsPaused = false;
        }
    }
    get internalAudio() {
        return this.privAudio;
    }
    async updateSourceBuffer() {
        if (this.privAudioBuffer !== undefined && (this.privAudioBuffer.length > 0) && this.sourceBufferAvailable()) {
            this.privAppendingToBuffer = true;
            const binary = this.privAudioBuffer.shift();
            try {
                this.privSourceBuffer.appendBuffer(binary);
            }
            catch (error) {
                this.privAudioBuffer.unshift(binary);
                // eslint-disable-next-line no-console
                console.log("buffer filled, pausing addition of binaries until space is made");
                return;
            }
            await this.notifyPlayback();
        }
        else if (this.canEndStream()) {
            await this.handleSourceBufferUpdateEnd();
        }
    }
    async handleSourceBufferUpdateEnd() {
        if (this.canEndStream() && this.sourceBufferAvailable()) {
            this.privMediaSource.endOfStream();
            await this.notifyPlayback();
        }
    }
    async notifyPlayback() {
        if (!this.privPlaybackStarted && this.privAudio !== undefined) {
            this.privPlaybackStarted = true;
            if (!!this.onAudioStart) {
                this.onAudioStart(this);
            }
            this.privAudio.onended = () => {
                if (!!this.onAudioEnd) {
                    this.onAudioEnd(this);
                }
            };
            if (!this.privIsPaused) {
                await this.privAudio.play();
            }
        }
    }
    canEndStream() {
        return (this.isClosed && this.privSourceBuffer !== undefined && (this.privAudioBuffer.length === 0)
            && this.privMediaSourceOpened && !this.privAppendingToBuffer && this.privMediaSource.readyState === "open");
    }
    sourceBufferAvailable() {
        return (this.privSourceBuffer !== undefined && !this.privSourceBuffer.updating);
    }
}
exports.SpeakerAudioDestination = SpeakerAudioDestination;

//# sourceMappingURL=SpeakerAudioDestination.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageConfig.js"
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageConfig.js ***!
  \*******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AutoDetectSourceLanguageConfig = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const LanguageIdMode_js_1 = __webpack_require__(/*! ./LanguageIdMode.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageIdMode.js");
/**
 * Language auto detect configuration.
 * @class AutoDetectSourceLanguageConfig
 * Added in version 1.13.0.
 */
class AutoDetectSourceLanguageConfig {
    constructor() {
        this.privProperties = new Exports_js_2.PropertyCollection();
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_LanguageIdMode, "AtStart");
        this.privLanguageIdMode = LanguageIdMode_js_1.LanguageIdMode.AtStart;
    }
    /**
     * @member AutoDetectSourceLanguageConfig.fromOpenRange
     * @function
     * @public
     * Only [[SpeechSynthesizer]] supports source language auto detection from open range,
     * for [[Recognizer]], please use AutoDetectSourceLanguageConfig with specific source languages.
     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with open range.
     */
    static fromOpenRange() {
        const config = new AutoDetectSourceLanguageConfig();
        config.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, Exports_js_1.AutoDetectSourceLanguagesOpenRangeOptionName);
        config.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, "en-US");
        return config;
    }
    /**
     * @member AutoDetectSourceLanguageConfig.fromLanguages
     * @function
     * @public
     * @param {string[]} languages Comma-separated string of languages (eg. "en-US,fr-FR") to populate properties of config.
     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given languages.
     */
    static fromLanguages(languages) {
        Contracts_js_1.Contracts.throwIfArrayEmptyOrWhitespace(languages, "languages");
        const config = new AutoDetectSourceLanguageConfig();
        config.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, languages.join());
        return config;
    }
    /**
     * @member AutoDetectSourceLanguageConfig.fromSourceLanguageConfigs
     * @function
     * @public
     * @param {SourceLanguageConfig[]} configs SourceLanguageConfigs to populate properties of config.
     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig
     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given SourceLanguageConfigs.
     */
    static fromSourceLanguageConfigs(configs) {
        if (configs.length < 1) {
            throw new Error("Expected non-empty SourceLanguageConfig array.");
        }
        const autoConfig = new AutoDetectSourceLanguageConfig();
        const langs = [];
        configs.forEach((config) => {
            langs.push(config.language);
            if (config.endpointId !== undefined && config.endpointId !== "") {
                const customProperty = config.language + Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId.toString();
                autoConfig.properties.setProperty(customProperty, config.endpointId);
            }
        });
        autoConfig.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, langs.join());
        return autoConfig;
    }
    /**
     * @member AutoDetectSourceLanguageConfig.prototype.properties
     * @function
     * @public
     * @return {PropertyCollection} Properties of the config.
     * @summary Gets an auto detected language config properties
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * @member AutoDetectSourceLanguageConfig.prototype.mode
     * @function
     * @public
     * @param {LanguageIdMode} mode LID mode desired.
     * @summary Sets LID operation to desired mode
     */
    set mode(mode) {
        if (mode === LanguageIdMode_js_1.LanguageIdMode.Continuous) {
            this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, "2");
            this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_LanguageIdMode, "Continuous");
        }
        else { // LanguageIdMode.AtStart
            this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, "1");
            this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_LanguageIdMode, "AtStart");
        }
        this.privLanguageIdMode = mode;
    }
}
exports.AutoDetectSourceLanguageConfig = AutoDetectSourceLanguageConfig;

//# sourceMappingURL=AutoDetectSourceLanguageConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageResult.js"
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageResult.js ***!
  \*******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AutoDetectSourceLanguageResult = void 0;
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
/**
 * Output format
 * @class AutoDetectSourceLanguageResult
 */
class AutoDetectSourceLanguageResult {
    constructor(language, languageDetectionConfidence) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(language, "language");
        Contracts_js_1.Contracts.throwIfNullOrUndefined(languageDetectionConfidence, "languageDetectionConfidence");
        this.privLanguage = language;
        this.privLanguageDetectionConfidence = languageDetectionConfidence;
    }
    /**
     * Creates an instance of AutoDetectSourceLanguageResult object from a SpeechRecognitionResult instance.
     * @member AutoDetectSourceLanguageResult.fromResult
     * @function
     * @public
     * @param {SpeechRecognitionResult} result - The recognition result.
     * @returns {AutoDetectSourceLanguageResult} AutoDetectSourceLanguageResult object being created.
     */
    static fromResult(result) {
        return new AutoDetectSourceLanguageResult(result.language, result.languageDetectionConfidence);
    }
    /**
     * Creates an instance of AutoDetectSourceLanguageResult object from a ConversationTranscriptionResult instance.
     * @member AutoDetectSourceLanguageResult.fromConversationTranscriptionResult
     * @function
     * @public
     * @param {ConversationTranscriptionResult} result - The transcription result.
     * @returns {AutoDetectSourceLanguageResult} AutoDetectSourceLanguageResult object being created.
     */
    static fromConversationTranscriptionResult(result) {
        return new AutoDetectSourceLanguageResult(result.language, result.languageDetectionConfidence);
    }
    get language() {
        return this.privLanguage;
    }
    get languageDetectionConfidence() {
        return this.privLanguageDetectionConfidence;
    }
}
exports.AutoDetectSourceLanguageResult = AutoDetectSourceLanguageResult;

//# sourceMappingURL=AutoDetectSourceLanguageResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarConfig.js"
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarConfig.js ***!
  \*************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AvatarConfig = void 0;
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines the talking avatar configuration.
 * @class AvatarConfig
 * Added in version 1.33.0
 *
 * @experimental This feature is experimental and might change or have limited support.
 */
class AvatarConfig {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} character - The avatar character.
     * @param {string} style - The avatar style.
     * @param {AvatarVideoFormat} videoFormat - The talking avatar output video format.
     */
    constructor(character, style, videoFormat) {
        this.privCustomized = false;
        this.privUseBuiltInVoice = false;
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(character, "character");
        this.character = character;
        this.style = style;
        if (videoFormat === undefined) {
            videoFormat = new Exports_js_1.AvatarVideoFormat();
        }
        this.videoFormat = videoFormat;
    }
    /**
     * Indicates if the talking avatar is customized.
     */
    get customized() {
        return this.privCustomized;
    }
    /**
     * Sets if the talking avatar is customized.
     */
    set customized(value) {
        this.privCustomized = value;
    }
    /**
     * Indicates whether to use built-in voice for custom avatar.
     */
    get useBuiltInVoice() {
        return this.privUseBuiltInVoice;
    }
    /**
     * Sets whether to use built-in voice for custom avatar.
     */
    set useBuiltInVoice(value) {
        this.privUseBuiltInVoice = value;
    }
    /**
     * Gets the photo avatar base model name.
     */
    get photoAvatarBaseModel() {
        return this.privPhotoAvatarBaseModel;
    }
    /**
     * Sets the photo avatar base model name.
     */
    set photoAvatarBaseModel(value) {
        this.privPhotoAvatarBaseModel = value;
    }
    /**
     * Gets the background color.
     */
    get backgroundColor() {
        return this.privBackgroundColor;
    }
    /**
     * Sets the background color.
     */
    set backgroundColor(value) {
        this.privBackgroundColor = value;
    }
    /**
     * Gets the background image.
     */
    get backgroundImage() {
        return this.privBackgroundImage;
    }
    /**
     * Sets the background image.
     * @param {URL} value - The background image.
     */
    set backgroundImage(value) {
        this.privBackgroundImage = value;
    }
    /**
     * Gets the remote ICE servers.
     * @remarks This method is designed to be used internally in the SDK.
     * @returns {RTCIceServer[]} The remote ICE servers.
     */
    get remoteIceServers() {
        return this.privRemoteIceServers;
    }
    /**
     * Sets the remote ICE servers.
     * @remarks Normally, the ICE servers are gathered from the PeerConnection,
     * set this property to override the ICE servers. E.g., the ICE servers are
     * different in client and server side.
     * @param {RTCIceServer[]} value - The remote ICE servers.
     */
    set remoteIceServers(value) {
        this.privRemoteIceServers = value;
    }
}
exports.AvatarConfig = AvatarConfig;

//# sourceMappingURL=AvatarConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarEventArgs.js"
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarEventArgs.js ***!
  \****************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AvatarEventArgs = exports.AvatarEventTypes = void 0;
var AvatarEventTypes;
(function (AvatarEventTypes) {
    AvatarEventTypes["SwitchedToSpeaking"] = "SwitchedToSpeaking";
    AvatarEventTypes["SwitchedToIdle"] = "SwitchedToIdle";
    AvatarEventTypes["SessionClosed"] = "SessionClosed";
})(AvatarEventTypes = exports.AvatarEventTypes || (exports.AvatarEventTypes = {}));
/**
 * Defines content for talking avatar events.
 * @class AvatarEventArgs
 * Added in version 1.33.0
 *
 * @experimental This feature is experimental and might change or have limited support.
 */
class AvatarEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {number} audioOffset - The audio offset.
     * @param {string} description - The description of the event.
     */
    constructor(audioOffset, description) {
        this.privOffset = audioOffset;
        this.privDescription = description;
    }
    /**
     * The type of the event.
     * @public
     * @returns {AvatarEventTypes} The type of the event.
     */
    get type() {
        return this.privType;
    }
    /**
     * The time offset associated with this event.
     * @public
     * @returns {number} The time offset associated with this event.
     */
    get offset() {
        return this.privOffset;
    }
    /**
     * The description of the event.
     * @public
     * @returns {string} The description of the event.
     */
    get description() {
        return this.privDescription;
    }
}
exports.AvatarEventArgs = AvatarEventArgs;

//# sourceMappingURL=AvatarEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarSynthesizer.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarSynthesizer.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AvatarSynthesizer = void 0;
const SpeechSynthesisConnectionFactory_js_1 = __webpack_require__(/*! ../common.speech/SpeechSynthesisConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SpeechSynthesisConnectionFactory.js");
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const AudioOutputFormat_js_1 = __webpack_require__(/*! ./Audio/AudioOutputFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Synthesizer_js_1 = __webpack_require__(/*! ./Synthesizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js");
/**
 * Defines the avatar synthesizer.
 * @class AvatarSynthesizer
 * Added in version 1.33.0
 *
 * @experimental This feature is experimental and might change or have limited support.
 */
class AvatarSynthesizer extends Exports_js_3.Synthesizer {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {SpeechConfig} speechConfig - The speech config.
     * @param {AvatarConfig} avatarConfig - The talking avatar config.
     */
    constructor(speechConfig, avatarConfig) {
        super(speechConfig);
        Contracts_js_1.Contracts.throwIfNullOrUndefined(avatarConfig, "avatarConfig");
        this.privConnectionFactory = new SpeechSynthesisConnectionFactory_js_1.SpeechSynthesisConnectionFactory();
        this.privAvatarConfig = avatarConfig;
        this.implCommonSynthesizeSetup();
    }
    implCommonSynthesizeSetup() {
        super.implCommonSynthesizeSetup();
        // The service checks the audio format setting while it ignores it in avatar synthesis.
        this.privAdapter.audioOutputFormat = AudioOutputFormat_js_1.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormat(Exports_js_3.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm);
    }
    /**
     * Starts the talking avatar session and establishes the WebRTC connection.
     * @member AvatarSynthesizer.prototype.startAvatarAsync
     * @function
     * @public
     * @param {AvatarWebRTCConnectionInfo} peerConnection - The peer connection.
     * @returns {Promise<SynthesisResult>} The promise of the connection result.
     */
    async startAvatarAsync(peerConnection) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(peerConnection, "peerConnection");
        this.privIceServers = peerConnection.getConfiguration().iceServers;
        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privIceServers, "Ice servers must be set.");
        const iceGatheringDone = new Exports_js_2.Deferred();
        // https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/icegatheringstatechange_event
        peerConnection.onicegatheringstatechange = () => {
            Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent("peer connection: ice gathering state: " + peerConnection.iceGatheringState, Exports_js_2.EventType.Debug));
            if (peerConnection.iceGatheringState === "complete") {
                Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent("peer connection: ice gathering complete.", Exports_js_2.EventType.Info));
                iceGatheringDone.resolve();
            }
        };
        peerConnection.onicecandidate = (event) => {
            if (event.candidate) {
                Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent("peer connection: ice candidate: " + event.candidate.candidate, Exports_js_2.EventType.Debug));
            }
            else {
                Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent("peer connection: ice candidate: complete", Exports_js_2.EventType.Debug));
                iceGatheringDone.resolve();
            }
        };
        // Set a timeout for ice gathering, currently 2 seconds.
        setTimeout(() => {
            if (peerConnection.iceGatheringState !== "complete") {
                Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent("peer connection: ice gathering timeout.", Exports_js_2.EventType.Warning));
                iceGatheringDone.resolve();
            }
        }, 2000);
        const sdp = await peerConnection.createOffer();
        await peerConnection.setLocalDescription(sdp);
        await iceGatheringDone.promise;
        Exports_js_2.Events.instance.onEvent(new Exports_js_2.PlatformEvent("peer connection: got local SDP.", Exports_js_2.EventType.Info));
        this.privProperties.setProperty(Exports_js_3.PropertyId.TalkingAvatarService_WebRTC_SDP, JSON.stringify(peerConnection.localDescription));
        const result = await this.speak("", false);
        if (result.reason !== Exports_js_3.ResultReason.SynthesizingAudioCompleted) {
            return new Exports_js_3.SynthesisResult(result.resultId, result.reason, result.errorDetails, result.properties);
        }
        const sdpAnswerString = atob(result.properties.getProperty(Exports_js_3.PropertyId.TalkingAvatarService_WebRTC_SDP));
        const sdpAnswer = new RTCSessionDescription(JSON.parse(sdpAnswerString));
        await peerConnection.setRemoteDescription(sdpAnswer);
        return new Exports_js_3.SynthesisResult(result.resultId, result.reason, undefined, result.properties);
    }
    /**
     * Speaks plain text asynchronously. The rendered audio and video will be sent via the WebRTC connection.
     * @member AvatarSynthesizer.prototype.speakTextAsync
     * @function
     * @public
     * @param {string} text - The plain text to speak.
     * @returns {Promise<SynthesisResult>} The promise of the synthesis result.
     */
    async speakTextAsync(text) {
        const r = await this.speak(text, false);
        return new Exports_js_3.SynthesisResult(r.resultId, r.reason, r.errorDetails, r.properties);
    }
    /**
     * Speaks SSML asynchronously. The rendered audio and video will be sent via the WebRTC connection.
     * @member AvatarSynthesizer.prototype.speakSsmlAsync
     * @function
     * @public
     * @param {string} ssml - The SSML text to speak.
     * @returns {Promise<SynthesisResult>} The promise of the synthesis result.
     */
    async speakSsmlAsync(ssml) {
        const r = await this.speak(ssml, true);
        return new Exports_js_3.SynthesisResult(r.resultId, r.reason, r.errorDetails, r.properties);
    }
    /**
     * Speaks text asynchronously. The avatar will switch to idle state.
     * @member AvatarSynthesizer.prototype.stopSpeakingAsync
     * @function
     * @public
     * @returns {Promise<void>} The promise of the void result.
     */
    async stopSpeakingAsync() {
        while (this.synthesisRequestQueue.length() > 0) {
            const request = await this.synthesisRequestQueue.dequeue();
            request.err("Synthesis is canceled by user.");
        }
        return this.privAdapter.stopSpeaking();
    }
    /**
     * Stops the talking avatar session and closes the WebRTC connection.
     * For now, this is the same as close().
     * You need to create a new AvatarSynthesizer instance to start a new session.
     * @member AvatarSynthesizer.prototype.stopAvatarAsync
     * @function
     * @public
     * @returns {Promise<void>} The promise of the void result.
     */
    async stopAvatarAsync() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);
        return this.dispose(true);
    }
    /**
     * Dispose of associated resources.
     * @member AvatarSynthesizer.prototype.close
     * @function
     * @public
     */
    async close() {
        if (this.privDisposed) {
            return;
        }
        return this.dispose(true);
    }
    /**
     * Gets the ICE servers. Internal use only.
     */
    get iceServers() {
        return this.privIceServers;
    }
    // Creates the synthesis adapter
    createSynthesisAdapter(authentication, connectionFactory, synthesizerConfig) {
        return new Exports_js_1.AvatarSynthesisAdapter(authentication, connectionFactory, synthesizerConfig, this, this.privAvatarConfig);
    }
    createRestSynthesisAdapter(_authentication, _synthesizerConfig) {
        return undefined;
    }
    createSynthesizerConfig(speechConfig) {
        const config = super.createSynthesizerConfig(speechConfig);
        config.avatarEnabled = true;
        return config;
    }
    async speak(text, isSSML) {
        const requestId = (0, Exports_js_2.createNoDashGuid)();
        const deferredResult = new Exports_js_2.Deferred();
        this.synthesisRequestQueue.enqueue(new Synthesizer_js_1.SynthesisRequest(requestId, text, isSSML, (e) => {
            deferredResult.resolve(e);
            this.privSynthesizing = false;
            void this.adapterSpeak();
        }, (e) => {
            deferredResult.reject(e);
            this.privSynthesizing = false;
        }));
        void this.adapterSpeak();
        return deferredResult.promise;
    }
}
exports.AvatarSynthesizer = AvatarSynthesizer;

//# sourceMappingURL=AvatarSynthesizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarVideoFormat.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarVideoFormat.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AvatarVideoFormat = exports.Coordinate = void 0;
/* eslint-disable max-classes-per-file */
/**
 * Defines a coordinate in 2D space.
 * @class Coordinate
 * Added in version 1.33.0
 */
class Coordinate {
    constructor(x, y) {
        this.x = x;
        this.y = y;
    }
}
exports.Coordinate = Coordinate;
/**
 * Defines the avatar output video format.
 * @class AvatarVideoFormat
 * Added in version 1.33.0
 *
 * @experimental This feature is experimental and might change in the future.
 */
class AvatarVideoFormat {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} codec - The video codec.
     * @param {number} bitrate - The video bitrate.
     * @param {number} width - The video width.
     * @param {number} height - The video height.
     */
    constructor(codec = "H264", bitrate = 2000000, width = 1920, height = 1080) {
        this.codec = codec;
        this.bitrate = bitrate;
        this.width = width;
        this.height = height;
    }
    /**
     * Sets the video crop range.
     */
    setCropRange(topLeft, bottomRight) {
        this.cropRange = {
            bottomRight,
            topLeft,
        };
    }
}
exports.AvatarVideoFormat = AvatarVideoFormat;

//# sourceMappingURL=AvatarVideoFormat.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarWebRTCConnectionResult.js"
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarWebRTCConnectionResult.js ***!
  \*****************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.AvatarWebRTCConnectionResult = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines the avatar WebRTC connection result.
 * @class AvatarWebRTCConnectionResult
 * Added in version 1.33.0
 *
 * @experimental This feature is experimental and might change in the future.
 */
class AvatarWebRTCConnectionResult extends Exports_js_1.SynthesisResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {RTCSessionDescriptionInit} SDPAnswer - The SDP answer of WebRTC connection.
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {string} errorDetails - Error details, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(SDPAnswer, resultId, reason, errorDetails, properties) {
        super(resultId, reason, errorDetails, properties);
        this.privSDPAnswer = SDPAnswer;
    }
    /**
     * Specifies SDP (Session Description Protocol) answer of WebRTC connection.
     * @member AvatarWebRTCConnectionResult.prototype.SDPAnswer
     * @function
     * @public
     * @returns {RTCSessionDescriptionInit} Specifies the SDP answer of WebRTC connection.
     */
    get SDPAnswer() {
        return this.privSDPAnswer;
    }
}
exports.AvatarWebRTCConnectionResult = AvatarWebRTCConnectionResult;

//# sourceMappingURL=AvatarWebRTCConnectionResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/BotFrameworkConfig.js"
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/BotFrameworkConfig.js ***!
  \*******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.BotFrameworkConfig = void 0;
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const DialogServiceConfig_js_1 = __webpack_require__(/*! ./DialogServiceConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js");
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Class that defines configurations for the dialog service connector object for using a Bot Framework backend.
 * @class BotFrameworkConfig
 */
class BotFrameworkConfig extends DialogServiceConfig_js_1.DialogServiceConfigImpl {
    /**
     * Creates an instance of BotFrameworkConfig.
     */
    constructor() {
        super();
    }
    /**
     * Creates a bot framework configuration instance with the provided subscription information.
     * @member BotFrameworkConfig.fromSubscription
     * @function
     * @public
     * @param subscription Subscription key associated with the bot
     * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
     * resource name.
     * @returns {BotFrameworkConfig} A new bot framework configuration instance.
     */
    static fromSubscription(subscription, region, botId) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(subscription, "subscription");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, "region");
        const botFrameworkConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.BotFramework);
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Key, subscription);
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Region, region);
        if (botId) {
            botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, botId);
        }
        return botFrameworkConfig;
    }
    /**
     * Creates a bot framework configuration instance for the specified authorization token and region.
     * Note: The caller must ensure that an authorization token is valid. Before an authorization token expires, the
     * caller must refresh it by setting the authorizationToken property on the corresponding
     * DialogServiceConnector instance created with this config. The contents of configuration objects are copied
     * when connectors are created, so setting authorizationToken on a DialogServiceConnector will not update the
     * original configuration's authorization token. Create a new configuration instance or set the
     * SpeechServiceAuthorization_Token property to update an existing instance if it will be used to create
     * further DialogServiceConnectors.
     * @member BotFrameworkConfig.fromAuthorizationToken
     * @function
     * @public
     * @param authorizationToken The authorization token associated with the bot
     * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
     * resource name.
     * @returns {BotFrameworkConfig} A new bot framework configuration instance.
     */
    static fromAuthorizationToken(authorizationToken, region, botId) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, "region");
        const botFrameworkConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.BotFramework);
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Region, region);
        if (botId) {
            botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, botId);
        }
        return botFrameworkConfig;
    }
    /**
     * Creates an instance of a BotFrameworkConfig.
     * This method is intended only for users who use a non-default service host. The standard resource path will be
     * assumed. For services with a non-standard resource path or no path at all, use fromEndpoint instead.
     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
     * Note: To use an authorization token with fromHost, use fromHost(URL) and then set the AuthorizationToken
     * property on the created BotFrameworkConfig instance.
     * Note: Added in version 1.15.0.
     * @member BotFrameworkConfig.fromHost
     * @function
     * @public
     * @param {URL | string} host - If a URL is provided, the fully-qualified host with protocol (e.g.
     * wss://your.host.com:1234) will be used. If a string is provided, it will be embedded in
     * wss://{host}.convai.speech.azure.us.
     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization
     * token must be set.
     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the
     * resource name.
     * @returns {BotFrameworkConfig} A new bot framework configuration instance.
     */
    static fromHost(host, subscriptionKey, botId) {
        void botId;
        Contracts_js_1.Contracts.throwIfNullOrUndefined(host, "host");
        const resolvedHost = host instanceof URL ? host : new URL(`wss://${host}.convai.speech.azure.us`);
        Contracts_js_1.Contracts.throwIfNullOrUndefined(resolvedHost, "resolvedHost");
        const botFrameworkConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.BotFramework);
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Host, resolvedHost.toString());
        if (undefined !== subscriptionKey) {
            botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
        }
        return botFrameworkConfig;
    }
    /**
     * Creates an instance of a BotFrameworkConfig.
     * This method is intended only for users who use a non-standard service endpoint or parameters.
     * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.
     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
     * fromEndpoint method, and then set authorizationToken="token" on the created BotFrameworkConfig instance to
     * use the authorization token.
     * Note: Added in version 1.15.0.
     * @member BotFrameworkConfig.fromEndpoint
     * @function
     * @public
     * @param {URL} endpoint - The service endpoint to connect to.
     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization
     * token must be set.
     * @returns {BotFrameworkConfig} - A new bot framework configuration instance using the provided endpoint.
     */
    static fromEndpoint(endpoint, subscriptionKey) {
        Contracts_js_1.Contracts.throwIfNull(endpoint, "endpoint");
        const botFrameworkConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.BotFramework);
        botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Endpoint, endpoint.toString());
        if (undefined !== subscriptionKey) {
            botFrameworkConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
        }
        return botFrameworkConfig;
    }
}
exports.BotFrameworkConfig = BotFrameworkConfig;

//# sourceMappingURL=BotFrameworkConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetails.js"
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetails.js ***!
  \********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CancellationDetails = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const CancellationDetailsBase_js_1 = __webpack_require__(/*! ./CancellationDetailsBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetailsBase.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Contains detailed information about why a result was canceled.
 * @class CancellationDetails
 */
class CancellationDetails extends CancellationDetailsBase_js_1.CancellationDetailsBase {
    constructor(reason, errorDetails, errorCode) {
        super(reason, errorDetails, errorCode);
    }
    /**
     * Creates an instance of CancellationDetails object for the canceled RecognitionResult.
     * @member CancellationDetails.fromResult
     * @function
     * @public
     * @param {RecognitionResult | SpeechSynthesisResult} result - The result that was canceled.
     * @returns {CancellationDetails} The cancellation details object being created.
     */
    static fromResult(result) {
        let reason = Exports_js_2.CancellationReason.Error;
        let errorCode = Exports_js_2.CancellationErrorCode.NoError;
        if (result instanceof Exports_js_2.RecognitionResult && !!result.json) {
            const simpleSpeech = Exports_js_1.SimpleSpeechPhrase.fromJSON(result.json, 0); // Offset fixups are already done.
            reason = Exports_js_1.EnumTranslation.implTranslateCancelResult(simpleSpeech.RecognitionStatus);
        }
        if (!!result.properties) {
            errorCode = Exports_js_2.CancellationErrorCode[result.properties.getProperty(Exports_js_1.CancellationErrorCodePropertyName, Exports_js_2.CancellationErrorCode[Exports_js_2.CancellationErrorCode.NoError])];
        }
        return new CancellationDetails(reason, result.errorDetails || Exports_js_1.EnumTranslation.implTranslateErrorDetails(errorCode), errorCode);
    }
}
exports.CancellationDetails = CancellationDetails;

//# sourceMappingURL=CancellationDetails.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetailsBase.js"
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetailsBase.js ***!
  \************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CancellationDetailsBase = void 0;
/**
 * Contains detailed information about why a result was canceled.
 * @class CancellationDetailsBase
 */
class CancellationDetailsBase {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {CancellationReason} reason - The cancellation reason.
     * @param {string} errorDetails - The error details, if provided.
     */
    constructor(reason, errorDetails, errorCode) {
        this.privReason = reason;
        this.privErrorDetails = errorDetails;
        this.privErrorCode = errorCode;
    }
    /**
     * The reason the recognition was canceled.
     * @member CancellationDetailsBase.prototype.reason
     * @function
     * @public
     * @returns {CancellationReason} Specifies the reason canceled.
     */
    get reason() {
        return this.privReason;
    }
    /**
     * In case of an unsuccessful recognition, provides details of the occurred error.
     * @member CancellationDetailsBase.prototype.errorDetails
     * @function
     * @public
     * @returns {string} A String that represents the error details.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
    /**
     * The error code in case of an unsuccessful recognition.
     * Added in version 1.1.0.
     * @return An error code that represents the error reason.
     */
    get ErrorCode() {
        return this.privErrorCode;
    }
}
exports.CancellationDetailsBase = CancellationDetailsBase;

//# sourceMappingURL=CancellationDetailsBase.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationErrorCodes.js"
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationErrorCodes.js ***!
  \***********************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CancellationErrorCode = void 0;
/**
 * Defines error code in case that CancellationReason is Error.
 * Added in version 1.1.0.
 */
var CancellationErrorCode;
(function (CancellationErrorCode) {
    /**
     * Indicates that no error occurred during speech recognition.
     */
    CancellationErrorCode[CancellationErrorCode["NoError"] = 0] = "NoError";
    /**
     * Indicates an authentication error.
     */
    CancellationErrorCode[CancellationErrorCode["AuthenticationFailure"] = 1] = "AuthenticationFailure";
    /**
     * Indicates that one or more recognition parameters are invalid.
     */
    CancellationErrorCode[CancellationErrorCode["BadRequestParameters"] = 2] = "BadRequestParameters";
    /**
     * Indicates that the number of parallel requests exceeded the number of allowed
     * concurrent transcriptions for the subscription.
     */
    CancellationErrorCode[CancellationErrorCode["TooManyRequests"] = 3] = "TooManyRequests";
    /**
     * Indicates a connection error.
     */
    CancellationErrorCode[CancellationErrorCode["ConnectionFailure"] = 4] = "ConnectionFailure";
    /**
     * Indicates a time-out error when waiting for response from service.
     */
    CancellationErrorCode[CancellationErrorCode["ServiceTimeout"] = 5] = "ServiceTimeout";
    /**
     * Indicates that an error is returned by the service.
     */
    CancellationErrorCode[CancellationErrorCode["ServiceError"] = 6] = "ServiceError";
    /**
     * Indicates an unexpected runtime error.
     */
    CancellationErrorCode[CancellationErrorCode["RuntimeError"] = 7] = "RuntimeError";
    /**
     * Indicates an quota overrun on existing key.
     */
    CancellationErrorCode[CancellationErrorCode["Forbidden"] = 8] = "Forbidden";
})(CancellationErrorCode = exports.CancellationErrorCode || (exports.CancellationErrorCode = {}));

//# sourceMappingURL=CancellationErrorCodes.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js"
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js ***!
  \**************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CancellationEventArgsBase = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines content of a CancellationEvent.
 * @class CancellationEventArgsBase
 */
class CancellationEventArgsBase extends Exports_js_1.RecognitionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {CancellationReason} reason - The cancellation reason.
     * @param {string} errorDetails - Error details, if provided.
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(reason, errorDetails, errorCode, offset, sessionId) {
        super(offset, sessionId);
        this.privReason = reason;
        this.privErrorDetails = errorDetails;
        this.privErrorCode = errorCode;
    }
    /**
     * The reason the recognition was canceled.
     * @member CancellationEventArgsBase.prototype.reason
     * @function
     * @public
     * @returns {CancellationReason} Specifies the reason canceled.
     */
    get reason() {
        return this.privReason;
    }
    /**
     * The error code in case of an unsuccessful operation.
     * @return An error code that represents the error reason.
     */
    get errorCode() {
        return this.privErrorCode;
    }
    /**
     * In case of an unsuccessful operation, provides details of the occurred error.
     * @member CancellationEventArgsBase.prototype.errorDetails
     * @function
     * @public
     * @returns {string} A String that represents the error details.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
}
exports.CancellationEventArgsBase = CancellationEventArgsBase;

//# sourceMappingURL=CancellationEventArgsBase.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationReason.js"
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationReason.js ***!
  \*******************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CancellationReason = void 0;
/**
 * Defines the possible reasons a recognition result might be canceled.
 * @class CancellationReason
 */
var CancellationReason;
(function (CancellationReason) {
    /**
     * Indicates that an error occurred during speech recognition.
     * @member CancellationReason.Error
     */
    CancellationReason[CancellationReason["Error"] = 0] = "Error";
    /**
     * Indicates that the end of the audio stream was reached.
     * @member CancellationReason.EndOfStream
     */
    CancellationReason[CancellationReason["EndOfStream"] = 1] = "EndOfStream";
})(CancellationReason = exports.CancellationReason || (exports.CancellationReason = {}));

//# sourceMappingURL=CancellationReason.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Connection.js"
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Connection.js ***!
  \***********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Connection = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const ConnectionMessage_js_1 = __webpack_require__(/*! ./ConnectionMessage.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessage.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Connection is a proxy class for managing connection to the speech service of the specified Recognizer.
 * By default, a Recognizer autonomously manages connection to service when needed.
 * The Connection class provides additional methods for users to explicitly open or close a connection and
 * to subscribe to connection status changes.
 * The use of Connection is optional, and mainly for scenarios where fine tuning of application
 * behavior based on connection status is needed. Users can optionally call Open() to manually set up a connection
 * in advance before starting recognition on the Recognizer associated with this Connection.
 * If the Recognizer needs to connect or disconnect to service, it will
 * setup or shutdown the connection independently. In this case the Connection will be notified by change of connection
 * status via Connected/Disconnected events.
 * Added in version 1.2.1.
 */
class Connection {
    /**
     * Gets the Connection instance from the specified recognizer.
     * @param recognizer The recognizer associated with the connection.
     * @return The Connection instance of the recognizer.
     */
    static fromRecognizer(recognizer) {
        const recoBase = recognizer.internalData;
        const ret = new Connection();
        ret.privInternalData = recoBase;
        ret.setupEvents();
        return ret;
    }
    /**
     * Gets the Connection instance from the specified synthesizer.
     * @param synthesizer The synthesizer associated with the connection.
     * @return The Connection instance of the synthesizer.
     */
    static fromSynthesizer(synthesizer) {
        const synthBase = synthesizer.internalData;
        const ret = new Connection();
        ret.privInternalData = synthBase;
        ret.setupEvents();
        return ret;
    }
    /**
     * Starts to set up connection to the service.
     * Users can optionally call openConnection() to manually set up a connection in advance before starting recognition on the
     * Recognizer associated with this Connection. After starting recognition, calling Open() will have no effect
     *
     * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
     * be notified when the connection is established.
     */
    openConnection(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.privInternalData.connect(), cb, err);
    }
    /**
     * Closes the connection the service.
     * Users can optionally call closeConnection() to manually shutdown the connection of the associated Recognizer.
     *
     * If closeConnection() is called during recognition, recognition will fail and cancel with an error.
     */
    closeConnection(cb, err) {
        if (this.privInternalData instanceof Exports_js_1.SynthesisAdapterBase) {
            throw new Error("Disconnecting a synthesizer's connection is currently not supported");
        }
        else {
            (0, Exports_js_2.marshalPromiseToCallbacks)(this.privInternalData.disconnect(), cb, err);
        }
    }
    /**
     * Appends a parameter in a message to service.
     * Added in version 1.12.1.
     * @param path The path of the network message.
     * @param propertyName Name of the property
     * @param propertyValue Value of the property. This is a json string.
     */
    setMessageProperty(path, propertyName, propertyValue) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(propertyName, "propertyName");
        if (this.privInternalData instanceof Exports_js_1.ServiceRecognizerBase) {
            if (path.toLowerCase() !== "speech.context") {
                throw new Error("Only speech.context message property sets are currently supported for recognizer");
            }
            else {
                const context = this.privInternalData.speechContext.getContext();
                context[propertyName] = propertyValue;
            }
        }
        else if (this.privInternalData instanceof Exports_js_1.SynthesisAdapterBase) {
            if (path.toLowerCase() !== "speech.config" && path.toLowerCase() !== "synthesis.context") {
                throw new Error("Only speech.config and synthesis.context message paths are currently supported for synthesizer");
            }
            else if (path.toLowerCase() === "speech.config") {
                if (propertyName.toLowerCase() !== "context") {
                    throw new Error("Only context property is currently supported for speech.config message path for synthesizer");
                }
                else {
                    this.privInternalData.synthesizerConfig.setContextFromJson(propertyValue);
                }
            }
            else {
                this.privInternalData.synthesisContext.setSection(propertyName, propertyValue);
            }
        }
    }
    /**
     * Sends a message to the speech service.
     * Added in version 1.13.0.
     * @param path The WebSocket path of the message
     * @param payload The payload of the message. This is a json string or a ArrayBuffer.
     * @param success A callback to indicate success.
     * @param error A callback to indicate an error.
     */
    sendMessageAsync(path, payload, success, error) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.privInternalData.sendNetworkMessage(path, payload), success, error);
    }
    /**
     * Dispose of associated resources.
     */
    close() {
        /* eslint-disable no-empty */
    }
    setupEvents() {
        this.privEventListener = this.privInternalData.connectionEvents.attach((connectionEvent) => {
            if (connectionEvent.name === "ConnectionEstablishedEvent") {
                if (!!this.connected) {
                    this.connected(new Exports_js_3.ConnectionEventArgs(connectionEvent.connectionId));
                }
            }
            else if (connectionEvent.name === "ConnectionClosedEvent") {
                if (!!this.disconnected) {
                    this.disconnected(new Exports_js_3.ConnectionEventArgs(connectionEvent.connectionId));
                }
            }
            else if (connectionEvent.name === "ConnectionMessageSentEvent") {
                if (!!this.messageSent) {
                    this.messageSent(new Exports_js_3.ConnectionMessageEventArgs(new ConnectionMessage_js_1.ConnectionMessageImpl(connectionEvent.message)));
                }
            }
            else if (connectionEvent.name === "ConnectionMessageReceivedEvent") {
                if (!!this.messageReceived) {
                    this.messageReceived(new Exports_js_3.ConnectionMessageEventArgs(new ConnectionMessage_js_1.ConnectionMessageImpl(connectionEvent.message)));
                }
            }
        });
        this.privServiceEventListener = this.privInternalData.serviceEvents.attach((e) => {
            if (!!this.receivedServiceMessage) {
                this.receivedServiceMessage(new Exports_js_3.ServiceEventArgs(e.jsonString, e.name));
            }
        });
    }
}
exports.Connection = Connection;

//# sourceMappingURL=Connection.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionEventArgs.js"
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionEventArgs.js ***!
  \********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConnectionEventArgs = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines payload for connection events like Connected/Disconnected.
 * Added in version 1.2.0
 */
class ConnectionEventArgs extends Exports_js_1.SessionEventArgs {
}
exports.ConnectionEventArgs = ConnectionEventArgs;

//# sourceMappingURL=ConnectionEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessage.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessage.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConnectionMessageImpl = exports.ConnectionMessage = void 0;
// eslint-disable-next-line max-classes-per-file
const HeaderNames_js_1 = __webpack_require__(/*! ../common.speech/HeaderNames.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/HeaderNames.js");
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const PropertyCollection_js_1 = __webpack_require__(/*! ./PropertyCollection.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyCollection.js");
const PropertyId_js_1 = __webpack_require__(/*! ./PropertyId.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js");
/**
 * ConnectionMessage represents implementation specific messages sent to and received from
 * the speech service. These messages are provided for debugging purposes and should not
 * be used for production use cases with the Azure Cognitive Services Speech Service.
 * Messages sent to and received from the Speech Service are subject to change without
 * notice. This includes message contents, headers, payloads, ordering, etc.
 * Added in version 1.11.0.
 */
class ConnectionMessage {
}
exports.ConnectionMessage = ConnectionMessage;
class ConnectionMessageImpl {
    constructor(message) {
        this.privConnectionMessage = message;
        this.privProperties = new PropertyCollection_js_1.PropertyCollection();
        if (!!this.privConnectionMessage.headers[HeaderNames_js_1.HeaderNames.ConnectionId]) {
            this.privProperties.setProperty(PropertyId_js_1.PropertyId.Speech_SessionId, this.privConnectionMessage.headers[HeaderNames_js_1.HeaderNames.ConnectionId]);
        }
        Object.keys(this.privConnectionMessage.headers).forEach((header) => {
            this.privProperties.setProperty(header, this.privConnectionMessage.headers[header]);
        });
    }
    /**
     * The message path.
     */
    get path() {
        return this.privConnectionMessage.headers[Object.keys(this.privConnectionMessage.headers).find((key) => key.toLowerCase() === "path".toLowerCase())];
    }
    /**
     * Checks to see if the ConnectionMessage is a text message.
     * See also IsBinaryMessage().
     */
    get isTextMessage() {
        return this.privConnectionMessage.messageType === Exports_js_1.MessageType.Text;
    }
    /**
     * Checks to see if the ConnectionMessage is a binary message.
     * See also GetBinaryMessage().
     */
    get isBinaryMessage() {
        return this.privConnectionMessage.messageType === Exports_js_1.MessageType.Binary;
    }
    /**
     * Gets the text message payload. Typically the text message content-type is
     * application/json. To determine other content-types use
     * Properties.GetProperty("Content-Type").
     */
    get TextMessage() {
        return this.privConnectionMessage.textBody;
    }
    /**
     * Gets the binary message payload.
     */
    get binaryMessage() {
        return this.privConnectionMessage.binaryBody;
    }
    /**
     * A collection of properties and their values defined for this <see cref="ConnectionMessage"/>.
     * Message headers can be accessed via this collection (e.g. "Content-Type").
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Returns a string that represents the connection message.
     */
    toString() {
        return "";
    }
}
exports.ConnectionMessageImpl = ConnectionMessageImpl;

//# sourceMappingURL=ConnectionMessage.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessageEventArgs.js"
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessageEventArgs.js ***!
  \***************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConnectionMessageEventArgs = void 0;
class ConnectionMessageEventArgs {
    constructor(message) {
        this.privConnectionMessage = message;
    }
    /**
     * Gets the <see cref="ConnectionMessage"/> associated with this <see cref="ConnectionMessageEventArgs"/>.
     */
    get message() {
        return this.privConnectionMessage;
    }
    /**
     * Returns a string that represents the connection message event.
     */
    toString() {
        return "Message: " + this.privConnectionMessage.toString();
    }
}
exports.ConnectionMessageEventArgs = ConnectionMessageEventArgs;

//# sourceMappingURL=ConnectionMessageEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js"
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js ***!
  \**********************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Contracts = void 0;
/**
 * @class Contracts
 * @private
 */
class Contracts {
    static throwIfNullOrUndefined(param, name) {
        if (param === undefined || param === null) {
            throw new Error("throwIfNullOrUndefined:" + name);
        }
    }
    static throwIfNull(param, name) {
        if (param === null) {
            throw new Error("throwIfNull:" + name);
        }
    }
    static throwIfNullOrWhitespace(param, name) {
        Contracts.throwIfNullOrUndefined(param, name);
        if (("" + param).trim().length < 1) {
            throw new Error("throwIfNullOrWhitespace:" + name);
        }
    }
    static throwIfNullOrTooLong(param, name, maxLength) {
        Contracts.throwIfNullOrUndefined(param, name);
        if (("" + param).length > maxLength) {
            throw new Error("throwIfNullOrTooLong:" + name + " (more than " + maxLength.toString() + " characters)");
        }
    }
    static throwIfNullOrTooShort(param, name, minLength) {
        Contracts.throwIfNullOrUndefined(param, name);
        if (("" + param).length < minLength) {
            throw new Error("throwIfNullOrTooShort:" + name + " (less than " + minLength.toString() + " characters)");
        }
    }
    static throwIfDisposed(isDisposed) {
        if (isDisposed) {
            throw new Error("the object is already disposed");
        }
    }
    static throwIfArrayEmptyOrWhitespace(array, name) {
        Contracts.throwIfNullOrUndefined(array, name);
        if (array.length === 0) {
            throw new Error("throwIfArrayEmptyOrWhitespace:" + name);
        }
        for (const item of array) {
            Contracts.throwIfNullOrWhitespace(item, name);
        }
    }
    static throwIfFileDoesNotExist(param, name) {
        Contracts.throwIfNullOrWhitespace(param, name);
        // TODO check for file existence.
    }
    static throwIfNotUndefined(param, name) {
        if (param !== undefined) {
            throw new Error("throwIfNotUndefined:" + name);
        }
    }
    static throwIfNumberOutOfRange(value, name, rangeStart, rangeEnd) {
        Contracts.throwIfNullOrUndefined(value, name);
        if (value < rangeStart || value > rangeEnd) {
            throw new Error("throwIfNumberOutOfRange:" + name + " (must be between " + rangeStart.toString() + " and " + rangeEnd.toString() + ")");
        }
    }
}
exports.Contracts = Contracts;

//# sourceMappingURL=Contracts.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConversationTranscriptionCanceledEventArgs.js"
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConversationTranscriptionCanceledEventArgs.js ***!
  \*******************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranscriptionCanceledEventArgs = void 0;
const CancellationEventArgsBase_js_1 = __webpack_require__(/*! ./CancellationEventArgsBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js");
/**
 * Defines content of a RecognitionErrorEvent.
 * @class ConversationTranscriptionCanceledEventArgs
 */
class ConversationTranscriptionCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {
}
exports.ConversationTranscriptionCanceledEventArgs = ConversationTranscriptionCanceledEventArgs;

//# sourceMappingURL=ConversationTranscriptionCanceledEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CustomCommandsConfig.js"
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CustomCommandsConfig.js ***!
  \*********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CustomCommandsConfig = void 0;
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const DialogServiceConfig_js_1 = __webpack_require__(/*! ./DialogServiceConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js");
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Class that defines configurations for the dialog service connector object for using a CustomCommands backend.
 * @class CustomCommandsConfig
 */
class CustomCommandsConfig extends DialogServiceConfig_js_1.DialogServiceConfigImpl {
    /**
     * Creates an instance of CustomCommandsConfig.
     */
    constructor() {
        super();
    }
    /**
     * Creates an instance of the bot framework config with the specified subscription and region.
     * @member CustomCommandsConfig.fromSubscription
     * @function
     * @public
     * @param applicationId Speech Commands application id.
     * @param subscription Subscription key associated with the bot
     * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {CustomCommandsConfig} A new bot framework config.
     */
    static fromSubscription(applicationId, subscription, region) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(applicationId, "applicationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(subscription, "subscription");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, "region");
        const customCommandsConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();
        customCommandsConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.CustomCommands);
        customCommandsConfig.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, applicationId);
        customCommandsConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Key, subscription);
        customCommandsConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Region, region);
        return customCommandsConfig;
    }
    /**
     * Creates an instance of the bot framework config with the specified Speech Commands application id, authorization token and region.
     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
     * expires, the caller needs to refresh it by calling this setter with a new valid token.
     * As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
     * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
     * @member CustomCommandsConfig.fromAuthorizationToken
     * @function
     * @public
     * @param applicationId Speech Commands application id.
     * @param authorizationToken The authorization token associated with the application.
     * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {CustomCommandsConfig} A new speech commands config.
     */
    static fromAuthorizationToken(applicationId, authorizationToken, region) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(applicationId, "applicationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, "region");
        const customCommandsConfig = new DialogServiceConfig_js_1.DialogServiceConfigImpl();
        customCommandsConfig.setProperty(Exports_js_1.PropertyId.Conversation_DialogType, DialogServiceConfig_js_1.DialogServiceConfig.DialogTypes.CustomCommands);
        customCommandsConfig.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, applicationId);
        customCommandsConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);
        customCommandsConfig.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_Region, region);
        return customCommandsConfig;
    }
    /**
     * Sets the corresponding backend application identifier.
     * @member CustomCommandsConfig.prototype.Conversation_ApplicationId
     * @function
     * @public
     * @param {string} value - The application identifier to set.
     */
    set applicationId(value) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, "value");
        this.setProperty(Exports_js_1.PropertyId.Conversation_ApplicationId, value);
    }
    /**
     * Gets the corresponding backend application identifier.
     * @member CustomCommandsConfig.prototype.Conversation_ApplicationId
     * @function
     * @public
     * @param {string} value - The application identifier to get.
     */
    get applicationId() {
        return this.getProperty(Exports_js_1.PropertyId.Conversation_ApplicationId);
    }
}
exports.CustomCommandsConfig = CustomCommandsConfig;

//# sourceMappingURL=CustomCommandsConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Diagnostics.js"
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Diagnostics.js ***!
  \************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Diagnostics = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.browser/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
/**
 * Defines diagnostics API for managing console output
 * Added in version 1.21.0
 */
class Diagnostics {
    static SetLoggingLevel(logLevel) {
        this.privListener = new Exports_js_1.ConsoleLoggingListener(logLevel);
        Exports_js_2.Events.instance.attachConsoleListener(this.privListener);
    }
    static StartConsoleOutput() {
        if (!!this.privListener) {
            this.privListener.enableConsoleOutput = true;
        }
    }
    static StopConsoleOutput() {
        if (!!this.privListener) {
            this.privListener.enableConsoleOutput = false;
        }
    }
    static SetLogOutputPath(path) {
        if (typeof window === "undefined") {
            if (!!this.privListener) {
                this.privListener.logPath = path;
            }
        }
        else {
            throw new Error("File system logging not available in browser.");
        }
    }
    static set onLogOutput(callback) {
        if (!!this.privListener) {
            this.privListener.logCallback = callback;
        }
    }
}
exports.Diagnostics = Diagnostics;
Diagnostics.privListener = undefined;

//# sourceMappingURL=Diagnostics.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js"
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js ***!
  \********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DialogServiceConfigImpl = exports.DialogServiceConfig = void 0;
/* eslint-disable max-classes-per-file */
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Class that defines base configurations for dialog service connector
 * @class DialogServiceConfig
 */
class DialogServiceConfig {
    /**
     * Creates an instance of DialogService config.
     * @constructor
     */
    constructor() {
        return;
    }
    /**
     * Sets the corresponding backend application identifier.
     * @member DialogServiceConfig.prototype.Conversation_ApplicationId
     * @function
     * @public
     * @param {string} value - The application identifier to set.
     */
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    set applicationId(value) { }
    static get DialogTypes() {
        return {
            BotFramework: "bot_framework",
            CustomCommands: "custom_commands"
        };
    }
}
exports.DialogServiceConfig = DialogServiceConfig;
/**
 * Dialog Service configuration.
 * @class DialogServiceConfigImpl
 */
class DialogServiceConfigImpl extends DialogServiceConfig {
    /**
     * Creates an instance of dialogService config.
     */
    constructor() {
        super();
        this.privSpeechConfig = new Exports_js_1.SpeechConfigImpl();
    }
    /**
     * Provides access to custom properties.
     * @member DialogServiceConfigImpl.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The properties.
     */
    get properties() {
        return this.privSpeechConfig.properties;
    }
    /**
     * Gets the speech recognition language.
     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage
     * @function
     * @public
     */
    get speechRecognitionLanguage() {
        return this.privSpeechConfig.speechRecognitionLanguage;
    }
    /**
     * Sets the speech recognition language.
     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @param {string} value - The language to set.
     */
    set speechRecognitionLanguage(value) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, "value");
        this.privSpeechConfig.speechRecognitionLanguage = value;
    }
    get outputFormat() {
        return this.privSpeechConfig.outputFormat;
    }
    set outputFormat(value) {
        this.privSpeechConfig.outputFormat = value;
    }
    /**
     * Sets a named property as value
     * @member DialogServiceConfigImpl.prototype.setProperty
     * @function
     * @public
     * @param {PropertyId | string} name - The property to set.
     * @param {string} value - The value.
     */
    setProperty(name, value) {
        this.privSpeechConfig.setProperty(name, value);
    }
    /**
     * Sets a named property as value
     * @member DialogServiceConfigImpl.prototype.getProperty
     * @function
     * @public
     * @param {PropertyId | string} name - The property to get.
     * @param {string} def - The default value to return in case the property is not known.
     * @returns {string} The current value, or provided default, of the given property.
     */
    getProperty(name, def) {
        void def;
        return this.privSpeechConfig.getProperty(name);
    }
    /**
     * Sets the proxy configuration.
     * Only relevant in Node.js environments.
     * Added in version 1.4.0.
     * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)
     * @param proxyPort The port number of the proxy server.
     * @param proxyUserName The user name of the proxy server.
     * @param proxyPassword The password of the proxy server.
     */
    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
        this.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyHostName, proxyHostName);
        this.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyPort, `${proxyPort}`);
        if (proxyUserName) {
            this.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyUserName, proxyUserName);
        }
        if (proxyPassword) {
            this.setProperty(Exports_js_1.PropertyId.SpeechServiceConnection_ProxyPassword, proxyPassword);
        }
    }
    setServiceProperty(name, value, channel) {
        void channel;
        this.privSpeechConfig.setServiceProperty(name, value);
    }
    /**
     * Dispose of associated resources.
     * @member DialogServiceConfigImpl.prototype.close
     * @function
     * @public
     */
    close() {
        return;
    }
}
exports.DialogServiceConfigImpl = DialogServiceConfigImpl;

//# sourceMappingURL=DialogServiceConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConnector.js"
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConnector.js ***!
  \***********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.DialogServiceConnector = void 0;
const DialogConnectorFactory_js_1 = __webpack_require__(/*! ../common.speech/DialogConnectorFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/DialogConnectorFactory.js");
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ../common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const PropertyId_js_1 = __webpack_require__(/*! ./PropertyId.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js");
/**
 * Dialog Service Connector
 * @class DialogServiceConnector
 */
class DialogServiceConnector extends Exports_js_3.Recognizer {
    /**
     * Initializes an instance of the DialogServiceConnector.
     * @constructor
     * @param {DialogServiceConfig} dialogConfig - Set of properties to configure this recognizer.
     * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
     */
    constructor(dialogConfig, audioConfig) {
        const dialogServiceConfigImpl = dialogConfig;
        Contracts_js_1.Contracts.throwIfNull(dialogConfig, "dialogConfig");
        super(audioConfig, dialogServiceConfigImpl.properties, new DialogConnectorFactory_js_1.DialogConnectionFactory());
        this.isTurnComplete = true;
        this.privIsDisposed = false;
        this.privProperties = dialogServiceConfigImpl.properties.clone();
        const agentConfig = this.buildAgentConfig();
        this.privReco.agentConfig.set(agentConfig);
    }
    /**
     * Starts a connection to the service.
     * Users can optionally call connect() to manually set up a connection in advance, before starting interactions.
     *
     * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
     * be notified when the connection is established.
     * @member DialogServiceConnector.prototype.connect
     * @function
     * @public
     */
    connect(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.privReco.connect(), cb, err);
    }
    /**
     * Closes the connection the service.
     * Users can optionally call disconnect() to manually shutdown the connection of the associated DialogServiceConnector.
     *
     * If disconnect() is called during a recognition, recognition will fail and cancel with an error.
     */
    disconnect(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.privReco.disconnect(), cb, err);
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member DialogServiceConnector.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(PropertyId_js_1.PropertyId.SpeechServiceAuthorization_Token);
    }
    /**
     * Sets the authorization token used to communicate with the service.
     * @member DialogServiceConnector.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(PropertyId_js_1.PropertyId.SpeechServiceAuthorization_Token, token);
    }
    /**
     * The collection of properties and their values defined for this DialogServiceConnector.
     * @member DialogServiceConnector.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this DialogServiceConnector.
     */
    get properties() {
        return this.privProperties;
    }
    /** Gets the template for the activity generated by service from speech.
     * Properties from the template will be stamped on the generated activity.
     * It can be empty
     */
    get speechActivityTemplate() {
        return this.properties.getProperty(PropertyId_js_1.PropertyId.Conversation_Speech_Activity_Template);
    }
    /** Sets the template for the activity generated by service from speech.
     * Properties from the template will be stamped on the generated activity.
     * It can be null or empty.
     * Note: it has to be a valid Json object.
     */
    set speechActivityTemplate(speechActivityTemplate) {
        this.properties.setProperty(PropertyId_js_1.PropertyId.Conversation_Speech_Activity_Template, speechActivityTemplate);
    }
    /**
     * Starts recognition and stops after the first utterance is recognized.
     * @member DialogServiceConnector.prototype.listenOnceAsync
     * @function
     * @public
     * @param cb - Callback that received the result when the reco has completed.
     * @param err - Callback invoked in case of an error.
     */
    listenOnceAsync(cb, err) {
        if (this.isTurnComplete) {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            const callbackHolder = async () => {
                await this.privReco.connect();
                await this.implRecognizerStop();
                this.isTurnComplete = false;
                const ret = new Exports_js_2.Deferred();
                await this.privReco.recognize(PhraseDetectionContext_js_1.RecognitionMode.Conversation, ret.resolve, ret.reject);
                const e = await ret.promise;
                await this.implRecognizerStop();
                return e;
            };
            const retPromise = callbackHolder();
            retPromise.catch(() => {
                // Destroy the recognizer.
                // We've done all we can here.
                // eslint-disable-next-line @typescript-eslint/no-empty-function
                this.dispose(true).catch(() => { });
            });
            (0, Exports_js_2.marshalPromiseToCallbacks)(retPromise.finally(() => {
                this.isTurnComplete = true;
            }), cb, err);
        }
    }
    sendActivityAsync(activity, cb, errCb) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.privReco.sendMessage(activity), cb, errCb);
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member DialogServiceConnector.prototype.close
     * @function
     * @public
     */
    close(cb, err) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.dispose(true), cb, err);
    }
    async dispose(disposing) {
        if (this.privIsDisposed) {
            return;
        }
        if (disposing) {
            this.privIsDisposed = true;
            await this.implRecognizerStop();
            await super.dispose(disposing);
        }
    }
    createRecognizerConfig(speechConfig) {
        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const audioSource = audioConfig;
        return new Exports_js_1.DialogServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);
    }
    buildAgentConfig() {
        const communicationType = this.properties.getProperty("Conversation_Communication_Type", "Default");
        return {
            botInfo: {
                commType: communicationType,
                commandsCulture: undefined,
                connectionId: this.properties.getProperty(PropertyId_js_1.PropertyId.Conversation_Agent_Connection_Id),
                conversationId: this.properties.getProperty(PropertyId_js_1.PropertyId.Conversation_Conversation_Id, undefined),
                fromId: this.properties.getProperty(PropertyId_js_1.PropertyId.Conversation_From_Id, undefined),
                ttsAudioFormat: this.properties.getProperty(PropertyId_js_1.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)
            },
            version: 0.2
        };
    }
}
exports.DialogServiceConnector = DialogServiceConnector;

//# sourceMappingURL=DialogServiceConnector.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js"
/*!********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js ***!
  \********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.CustomCommandsConfig = exports.BotFrameworkConfig = exports.DialogServiceConfig = exports.PhraseListGrammar = exports.Connection = exports.ServiceEventArgs = exports.ConnectionEventArgs = exports.CancellationErrorCode = exports.CancellationDetails = exports.CancellationDetailsBase = exports.TranslationRecognitionCanceledEventArgs = exports.NoMatchDetails = exports.NoMatchReason = exports.Translations = exports.TranslationRecognizer = exports.SpeechRecognizer = exports.Recognizer = exports.PropertyId = exports.PropertyCollection = exports.SpeechTranslationConfigImpl = exports.SpeechTranslationConfig = exports.SpeechConfigImpl = exports.SpeechConfig = exports.ResultReason = exports.TranslationSynthesisResult = exports.TranslationRecognitionResult = exports.TranslationSynthesisEventArgs = exports.TranslationRecognitionEventArgs = exports.SpeechRecognitionCanceledEventArgs = exports.MeetingTranscriptionEventArgs = exports.ConversationTranscriptionEventArgs = exports.SpeechRecognitionEventArgs = exports.SpeechRecognitionResult = exports.RecognitionResult = exports.OutputFormat = exports.RecognitionEventArgs = exports.SessionEventArgs = exports.KeywordRecognitionModel = exports.PushAudioOutputStreamCallback = exports.PullAudioInputStreamCallback = exports.CancellationReason = exports.PushAudioOutputStream = exports.PullAudioOutputStream = exports.AudioOutputStream = exports.PushAudioInputStream = exports.PullAudioInputStream = exports.AudioInputStream = exports.AudioFormatTag = exports.AudioStreamFormat = exports.AudioConfig = void 0;
exports.AvatarSynthesizer = exports.AvatarEventArgs = exports.AvatarConfig = exports.LanguageIdMode = exports.PronunciationAssessmentResult = exports.PronunciationAssessmentConfig = exports.PronunciationAssessmentGranularity = exports.PronunciationAssessmentGradingSystem = exports.MeetingTranscriptionCanceledEventArgs = exports.ConversationTranscriptionCanceledEventArgs = exports.SpeakerAudioDestination = exports.VoiceInfo = exports.SynthesisVoiceType = exports.SynthesisVoiceGender = exports.SynthesisVoicesResult = exports.SpeechSynthesisBoundaryType = exports.SpeechSynthesisVisemeEventArgs = exports.SpeechSynthesisBookmarkEventArgs = exports.SpeechSynthesisWordBoundaryEventArgs = exports.SpeechSynthesisEventArgs = exports.SpeechSynthesisResult = exports.SynthesisResult = exports.SpeechSynthesizer = exports.SpeechSynthesisOutputFormat = exports.Synthesizer = exports.User = exports.ParticipantChangedReason = exports.Participant = exports.MeetingTranscriber = exports.Meeting = exports.ConversationTranscriptionResult = exports.ConversationTranscriber = exports.ConversationTranslator = exports.ConversationTranslationResult = exports.ConversationTranslationEventArgs = exports.ConversationTranslationCanceledEventArgs = exports.ConversationParticipantsChangedEventArgs = exports.ConversationExpirationEventArgs = exports.Conversation = exports.SourceLanguageConfig = exports.AutoDetectSourceLanguageResult = exports.AutoDetectSourceLanguageConfig = exports.ConnectionMessage = exports.ConnectionMessageEventArgs = exports.BaseAudioPlayer = exports.ProfanityOption = exports.ServicePropertyChannel = exports.TurnStatusReceivedEventArgs = exports.ActivityReceivedEventArgs = exports.DialogServiceConnector = void 0;
exports.LogLevel = exports.Diagnostics = exports.AvatarWebRTCConnectionResult = exports.Coordinate = exports.AvatarVideoFormat = void 0;
var AudioConfig_js_1 = __webpack_require__(/*! ./Audio/AudioConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioConfig.js");
Object.defineProperty(exports, "AudioConfig", ({ enumerable: true, get: function () { return AudioConfig_js_1.AudioConfig; } }));
var AudioStreamFormat_js_1 = __webpack_require__(/*! ./Audio/AudioStreamFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat.js");
Object.defineProperty(exports, "AudioStreamFormat", ({ enumerable: true, get: function () { return AudioStreamFormat_js_1.AudioStreamFormat; } }));
Object.defineProperty(exports, "AudioFormatTag", ({ enumerable: true, get: function () { return AudioStreamFormat_js_1.AudioFormatTag; } }));
var AudioInputStream_js_1 = __webpack_require__(/*! ./Audio/AudioInputStream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioInputStream.js");
Object.defineProperty(exports, "AudioInputStream", ({ enumerable: true, get: function () { return AudioInputStream_js_1.AudioInputStream; } }));
Object.defineProperty(exports, "PullAudioInputStream", ({ enumerable: true, get: function () { return AudioInputStream_js_1.PullAudioInputStream; } }));
Object.defineProperty(exports, "PushAudioInputStream", ({ enumerable: true, get: function () { return AudioInputStream_js_1.PushAudioInputStream; } }));
var AudioOutputStream_js_1 = __webpack_require__(/*! ./Audio/AudioOutputStream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js");
Object.defineProperty(exports, "AudioOutputStream", ({ enumerable: true, get: function () { return AudioOutputStream_js_1.AudioOutputStream; } }));
Object.defineProperty(exports, "PullAudioOutputStream", ({ enumerable: true, get: function () { return AudioOutputStream_js_1.PullAudioOutputStream; } }));
Object.defineProperty(exports, "PushAudioOutputStream", ({ enumerable: true, get: function () { return AudioOutputStream_js_1.PushAudioOutputStream; } }));
var CancellationReason_js_1 = __webpack_require__(/*! ./CancellationReason.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationReason.js");
Object.defineProperty(exports, "CancellationReason", ({ enumerable: true, get: function () { return CancellationReason_js_1.CancellationReason; } }));
var PullAudioInputStreamCallback_js_1 = __webpack_require__(/*! ./Audio/PullAudioInputStreamCallback.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PullAudioInputStreamCallback.js");
Object.defineProperty(exports, "PullAudioInputStreamCallback", ({ enumerable: true, get: function () { return PullAudioInputStreamCallback_js_1.PullAudioInputStreamCallback; } }));
var PushAudioOutputStreamCallback_js_1 = __webpack_require__(/*! ./Audio/PushAudioOutputStreamCallback.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/PushAudioOutputStreamCallback.js");
Object.defineProperty(exports, "PushAudioOutputStreamCallback", ({ enumerable: true, get: function () { return PushAudioOutputStreamCallback_js_1.PushAudioOutputStreamCallback; } }));
var KeywordRecognitionModel_js_1 = __webpack_require__(/*! ./KeywordRecognitionModel.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/KeywordRecognitionModel.js");
Object.defineProperty(exports, "KeywordRecognitionModel", ({ enumerable: true, get: function () { return KeywordRecognitionModel_js_1.KeywordRecognitionModel; } }));
var SessionEventArgs_js_1 = __webpack_require__(/*! ./SessionEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SessionEventArgs.js");
Object.defineProperty(exports, "SessionEventArgs", ({ enumerable: true, get: function () { return SessionEventArgs_js_1.SessionEventArgs; } }));
var RecognitionEventArgs_js_1 = __webpack_require__(/*! ./RecognitionEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionEventArgs.js");
Object.defineProperty(exports, "RecognitionEventArgs", ({ enumerable: true, get: function () { return RecognitionEventArgs_js_1.RecognitionEventArgs; } }));
var OutputFormat_js_1 = __webpack_require__(/*! ./OutputFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/OutputFormat.js");
Object.defineProperty(exports, "OutputFormat", ({ enumerable: true, get: function () { return OutputFormat_js_1.OutputFormat; } }));
var RecognitionResult_js_1 = __webpack_require__(/*! ./RecognitionResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionResult.js");
Object.defineProperty(exports, "RecognitionResult", ({ enumerable: true, get: function () { return RecognitionResult_js_1.RecognitionResult; } }));
var SpeechRecognitionResult_js_1 = __webpack_require__(/*! ./SpeechRecognitionResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionResult.js");
Object.defineProperty(exports, "SpeechRecognitionResult", ({ enumerable: true, get: function () { return SpeechRecognitionResult_js_1.SpeechRecognitionResult; } }));
var SpeechRecognitionEventArgs_js_1 = __webpack_require__(/*! ./SpeechRecognitionEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionEventArgs.js");
Object.defineProperty(exports, "SpeechRecognitionEventArgs", ({ enumerable: true, get: function () { return SpeechRecognitionEventArgs_js_1.SpeechRecognitionEventArgs; } }));
Object.defineProperty(exports, "ConversationTranscriptionEventArgs", ({ enumerable: true, get: function () { return SpeechRecognitionEventArgs_js_1.ConversationTranscriptionEventArgs; } }));
Object.defineProperty(exports, "MeetingTranscriptionEventArgs", ({ enumerable: true, get: function () { return SpeechRecognitionEventArgs_js_1.MeetingTranscriptionEventArgs; } }));
var SpeechRecognitionCanceledEventArgs_js_1 = __webpack_require__(/*! ./SpeechRecognitionCanceledEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionCanceledEventArgs.js");
Object.defineProperty(exports, "SpeechRecognitionCanceledEventArgs", ({ enumerable: true, get: function () { return SpeechRecognitionCanceledEventArgs_js_1.SpeechRecognitionCanceledEventArgs; } }));
var TranslationRecognitionEventArgs_js_1 = __webpack_require__(/*! ./TranslationRecognitionEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionEventArgs.js");
Object.defineProperty(exports, "TranslationRecognitionEventArgs", ({ enumerable: true, get: function () { return TranslationRecognitionEventArgs_js_1.TranslationRecognitionEventArgs; } }));
var TranslationSynthesisEventArgs_js_1 = __webpack_require__(/*! ./TranslationSynthesisEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisEventArgs.js");
Object.defineProperty(exports, "TranslationSynthesisEventArgs", ({ enumerable: true, get: function () { return TranslationSynthesisEventArgs_js_1.TranslationSynthesisEventArgs; } }));
var TranslationRecognitionResult_js_1 = __webpack_require__(/*! ./TranslationRecognitionResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionResult.js");
Object.defineProperty(exports, "TranslationRecognitionResult", ({ enumerable: true, get: function () { return TranslationRecognitionResult_js_1.TranslationRecognitionResult; } }));
var TranslationSynthesisResult_js_1 = __webpack_require__(/*! ./TranslationSynthesisResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisResult.js");
Object.defineProperty(exports, "TranslationSynthesisResult", ({ enumerable: true, get: function () { return TranslationSynthesisResult_js_1.TranslationSynthesisResult; } }));
var ResultReason_js_1 = __webpack_require__(/*! ./ResultReason.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ResultReason.js");
Object.defineProperty(exports, "ResultReason", ({ enumerable: true, get: function () { return ResultReason_js_1.ResultReason; } }));
var SpeechConfig_js_1 = __webpack_require__(/*! ./SpeechConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechConfig.js");
Object.defineProperty(exports, "SpeechConfig", ({ enumerable: true, get: function () { return SpeechConfig_js_1.SpeechConfig; } }));
Object.defineProperty(exports, "SpeechConfigImpl", ({ enumerable: true, get: function () { return SpeechConfig_js_1.SpeechConfigImpl; } }));
var SpeechTranslationConfig_js_1 = __webpack_require__(/*! ./SpeechTranslationConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechTranslationConfig.js");
Object.defineProperty(exports, "SpeechTranslationConfig", ({ enumerable: true, get: function () { return SpeechTranslationConfig_js_1.SpeechTranslationConfig; } }));
Object.defineProperty(exports, "SpeechTranslationConfigImpl", ({ enumerable: true, get: function () { return SpeechTranslationConfig_js_1.SpeechTranslationConfigImpl; } }));
var PropertyCollection_js_1 = __webpack_require__(/*! ./PropertyCollection.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyCollection.js");
Object.defineProperty(exports, "PropertyCollection", ({ enumerable: true, get: function () { return PropertyCollection_js_1.PropertyCollection; } }));
var PropertyId_js_1 = __webpack_require__(/*! ./PropertyId.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js");
Object.defineProperty(exports, "PropertyId", ({ enumerable: true, get: function () { return PropertyId_js_1.PropertyId; } }));
var Recognizer_js_1 = __webpack_require__(/*! ./Recognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Recognizer.js");
Object.defineProperty(exports, "Recognizer", ({ enumerable: true, get: function () { return Recognizer_js_1.Recognizer; } }));
var SpeechRecognizer_js_1 = __webpack_require__(/*! ./SpeechRecognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognizer.js");
Object.defineProperty(exports, "SpeechRecognizer", ({ enumerable: true, get: function () { return SpeechRecognizer_js_1.SpeechRecognizer; } }));
var TranslationRecognizer_js_1 = __webpack_require__(/*! ./TranslationRecognizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognizer.js");
Object.defineProperty(exports, "TranslationRecognizer", ({ enumerable: true, get: function () { return TranslationRecognizer_js_1.TranslationRecognizer; } }));
var Translations_js_1 = __webpack_require__(/*! ./Translations.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Translations.js");
Object.defineProperty(exports, "Translations", ({ enumerable: true, get: function () { return Translations_js_1.Translations; } }));
var NoMatchReason_js_1 = __webpack_require__(/*! ./NoMatchReason.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchReason.js");
Object.defineProperty(exports, "NoMatchReason", ({ enumerable: true, get: function () { return NoMatchReason_js_1.NoMatchReason; } }));
var NoMatchDetails_js_1 = __webpack_require__(/*! ./NoMatchDetails.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchDetails.js");
Object.defineProperty(exports, "NoMatchDetails", ({ enumerable: true, get: function () { return NoMatchDetails_js_1.NoMatchDetails; } }));
var TranslationRecognitionCanceledEventArgs_js_1 = __webpack_require__(/*! ./TranslationRecognitionCanceledEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionCanceledEventArgs.js");
Object.defineProperty(exports, "TranslationRecognitionCanceledEventArgs", ({ enumerable: true, get: function () { return TranslationRecognitionCanceledEventArgs_js_1.TranslationRecognitionCanceledEventArgs; } }));
var CancellationDetailsBase_js_1 = __webpack_require__(/*! ./CancellationDetailsBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetailsBase.js");
Object.defineProperty(exports, "CancellationDetailsBase", ({ enumerable: true, get: function () { return CancellationDetailsBase_js_1.CancellationDetailsBase; } }));
var CancellationDetails_js_1 = __webpack_require__(/*! ./CancellationDetails.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationDetails.js");
Object.defineProperty(exports, "CancellationDetails", ({ enumerable: true, get: function () { return CancellationDetails_js_1.CancellationDetails; } }));
var CancellationErrorCodes_js_1 = __webpack_require__(/*! ./CancellationErrorCodes.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationErrorCodes.js");
Object.defineProperty(exports, "CancellationErrorCode", ({ enumerable: true, get: function () { return CancellationErrorCodes_js_1.CancellationErrorCode; } }));
var ConnectionEventArgs_js_1 = __webpack_require__(/*! ./ConnectionEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionEventArgs.js");
Object.defineProperty(exports, "ConnectionEventArgs", ({ enumerable: true, get: function () { return ConnectionEventArgs_js_1.ConnectionEventArgs; } }));
var ServiceEventArgs_js_1 = __webpack_require__(/*! ./ServiceEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServiceEventArgs.js");
Object.defineProperty(exports, "ServiceEventArgs", ({ enumerable: true, get: function () { return ServiceEventArgs_js_1.ServiceEventArgs; } }));
var Connection_js_1 = __webpack_require__(/*! ./Connection.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Connection.js");
Object.defineProperty(exports, "Connection", ({ enumerable: true, get: function () { return Connection_js_1.Connection; } }));
var PhraseListGrammar_js_1 = __webpack_require__(/*! ./PhraseListGrammar.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PhraseListGrammar.js");
Object.defineProperty(exports, "PhraseListGrammar", ({ enumerable: true, get: function () { return PhraseListGrammar_js_1.PhraseListGrammar; } }));
var DialogServiceConfig_js_1 = __webpack_require__(/*! ./DialogServiceConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConfig.js");
Object.defineProperty(exports, "DialogServiceConfig", ({ enumerable: true, get: function () { return DialogServiceConfig_js_1.DialogServiceConfig; } }));
var BotFrameworkConfig_js_1 = __webpack_require__(/*! ./BotFrameworkConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/BotFrameworkConfig.js");
Object.defineProperty(exports, "BotFrameworkConfig", ({ enumerable: true, get: function () { return BotFrameworkConfig_js_1.BotFrameworkConfig; } }));
var CustomCommandsConfig_js_1 = __webpack_require__(/*! ./CustomCommandsConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CustomCommandsConfig.js");
Object.defineProperty(exports, "CustomCommandsConfig", ({ enumerable: true, get: function () { return CustomCommandsConfig_js_1.CustomCommandsConfig; } }));
var DialogServiceConnector_js_1 = __webpack_require__(/*! ./DialogServiceConnector.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/DialogServiceConnector.js");
Object.defineProperty(exports, "DialogServiceConnector", ({ enumerable: true, get: function () { return DialogServiceConnector_js_1.DialogServiceConnector; } }));
var ActivityReceivedEventArgs_js_1 = __webpack_require__(/*! ./ActivityReceivedEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ActivityReceivedEventArgs.js");
Object.defineProperty(exports, "ActivityReceivedEventArgs", ({ enumerable: true, get: function () { return ActivityReceivedEventArgs_js_1.ActivityReceivedEventArgs; } }));
var TurnStatusReceivedEventArgs_js_1 = __webpack_require__(/*! ./TurnStatusReceivedEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TurnStatusReceivedEventArgs.js");
Object.defineProperty(exports, "TurnStatusReceivedEventArgs", ({ enumerable: true, get: function () { return TurnStatusReceivedEventArgs_js_1.TurnStatusReceivedEventArgs; } }));
var ServicePropertyChannel_js_1 = __webpack_require__(/*! ./ServicePropertyChannel.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServicePropertyChannel.js");
Object.defineProperty(exports, "ServicePropertyChannel", ({ enumerable: true, get: function () { return ServicePropertyChannel_js_1.ServicePropertyChannel; } }));
var ProfanityOption_js_1 = __webpack_require__(/*! ./ProfanityOption.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ProfanityOption.js");
Object.defineProperty(exports, "ProfanityOption", ({ enumerable: true, get: function () { return ProfanityOption_js_1.ProfanityOption; } }));
var BaseAudioPlayer_js_1 = __webpack_require__(/*! ./Audio/BaseAudioPlayer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/BaseAudioPlayer.js");
Object.defineProperty(exports, "BaseAudioPlayer", ({ enumerable: true, get: function () { return BaseAudioPlayer_js_1.BaseAudioPlayer; } }));
var ConnectionMessageEventArgs_js_1 = __webpack_require__(/*! ./ConnectionMessageEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessageEventArgs.js");
Object.defineProperty(exports, "ConnectionMessageEventArgs", ({ enumerable: true, get: function () { return ConnectionMessageEventArgs_js_1.ConnectionMessageEventArgs; } }));
var ConnectionMessage_js_1 = __webpack_require__(/*! ./ConnectionMessage.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConnectionMessage.js");
Object.defineProperty(exports, "ConnectionMessage", ({ enumerable: true, get: function () { return ConnectionMessage_js_1.ConnectionMessage; } }));
var AutoDetectSourceLanguageConfig_js_1 = __webpack_require__(/*! ./AutoDetectSourceLanguageConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageConfig.js");
Object.defineProperty(exports, "AutoDetectSourceLanguageConfig", ({ enumerable: true, get: function () { return AutoDetectSourceLanguageConfig_js_1.AutoDetectSourceLanguageConfig; } }));
var AutoDetectSourceLanguageResult_js_1 = __webpack_require__(/*! ./AutoDetectSourceLanguageResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AutoDetectSourceLanguageResult.js");
Object.defineProperty(exports, "AutoDetectSourceLanguageResult", ({ enumerable: true, get: function () { return AutoDetectSourceLanguageResult_js_1.AutoDetectSourceLanguageResult; } }));
var SourceLanguageConfig_js_1 = __webpack_require__(/*! ./SourceLanguageConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SourceLanguageConfig.js");
Object.defineProperty(exports, "SourceLanguageConfig", ({ enumerable: true, get: function () { return SourceLanguageConfig_js_1.SourceLanguageConfig; } }));
var Exports_js_1 = __webpack_require__(/*! ./Transcription/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js");
Object.defineProperty(exports, "Conversation", ({ enumerable: true, get: function () { return Exports_js_1.Conversation; } }));
Object.defineProperty(exports, "ConversationExpirationEventArgs", ({ enumerable: true, get: function () { return Exports_js_1.ConversationExpirationEventArgs; } }));
Object.defineProperty(exports, "ConversationParticipantsChangedEventArgs", ({ enumerable: true, get: function () { return Exports_js_1.ConversationParticipantsChangedEventArgs; } }));
Object.defineProperty(exports, "ConversationTranslationCanceledEventArgs", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranslationCanceledEventArgs; } }));
Object.defineProperty(exports, "ConversationTranslationEventArgs", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranslationEventArgs; } }));
Object.defineProperty(exports, "ConversationTranslationResult", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranslationResult; } }));
Object.defineProperty(exports, "ConversationTranslator", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranslator; } }));
Object.defineProperty(exports, "ConversationTranscriber", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranscriber; } }));
Object.defineProperty(exports, "ConversationTranscriptionResult", ({ enumerable: true, get: function () { return Exports_js_1.ConversationTranscriptionResult; } }));
Object.defineProperty(exports, "Meeting", ({ enumerable: true, get: function () { return Exports_js_1.Meeting; } }));
Object.defineProperty(exports, "MeetingTranscriber", ({ enumerable: true, get: function () { return Exports_js_1.MeetingTranscriber; } }));
Object.defineProperty(exports, "Participant", ({ enumerable: true, get: function () { return Exports_js_1.Participant; } }));
Object.defineProperty(exports, "ParticipantChangedReason", ({ enumerable: true, get: function () { return Exports_js_1.ParticipantChangedReason; } }));
Object.defineProperty(exports, "User", ({ enumerable: true, get: function () { return Exports_js_1.User; } }));
var Synthesizer_js_1 = __webpack_require__(/*! ./Synthesizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js");
Object.defineProperty(exports, "Synthesizer", ({ enumerable: true, get: function () { return Synthesizer_js_1.Synthesizer; } }));
var SpeechSynthesisOutputFormat_js_1 = __webpack_require__(/*! ./SpeechSynthesisOutputFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisOutputFormat.js");
Object.defineProperty(exports, "SpeechSynthesisOutputFormat", ({ enumerable: true, get: function () { return SpeechSynthesisOutputFormat_js_1.SpeechSynthesisOutputFormat; } }));
var SpeechSynthesizer_js_1 = __webpack_require__(/*! ./SpeechSynthesizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesizer.js");
Object.defineProperty(exports, "SpeechSynthesizer", ({ enumerable: true, get: function () { return SpeechSynthesizer_js_1.SpeechSynthesizer; } }));
var SynthesisResult_js_1 = __webpack_require__(/*! ./SynthesisResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisResult.js");
Object.defineProperty(exports, "SynthesisResult", ({ enumerable: true, get: function () { return SynthesisResult_js_1.SynthesisResult; } }));
var SpeechSynthesisResult_js_1 = __webpack_require__(/*! ./SpeechSynthesisResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisResult.js");
Object.defineProperty(exports, "SpeechSynthesisResult", ({ enumerable: true, get: function () { return SpeechSynthesisResult_js_1.SpeechSynthesisResult; } }));
var SpeechSynthesisEventArgs_js_1 = __webpack_require__(/*! ./SpeechSynthesisEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisEventArgs.js");
Object.defineProperty(exports, "SpeechSynthesisEventArgs", ({ enumerable: true, get: function () { return SpeechSynthesisEventArgs_js_1.SpeechSynthesisEventArgs; } }));
var SpeechSynthesisWordBoundaryEventArgs_js_1 = __webpack_require__(/*! ./SpeechSynthesisWordBoundaryEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js");
Object.defineProperty(exports, "SpeechSynthesisWordBoundaryEventArgs", ({ enumerable: true, get: function () { return SpeechSynthesisWordBoundaryEventArgs_js_1.SpeechSynthesisWordBoundaryEventArgs; } }));
var SpeechSynthesisBookmarkEventArgs_js_1 = __webpack_require__(/*! ./SpeechSynthesisBookmarkEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBookmarkEventArgs.js");
Object.defineProperty(exports, "SpeechSynthesisBookmarkEventArgs", ({ enumerable: true, get: function () { return SpeechSynthesisBookmarkEventArgs_js_1.SpeechSynthesisBookmarkEventArgs; } }));
var SpeechSynthesisVisemeEventArgs_js_1 = __webpack_require__(/*! ./SpeechSynthesisVisemeEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisVisemeEventArgs.js");
Object.defineProperty(exports, "SpeechSynthesisVisemeEventArgs", ({ enumerable: true, get: function () { return SpeechSynthesisVisemeEventArgs_js_1.SpeechSynthesisVisemeEventArgs; } }));
var SpeechSynthesisBoundaryType_js_1 = __webpack_require__(/*! ./SpeechSynthesisBoundaryType.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBoundaryType.js");
Object.defineProperty(exports, "SpeechSynthesisBoundaryType", ({ enumerable: true, get: function () { return SpeechSynthesisBoundaryType_js_1.SpeechSynthesisBoundaryType; } }));
var SynthesisVoicesResult_js_1 = __webpack_require__(/*! ./SynthesisVoicesResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisVoicesResult.js");
Object.defineProperty(exports, "SynthesisVoicesResult", ({ enumerable: true, get: function () { return SynthesisVoicesResult_js_1.SynthesisVoicesResult; } }));
var VoiceInfo_js_1 = __webpack_require__(/*! ./VoiceInfo.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceInfo.js");
Object.defineProperty(exports, "SynthesisVoiceGender", ({ enumerable: true, get: function () { return VoiceInfo_js_1.SynthesisVoiceGender; } }));
Object.defineProperty(exports, "SynthesisVoiceType", ({ enumerable: true, get: function () { return VoiceInfo_js_1.SynthesisVoiceType; } }));
Object.defineProperty(exports, "VoiceInfo", ({ enumerable: true, get: function () { return VoiceInfo_js_1.VoiceInfo; } }));
var SpeakerAudioDestination_js_1 = __webpack_require__(/*! ./Audio/SpeakerAudioDestination.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/SpeakerAudioDestination.js");
Object.defineProperty(exports, "SpeakerAudioDestination", ({ enumerable: true, get: function () { return SpeakerAudioDestination_js_1.SpeakerAudioDestination; } }));
var ConversationTranscriptionCanceledEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranscriptionCanceledEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ConversationTranscriptionCanceledEventArgs.js");
Object.defineProperty(exports, "ConversationTranscriptionCanceledEventArgs", ({ enumerable: true, get: function () { return ConversationTranscriptionCanceledEventArgs_js_1.ConversationTranscriptionCanceledEventArgs; } }));
var MeetingTranscriptionCanceledEventArgs_js_1 = __webpack_require__(/*! ./MeetingTranscriptionCanceledEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/MeetingTranscriptionCanceledEventArgs.js");
Object.defineProperty(exports, "MeetingTranscriptionCanceledEventArgs", ({ enumerable: true, get: function () { return MeetingTranscriptionCanceledEventArgs_js_1.MeetingTranscriptionCanceledEventArgs; } }));
var PronunciationAssessmentGradingSystem_js_1 = __webpack_require__(/*! ./PronunciationAssessmentGradingSystem.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGradingSystem.js");
Object.defineProperty(exports, "PronunciationAssessmentGradingSystem", ({ enumerable: true, get: function () { return PronunciationAssessmentGradingSystem_js_1.PronunciationAssessmentGradingSystem; } }));
var PronunciationAssessmentGranularity_js_1 = __webpack_require__(/*! ./PronunciationAssessmentGranularity.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGranularity.js");
Object.defineProperty(exports, "PronunciationAssessmentGranularity", ({ enumerable: true, get: function () { return PronunciationAssessmentGranularity_js_1.PronunciationAssessmentGranularity; } }));
var PronunciationAssessmentConfig_js_1 = __webpack_require__(/*! ./PronunciationAssessmentConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentConfig.js");
Object.defineProperty(exports, "PronunciationAssessmentConfig", ({ enumerable: true, get: function () { return PronunciationAssessmentConfig_js_1.PronunciationAssessmentConfig; } }));
var PronunciationAssessmentResult_js_1 = __webpack_require__(/*! ./PronunciationAssessmentResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentResult.js");
Object.defineProperty(exports, "PronunciationAssessmentResult", ({ enumerable: true, get: function () { return PronunciationAssessmentResult_js_1.PronunciationAssessmentResult; } }));
var LanguageIdMode_js_1 = __webpack_require__(/*! ./LanguageIdMode.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageIdMode.js");
Object.defineProperty(exports, "LanguageIdMode", ({ enumerable: true, get: function () { return LanguageIdMode_js_1.LanguageIdMode; } }));
var AvatarConfig_js_1 = __webpack_require__(/*! ./AvatarConfig.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarConfig.js");
Object.defineProperty(exports, "AvatarConfig", ({ enumerable: true, get: function () { return AvatarConfig_js_1.AvatarConfig; } }));
var AvatarEventArgs_js_1 = __webpack_require__(/*! ./AvatarEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarEventArgs.js");
Object.defineProperty(exports, "AvatarEventArgs", ({ enumerable: true, get: function () { return AvatarEventArgs_js_1.AvatarEventArgs; } }));
var AvatarSynthesizer_js_1 = __webpack_require__(/*! ./AvatarSynthesizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarSynthesizer.js");
Object.defineProperty(exports, "AvatarSynthesizer", ({ enumerable: true, get: function () { return AvatarSynthesizer_js_1.AvatarSynthesizer; } }));
var AvatarVideoFormat_js_1 = __webpack_require__(/*! ./AvatarVideoFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarVideoFormat.js");
Object.defineProperty(exports, "AvatarVideoFormat", ({ enumerable: true, get: function () { return AvatarVideoFormat_js_1.AvatarVideoFormat; } }));
Object.defineProperty(exports, "Coordinate", ({ enumerable: true, get: function () { return AvatarVideoFormat_js_1.Coordinate; } }));
var AvatarWebRTCConnectionResult_js_1 = __webpack_require__(/*! ./AvatarWebRTCConnectionResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/AvatarWebRTCConnectionResult.js");
Object.defineProperty(exports, "AvatarWebRTCConnectionResult", ({ enumerable: true, get: function () { return AvatarWebRTCConnectionResult_js_1.AvatarWebRTCConnectionResult; } }));
var Diagnostics_js_1 = __webpack_require__(/*! ./Diagnostics.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Diagnostics.js");
Object.defineProperty(exports, "Diagnostics", ({ enumerable: true, get: function () { return Diagnostics_js_1.Diagnostics; } }));
var LogLevel_js_1 = __webpack_require__(/*! ./LogLevel.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LogLevel.js");
Object.defineProperty(exports, "LogLevel", ({ enumerable: true, get: function () { return LogLevel_js_1.LogLevel; } }));

//# sourceMappingURL=Exports.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/KeywordRecognitionModel.js"
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/KeywordRecognitionModel.js ***!
  \************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.KeywordRecognitionModel = void 0;
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
/**
 * Represents a keyword recognition model for recognizing when
 * the user says a keyword to initiate further speech recognition.
 * @class KeywordRecognitionModel
 */
class KeywordRecognitionModel {
    /**
     * Create and initializes a new instance.
     * @constructor
     */
    constructor() {
        this.privDisposed = false;
        return;
    }
    /**
     * Creates a keyword recognition model using the specified filename.
     * @member KeywordRecognitionModel.fromFile
     * @function
     * @public
     * @param {string} fileName - A string that represents file name for the keyword recognition model.
     * Note, the file can point to a zip file in which case the model
     * will be extracted from the zip.
     * @returns {KeywordRecognitionModel} The keyword recognition model being created.
     */
    static fromFile(fileName) {
        Contracts_js_1.Contracts.throwIfFileDoesNotExist(fileName, "fileName");
        throw new Error("Not yet implemented.");
    }
    /**
     * Creates a keyword recognition model using the specified filename.
     * @member KeywordRecognitionModel.fromStream
     * @function
     * @public
     * @param {string} file - A File that represents file for the keyword recognition model.
     * Note, the file can point to a zip file in which case the model will be extracted from the zip.
     * @returns {KeywordRecognitionModel} The keyword recognition model being created.
     */
    static fromStream(file) {
        Contracts_js_1.Contracts.throwIfNull(file, "file");
        throw new Error("Not yet implemented.");
    }
    /**
     * Dispose of associated resources.
     * @member KeywordRecognitionModel.prototype.close
     * @function
     * @public
     */
    close() {
        if (this.privDisposed) {
            return;
        }
        this.privDisposed = true;
    }
}
exports.KeywordRecognitionModel = KeywordRecognitionModel;

//# sourceMappingURL=KeywordRecognitionModel.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageIdMode.js"
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LanguageIdMode.js ***!
  \***************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.LanguageIdMode = void 0;
/**
 * Language Identification mode
 * @class LanguageIdMode
 */
var LanguageIdMode;
(function (LanguageIdMode) {
    /**
     * Detect language at audio start
     * @member LanguageIdMode.AtStart
     */
    LanguageIdMode[LanguageIdMode["AtStart"] = 0] = "AtStart";
    /**
     * Continuously detect language
     * @member LanguageIdMode.Continuous
     */
    LanguageIdMode[LanguageIdMode["Continuous"] = 1] = "Continuous";
})(LanguageIdMode = exports.LanguageIdMode || (exports.LanguageIdMode = {}));

//# sourceMappingURL=LanguageIdMode.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LogLevel.js"
/*!*********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/LogLevel.js ***!
  \*********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.LogLevel = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
Object.defineProperty(exports, "LogLevel", ({ enumerable: true, get: function () { return Exports_js_1.EventType; } }));

//# sourceMappingURL=LogLevel.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/MeetingTranscriptionCanceledEventArgs.js"
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/MeetingTranscriptionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MeetingTranscriptionCanceledEventArgs = void 0;
const CancellationEventArgsBase_js_1 = __webpack_require__(/*! ./CancellationEventArgsBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js");
/**
 * Defines content of a MeetingTranscriptionCanceledEvent.
 * @class MeetingTranscriptionCanceledEventArgs
 */
class MeetingTranscriptionCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {
}
exports.MeetingTranscriptionCanceledEventArgs = MeetingTranscriptionCanceledEventArgs;

//# sourceMappingURL=MeetingTranscriptionCanceledEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchDetails.js"
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchDetails.js ***!
  \***************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.NoMatchDetails = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../src/common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Contains detailed information for NoMatch recognition results.
 * @class NoMatchDetails
 */
class NoMatchDetails {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {NoMatchReason} reason - The no-match reason.
     */
    constructor(reason) {
        this.privReason = reason;
    }
    /**
     * Creates an instance of NoMatchDetails object for the NoMatch SpeechRecognitionResults.
     * @member NoMatchDetails.fromResult
     * @function
     * @public
     * @param {SpeechRecognitionResult | TranslationRecognitionResult}
     * result - The recognition result that was not recognized.
     * @returns {NoMatchDetails} The no match details object being created.
     */
    static fromResult(result) {
        const simpleSpeech = Exports_js_1.SimpleSpeechPhrase.fromJSON(result.json, 0); // Offset fixups are already done.
        let reason = Exports_js_2.NoMatchReason.NotRecognized;
        switch (simpleSpeech.RecognitionStatus) {
            case Exports_js_1.RecognitionStatus.BabbleTimeout:
                reason = Exports_js_2.NoMatchReason.InitialBabbleTimeout;
                break;
            case Exports_js_1.RecognitionStatus.InitialSilenceTimeout:
                reason = Exports_js_2.NoMatchReason.InitialSilenceTimeout;
                break;
            default:
                reason = Exports_js_2.NoMatchReason.NotRecognized;
                break;
        }
        return new NoMatchDetails(reason);
    }
    /**
     * The reason the recognition was canceled.
     * @member NoMatchDetails.prototype.reason
     * @function
     * @public
     * @returns {NoMatchReason} Specifies the reason canceled.
     */
    get reason() {
        return this.privReason;
    }
}
exports.NoMatchDetails = NoMatchDetails;

//# sourceMappingURL=NoMatchDetails.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchReason.js"
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/NoMatchReason.js ***!
  \**************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.NoMatchReason = void 0;
/**
 * Defines the possible reasons a recognition result might not be recognized.
 * @class NoMatchReason
 */
var NoMatchReason;
(function (NoMatchReason) {
    /**
     * Indicates that speech was detected, but not recognized.
     * @member NoMatchReason.NotRecognized
     */
    NoMatchReason[NoMatchReason["NotRecognized"] = 0] = "NotRecognized";
    /**
     * Indicates that the start of the audio stream contained only silence,
     * and the service timed out waiting for speech.
     * @member NoMatchReason.InitialSilenceTimeout
     */
    NoMatchReason[NoMatchReason["InitialSilenceTimeout"] = 1] = "InitialSilenceTimeout";
    /**
     * Indicates that the start of the audio stream contained only noise,
     * and the service timed out waiting for speech.
     * @member NoMatchReason.InitialBabbleTimeout
     */
    NoMatchReason[NoMatchReason["InitialBabbleTimeout"] = 2] = "InitialBabbleTimeout";
})(NoMatchReason = exports.NoMatchReason || (exports.NoMatchReason = {}));

//# sourceMappingURL=NoMatchReason.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/OutputFormat.js"
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/OutputFormat.js ***!
  \*************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.OutputFormat = void 0;
/**
 * Define Speech Recognizer output formats.
 * @class OutputFormat
 */
var OutputFormat;
(function (OutputFormat) {
    /**
     * @member OutputFormat.Simple
     */
    OutputFormat[OutputFormat["Simple"] = 0] = "Simple";
    /**
     * @member OutputFormat.Detailed
     */
    OutputFormat[OutputFormat["Detailed"] = 1] = "Detailed";
})(OutputFormat = exports.OutputFormat || (exports.OutputFormat = {}));

//# sourceMappingURL=OutputFormat.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PhraseListGrammar.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PhraseListGrammar.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PhraseListGrammar = void 0;
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
/**
 * Allows additions of new phrases to improve speech recognition.
 *
 * Phrases added to the recognizer are effective at the start of the next recognition, or the next time the SpeechSDK must reconnect
 * to the speech service.
 */
class PhraseListGrammar {
    constructor(recogBase) {
        this.privGrammerBuilder = recogBase.dynamicGrammar;
    }
    /**
     * Creates a PhraseListGrammar from a given speech recognizer. Will accept any recognizer that derives from @class Recognizer.
     * @param recognizer The recognizer to add phrase lists to.
     */
    static fromRecognizer(recognizer) {
        const recoBase = recognizer.internalData;
        return new PhraseListGrammar(recoBase);
    }
    /**
     * Adds a single phrase to the current recognizer.
     * @param phrase Phrase to add.
     */
    addPhrase(phrase) {
        this.privGrammerBuilder.addPhrase(phrase);
    }
    /**
     * Adds multiple phrases to the current recognizer.
     * @param phrases Array of phrases to add.
     */
    addPhrases(phrases) {
        this.privGrammerBuilder.addPhrase(phrases);
    }
    /**
     * Clears all phrases added to the current recognizer.
     */
    clear() {
        this.privGrammerBuilder.clearPhrases();
    }
    /**
     * Sets the phrase list grammar biasing weight.
     * The allowed range is [0.0, 2.0].
     * The default weight is 1.0. Value zero disables the phrase list.
     * @param weight Phrase list grammar biasing weight.
     */
    setWeight(weight) {
        Contracts_js_1.Contracts.throwIfNumberOutOfRange(weight, "weight", 0.0, 2.0);
        this.privGrammerBuilder.setWeight(weight);
    }
}
exports.PhraseListGrammar = PhraseListGrammar;

//# sourceMappingURL=PhraseListGrammar.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ProfanityOption.js"
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ProfanityOption.js ***!
  \****************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ProfanityOption = void 0;
/**
 * Profanity option.
 * Added in version 1.7.0.
 */
var ProfanityOption;
(function (ProfanityOption) {
    ProfanityOption[ProfanityOption["Masked"] = 0] = "Masked";
    ProfanityOption[ProfanityOption["Removed"] = 1] = "Removed";
    ProfanityOption[ProfanityOption["Raw"] = 2] = "Raw";
})(ProfanityOption = exports.ProfanityOption || (exports.ProfanityOption = {}));

//# sourceMappingURL=ProfanityOption.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentConfig.js"
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentConfig.js ***!
  \******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PronunciationAssessmentConfig = void 0;
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Pronunciation assessment configuration.
 * @class PronunciationAssessmentConfig
 * Added in version 1.15.0.
 */
class PronunciationAssessmentConfig {
    /**
     * PronunciationAssessmentConfig constructor.
     * @constructor
     * @param {string} referenceText
     * @param gradingSystem
     * @param granularity
     * @param enableMiscue
     */
    constructor(referenceText, gradingSystem = Exports_js_1.PronunciationAssessmentGradingSystem.FivePoint, granularity = Exports_js_1.PronunciationAssessmentGranularity.Phoneme, enableMiscue = false) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(referenceText, "referenceText");
        this.privProperties = new Exports_js_1.PropertyCollection();
        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_ReferenceText, referenceText);
        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_GradingSystem, Exports_js_1.PronunciationAssessmentGradingSystem[gradingSystem]);
        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_Granularity, Exports_js_1.PronunciationAssessmentGranularity[granularity]);
        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_EnableMiscue, String(enableMiscue));
    }
    /**
     * @member PronunciationAssessmentConfig.fromJSON
     * @function
     * @public
     * @param {string} json The json string containing the pronunciation assessment parameters.
     * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig
     * @summary Creates an instance of the PronunciationAssessmentConfig from json.
     * This method is designed to support the pronunciation assessment parameters still in preview.
     * Under normal circumstances, use the constructor instead.
     */
    static fromJSON(json) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(json, "json");
        const config = new PronunciationAssessmentConfig("");
        config.privProperties = new Exports_js_1.PropertyCollection();
        config.properties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_Json, json);
        return config;
    }
    toJSON() {
        this.updateJson();
        return this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_Params);
    }
    applyTo(recognizer) {
        this.updateJson();
        const recoBase = recognizer.internalData;
        recoBase.speechContext.setPronunciationAssessmentParams(this.properties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_Params), recoBase.isSpeakerDiarizationEnabled);
    }
    /**
     * Gets the reference text.
     * @member PronunciationAssessmentConfig.prototype.referenceText
     * @function
     * @public
     * @returns {string} Reference text.
     */
    get referenceText() {
        return this.properties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_ReferenceText);
    }
    /**
     * Gets/Sets the reference text.
     * @member PronunciationAssessmentConfig.prototype.referenceText
     * @function
     * @public
     * @param {string} referenceText - Reference text.
     */
    set referenceText(referenceText) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(referenceText, "referenceText");
        this.properties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_ReferenceText, referenceText);
    }
    /**
     * Sets the phoneme alphabet.
     * The valid values are "SAPI" (default) and "IPA".
     * Added in version 1.20.0
     * @member PronunciationAssessmentConfig.prototype.phonemeAlphabet
     * @function
     * @public
     * @param {string} phonemeAlphabet - Phoneme alphabet.
     */
    set phonemeAlphabet(phonemeAlphabet) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(phonemeAlphabet, "phonemeAlphabet");
        this.privPhonemeAlphabet = phonemeAlphabet;
    }
    /**
     * Sets the boolean enableMiscue property.
     * Added in version 1.26.0
     * @member PronunciationAssessmentConfig.prototype.enableMiscue
     * @function
     * @public
     * @param {boolean} enableMiscue - enable miscue.
     */
    set enableMiscue(enableMiscue) {
        const enableMiscueString = enableMiscue ? "true" : "false";
        this.properties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_EnableMiscue, enableMiscueString);
    }
    /**
     * Gets the boolean enableMiscue property.
     * Added in version 1.26.0
     * @member PronunciationAssessmentConfig.prototype.enableMiscue
     * @function
     * @public
     * @return {boolean} enableMiscue - enable miscue.
     */
    get enableMiscue() {
        const enableMiscueString = this.properties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_EnableMiscue, "false");
        return (enableMiscueString.toLowerCase() === "true");
    }
    /**
     * Sets the nbest phoneme count
     * Added in version 1.20.0
     * @member PronunciationAssessmentConfig.prototype.nbestPhonemeCount
     * @function
     * @public
     * @param {number} nbestPhonemeCount - NBest phoneme count.
     */
    set nbestPhonemeCount(nbestPhonemeCount) {
        this.privNBestPhonemeCount = nbestPhonemeCount;
    }
    /**
     * Enables the prosody assessment.
     * Added in version 1.34.0
     * @member PronunciationAssessmentConfig.prototype.enableProsodyAssessment
     * @function
     * @public
     * @param {boolean} enableProsodyAssessment - enable prosody assessment.
     */
    set enableProsodyAssessment(enableProsodyAssessment) {
        this.privEnableProsodyAssessment = enableProsodyAssessment;
    }
    /**
     * @member PronunciationAssessmentConfig.prototype.properties
     * @function
     * @public
     * @return {PropertyCollection} Properties of the config.
     * @summary Gets a pronunciation assessment config properties
     */
    get properties() {
        return this.privProperties;
    }
    updateJson() {
        const jsonString = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_Json, "{}");
        const paramsJson = JSON.parse(jsonString);
        const referenceText = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_ReferenceText);
        if (referenceText) {
            paramsJson.referenceText = referenceText;
        }
        const gradingSystem = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_GradingSystem);
        if (gradingSystem) {
            paramsJson.gradingSystem = gradingSystem;
        }
        const granularity = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_Granularity);
        if (granularity) {
            paramsJson.granularity = granularity;
        }
        if (this.privPhonemeAlphabet) {
            paramsJson.phonemeAlphabet = this.privPhonemeAlphabet;
        }
        if (this.privNBestPhonemeCount) {
            paramsJson.nbestPhonemeCount = this.privNBestPhonemeCount;
        }
        paramsJson.enableProsodyAssessment = this.privEnableProsodyAssessment;
        // always set dimension to Comprehensive
        paramsJson.dimension = "Comprehensive";
        const enableMiscueString = this.privProperties.getProperty(Exports_js_1.PropertyId.PronunciationAssessment_EnableMiscue);
        if (enableMiscueString) {
            paramsJson.enableMiscue = this.enableMiscue;
        }
        this.privProperties.setProperty(Exports_js_1.PropertyId.PronunciationAssessment_Params, JSON.stringify(paramsJson));
    }
}
exports.PronunciationAssessmentConfig = PronunciationAssessmentConfig;

//# sourceMappingURL=PronunciationAssessmentConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGradingSystem.js"
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGradingSystem.js ***!
  \*************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PronunciationAssessmentGradingSystem = void 0;
/**
 * Defines the point system for pronunciation score calibration; default value is FivePoint.
 * Added in version 1.15.0
 * @class PronunciationAssessmentGradingSystem
 */
var PronunciationAssessmentGradingSystem;
(function (PronunciationAssessmentGradingSystem) {
    /**
     * Five point calibration
     * @member PronunciationAssessmentGradingSystem.FivePoint
     */
    PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem["FivePoint"] = 1] = "FivePoint";
    /**
     * Hundred mark
     * @member PronunciationAssessmentGradingSystem.HundredMark
     */
    PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem["HundredMark"] = 2] = "HundredMark";
})(PronunciationAssessmentGradingSystem = exports.PronunciationAssessmentGradingSystem || (exports.PronunciationAssessmentGradingSystem = {}));

//# sourceMappingURL=PronunciationAssessmentGradingSystem.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGranularity.js"
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentGranularity.js ***!
  \***********************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PronunciationAssessmentGranularity = void 0;
/**
 * Defines the pronunciation evaluation granularity; default value is Phoneme.
 * Added in version 1.15.0
 * @class PronunciationAssessmentGranularity
 */
var PronunciationAssessmentGranularity;
(function (PronunciationAssessmentGranularity) {
    /**
     * Shows the score on the full text, word and phoneme level
     * @member PronunciationAssessmentGranularity.Phoneme
     */
    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity["Phoneme"] = 1] = "Phoneme";
    /**
     * Shows the score on the full text and word level
     * @member PronunciationAssessmentGranularity.Word
     */
    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity["Word"] = 2] = "Word";
    /**
     * Shows the score on the full text level only
     * @member PronunciationAssessmentGranularity.FullText
     */
    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity["FullText"] = 3] = "FullText";
})(PronunciationAssessmentGranularity = exports.PronunciationAssessmentGranularity || (exports.PronunciationAssessmentGranularity = {}));

//# sourceMappingURL=PronunciationAssessmentGranularity.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentResult.js"
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PronunciationAssessmentResult.js ***!
  \******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PronunciationAssessmentResult = void 0;
/* eslint-disable max-classes-per-file */
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Pronunciation assessment results.
 * @class PronunciationAssessmentResult
 * Added in version 1.15.0.
 */
class PronunciationAssessmentResult {
    constructor(jsonString) {
        const j = JSON.parse(jsonString);
        Contracts_js_1.Contracts.throwIfNullOrUndefined(j.NBest[0], "NBest");
        this.privPronJson = j.NBest[0];
    }
    /**
     * @member PronunciationAssessmentResult.fromResult
     * @function
     * @public
     * @param {RecognitionResult} result The recognition result.
     * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig
     * @summary Creates an instance of the PronunciationAssessmentResult from recognition result.
     */
    static fromResult(result) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(result, "result");
        const json = result.properties.getProperty(Exports_js_1.PropertyId.SpeechServiceResponse_JsonResult);
        Contracts_js_1.Contracts.throwIfNullOrUndefined(json, "json");
        return new PronunciationAssessmentResult(json);
    }
    /**
     * Gets the detail result of pronunciation assessment.
     * @member PronunciationAssessmentConfig.prototype.detailResult
     * @function
     * @public
     * @returns {DetailResult} detail result.
     */
    get detailResult() {
        return this.privPronJson;
    }
    /**
     * The score indicating the pronunciation accuracy of the given speech, which indicates
     * how closely the phonemes match a native speaker's pronunciation.
     * @member PronunciationAssessmentResult.prototype.accuracyScore
     * @function
     * @public
     * @returns {number} Accuracy score.
     */
    get accuracyScore() {
        return this.detailResult.PronunciationAssessment?.AccuracyScore;
    }
    /**
     * The overall score indicating the pronunciation quality of the given speech.
     * This is calculated from AccuracyScore, FluencyScore and CompletenessScore with weight.
     * @member PronunciationAssessmentResult.prototype.pronunciationScore
     * @function
     * @public
     * @returns {number} Pronunciation score.
     */
    get pronunciationScore() {
        return this.detailResult.PronunciationAssessment?.PronScore;
    }
    /**
     * The score indicating the completeness of the given speech by calculating the ratio of pronounced words towards entire input.
     * @member PronunciationAssessmentResult.prototype.completenessScore
     * @function
     * @public
     * @returns {number} Completeness score.
     */
    get completenessScore() {
        return this.detailResult.PronunciationAssessment?.CompletenessScore;
    }
    /**
     * The score indicating the fluency of the given speech.
     * @member PronunciationAssessmentResult.prototype.fluencyScore
     * @function
     * @public
     * @returns {number} Fluency score.
     */
    get fluencyScore() {
        return this.detailResult.PronunciationAssessment?.FluencyScore;
    }
    /**
     * The prosody score, which indicates how nature of the given speech, including stress, intonation, speaking speed and rhythm.
     * @member PronunciationAssessmentResult.prototype.prosodyScore
     * @function
     * @public
     * @returns {number} Prosody score.
     */
    get prosodyScore() {
        return this.detailResult.PronunciationAssessment?.ProsodyScore;
    }
}
exports.PronunciationAssessmentResult = PronunciationAssessmentResult;

//# sourceMappingURL=PronunciationAssessmentResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyCollection.js"
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyCollection.js ***!
  \*******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PropertyCollection = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Represents collection of properties and their values.
 * @class PropertyCollection
 */
class PropertyCollection {
    constructor() {
        this.privKeys = [];
        this.privValues = [];
    }
    /**
     * Returns the property value in type String.
     * Currently only String, int and bool are allowed.
     * If the name is not available, the specified defaultValue is returned.
     * @member PropertyCollection.prototype.getProperty
     * @function
     * @public
     * @param {string} key - The parameter name.
     * @param {string | number | boolean} def - The default value which is returned if the parameter
     * is not available in the collection.
     * @returns {string} value of the parameter.
     */
    getProperty(key, def) {
        let keyToUse;
        if (typeof key === "string") {
            keyToUse = key;
        }
        else {
            keyToUse = Exports_js_1.PropertyId[key];
        }
        for (let n = 0; n < this.privKeys.length; n++) {
            if (this.privKeys[n] === keyToUse) {
                return this.privValues[n];
            }
        }
        if (def === undefined) {
            return undefined;
        }
        return String(def);
    }
    /**
     * Sets the String value of the parameter specified by name.
     * @member PropertyCollection.prototype.setProperty
     * @function
     * @public
     * @param {string} key - The parameter name.
     * @param {string} value - The value of the parameter.
     */
    setProperty(key, value) {
        let keyToUse;
        if (typeof key === "string") {
            keyToUse = key;
        }
        else {
            keyToUse = Exports_js_1.PropertyId[key];
        }
        for (let n = 0; n < this.privKeys.length; n++) {
            if (this.privKeys[n] === keyToUse) {
                this.privValues[n] = value;
                return;
            }
        }
        this.privKeys.push(keyToUse);
        this.privValues.push(value);
    }
    /**
     * Clones the collection.
     * @member PropertyCollection.prototype.clone
     * @function
     * @public
     * @returns {PropertyCollection} A copy of the collection.
     */
    clone() {
        const clonedMap = new PropertyCollection();
        for (let n = 0; n < this.privKeys.length; n++) {
            clonedMap.privKeys.push(this.privKeys[n]);
            clonedMap.privValues.push(this.privValues[n]);
        }
        return clonedMap;
    }
    /**
     * Merges this set of properties into another, no overwrites.
     * @member PropertyCollection.prototype.mergeTo
     * @function
     * @public
     * @param {PropertyCollection}  destinationCollection - The collection to merge into.
     */
    mergeTo(destinationCollection) {
        this.privKeys.forEach((key) => {
            if (destinationCollection.getProperty(key, undefined) === undefined) {
                const value = this.getProperty(key);
                destinationCollection.setProperty(key, value);
            }
        });
    }
    /**
     * Get the keys in Property Collection.
     * @member PropertyCollection.prototype.keys
     * @function
     * @public
     * @returns {string []} Keys in the collection.
     */
    get keys() {
        return this.privKeys;
    }
}
exports.PropertyCollection = PropertyCollection;

//# sourceMappingURL=PropertyCollection.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js"
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/PropertyId.js ***!
  \***********************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PropertyId = void 0;
/**
 * Defines speech property ids.
 * @class PropertyId
 */
var PropertyId;
(function (PropertyId) {
    /**
     * The Cognitive Services Speech Service subscription Key. Under normal circumstances, you shouldn't
     * have to use this property directly.
     * Instead, use [[SpeechConfig.fromSubscription]].
     * @member PropertyId.SpeechServiceConnection_Key
     */
    PropertyId[PropertyId["SpeechServiceConnection_Key"] = 0] = "SpeechServiceConnection_Key";
    /**
     * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't
     * have to use this property directly.
     * Instead, use [[SpeechConfig.fromEndpoint]].
     * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.
     * @member PropertyId.SpeechServiceConnection_Endpoint
     */
    PropertyId[PropertyId["SpeechServiceConnection_Endpoint"] = 1] = "SpeechServiceConnection_Endpoint";
    /**
     * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to
     * use this property directly.
     * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].
     * @member PropertyId.SpeechServiceConnection_Region
     */
    PropertyId[PropertyId["SpeechServiceConnection_Region"] = 2] = "SpeechServiceConnection_Region";
    /**
     * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,
     * you shouldn't have to use this property directly.
     * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],
     * [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].
     * @member PropertyId.SpeechServiceAuthorization_Token
     */
    PropertyId[PropertyId["SpeechServiceAuthorization_Token"] = 3] = "SpeechServiceAuthorization_Token";
    /**
     * The Cognitive Services Speech Service authorization type. Currently unused.
     * @member PropertyId.SpeechServiceAuthorization_Type
     */
    PropertyId[PropertyId["SpeechServiceAuthorization_Type"] = 4] = "SpeechServiceAuthorization_Type";
    /**
     * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't
     * have to use this property directly.
     * Instead, use [[SpeechConfig.endpointId]].
     * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.
     * @member PropertyId.SpeechServiceConnection_EndpointId
     */
    PropertyId[PropertyId["SpeechServiceConnection_EndpointId"] = 5] = "SpeechServiceConnection_EndpointId";
    /**
     * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,
     * you shouldn't have to use this property directly.
     * Instead use [[SpeechTranslationConfig.addTargetLanguage]],
     * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].
     * @member PropertyId.SpeechServiceConnection_TranslationToLanguages
     */
    PropertyId[PropertyId["SpeechServiceConnection_TranslationToLanguages"] = 6] = "SpeechServiceConnection_TranslationToLanguages";
    /**
     * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this
     * property directly.
     * Instead, use [[SpeechTranslationConfig.voiceName]].
     * NOTE: Valid voice names can be found <a href="https://aka.ms/csspeech/voicenames">here</a>.
     * @member PropertyId.SpeechServiceConnection_TranslationVoice
     */
    PropertyId[PropertyId["SpeechServiceConnection_TranslationVoice"] = 7] = "SpeechServiceConnection_TranslationVoice";
    /**
     * Translation features.
     * @member PropertyId.SpeechServiceConnection_TranslationFeatures
     */
    PropertyId[PropertyId["SpeechServiceConnection_TranslationFeatures"] = 8] = "SpeechServiceConnection_TranslationFeatures";
    /**
     * The category ID for translation.
     * @member PropertyId.SpeechServiceConnection_TranslationCategoryId
     */
    PropertyId[PropertyId["SpeechServiceConnection_TranslationCategoryId"] = 9] = "SpeechServiceConnection_TranslationCategoryId";
    /**
     * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
     * You shouldn't have to use this property directly.
     * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
     * Added in version 1.4.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_ProxyHostName"] = 10] = "SpeechServiceConnection_ProxyHostName";
    /**
     * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
     * You shouldn't have to use this property directly.
     * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
     * Added in version 1.4.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_ProxyPort"] = 11] = "SpeechServiceConnection_ProxyPort";
    /**
     * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
     * You shouldn't have to use this property directly.
     * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
     * Added in version 1.4.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_ProxyUserName"] = 12] = "SpeechServiceConnection_ProxyUserName";
    /**
     * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
     * You shouldn't have to use this property directly.
     * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
     * Added in version 1.4.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_ProxyPassword"] = 13] = "SpeechServiceConnection_ProxyPassword";
    /**
     * The Cognitive Services Speech Service recognition Mode. Can be "INTERACTIVE", "CONVERSATION", "DICTATION".
     * This property is intended to be read-only. The SDK is using it internally.
     * @member PropertyId.SpeechServiceConnection_RecoMode
     */
    PropertyId[PropertyId["SpeechServiceConnection_RecoMode"] = 14] = "SpeechServiceConnection_RecoMode";
    /**
     * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property
     * directly.
     * Instead, use [[SpeechConfig.speechRecognitionLanguage]].
     * @member PropertyId.SpeechServiceConnection_RecoLanguage
     */
    PropertyId[PropertyId["SpeechServiceConnection_RecoLanguage"] = 15] = "SpeechServiceConnection_RecoLanguage";
    /**
     * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream
     * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this
     * property directly.
     * Instead use [[SessionEventArgs.sessionId]].
     * @member PropertyId.Speech_SessionId
     */
    PropertyId[PropertyId["Speech_SessionId"] = 16] = "Speech_SessionId";
    /**
     * The spoken language to be synthesized (e.g. en-US)
     * @member PropertyId.SpeechServiceConnection_SynthLanguage
     */
    PropertyId[PropertyId["SpeechServiceConnection_SynthLanguage"] = 17] = "SpeechServiceConnection_SynthLanguage";
    /**
     * The name of the TTS voice to be used for speech synthesis
     * @member PropertyId.SpeechServiceConnection_SynthVoice
     */
    PropertyId[PropertyId["SpeechServiceConnection_SynthVoice"] = 18] = "SpeechServiceConnection_SynthVoice";
    /**
     * The string to specify TTS output audio format
     * @member PropertyId.SpeechServiceConnection_SynthOutputFormat
     */
    PropertyId[PropertyId["SpeechServiceConnection_SynthOutputFormat"] = 19] = "SpeechServiceConnection_SynthOutputFormat";
    /**
     * The list of comma separated languages used as possible source languages
     * Added in version 1.13.0
     * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages
     */
    PropertyId[PropertyId["SpeechServiceConnection_AutoDetectSourceLanguages"] = 20] = "SpeechServiceConnection_AutoDetectSourceLanguages";
    /**
     * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have
     * to use this property directly.
     * Instead use [[SpeechConfig.outputFormat]].
     * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
     */
    PropertyId[PropertyId["SpeechServiceResponse_RequestDetailedResultTrueFalse"] = 21] = "SpeechServiceResponse_RequestDetailedResultTrueFalse";
    /**
     * The requested Cognitive Services Speech Service response output profanity level. Currently unused.
     * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
     */
    PropertyId[PropertyId["SpeechServiceResponse_RequestProfanityFilterTrueFalse"] = 22] = "SpeechServiceResponse_RequestProfanityFilterTrueFalse";
    /**
     * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.
     * @member PropertyId.SpeechServiceResponse_JsonResult
     */
    PropertyId[PropertyId["SpeechServiceResponse_JsonResult"] = 23] = "SpeechServiceResponse_JsonResult";
    /**
     * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to
     * use this property directly. Instead use [[CancellationDetails.errorDetails]].
     * @member PropertyId.SpeechServiceResponse_JsonErrorDetails
     */
    PropertyId[PropertyId["SpeechServiceResponse_JsonErrorDetails"] = 24] = "SpeechServiceResponse_JsonErrorDetails";
    /**
     * The cancellation reason. Currently unused.
     * @member PropertyId.CancellationDetails_Reason
     */
    PropertyId[PropertyId["CancellationDetails_Reason"] = 25] = "CancellationDetails_Reason";
    /**
     * The cancellation text. Currently unused.
     * @member PropertyId.CancellationDetails_ReasonText
     */
    PropertyId[PropertyId["CancellationDetails_ReasonText"] = 26] = "CancellationDetails_ReasonText";
    /**
     * The Cancellation detailed text. Currently unused.
     * @member PropertyId.CancellationDetails_ReasonDetailedText
     */
    PropertyId[PropertyId["CancellationDetails_ReasonDetailedText"] = 27] = "CancellationDetails_ReasonDetailedText";
    /**
     * The URL string built from speech configuration.
     * This property is intended to be read-only. The SDK is using it internally.
     * NOTE: Added in version 1.7.0.
     */
    PropertyId[PropertyId["SpeechServiceConnection_Url"] = 28] = "SpeechServiceConnection_Url";
    /**
     * The initial silence timeout value (in milliseconds) used by the service.
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceConnection_InitialSilenceTimeoutMs"] = 29] = "SpeechServiceConnection_InitialSilenceTimeoutMs";
    /**
     * This property is deprecated.
     * For current information about silence timeouts, please visit https://aka.ms/csspeech/timeouts.
     */
    PropertyId[PropertyId["SpeechServiceConnection_EndSilenceTimeoutMs"] = 30] = "SpeechServiceConnection_EndSilenceTimeoutMs";
    /**
     * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken
     * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations
     * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently
     * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low
     * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting
     * behavior should be thoroughly validated as intended.
     *
     * Refer to the documentation for valid value ranges and additional details:
     * https://aka.ms/csspeech/timeouts
     *
     * Added in version 1.42.0.
     */
    PropertyId[PropertyId["Speech_SegmentationSilenceTimeoutMs"] = 31] = "Speech_SegmentationSilenceTimeoutMs";
    /**
     * SegmentationMaximumTimeMs represents the maximum length of a spoken phrase when using the Time segmentation strategy.
     * @member Speech_SegmentationSilenceTimeoutMs must be set in order to use this setting.
     * As the length of a spoken phrase approaches this value, the @member Speech_SegmentationSilenceTimeoutMs will be reduced until either
     * the phrase silence timeout is reached or the phrase reaches the maximum length.
     *
     * Valid range: **20,000 to 70,000** milliseconds.
     *
     * Added in version 1.42.0.
     */
    PropertyId[PropertyId["Speech_SegmentationMaximumTimeMs"] = 32] = "Speech_SegmentationMaximumTimeMs";
    /**
     * Specifies the strategy used to determine when a spoken phrase has ended,
     * triggering the generation of a final recognition result.
     *
     * Supported values:
     * - "Default": Uses the Speech Service's default segmentation strategy. Recommended for most use cases.
     * - "Time": Uses a silence-based timeout. A final result is generated after a defined period of silence.
     * Requires @member Speech_SegmentationMaximumTimeMs to be configured appropriately.
     * Optional: Adjust @member Speech_SegmentationSilenceTimeoutMs to control how much silence ends a phrase.
     * - "Semantic": Uses an AI model to semantically infer phrase boundaries based on content.
     * No adjustable parameters are available for this strategy.
     *
     * Introduced in version 1.42.0.
     */
    PropertyId[PropertyId["Speech_SegmentationStrategy"] = 33] = "Speech_SegmentationStrategy";
    /**
     * The sensitivity of how soon a potential speech start can be signaled.
     * Allowed values are "low" (default), "medium" and "high".
     */
    PropertyId[PropertyId["Speech_StartEventSensitivity"] = 34] = "Speech_StartEventSensitivity";
    /**
     * A boolean value specifying whether audio logging is enabled in the service or not.
     * Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked
     * to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource).
     * The logs will be removed after 30 days.
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceConnection_EnableAudioLogging"] = 35] = "SpeechServiceConnection_EnableAudioLogging";
    /**
     * The speech service connection language identifier mode.
     * Can be "AtStart" (the default), or "Continuous". See Language
     * Identification document https://aka.ms/speech/lid?pivots=programming-language-javascript
     * for more details.
     * Added in 1.25.0
     **/
    PropertyId[PropertyId["SpeechServiceConnection_LanguageIdMode"] = 36] = "SpeechServiceConnection_LanguageIdMode";
    /**
     * A string value representing the desired endpoint version to target for Speech Recognition.
     * Added in version 1.21.0
     */
    PropertyId[PropertyId["SpeechServiceConnection_RecognitionEndpointVersion"] = 37] = "SpeechServiceConnection_RecognitionEndpointVersion";
    /**
     * The requested Cognitive Services Speech Service response output profanity setting.
     * Allowed values are "masked", "removed", and "raw".
     * Added in version 1.7.0.
     */
    PropertyId[PropertyId["SpeechServiceResponse_ProfanityOption"] = 38] = "SpeechServiceResponse_ProfanityOption";
    /**
     * A string value specifying which post processing option should be used by service.
     * Allowed values are "TrueText".
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceResponse_PostProcessingOption"] = 39] = "SpeechServiceResponse_PostProcessingOption";
    /**
     * A boolean value specifying whether to include word-level timestamps in the response result.
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceResponse_RequestWordLevelTimestamps"] = 40] = "SpeechServiceResponse_RequestWordLevelTimestamps";
    /**
     * The number of times a word has to be in partial results to be returned.
     * Added in version 1.7.0
     */
    PropertyId[PropertyId["SpeechServiceResponse_StablePartialResultThreshold"] = 41] = "SpeechServiceResponse_StablePartialResultThreshold";
    /**
     * A string value specifying the output format option in the response result. Internal use only.
     * Added in version 1.7.0.
     */
    PropertyId[PropertyId["SpeechServiceResponse_OutputFormatOption"] = 42] = "SpeechServiceResponse_OutputFormatOption";
    /**
     * A boolean value to request for stabilizing translation partial results by omitting words in the end.
     * Added in version 1.7.0.
     */
    PropertyId[PropertyId["SpeechServiceResponse_TranslationRequestStablePartialResult"] = 43] = "SpeechServiceResponse_TranslationRequestStablePartialResult";
    /**
     * A boolean value specifying whether to request WordBoundary events.
     * @member PropertyId.SpeechServiceResponse_RequestWordBoundary
     * Added in version 1.21.0.
     */
    PropertyId[PropertyId["SpeechServiceResponse_RequestWordBoundary"] = 44] = "SpeechServiceResponse_RequestWordBoundary";
    /**
     * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.
     * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary
     * Added in version 1.21.0.
     */
    PropertyId[PropertyId["SpeechServiceResponse_RequestPunctuationBoundary"] = 45] = "SpeechServiceResponse_RequestPunctuationBoundary";
    /**
     * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.
     * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary
     * Added in version 1.21.0.
     */
    PropertyId[PropertyId["SpeechServiceResponse_RequestSentenceBoundary"] = 46] = "SpeechServiceResponse_RequestSentenceBoundary";
    /**
     * Determines if intermediate results contain speaker identification.
     * Allowed values are "true" or "false". If set to "true", the intermediate results will contain speaker identification.
     * The default value if unset or set to an invalid value is "false".
     * This is currently only supported for scenarios using the ConversationTranscriber".
     * @member PropertyId.SpeechServiceResponse_DiarizeIntermediateResults
     * Adding in version 1.41.
     */
    PropertyId[PropertyId["SpeechServiceResponse_DiarizeIntermediateResults"] = 47] = "SpeechServiceResponse_DiarizeIntermediateResults";
    /**
     * Identifier used to connect to the backend service.
     * @member PropertyId.Conversation_ApplicationId
     */
    PropertyId[PropertyId["Conversation_ApplicationId"] = 48] = "Conversation_ApplicationId";
    /**
     * Type of dialog backend to connect to.
     * @member PropertyId.Conversation_DialogType
     */
    PropertyId[PropertyId["Conversation_DialogType"] = 49] = "Conversation_DialogType";
    /**
     * Silence timeout for listening
     * @member PropertyId.Conversation_Initial_Silence_Timeout
     */
    PropertyId[PropertyId["Conversation_Initial_Silence_Timeout"] = 50] = "Conversation_Initial_Silence_Timeout";
    /**
     * From Id to add to speech recognition activities.
     * @member PropertyId.Conversation_From_Id
     */
    PropertyId[PropertyId["Conversation_From_Id"] = 51] = "Conversation_From_Id";
    /**
     * ConversationId for the session.
     * @member PropertyId.Conversation_Conversation_Id
     */
    PropertyId[PropertyId["Conversation_Conversation_Id"] = 52] = "Conversation_Conversation_Id";
    /**
     * Comma separated list of custom voice deployment ids.
     * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids
     */
    PropertyId[PropertyId["Conversation_Custom_Voice_Deployment_Ids"] = 53] = "Conversation_Custom_Voice_Deployment_Ids";
    /**
     * Speech activity template, stamp properties from the template on the activity generated by the service for speech.
     * @member PropertyId.Conversation_Speech_Activity_Template
     * Added in version 1.10.0.
     */
    PropertyId[PropertyId["Conversation_Speech_Activity_Template"] = 54] = "Conversation_Speech_Activity_Template";
    /**
     * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.
     * @member PropertyId.Conversation_Request_Bot_Status_Messages
     * Added in version 1.15.0.
     */
    PropertyId[PropertyId["Conversation_Request_Bot_Status_Messages"] = 55] = "Conversation_Request_Bot_Status_Messages";
    /**
     * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for
     * channel authentication.
     * Added in version 1.15.1.
     */
    PropertyId[PropertyId["Conversation_Agent_Connection_Id"] = 56] = "Conversation_Agent_Connection_Id";
    /**
     * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.
     * Instead, use [[SpeechConfig.fromHost]].
     */
    PropertyId[PropertyId["SpeechServiceConnection_Host"] = 57] = "SpeechServiceConnection_Host";
    /**
     * Set the host for service calls to the Conversation Translator REST management and websocket calls.
     */
    PropertyId[PropertyId["ConversationTranslator_Host"] = 58] = "ConversationTranslator_Host";
    /**
     * Optionally set the the host's display name.
     * Used when joining a conversation.
     */
    PropertyId[PropertyId["ConversationTranslator_Name"] = 59] = "ConversationTranslator_Name";
    /**
     * Optionally set a value for the X-CorrelationId request header.
     * Used for troubleshooting errors in the server logs. It should be a valid guid.
     */
    PropertyId[PropertyId["ConversationTranslator_CorrelationId"] = 60] = "ConversationTranslator_CorrelationId";
    /**
     * Set the conversation token to be sent to the speech service. This enables the
     * service to service call from the speech service to the Conversation Translator service for relaying
     * recognitions. For internal use.
     */
    PropertyId[PropertyId["ConversationTranslator_Token"] = 61] = "ConversationTranslator_Token";
    /**
     * The reference text of the audio for pronunciation evaluation.
     * For this and the following pronunciation assessment parameters, see
     * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_ReferenceText"] = 62] = "PronunciationAssessment_ReferenceText";
    /**
     * The point system for pronunciation score calibration (FivePoint or HundredMark).
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_GradingSystem"] = 63] = "PronunciationAssessment_GradingSystem";
    /**
     * The pronunciation evaluation granularity (Phoneme, Word, or FullText).
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_Granularity"] = 64] = "PronunciationAssessment_Granularity";
    /**
     * Defines if enable miscue calculation.
     * With this enabled, the pronounced words will be compared to the reference text,
     * and will be marked with omission/insertion based on the comparison. The default setting is False.
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_EnableMiscue"] = 65] = "PronunciationAssessment_EnableMiscue";
    /**
     * The json string of pronunciation assessment parameters
     * Under normal circumstances, you shouldn't have to use this property directly.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_Json"] = 66] = "PronunciationAssessment_Json";
    /**
     * Pronunciation assessment parameters.
     * This property is intended to be read-only. The SDK is using it internally.
     * Added in version 1.15.0
     */
    PropertyId[PropertyId["PronunciationAssessment_Params"] = 67] = "PronunciationAssessment_Params";
    /**
     * Specifies whether to allow load of data URL for web worker
     * Allowed values are "off" and "on". Default is "on".
     * Added in version 1.32.0
     */
    PropertyId[PropertyId["WebWorkerLoadType"] = 68] = "WebWorkerLoadType";
    /**
     * Talking avatar service WebRTC session description protocol.
     * This property is intended to be read-only. The SDK is using it internally.
     * Added in version 1.33.0
     */
    PropertyId[PropertyId["TalkingAvatarService_WebRTC_SDP"] = 69] = "TalkingAvatarService_WebRTC_SDP";
})(PropertyId = exports.PropertyId || (exports.PropertyId = {}));

//# sourceMappingURL=PropertyId.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionEventArgs.js"
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionEventArgs.js ***!
  \*********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RecognitionEventArgs = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines payload for session events like Speech Start/End Detected
 * @class
 */
class RecognitionEventArgs extends Exports_js_1.SessionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(offset, sessionId) {
        super(sessionId);
        this.privOffset = offset;
    }
    /**
     * Represents the message offset
     * @member RecognitionEventArgs.prototype.offset
     * @function
     * @public
     */
    get offset() {
        return this.privOffset;
    }
}
exports.RecognitionEventArgs = RecognitionEventArgs;

//# sourceMappingURL=RecognitionEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionResult.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/RecognitionResult.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.RecognitionResult = void 0;
/**
 * Defines result of speech recognition.
 * @class RecognitionResult
 */
class RecognitionResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {string} text - The recognized text.
     * @param {number} duration - The duration.
     * @param {number} offset - The offset into the stream.
     * @param {string} language - Primary Language detected, if provided.
     * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
     * @param {string} errorDetails - Error details, if provided.
     * @param {string} json - Additional Json, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {
        this.privResultId = resultId;
        this.privReason = reason;
        this.privText = text;
        this.privDuration = duration;
        this.privOffset = offset;
        this.privLanguage = language;
        this.privLanguageDetectionConfidence = languageDetectionConfidence;
        this.privErrorDetails = errorDetails;
        this.privJson = json;
        this.privProperties = properties;
    }
    /**
     * Specifies the result identifier.
     * @member RecognitionResult.prototype.resultId
     * @function
     * @public
     * @returns {string} Specifies the result identifier.
     */
    get resultId() {
        return this.privResultId;
    }
    /**
     * Specifies status of the result.
     * @member RecognitionResult.prototype.reason
     * @function
     * @public
     * @returns {ResultReason} Specifies status of the result.
     */
    get reason() {
        return this.privReason;
    }
    /**
     * Presents the recognized text in the result.
     * @member RecognitionResult.prototype.text
     * @function
     * @public
     * @returns {string} Presents the recognized text in the result.
     */
    get text() {
        return this.privText;
    }
    /**
     * Duration of recognized speech in 100 nano second increments.
     * @member RecognitionResult.prototype.duration
     * @function
     * @public
     * @returns {number} Duration of recognized speech in 100 nano second increments.
     */
    get duration() {
        return this.privDuration;
    }
    /**
     * Offset of recognized speech in 100 nano second increments.
     * @member RecognitionResult.prototype.offset
     * @function
     * @public
     * @returns {number} Offset of recognized speech in 100 nano second increments.
     */
    get offset() {
        return this.privOffset;
    }
    /**
     * Primary Language detected.
     * @member RecognitionResult.prototype.language
     * @function
     * @public
     * @returns {string} language detected.
     */
    get language() {
        return this.privLanguage;
    }
    /**
     * Primary Language detection confidence (Unknown, Low, Medium, High).
     * @member RecognitionResult.prototype.languageDetectionConfidence
     * @function
     * @public
     * @returns {string} detection confidence strength.
     */
    get languageDetectionConfidence() {
        return this.privLanguageDetectionConfidence;
    }
    /**
     * In case of an unsuccessful recognition, provides details of the occurred error.
     * @member RecognitionResult.prototype.errorDetails
     * @function
     * @public
     * @returns {string} a brief description of an error.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
    /**
     * A string containing Json serialized recognition result as it was received from the service.
     * @member RecognitionResult.prototype.json
     * @function
     * @private
     * @returns {string} Json serialized representation of the result.
     */
    get json() {
        return this.privJson;
    }
    /**
     * The set of properties exposed in the result.
     * @member RecognitionResult.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The set of properties exposed in the result.
     */
    get properties() {
        return this.privProperties;
    }
}
exports.RecognitionResult = RecognitionResult;

//# sourceMappingURL=RecognitionResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Recognizer.js"
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Recognizer.js ***!
  \***********************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Recognizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines the base class Recognizer which mainly contains common event handlers.
 * @class Recognizer
 */
class Recognizer {
    /**
     * Creates and initializes an instance of a Recognizer
     * @constructor
     * @param {AudioConfig} audioInput - An optional audio input stream associated with the recognizer
     * @param {PropertyCollection} properties - A set of properties to set on the recognizer
     * @param {IConnectionFactory} connectionFactory - The factory class used to create a custom IConnection for the recognizer
     */
    constructor(audioConfig, properties, connectionFactory, tokenCredential) {
        this.audioConfig = (audioConfig !== undefined) ? audioConfig : Exports_js_3.AudioConfig.fromDefaultMicrophoneInput();
        this.privDisposed = false;
        this.privProperties = properties.clone();
        this.privConnectionFactory = connectionFactory;
        this.tokenCredential = tokenCredential;
        this.implCommonRecognizerSetup();
    }
    /**
     * Dispose of associated resources.
     * @member Recognizer.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
    }
    /**
     * @Internal
     * Internal data member to support fromRecognizer* pattern methods on other classes.
     * Do not use externally, object returned will change without warning or notice.
     */
    get internalData() {
        return this.privReco;
    }
    /**
     * This method performs cleanup of resources.
     * The Boolean parameter disposing indicates whether the method is called
     * from Dispose (if disposing is true) or from the finalizer (if disposing is false).
     * Derived classes should override this method to dispose resource if needed.
     * @member Recognizer.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - Flag to request disposal.
     */
    async dispose(disposing) {
        if (this.privDisposed) {
            return;
        }
        this.privDisposed = true;
        if (disposing) {
            if (this.privReco) {
                await this.privReco.audioSource.turnOff();
                await this.privReco.dispose();
            }
        }
    }
    /**
     * This method returns the current state of the telemetry setting.
     * @member Recognizer.prototype.telemetryEnabled
     * @function
     * @public
     * @returns true if the telemetry is enabled, false otherwise.
     */
    static get telemetryEnabled() {
        return Exports_js_1.ServiceRecognizerBase.telemetryDataEnabled;
    }
    /**
     * This method globally enables or disables telemetry.
     * @member Recognizer.prototype.enableTelemetry
     * @function
     * @public
     * @param enabled - Global setting for telemetry collection.
     * If set to true, telemetry information like microphone errors,
     * recognition errors are collected and sent to Microsoft.
     * If set to false, no telemetry is sent to Microsoft.
     */
    static enableTelemetry(enabled) {
        Exports_js_1.ServiceRecognizerBase.telemetryDataEnabled = enabled;
    }
    // Does the generic recognizer setup that is common across all recognizer types.
    implCommonRecognizerSetup() {
        let osPlatform = (typeof window !== "undefined") ? "Browser" : "Node";
        let osName = "unknown";
        let osVersion = "unknown";
        if (typeof navigator !== "undefined") {
            osPlatform = osPlatform + "/" + navigator.platform;
            osName = navigator.userAgent;
            osVersion = navigator.appVersion;
        }
        const recognizerConfig = this.createRecognizerConfig(new Exports_js_1.SpeechServiceConfig(new Exports_js_1.Context(new Exports_js_1.OS(osPlatform, osName, osVersion))));
        this.privReco = this.createServiceRecognizer(Recognizer.getAuth(this.privProperties, this.tokenCredential), this.privConnectionFactory, this.audioConfig, recognizerConfig);
    }
    async recognizeOnceAsyncImpl(recognitionMode) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);
        const ret = new Exports_js_2.Deferred();
        await this.implRecognizerStop();
        await this.privReco.recognize(recognitionMode, ret.resolve, ret.reject);
        const result = await ret.promise;
        await this.implRecognizerStop();
        return result;
    }
    async startContinuousRecognitionAsyncImpl(recognitionMode) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);
        await this.implRecognizerStop();
        await this.privReco.recognize(recognitionMode, undefined, undefined);
    }
    async stopContinuousRecognitionAsyncImpl() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);
        await this.implRecognizerStop();
    }
    async implRecognizerStop() {
        if (this.privReco) {
            await this.privReco.stopRecognizing();
        }
        return;
    }
    static getAuth(properties, tokenCredential) {
        const subscriptionKey = properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Key, undefined);
        if (subscriptionKey && subscriptionKey !== "") {
            return new Exports_js_1.CognitiveSubscriptionKeyAuthentication(subscriptionKey);
        }
        if (tokenCredential) {
            return new Exports_js_1.CognitiveTokenAuthentication(async () => {
                try {
                    const tokenResponse = await tokenCredential.getToken("https://cognitiveservices.azure.com/.default");
                    return tokenResponse?.token ?? "";
                }
                catch (err) {
                    throw err;
                }
            }, async () => {
                try {
                    const tokenResponse = await tokenCredential.getToken("https://cognitiveservices.azure.com/.default");
                    return tokenResponse?.token ?? "";
                }
                catch (err) {
                    throw err;
                }
            });
        }
        return new Exports_js_1.CognitiveTokenAuthentication(() => {
            const authorizationToken = properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, undefined);
            return Promise.resolve(authorizationToken);
        }, () => {
            const authorizationToken = properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, undefined);
            return Promise.resolve(authorizationToken);
        });
    }
}
exports.Recognizer = Recognizer;

//# sourceMappingURL=Recognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ResultReason.js"
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ResultReason.js ***!
  \*************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ResultReason = void 0;
/**
 * Defines the possible reasons a recognition result might be generated.
 * @class ResultReason
 */
var ResultReason;
(function (ResultReason) {
    /**
     * Indicates speech could not be recognized. More details
     * can be found in the NoMatchDetails object.
     * @member ResultReason.NoMatch
     */
    ResultReason[ResultReason["NoMatch"] = 0] = "NoMatch";
    /**
     * Indicates that the recognition was canceled. More details
     * can be found using the CancellationDetails object.
     * @member ResultReason.Canceled
     */
    ResultReason[ResultReason["Canceled"] = 1] = "Canceled";
    /**
     * Indicates the speech result contains hypothesis text.
     * @member ResultReason.RecognizedSpeech
     */
    ResultReason[ResultReason["RecognizingSpeech"] = 2] = "RecognizingSpeech";
    /**
     * Indicates the speech result contains final text that has been recognized.
     * Speech Recognition is now complete for this phrase.
     * @member ResultReason.RecognizedSpeech
     */
    ResultReason[ResultReason["RecognizedSpeech"] = 3] = "RecognizedSpeech";
    /**
     * Indicates the speech result contains a finalized acceptance of a provided keyword.
     * Speech recognition will continue unless otherwise configured.
     * @member ResultReason.RecognizedKeyword
     */
    ResultReason[ResultReason["RecognizedKeyword"] = 4] = "RecognizedKeyword";
    /**
     * Indicates the translation result contains hypothesis text and its translation(s).
     * @member ResultReason.TranslatingSpeech
     */
    ResultReason[ResultReason["TranslatingSpeech"] = 5] = "TranslatingSpeech";
    /**
     * Indicates the translation result contains final text and corresponding translation(s).
     * Speech Recognition and Translation are now complete for this phrase.
     * @member ResultReason.TranslatedSpeech
     */
    ResultReason[ResultReason["TranslatedSpeech"] = 6] = "TranslatedSpeech";
    /**
     * Indicates the synthesized audio result contains a non-zero amount of audio data
     * @member ResultReason.SynthesizingAudio
     */
    ResultReason[ResultReason["SynthesizingAudio"] = 7] = "SynthesizingAudio";
    /**
     * Indicates the synthesized audio is now complete for this phrase.
     * @member ResultReason.SynthesizingAudioCompleted
     */
    ResultReason[ResultReason["SynthesizingAudioCompleted"] = 8] = "SynthesizingAudioCompleted";
    /**
     * Indicates the speech synthesis is now started
     * @member ResultReason.SynthesizingAudioStarted
     */
    ResultReason[ResultReason["SynthesizingAudioStarted"] = 9] = "SynthesizingAudioStarted";
    /**
     * Indicates synthesis voices list has been successfully retrieved.
     * @member ResultReason.VoicesListRetrieved
     */
    ResultReason[ResultReason["VoicesListRetrieved"] = 10] = "VoicesListRetrieved";
    /**
     * Indicates the transcription result contains hypothesis text and its translation(s) for
     * other participants in the conversation.
     * @member ResultReason.TranslatingParticipantSpeech
     */
    ResultReason[ResultReason["TranslatingParticipantSpeech"] = 11] = "TranslatingParticipantSpeech";
    /**
     * Indicates the transcription result contains final text and corresponding translation(s)
     * for other participants in the conversation. Speech Recognition and Translation are now
     * complete for this phrase.
     * @member ResultReason.TranslatedParticipantSpeech
     */
    ResultReason[ResultReason["TranslatedParticipantSpeech"] = 12] = "TranslatedParticipantSpeech";
    /**
     * <summary>
     * Indicates the transcription result contains the instant message and corresponding
     * translation(s).
     * @member ResultReason.TranslatedInstantMessage
     */
    ResultReason[ResultReason["TranslatedInstantMessage"] = 13] = "TranslatedInstantMessage";
    /**
     * Indicates the transcription result contains the instant message for other participants
     * in the conversation and corresponding translation(s).
     * @member ResultReason.TranslatedParticipantInstantMessage
     */
    ResultReason[ResultReason["TranslatedParticipantInstantMessage"] = 14] = "TranslatedParticipantInstantMessage";
})(ResultReason = exports.ResultReason || (exports.ResultReason = {}));

//# sourceMappingURL=ResultReason.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServiceEventArgs.js"
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServiceEventArgs.js ***!
  \*****************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.
//
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ServiceEventArgs = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines payload for any Service message event
 * Added in version 1.9.0
 */
class ServiceEventArgs extends Exports_js_1.SessionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} json - json payload of the USP message.
     */
    constructor(json, name, sessionId) {
        super(sessionId);
        this.privJsonResult = json;
        this.privEventName = name;
    }
    get jsonString() {
        return this.privJsonResult;
    }
    get eventName() {
        return this.privEventName;
    }
}
exports.ServiceEventArgs = ServiceEventArgs;

//# sourceMappingURL=ServiceEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServicePropertyChannel.js"
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/ServicePropertyChannel.js ***!
  \***********************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ServicePropertyChannel = void 0;
/**
 * Defines channels used to pass property settings to service.
 * Added in version 1.7.0.
 */
var ServicePropertyChannel;
(function (ServicePropertyChannel) {
    /**
     * Uses URI query parameter to pass property settings to service.
     */
    ServicePropertyChannel[ServicePropertyChannel["UriQueryParameter"] = 0] = "UriQueryParameter";
})(ServicePropertyChannel = exports.ServicePropertyChannel || (exports.ServicePropertyChannel = {}));

//# sourceMappingURL=ServicePropertyChannel.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SessionEventArgs.js"
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SessionEventArgs.js ***!
  \*****************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SessionEventArgs = void 0;
/**
 * Defines content for session events like SessionStarted/Stopped, SoundStarted/Stopped.
 * @class SessionEventArgs
 */
class SessionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} sessionId - The session id.
     */
    constructor(sessionId) {
        this.privSessionId = sessionId;
    }
    /**
     * Represents the session identifier.
     * @member SessionEventArgs.prototype.sessionId
     * @function
     * @public
     * @returns {string} Represents the session identifier.
     */
    get sessionId() {
        return this.privSessionId;
    }
}
exports.SessionEventArgs = SessionEventArgs;

//# sourceMappingURL=SessionEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SourceLanguageConfig.js"
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SourceLanguageConfig.js ***!
  \*********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SourceLanguageConfig = void 0;
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
/**
 * Source Language configuration.
 * @class SourceLanguageConfig
 */
class SourceLanguageConfig {
    constructor(language, endpointId) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(language, "language");
        this.privLanguage = language;
        this.privEndpointId = endpointId;
    }
    /**
     * @member SourceLanguageConfig.fromLanguage
     * @function
     * @public
     * @param {string} language language (eg. "en-US") value of config.
     * @param {string?} endpointId endpointId of model bound to given language of config.
     * @return {SourceLanguageConfig} Instance of SourceLanguageConfig
     * @summary Creates an instance of the SourceLanguageConfig with the given language and optional endpointId.
     * Added in version 1.13.0.
     */
    static fromLanguage(language, endpointId) {
        return new SourceLanguageConfig(language, endpointId);
    }
    get language() {
        return this.privLanguage;
    }
    get endpointId() {
        return this.privEndpointId;
    }
}
exports.SourceLanguageConfig = SourceLanguageConfig;

//# sourceMappingURL=SourceLanguageConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechConfig.js"
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechConfig.js ***!
  \*************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
/* eslint-disable max-classes-per-file */
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechConfigImpl = exports.SpeechConfig = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Speech configuration.
 * @class SpeechConfig
 */
class SpeechConfig {
    /**
     * Creates and initializes an instance.
     * @constructor
     */
    constructor() {
        return;
    }
    /**
     * Static instance of SpeechConfig returned by passing subscriptionKey and service region.
     * @member SpeechConfig.fromSubscription
     * @function
     * @public
     * @param {string} subscriptionKey - The subscription key.
     * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {SpeechConfig} The speech factory
     */
    static fromSubscription(subscriptionKey, region) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, "region");
        const speechImpl = new SpeechConfigImpl();
        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, region);
        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
        return speechImpl;
    }
    /**
     * Internal implementation of fromEndpoint() overloads. Accepts either a subscription key or a TokenCredential.
     * @private
     */
    static fromEndpoint(endpoint, auth) {
        Contracts_js_1.Contracts.throwIfNull(endpoint, "endpoint");
        const isValidString = typeof auth === "string" && auth.trim().length > 0;
        const isTokenCredential = typeof auth === "object" && auth !== null && typeof auth.getToken === "function";
        const isKeyCredential = typeof auth === "object" && auth !== null && typeof auth.key === "string";
        if (auth !== undefined && !isValidString && !isTokenCredential && !isKeyCredential) {
            throw new Error("Invalid 'auth' parameter: expected a non-empty API key string, a TokenCredential, or a KeyCredential.");
        }
        let speechImpl;
        if (typeof auth === "string") {
            speechImpl = new SpeechConfigImpl();
            speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, auth);
        }
        else if (typeof auth === "object" && typeof auth.getToken === "function") {
            speechImpl = new SpeechConfigImpl(auth);
        }
        else if (typeof auth === "object" && typeof auth.key === "string") {
            speechImpl = new SpeechConfigImpl();
            speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, auth.key);
        }
        else {
            speechImpl = new SpeechConfigImpl();
        }
        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);
        return speechImpl;
    }
    /**
     * Creates an instance of the speech config with specified host and subscription key.
     * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
     * For services with a non-standard resource path or no path at all, use fromEndpoint instead.
     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
     * Note: To use an authorization token with fromHost, use fromHost(URL),
     * and then set the AuthorizationToken property on the created SpeechConfig instance.
     * Note: Added in version 1.9.0.
     * @member SpeechConfig.fromHost
     * @function
     * @public
     * @param {URL} host - The service endpoint to connect to. Format is "protocol://host:port" where ":port" is optional.
     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
     * @returns {SpeechConfig} A speech factory instance.
     */
    static fromHost(hostName, subscriptionKey) {
        Contracts_js_1.Contracts.throwIfNull(hostName, "hostName");
        const speechImpl = new SpeechConfigImpl();
        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, hostName.protocol + "//" + hostName.hostname + (hostName.port === "" ? "" : ":" + hostName.port));
        // Containers do not yet have /stt/speech/universal/v2 routes.
        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, "1");
        if (undefined !== subscriptionKey) {
            speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
        }
        return speechImpl;
    }
    /**
     * Creates an instance of the speech factory with specified initial authorization token and region.
     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
     * expires, the caller needs to refresh it by calling this setter with a new valid token.
     * Note: As configuration values are copied when creating a new recognizer,
     * the new token value will not apply to recognizers that have already been created. For recognizers
     * that have been created before, you need to set authorization token of the corresponding recognizer
     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
     * @member SpeechConfig.fromAuthorizationToken
     * @function
     * @public
     * @param {string} authorizationToken - The initial authorization token.
     * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {SpeechConfig} A speech factory instance.
     */
    static fromAuthorizationToken(authorizationToken, region) {
        Contracts_js_1.Contracts.throwIfNull(authorizationToken, "authorizationToken");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, "region");
        const speechImpl = new SpeechConfigImpl();
        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, region);
        speechImpl.authorizationToken = authorizationToken;
        return speechImpl;
    }
    /**
     * Closes the configuration.
     * @member SpeechConfig.prototype.close
     * @function
     * @public
     */
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    close() { }
}
exports.SpeechConfig = SpeechConfig;
/**
 * @public
 * @class SpeechConfigImpl
 */
class SpeechConfigImpl extends SpeechConfig {
    constructor(tokenCredential) {
        super();
        this.privProperties = new Exports_js_2.PropertyCollection();
        this.speechRecognitionLanguage = "en-US"; // Should we have a default?
        this.outputFormat = Exports_js_2.OutputFormat.Simple;
        this.privTokenCredential = tokenCredential;
    }
    get properties() {
        return this.privProperties;
    }
    get endPoint() {
        return new URL(this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint));
    }
    get subscriptionKey() {
        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key);
    }
    get region() {
        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region);
    }
    get authorizationToken() {
        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token);
    }
    set authorizationToken(value) {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, value);
    }
    get speechRecognitionLanguage() {
        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage);
    }
    set speechRecognitionLanguage(value) {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, value);
    }
    get autoDetectSourceLanguages() {
        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages);
    }
    set autoDetectSourceLanguages(value) {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, value);
    }
    get outputFormat() {
        return Exports_js_2.OutputFormat[this.privProperties.getProperty(Exports_js_1.OutputFormatPropertyName, undefined)];
    }
    set outputFormat(value) {
        this.privProperties.setProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_2.OutputFormat[value]);
    }
    get endpointId() {
        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId);
    }
    set endpointId(value) {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, value);
    }
    get tokenCredential() {
        return this.privTokenCredential;
    }
    setProperty(name, value) {
        Contracts_js_1.Contracts.throwIfNull(value, "value");
        this.privProperties.setProperty(name, value);
    }
    getProperty(name, def) {
        return this.privProperties.getProperty(name, def);
    }
    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);
        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);
        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);
        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);
    }
    setServiceProperty(name, value) {
        const currentProperties = JSON.parse(this.privProperties.getProperty(Exports_js_1.ServicePropertiesPropertyName, "{}"));
        currentProperties[name] = value;
        this.privProperties.setProperty(Exports_js_1.ServicePropertiesPropertyName, JSON.stringify(currentProperties));
    }
    setProfanity(profanity) {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_ProfanityOption, Exports_js_2.ProfanityOption[profanity]);
    }
    enableAudioLogging() {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EnableAudioLogging, "true");
    }
    requestWordLevelTimestamps() {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "true");
        this.privProperties.setProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_2.OutputFormat[Exports_js_2.OutputFormat.Detailed]);
    }
    enableDictation() {
        this.privProperties.setProperty(Exports_js_1.ForceDictationPropertyName, "true");
    }
    clone() {
        const ret = new SpeechConfigImpl(this.tokenCredential);
        ret.privProperties = this.privProperties.clone();
        return ret;
    }
    get speechSynthesisLanguage() {
        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthLanguage);
    }
    set speechSynthesisLanguage(language) {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthLanguage, language);
    }
    get speechSynthesisVoiceName() {
        return this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthVoice);
    }
    set speechSynthesisVoiceName(voice) {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthVoice, voice);
    }
    get speechSynthesisOutputFormat() {
        return Exports_js_2.SpeechSynthesisOutputFormat[this.privProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)];
    }
    set speechSynthesisOutputFormat(format) {
        this.privProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthOutputFormat, Exports_js_2.SpeechSynthesisOutputFormat[format]);
    }
}
exports.SpeechConfigImpl = SpeechConfigImpl;

//# sourceMappingURL=SpeechConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionCanceledEventArgs.js"
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionCanceledEventArgs.js ***!
  \***********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechRecognitionCanceledEventArgs = void 0;
const CancellationEventArgsBase_js_1 = __webpack_require__(/*! ./CancellationEventArgsBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js");
class SpeechRecognitionCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {
}
exports.SpeechRecognitionCanceledEventArgs = SpeechRecognitionCanceledEventArgs;

//# sourceMappingURL=SpeechRecognitionCanceledEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionEventArgs.js"
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionEventArgs.js ***!
  \***************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MeetingTranscriptionEventArgs = exports.ConversationTranscriptionEventArgs = exports.SpeechRecognitionEventArgs = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines contents of speech recognizing/recognized event.
 * @class SpeechRecognitionEventArgs
 */
class SpeechRecognitionEventArgs extends Exports_js_1.RecognitionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {SpeechRecognitionResult} result - The speech recognition result.
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(result, offset, sessionId) {
        super(offset, sessionId);
        this.privResult = result;
    }
    /**
     * Specifies the recognition result.
     * @member SpeechRecognitionEventArgs.prototype.result
     * @function
     * @public
     * @returns {SpeechRecognitionResult} the recognition result.
     */
    get result() {
        return this.privResult;
    }
}
exports.SpeechRecognitionEventArgs = SpeechRecognitionEventArgs;
/**
 * Defines contents of conversation transcribed/transcribing event.
 * @class ConversationTranscriptionEventArgs
 */
class ConversationTranscriptionEventArgs extends Exports_js_1.RecognitionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {ConversationTranscriptionResult} result - The conversation transcription result.
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(result, offset, sessionId) {
        super(offset, sessionId);
        this.privResult = result;
    }
    /**
     * Specifies the transcription result.
     * @member ConversationTranscription1EventArgs.prototype.result
     * @function
     * @public
     * @returns {ConversationTranscriptionResult} the recognition result.
     */
    get result() {
        return this.privResult;
    }
}
exports.ConversationTranscriptionEventArgs = ConversationTranscriptionEventArgs;
/**
 * Defines contents of meeting transcribed/transcribing event.
 * @class MeetingTranscriptionEventArgs
 */
class MeetingTranscriptionEventArgs extends SpeechRecognitionEventArgs {
}
exports.MeetingTranscriptionEventArgs = MeetingTranscriptionEventArgs;

//# sourceMappingURL=SpeechRecognitionEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionResult.js"
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognitionResult.js ***!
  \************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechRecognitionResult = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines result of speech recognition.
 * @class SpeechRecognitionResult
 */
class SpeechRecognitionResult extends Exports_js_1.RecognitionResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @public
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {string} text - The recognized text.
     * @param {number} duration - The duration.
     * @param {number} offset - The offset into the stream.
     * @param {string} language - Primary Language detected, if provided.
     * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
     * @param {string} speakerId - speaker id for conversation transcription, if provided.
     * @param {string} errorDetails - Error details, if provided.
     * @param {string} json - Additional Json, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {
        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);
        this.privSpeakerId = speakerId;
    }
    /**
     * speaker id from conversation transcription/id scenarios
     * @member SpeechRecognitionResult.prototype.speakerId
     * @function
     * @public
     * @returns {string} id of speaker in given result
     */
    get speakerId() {
        return this.privSpeakerId;
    }
}
exports.SpeechRecognitionResult = SpeechRecognitionResult;

//# sourceMappingURL=SpeechRecognitionResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognizer.js"
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechRecognizer.js ***!
  \*****************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechRecognizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ../common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.
 * @class SpeechRecognizer
 */
class SpeechRecognizer extends Exports_js_3.Recognizer {
    /**
     * SpeechRecognizer constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    constructor(speechConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        Contracts_js_1.Contracts.throwIfNull(speechConfigImpl, "speechConfig");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);
        super(audioConfig, speechConfigImpl.properties, new Exports_js_1.SpeechConnectionFactory(), speechConfig.tokenCredential);
        this.privDisposedRecognizer = false;
    }
    /**
     * SpeechRecognizer constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);
        const recognizer = new SpeechRecognizer(speechConfig, audioConfig);
        return recognizer;
    }
    /**
     * Gets the endpoint id of a customized speech model that is used for speech recognition.
     * @member SpeechRecognizer.prototype.endpointId
     * @function
     * @public
     * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.
     */
    get endpointId() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_EndpointId, "00000000-0000-0000-0000-000000000000");
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member SpeechRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member SpeechRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, token);
    }
    /**
     * Gets the spoken language of recognition.
     * @member SpeechRecognizer.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @returns {string} The spoken language of recognition.
     */
    get speechRecognitionLanguage() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage);
    }
    /**
     * Gets the output format of recognition.
     * @member SpeechRecognizer.prototype.outputFormat
     * @function
     * @public
     * @returns {OutputFormat} The output format of recognition.
     */
    get outputFormat() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        if (this.properties.getProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]) === Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]) {
            return Exports_js_3.OutputFormat.Simple;
        }
        else {
            return Exports_js_3.OutputFormat.Detailed;
        }
    }
    /**
     * The collection of properties and their values defined for this SpeechRecognizer.
     * @member SpeechRecognizer.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Starts speech recognition, and stops after the first utterance is recognized.
     * The task returns the recognition text as result.
     * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,
     * so it is suitable only for single shot recognition
     * like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.
     * @member SpeechRecognizer.prototype.recognizeOnceAsync
     * @function
     * @public
     * @param cb - Callback that received the SpeechRecognitionResult.
     * @param err - Callback invoked in case of an error.
     */
    recognizeOnceAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.recognizeOnceAsyncImpl(PhraseDetectionContext_js_1.RecognitionMode.Interactive), cb, err);
    }
    /**
     * Starts speech recognition, until stopContinuousRecognitionAsync() is called.
     * User must subscribe to events to receive recognition results.
     * @member SpeechRecognizer.prototype.startContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback invoked once the recognition has started.
     * @param err - Callback invoked in case of an error.
     */
    startContinuousRecognitionAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(this.properties.getProperty(Exports_js_1.ForceDictationPropertyName, undefined) === undefined ? PhraseDetectionContext_js_1.RecognitionMode.Conversation : PhraseDetectionContext_js_1.RecognitionMode.Dictation), cb, err);
    }
    /**
     * Stops continuous speech recognition.
     * @member SpeechRecognizer.prototype.stopContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback invoked once the recognition has stopped.
     * @param err - Callback invoked in case of an error.
     */
    stopContinuousRecognitionAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);
    }
    /**
     * Starts speech recognition with keyword spotting, until
     * stopKeywordRecognitionAsync() is called.
     * User must subscribe to events to receive recognition results.
     * Note: Key word spotting functionality is only available on the
     * Speech Devices SDK. This functionality is currently not included in the SDK itself.
     * @member SpeechRecognizer.prototype.startKeywordRecognitionAsync
     * @function
     * @public
     * @param {KeywordRecognitionModel} model The keyword recognition model that
     * specifies the keyword to be recognized.
     * @param cb - Callback invoked once the recognition has started.
     * @param err - Callback invoked in case of an error.
     */
    startKeywordRecognitionAsync(model, cb, err) {
        Contracts_js_1.Contracts.throwIfNull(model, "model");
        if (!!err) {
            err("Not yet implemented.");
        }
    }
    /**
     * Stops continuous speech recognition.
     * Note: Key word spotting functionality is only available on the
     * Speech Devices SDK. This functionality is currently not included in the SDK itself.
     * @member SpeechRecognizer.prototype.stopKeywordRecognitionAsync
     * @function
     * @public
     * @param cb - Callback invoked once the recognition has stopped.
     * @param err - Callback invoked in case of an error.
     */
    stopKeywordRecognitionAsync(cb) {
        if (!!cb) {
            cb();
        }
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member SpeechRecognizer.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
    }
    /**
     * Disposes any resources held by the object.
     * @member SpeechRecognizer.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - true if disposing the object.
     */
    async dispose(disposing) {
        if (this.privDisposedRecognizer) {
            return;
        }
        if (disposing) {
            this.privDisposedRecognizer = true;
            await this.implRecognizerStop();
        }
        await super.dispose(disposing);
    }
    createRecognizerConfig(speechConfig) {
        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const configImpl = audioConfig;
        return new Exports_js_1.SpeechServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
    }
}
exports.SpeechRecognizer = SpeechRecognizer;

//# sourceMappingURL=SpeechRecognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBookmarkEventArgs.js"
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBookmarkEventArgs.js ***!
  \*********************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesisBookmarkEventArgs = void 0;
/**
 * Defines contents of speech synthesis bookmark event.
 * @class SpeechSynthesisBookmarkEventArgs
 * Added in version 1.16.0
 */
class SpeechSynthesisBookmarkEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {number} audioOffset - The audio offset.
     * @param {string} text - The bookmark text.
     */
    constructor(audioOffset, text) {
        this.privAudioOffset = audioOffset;
        this.privText = text;
    }
    /**
     * Specifies the audio offset.
     * @member SpeechSynthesisBookmarkEventArgs.prototype.audioOffset
     * @function
     * @public
     * @returns {number} the audio offset.
     */
    get audioOffset() {
        return this.privAudioOffset;
    }
    /**
     * Specifies the bookmark.
     * @member SpeechSynthesisBookmarkEventArgs.prototype.text
     * @function
     * @public
     * @returns {string} the bookmark text.
     */
    get text() {
        return this.privText;
    }
}
exports.SpeechSynthesisBookmarkEventArgs = SpeechSynthesisBookmarkEventArgs;

//# sourceMappingURL=SpeechSynthesisBookmarkEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBoundaryType.js"
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisBoundaryType.js ***!
  \****************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesisBoundaryType = void 0;
/**
 * Defines the boundary type of speech synthesis boundary event.
 * @class SpeechSynthesisBoundaryType
 * Added in version 1.21.0
 */
var SpeechSynthesisBoundaryType;
(function (SpeechSynthesisBoundaryType) {
    /**
     * Indicates the boundary text is a word.
     * @member SpeechSynthesisBoundaryType.Word
     */
    SpeechSynthesisBoundaryType["Word"] = "WordBoundary";
    /**
     * Indicates the boundary text is a punctuation.
     * @member SpeechSynthesisBoundaryType.Punctuation
     */
    SpeechSynthesisBoundaryType["Punctuation"] = "PunctuationBoundary";
    /**
     * Indicates the boundary text is a sentence.
     * @member SpeechSynthesisBoundaryType.Sentence
     */
    SpeechSynthesisBoundaryType["Sentence"] = "SentenceBoundary";
})(SpeechSynthesisBoundaryType = exports.SpeechSynthesisBoundaryType || (exports.SpeechSynthesisBoundaryType = {}));

//# sourceMappingURL=SpeechSynthesisBoundaryType.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisEventArgs.js"
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisEventArgs.js ***!
  \*************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesisEventArgs = void 0;
/**
 * Defines contents of speech synthesis events.
 * @class SpeechSynthesisEventArgs
 * Added in version 1.11.0
 */
class SpeechSynthesisEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {SpeechSynthesisResult} result - The speech synthesis result.
     */
    constructor(result) {
        this.privResult = result;
    }
    /**
     * Specifies the synthesis result.
     * @member SpeechSynthesisEventArgs.prototype.result
     * @function
     * @public
     * @returns {SpeechSynthesisResult} the synthesis result.
     */
    get result() {
        return this.privResult;
    }
}
exports.SpeechSynthesisEventArgs = SpeechSynthesisEventArgs;

//# sourceMappingURL=SpeechSynthesisEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisOutputFormat.js"
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisOutputFormat.js ***!
  \****************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesisOutputFormat = void 0;
/**
 * Define speech synthesis audio output formats.
 * @enum SpeechSynthesisOutputFormat
 * Updated in version 1.17.0
 */
var SpeechSynthesisOutputFormat;
(function (SpeechSynthesisOutputFormat) {
    /**
     * raw-8khz-8bit-mono-mulaw
     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw,
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw8Khz8BitMonoMULaw"] = 0] = "Raw8Khz8BitMonoMULaw";
    /**
     * riff-16khz-16kbps-mono-siren
     * @note Unsupported by the service. Do not use this value.
     * @member SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff16Khz16KbpsMonoSiren"] = 1] = "Riff16Khz16KbpsMonoSiren";
    /**
     * audio-16khz-16kbps-mono-siren
     * @note Unsupported by the service. Do not use this value.
     * @member SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz16KbpsMonoSiren"] = 2] = "Audio16Khz16KbpsMonoSiren";
    /**
     * audio-16khz-32kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz32KBitRateMonoMp3"] = 3] = "Audio16Khz32KBitRateMonoMp3";
    /**
     * audio-16khz-128kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz128KBitRateMonoMp3"] = 4] = "Audio16Khz128KBitRateMonoMp3";
    /**
     * audio-16khz-64kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz64KBitRateMonoMp3"] = 5] = "Audio16Khz64KBitRateMonoMp3";
    /**
     * audio-24khz-48kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz48KBitRateMonoMp3"] = 6] = "Audio24Khz48KBitRateMonoMp3";
    /**
     * audio-24khz-96kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz96KBitRateMonoMp3"] = 7] = "Audio24Khz96KBitRateMonoMp3";
    /**
     * audio-24khz-160kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz160KBitRateMonoMp3"] = 8] = "Audio24Khz160KBitRateMonoMp3";
    /**
     * raw-16khz-16bit-mono-truesilk
     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw16Khz16BitMonoTrueSilk"] = 9] = "Raw16Khz16BitMonoTrueSilk";
    /**
     * riff-16khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff16Khz16BitMonoPcm"] = 10] = "Riff16Khz16BitMonoPcm";
    /**
     * riff-8khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff8Khz16BitMonoPcm"] = 11] = "Riff8Khz16BitMonoPcm";
    /**
     * riff-24khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff24Khz16BitMonoPcm"] = 12] = "Riff24Khz16BitMonoPcm";
    /**
     * riff-8khz-8bit-mono-mulaw
     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff8Khz8BitMonoMULaw"] = 13] = "Riff8Khz8BitMonoMULaw";
    /**
     * raw-16khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw16Khz16BitMonoPcm"] = 14] = "Raw16Khz16BitMonoPcm";
    /**
     * raw-24khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw24Khz16BitMonoPcm"] = 15] = "Raw24Khz16BitMonoPcm";
    /**
     * raw-8khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw8Khz16BitMonoPcm"] = 16] = "Raw8Khz16BitMonoPcm";
    /**
     * ogg-16khz-16bit-mono-opus
     * @member SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Ogg16Khz16BitMonoOpus"] = 17] = "Ogg16Khz16BitMonoOpus";
    /**
     * ogg-24khz-16bit-mono-opus
     * @member SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Ogg24Khz16BitMonoOpus"] = 18] = "Ogg24Khz16BitMonoOpus";
    /**
     * raw-48khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw48Khz16BitMonoPcm"] = 19] = "Raw48Khz16BitMonoPcm";
    /**
     * riff-48khz-16bit-mono-pcm
     * @member SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff48Khz16BitMonoPcm"] = 20] = "Riff48Khz16BitMonoPcm";
    /**
     * audio-48khz-96kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio48Khz96KBitRateMonoMp3"] = 21] = "Audio48Khz96KBitRateMonoMp3";
    /**
     * audio-48khz-192kbitrate-mono-mp3
     * @member SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio48Khz192KBitRateMonoMp3"] = 22] = "Audio48Khz192KBitRateMonoMp3";
    /**
     * ogg-48khz-16bit-mono-opus
     * Added in version 1.16.0
     * @member SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Ogg48Khz16BitMonoOpus"] = 23] = "Ogg48Khz16BitMonoOpus";
    /**
     * webm-16khz-16bit-mono-opus
     * Added in version 1.16.0
     * @member SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Webm16Khz16BitMonoOpus"] = 24] = "Webm16Khz16BitMonoOpus";
    /**
     * webm-24khz-16bit-mono-opus
     * Added in version 1.16.0
     * @member SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Webm24Khz16BitMonoOpus"] = 25] = "Webm24Khz16BitMonoOpus";
    /**
     * raw-24khz-16bit-mono-truesilk
     * Added in version 1.17.0
     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw24Khz16BitMonoTrueSilk"] = 26] = "Raw24Khz16BitMonoTrueSilk";
    /**
     * raw-8khz-8bit-mono-alaw
     * Added in version 1.17.0
     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw8Khz8BitMonoALaw"] = 27] = "Raw8Khz8BitMonoALaw";
    /**
     * riff-8khz-8bit-mono-alaw
     * Added in version 1.17.0
     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff8Khz8BitMonoALaw"] = 28] = "Riff8Khz8BitMonoALaw";
    /**
     * webm-24khz-16bit-24kbps-mono-opus
     * Audio compressed by OPUS codec in a webm container, with bitrate of 24kbps, optimized for IoT scenario.
     * Added in version 1.19.0
     * @member SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Webm24Khz16Bit24KbpsMonoOpus"] = 29] = "Webm24Khz16Bit24KbpsMonoOpus";
    /**
     * audio-16khz-16bit-32kbps-mono-opus
     * Audio compressed by OPUS codec without container, with bitrate of 32kbps.
     * Added in version 1.20.0
     * @member SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio16Khz16Bit32KbpsMonoOpus"] = 30] = "Audio16Khz16Bit32KbpsMonoOpus";
    /**
     * audio-24khz-16bit-48kbps-mono-opus
     * Audio compressed by OPUS codec without container, with bitrate of 48kbps.
     * Added in version 1.20.0
     * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz16Bit48KbpsMonoOpus"] = 31] = "Audio24Khz16Bit48KbpsMonoOpus";
    /**
     * audio-24khz-16bit-24kbps-mono-opus
     * Audio compressed by OPUS codec without container, with bitrate of 24kbps.
     * Added in version 1.20.0
     * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Audio24Khz16Bit24KbpsMonoOpus"] = 32] = "Audio24Khz16Bit24KbpsMonoOpus";
    /**
     * raw-22050hz-16bit-mono-pcm
     * Raw PCM audio at 22050Hz sampling rate and 16-bit depth.
     * Added in version 1.22.0
     * @member SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw22050Hz16BitMonoPcm"] = 33] = "Raw22050Hz16BitMonoPcm";
    /**
     * riff-22050hz-16bit-mono-pcm
     * PCM audio at 22050Hz sampling rate and 16-bit depth, with RIFF header.
     * Added in version 1.22.0
     * @member SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff22050Hz16BitMonoPcm"] = 34] = "Riff22050Hz16BitMonoPcm";
    /**
     * raw-44100hz-16bit-mono-pcm
     * Raw PCM audio at 44100Hz sampling rate and 16-bit depth.
     * Added in version 1.22.0
     * @member SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Raw44100Hz16BitMonoPcm"] = 35] = "Raw44100Hz16BitMonoPcm";
    /**
     * riff-44100hz-16bit-mono-pcm
     * PCM audio at 44100Hz sampling rate and 16-bit depth, with RIFF header.
     * Added in version 1.22.0
     * @member SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["Riff44100Hz16BitMonoPcm"] = 36] = "Riff44100Hz16BitMonoPcm";
    /**
     * amr-wb-16000hz
     * AMR-WB audio at 16kHz sampling rate.
     * Added in version 1.38.0
     * @member SpeechSynthesisOutputFormat.AmrWb16000Hz
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["AmrWb16000Hz"] = 37] = "AmrWb16000Hz";
    /**
     * g722-16khz-64kbps
     * G.722 audio at 16kHz sampling rate and 64kbps bitrate.
     * Added in version 1.38.0
     */
    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat["G72216Khz64Kbps"] = 38] = "G72216Khz64Kbps";
})(SpeechSynthesisOutputFormat = exports.SpeechSynthesisOutputFormat || (exports.SpeechSynthesisOutputFormat = {}));

//# sourceMappingURL=SpeechSynthesisOutputFormat.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisResult.js"
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisResult.js ***!
  \**********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesisResult = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines result of speech synthesis.
 * @class SpeechSynthesisResult
 * Added in version 1.11.0
 */
class SpeechSynthesisResult extends Exports_js_1.SynthesisResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {ArrayBuffer} audioData - The synthesized audio binary.
     * @param {string} errorDetails - Error details, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     * @param {number} audioDuration - The audio duration.
     */
    constructor(resultId, reason, audioData, errorDetails, properties, audioDuration) {
        super(resultId, reason, errorDetails, properties);
        this.privAudioData = audioData;
        this.privAudioDuration = audioDuration;
    }
    /**
     * The synthesized audio data
     * @member SpeechSynthesisResult.prototype.audioData
     * @function
     * @public
     * @returns {ArrayBuffer} The synthesized audio data.
     */
    get audioData() {
        return this.privAudioData;
    }
    /**
     * The time duration of synthesized audio, in ticks (100 nanoseconds).
     * @member SpeechSynthesisResult.prototype.audioDuration
     * @function
     * @public
     * @returns {number} The time duration of synthesized audio.
     */
    get audioDuration() {
        return this.privAudioDuration;
    }
}
exports.SpeechSynthesisResult = SpeechSynthesisResult;

//# sourceMappingURL=SpeechSynthesisResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisVisemeEventArgs.js"
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisVisemeEventArgs.js ***!
  \*******************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesisVisemeEventArgs = void 0;
/**
 * Defines contents of speech synthesis viseme event.
 * @class SpeechSynthesisVisemeEventArgs
 * Added in version 1.16.0
 */
class SpeechSynthesisVisemeEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {number} audioOffset - The audio offset.
     * @param {number} visemeId - The viseme ID.
     * @param {string} animation - The animation, could be in svg or other format.
     */
    constructor(audioOffset, visemeId, animation) {
        this.privAudioOffset = audioOffset;
        this.privVisemeId = visemeId;
        this.privAnimation = animation;
    }
    /**
     * Specifies the audio offset.
     * @member SpeechSynthesisVisemeEventArgs.prototype.audioOffset
     * @function
     * @public
     * @returns {number} the audio offset.
     */
    get audioOffset() {
        return this.privAudioOffset;
    }
    /**
     * Specifies the viseme ID.
     * @member SpeechSynthesisVisemeEventArgs.prototype.visemeId
     * @function
     * @public
     * @returns {number} the viseme ID.
     */
    get visemeId() {
        return this.privVisemeId;
    }
    /**
     * Specifies the animation.
     * @member SpeechSynthesisVisemeEventArgs.prototype.animation
     * @function
     * @public
     * @returns {string} the animation, could be in svg or other format.
     */
    get animation() {
        return this.privAnimation;
    }
}
exports.SpeechSynthesisVisemeEventArgs = SpeechSynthesisVisemeEventArgs;

//# sourceMappingURL=SpeechSynthesisVisemeEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js"
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js ***!
  \*************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesisWordBoundaryEventArgs = void 0;
/**
 * Defines contents of speech synthesis word boundary event.
 * @class SpeechSynthesisWordBoundaryEventArgs
 * Added in version 1.11.0
 */
class SpeechSynthesisWordBoundaryEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {number} audioOffset - The audio offset.
     * @param {number} duration - The audio duration.
     * @param {string} text - The text.
     * @param {number} wordLength - The length of the word.
     * @param {number} textOffset - The text offset.
     * @param {SpeechSynthesisBoundaryType} boundaryType - The boundary type
     */
    constructor(audioOffset, duration, text, wordLength, textOffset, boundaryType) {
        this.privAudioOffset = audioOffset;
        this.privDuration = duration;
        this.privText = text;
        this.privWordLength = wordLength;
        this.privTextOffset = textOffset;
        this.privBoundaryType = boundaryType;
    }
    /**
     * Specifies the audio offset.
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.audioOffset
     * @function
     * @public
     * @returns {number} the audio offset.
     */
    get audioOffset() {
        return this.privAudioOffset;
    }
    /**
     * Specifies the duration, in ticks (100 nanoseconds).
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.duration
     * @function
     * @public
     * @returns {number} Duration in 100 nanosecond increments.
     */
    get duration() {
        return this.privDuration;
    }
    /**
     * Specifies the text of the word boundary event.
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.text
     * @function
     * @public
     * @returns {string} the text.
     */
    get text() {
        return this.privText;
    }
    /**
     * Specifies the word length
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.wordLength
     * @function
     * @public
     * @returns {number} the word length
     */
    get wordLength() {
        return this.privWordLength;
    }
    /**
     * Specifies the text offset.
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.textOffset
     * @function
     * @public
     * @returns {number} the text offset.
     */
    get textOffset() {
        return this.privTextOffset;
    }
    /**
     * Specifies the boundary type.
     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.boundaryType
     * @function
     * @public
     * @returns {SpeechSynthesisBoundaryType} the boundary type.
     */
    get boundaryType() {
        return this.privBoundaryType;
    }
}
exports.SpeechSynthesisWordBoundaryEventArgs = SpeechSynthesisWordBoundaryEventArgs;

//# sourceMappingURL=SpeechSynthesisWordBoundaryEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesizer.js"
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechSynthesizer.js ***!
  \******************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechSynthesizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const AudioFileWriter_js_1 = __webpack_require__(/*! ./Audio/AudioFileWriter.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioFileWriter.js");
const AudioOutputFormat_js_1 = __webpack_require__(/*! ./Audio/AudioOutputFormat.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputFormat.js");
const AudioOutputStream_js_1 = __webpack_require__(/*! ./Audio/AudioOutputStream.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioOutputStream.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Synthesizer_js_1 = __webpack_require__(/*! ./Synthesizer.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js");
/**
 * Defines the class SpeechSynthesizer for text to speech.
 * Updated in version 1.16.0
 * @class SpeechSynthesizer
 */
class SpeechSynthesizer extends Exports_js_3.Synthesizer {
    /**
     * SpeechSynthesizer constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer.
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer.
     */
    constructor(speechConfig, audioConfig) {
        super(speechConfig);
        if (audioConfig !== null) {
            if (audioConfig === undefined) {
                this.audioConfig = (typeof window === "undefined") ? undefined : Exports_js_3.AudioConfig.fromDefaultSpeakerOutput();
            }
            else {
                this.audioConfig = audioConfig;
            }
        }
        this.privConnectionFactory = new Exports_js_1.SpeechSynthesisConnectionFactory();
        this.implCommonSynthesizeSetup();
    }
    /**
     * SpeechSynthesizer constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - an set of initial properties for this synthesizer
     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the synthesizer
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer
     */
    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);
        return new SpeechSynthesizer(speechConfig, audioConfig);
    }
    /**
     * Executes speech synthesis on plain text.
     * The task returns the synthesis result.
     * @member SpeechSynthesizer.prototype.speakTextAsync
     * @function
     * @public
     * @param text - Text to be synthesized.
     * @param cb - Callback that received the SpeechSynthesisResult.
     * @param err - Callback invoked in case of an error.
     * @param stream - AudioOutputStream to receive the synthesized audio.
     */
    speakTextAsync(text, cb, err, stream) {
        this.speakImpl(text, false, cb, err, stream);
    }
    /**
     * Executes speech synthesis on SSML.
     * The task returns the synthesis result.
     * @member SpeechSynthesizer.prototype.speakSsmlAsync
     * @function
     * @public
     * @param ssml - SSML to be synthesized.
     * @param cb - Callback that received the SpeechSynthesisResult.
     * @param err - Callback invoked in case of an error.
     * @param stream - AudioOutputStream to receive the synthesized audio.
     */
    speakSsmlAsync(ssml, cb, err, stream) {
        this.speakImpl(ssml, true, cb, err, stream);
    }
    /**
     * Get list of synthesis voices available.
     * The task returns the synthesis voice result.
     * @member SpeechSynthesizer.prototype.getVoicesAsync
     * @function
     * @async
     * @public
     * @param locale - Locale of voices in BCP-47 format; if left empty, get all available voices.
     * @return {Promise<SynthesisVoicesResult>} - Promise of a SynthesisVoicesResult.
     */
    async getVoicesAsync(locale = "") {
        return this.getVoices(locale);
    }
    /**
     * Dispose of associated resources.
     * @member SpeechSynthesizer.prototype.close
     * @function
     * @public
     */
    close(cb, err) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.dispose(true), cb, err);
    }
    /**
     * @Internal
     * Do not use externally, object returned will change without warning or notice.
     */
    get internalData() {
        return this.privAdapter;
    }
    //
    // ################################################################################################################
    // IMPLEMENTATION.
    // ################################################################################################################
    //
    // Creates the synthesis adapter
    createSynthesisAdapter(authentication, connectionFactory, synthesizerConfig) {
        return new Exports_js_1.SpeechSynthesisAdapter(authentication, connectionFactory, synthesizerConfig, this, this.audioConfig);
    }
    createRestSynthesisAdapter(authentication, synthesizerConfig) {
        return new Exports_js_1.SynthesisRestAdapter(synthesizerConfig, authentication);
    }
    implCommonSynthesizeSetup() {
        super.implCommonSynthesizeSetup();
        this.privAdapter.audioOutputFormat = AudioOutputFormat_js_1.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormat(Exports_js_3.SpeechSynthesisOutputFormat[this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)]);
    }
    speakImpl(text, IsSsml, cb, err, dataStream) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privDisposed);
            const requestId = (0, Exports_js_2.createNoDashGuid)();
            let audioDestination;
            if (dataStream instanceof Exports_js_3.PushAudioOutputStreamCallback) {
                audioDestination = new AudioOutputStream_js_1.PushAudioOutputStreamImpl(dataStream);
            }
            else if (dataStream instanceof Exports_js_3.PullAudioOutputStream) {
                audioDestination = dataStream;
            }
            else if (dataStream !== undefined) {
                audioDestination = new AudioFileWriter_js_1.AudioFileWriter(dataStream);
            }
            else {
                audioDestination = undefined;
            }
            this.synthesisRequestQueue.enqueue(new Synthesizer_js_1.SynthesisRequest(requestId, text, IsSsml, (e) => {
                this.privSynthesizing = false;
                if (!!cb) {
                    try {
                        cb(e);
                    }
                    catch (e) {
                        if (!!err) {
                            err(e);
                        }
                    }
                }
                cb = undefined;
                /* eslint-disable no-empty */
                this.adapterSpeak().catch(() => { });
            }, (e) => {
                if (!!err) {
                    err(e);
                }
            }, audioDestination));
            /* eslint-disable no-empty-function */
            this.adapterSpeak().catch(() => { });
        }
        catch (error) {
            if (!!err) {
                if (error instanceof Error) {
                    const typedError = error;
                    err(typedError.name + ": " + typedError.message);
                }
                else {
                    err(error);
                }
            }
            // Destroy the synthesizer.
            /* eslint-disable no-empty */
            this.dispose(true).catch(() => { });
        }
    }
    async getVoices(locale) {
        const requestId = (0, Exports_js_2.createNoDashGuid)();
        const response = await this.privRestAdapter.getVoicesList(requestId);
        if (response.ok && Array.isArray(response.json)) {
            let json = response.json;
            if (!!locale && locale.length > 0) {
                json = json.filter((item) => !!item.Locale && item.Locale.toLowerCase() === locale.toLowerCase());
            }
            return new Exports_js_3.SynthesisVoicesResult(requestId, json, undefined);
        }
        else {
            return new Exports_js_3.SynthesisVoicesResult(requestId, undefined, `Error: ${response.status}: ${response.statusText}`);
        }
    }
}
exports.SpeechSynthesizer = SpeechSynthesizer;

//# sourceMappingURL=SpeechSynthesizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechTranslationConfig.js"
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SpeechTranslationConfig.js ***!
  \************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SpeechTranslationConfigImpl = exports.SpeechTranslationConfig = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_2 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Speech translation configuration.
 * @class SpeechTranslationConfig
 */
class SpeechTranslationConfig extends Exports_js_2.SpeechConfig {
    /**
     * Creates an instance of recognizer config.
     */
    constructor() {
        super();
    }
    /**
     * Static instance of SpeechTranslationConfig returned by passing a subscription key and service region.
     * @member SpeechTranslationConfig.fromSubscription
     * @function
     * @public
     * @param {string} subscriptionKey - The subscription key.
     * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {SpeechTranslationConfig} The speech translation config.
     */
    static fromSubscription(subscriptionKey, region) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(subscriptionKey, "subscriptionKey");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, "region");
        const ret = new SpeechTranslationConfigImpl();
        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, region);
        return ret;
    }
    /**
     * Static instance of SpeechTranslationConfig returned by passing authorization token and service region.
     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
     * expires, the caller needs to refresh it by setting the property authorizationToken with a new
     * valid token. Otherwise, all the recognizers created by this SpeechTranslationConfig instance
     * will encounter errors during recognition.
     * As configuration values are copied when creating a new recognizer, the new token value will not apply
     * to recognizers that have already been created.
     * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
     * @member SpeechTranslationConfig.fromAuthorizationToken
     * @function
     * @public
     * @param {string} authorizationToken - The authorization token.
     * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
     * @returns {SpeechTranslationConfig} The speech translation config.
     */
    static fromAuthorizationToken(authorizationToken, region) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(authorizationToken, "authorizationToken");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(region, "region");
        const ret = new SpeechTranslationConfigImpl();
        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);
        ret.properties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region, region);
        return ret;
    }
    /**
     * Creates an instance of the speech config with specified host and subscription key.
     * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.
     * For services with a non-standard resource path or no path at all, use fromEndpoint instead.
     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.
     * Note: To use an authorization token with fromHost, use fromHost(URL),
     * and then set the AuthorizationToken property on the created SpeechConfig instance.
     * Note: Added in version 1.9.0.
     * @member SpeechConfig.fromHost
     * @function
     * @public
     * @param {URL} host - The service endpoint to connect to. Format is "protocol://host:port" where ":port" is optional.
     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
     * @returns {SpeechConfig} A speech factory instance.
     */
    static fromHost(hostName, subscriptionKey) {
        Contracts_js_1.Contracts.throwIfNull(hostName, "hostName");
        const speechImpl = new SpeechTranslationConfigImpl();
        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Host, hostName.protocol + "//" + hostName.hostname + (hostName.port === "" ? "" : ":" + hostName.port));
        if (undefined !== subscriptionKey) {
            speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, subscriptionKey);
        }
        return speechImpl;
    }
    /**
     * Internal implementation of fromEndpoint() overloads. Accepts either a subscription key or a TokenCredential.
     * @private
     */
    static fromEndpoint(endpoint, auth) {
        Contracts_js_1.Contracts.throwIfNull(endpoint, "endpoint");
        const isValidString = typeof auth === "string" && auth.trim().length > 0;
        const isTokenCredential = typeof auth === "object" && auth !== null && typeof auth.getToken === "function";
        const isKeyCredential = typeof auth === "object" && auth !== null && typeof auth.key === "string";
        if (auth !== undefined && !isValidString && !isTokenCredential && !isKeyCredential) {
            throw new Error("Invalid 'auth' parameter: expected a non-empty API key string, a TokenCredential, or a KeyCredential.");
        }
        let speechImpl;
        if (typeof auth === "string") {
            speechImpl = new SpeechTranslationConfigImpl();
            speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, auth);
        }
        else if (typeof auth === "object" && typeof auth.getToken === "function") {
            speechImpl = new SpeechTranslationConfigImpl(auth);
        }
        else if (typeof auth === "object" && typeof auth.key === "string") {
            speechImpl = new SpeechTranslationConfigImpl();
            speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Key, auth.key);
        }
        else {
            speechImpl = new SpeechTranslationConfigImpl();
        }
        speechImpl.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);
        return speechImpl;
    }
}
exports.SpeechTranslationConfig = SpeechTranslationConfig;
/**
 * @private
 * @class SpeechTranslationConfigImpl
 */
class SpeechTranslationConfigImpl extends SpeechTranslationConfig {
    constructor(tokenCredential) {
        super();
        this.privSpeechProperties = new Exports_js_2.PropertyCollection();
        this.outputFormat = Exports_js_2.OutputFormat.Simple;
        this.privTokenCredential = tokenCredential;
    }
    /**
     * Gets/Sets the authorization token.
     * If this is set, subscription key is ignored.
     * User needs to make sure the provided authorization token is valid and not expired.
     * @member SpeechTranslationConfigImpl.prototype.authorizationToken
     * @function
     * @public
     * @param {string} value - The authorization token.
     */
    set authorizationToken(value) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, "value");
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceAuthorization_Token, value);
    }
    /**
     * Sets the speech recognition language.
     * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @param {string} value - The authorization token.
     */
    set speechRecognitionLanguage(value) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, "value");
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage, value);
    }
    /**
     * Gets the speech recognition language.
     * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @return {string} The speechRecognitionLanguage.
     */
    get speechRecognitionLanguage() {
        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_RecoLanguage]);
    }
    /**
     * @member SpeechTranslationConfigImpl.prototype.subscriptionKey
     * @function
     * @public
     */
    get subscriptionKey() {
        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_Key]);
    }
    /**
     * Gets the output format
     * @member SpeechTranslationConfigImpl.prototype.outputFormat
     * @function
     * @public
     */
    get outputFormat() {
        // eslint-disable-next-line
        return Exports_js_2.OutputFormat[this.privSpeechProperties.getProperty(Exports_js_1.OutputFormatPropertyName, undefined)];
    }
    /**
     * Gets/Sets the output format
     * @member SpeechTranslationConfigImpl.prototype.outputFormat
     * @function
     * @public
     */
    set outputFormat(value) {
        this.privSpeechProperties.setProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_2.OutputFormat[value]);
    }
    /**
     * Gets the endpoint id.
     * @member SpeechTranslationConfigImpl.prototype.endpointId
     * @function
     * @public
     */
    get endpointId() {
        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId);
    }
    /**
     * Gets/Sets the endpoint id.
     * @member SpeechTranslationConfigImpl.prototype.endpointId
     * @function
     * @public
     */
    set endpointId(value) {
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EndpointId, value);
    }
    /**
     * Add a (text) target language to translate into.
     * @member SpeechTranslationConfigImpl.prototype.addTargetLanguage
     * @function
     * @public
     * @param {string} value - The language such as de-DE
     */
    addTargetLanguage(value) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, "value");
        const languages = this.targetLanguages;
        if (!languages.includes(value)) {
            languages.push(value);
            this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(","));
        }
    }
    /**
     * Gets the (text) target language to translate into.
     * @member SpeechTranslationConfigImpl.prototype.targetLanguages
     * @function
     * @public
     * @param {string} value - The language such as de-DE
     */
    get targetLanguages() {
        if (this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
            return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
        }
        else {
            return [];
        }
    }
    /**
     * Gets the voice name.
     * @member SpeechTranslationConfigImpl.prototype.voiceName
     * @function
     * @public
     */
    get voiceName() {
        return this.getProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_TranslationVoice]);
    }
    /**
     * Gets/Sets the voice of the translated language, enable voice synthesis output.
     * @member SpeechTranslationConfigImpl.prototype.voiceName
     * @function
     * @public
     * @param {string} value - The name of the voice.
     */
    set voiceName(value) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, "value");
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_TranslationVoice, value);
    }
    /**
     * Provides the region.
     * @member SpeechTranslationConfigImpl.prototype.region
     * @function
     * @public
     * @returns {string} The region.
     */
    get region() {
        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_Region);
    }
    get tokenCredential() {
        return this.privTokenCredential;
    }
    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {
        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);
        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);
        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);
        this.setProperty(Exports_js_2.PropertyId[Exports_js_2.PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);
    }
    /**
     * Gets an arbitrary property value.
     * @member SpeechTranslationConfigImpl.prototype.getProperty
     * @function
     * @public
     * @param {string} name - The name of the property.
     * @param {string} def - The default value of the property in case it is not set.
     * @returns {string} The value of the property.
     */
    getProperty(name, def) {
        return this.privSpeechProperties.getProperty(name, def);
    }
    /**
     * Gets/Sets an arbitrary property value.
     * @member SpeechTranslationConfigImpl.prototype.setProperty
     * @function
     * @public
     * @param {string | PropertyId} name - The name of the property to set.
     * @param {string} value - The value of the property.
     */
    setProperty(name, value) {
        this.privSpeechProperties.setProperty(name, value);
    }
    /**
     * Provides access to custom properties.
     * @member SpeechTranslationConfigImpl.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The properties.
     */
    get properties() {
        return this.privSpeechProperties;
    }
    /**
     * Dispose of associated resources.
     * @member SpeechTranslationConfigImpl.prototype.close
     * @function
     * @public
     */
    close() {
        return;
    }
    setServiceProperty(name, value) {
        const currentProperties = JSON.parse(this.privSpeechProperties.getProperty(Exports_js_1.ServicePropertiesPropertyName, "{}"));
        currentProperties[name] = value;
        this.privSpeechProperties.setProperty(Exports_js_1.ServicePropertiesPropertyName, JSON.stringify(currentProperties));
    }
    setProfanity(profanity) {
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_ProfanityOption, Exports_js_2.ProfanityOption[profanity]);
    }
    enableAudioLogging() {
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_EnableAudioLogging, "true");
    }
    requestWordLevelTimestamps() {
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, "true");
    }
    enableDictation() {
        this.privSpeechProperties.setProperty(Exports_js_1.ForceDictationPropertyName, "true");
    }
    get speechSynthesisLanguage() {
        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthLanguage);
    }
    set speechSynthesisLanguage(language) {
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthLanguage, language);
    }
    get speechSynthesisVoiceName() {
        return this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthVoice);
    }
    set speechSynthesisVoiceName(voice) {
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthVoice, voice);
    }
    get speechSynthesisOutputFormat() {
        // eslint-disable-next-line
        return Exports_js_2.SpeechSynthesisOutputFormat[this.privSpeechProperties.getProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)];
    }
    set speechSynthesisOutputFormat(format) {
        this.privSpeechProperties.setProperty(Exports_js_2.PropertyId.SpeechServiceConnection_SynthOutputFormat, Exports_js_2.SpeechSynthesisOutputFormat[format]);
    }
}
exports.SpeechTranslationConfigImpl = SpeechTranslationConfigImpl;

//# sourceMappingURL=SpeechTranslationConfig.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisResult.js"
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisResult.js ***!
  \****************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesisResult = void 0;
/**
 * Base class for synthesis results
 * @class SynthesisResult
 * Added in version 1.20.0
 */
class SynthesisResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {string} errorDetails - Error details, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(resultId, reason, errorDetails, properties) {
        this.privResultId = resultId;
        this.privReason = reason;
        this.privErrorDetails = errorDetails;
        this.privProperties = properties;
    }
    /**
     * Specifies the result identifier.
     * @member SynthesisResult.prototype.resultId
     * @function
     * @public
     * @returns {string} Specifies the result identifier.
     */
    get resultId() {
        return this.privResultId;
    }
    /**
     * Specifies status of the result.
     * @member SynthesisResult.prototype.reason
     * @function
     * @public
     * @returns {ResultReason} Specifies status of the result.
     */
    get reason() {
        return this.privReason;
    }
    /**
     * In case of an unsuccessful synthesis, provides details of the occurred error.
     * @member SynthesisResult.prototype.errorDetails
     * @function
     * @public
     * @returns {string} a brief description of an error.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
    /**
     * The set of properties exposed in the result.
     * @member SynthesisResult.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The set of properties exposed in the result.
     */
    get properties() {
        return this.privProperties;
    }
}
exports.SynthesisResult = SynthesisResult;

//# sourceMappingURL=SynthesisResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisVoicesResult.js"
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/SynthesisVoicesResult.js ***!
  \**********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesisVoicesResult = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines result of speech synthesis.
 * @class SynthesisVoicesResult
 * Added in version 1.20.0
 */
class SynthesisVoicesResult extends Exports_js_1.SynthesisResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param requestId - result id for request.
     * @param json - json payload from endpoint.
     */
    constructor(requestId, json, errorDetails) {
        if (Array.isArray(json)) {
            super(requestId, Exports_js_1.ResultReason.VoicesListRetrieved, undefined, new Exports_js_1.PropertyCollection());
            this.privVoices = [];
            for (const item of json) {
                this.privVoices.push(new Exports_js_1.VoiceInfo(item));
            }
        }
        else {
            super(requestId, Exports_js_1.ResultReason.Canceled, errorDetails ? errorDetails : "Error information unavailable", new Exports_js_1.PropertyCollection());
        }
    }
    /**
     * The list of voices
     * @member SynthesisVoicesResult.prototype.voices
     * @function
     * @public
     * @returns {VoiceInfo[]} List of synthesized voices.
     */
    get voices() {
        return this.privVoices;
    }
}
exports.SynthesisVoicesResult = SynthesisVoicesResult;

//# sourceMappingURL=SynthesisVoicesResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js"
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Synthesizer.js ***!
  \************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SynthesisRequest = exports.Synthesizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
class Synthesizer {
    /**
     * Creates and initializes an instance of a Recognizer
     * @constructor
     * @param {SpeechConfig} speechConfig - The speech config to initialize the synthesizer.
     */
    constructor(speechConfig) {
        const speechConfigImpl = speechConfig;
        Contracts_js_1.Contracts.throwIfNull(speechConfigImpl, "speechConfig");
        this.privProperties = speechConfigImpl.properties.clone();
        this.privDisposed = false;
        this.privSynthesizing = false;
        this.synthesisRequestQueue = new Exports_js_2.Queue();
        this.tokenCredential = speechConfig.tokenCredential;
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member Synthesizer.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member Synthesizer.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, token);
    }
    /**
     * The collection of properties and their values defined for this Synthesizer.
     * @member Synthesizer.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechSynthesizer.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Indicates if auto detect source language is enabled
     * @member Synthesizer.prototype.autoDetectSourceLanguage
     * @function
     * @public
     * @returns {boolean} if auto detect source language is enabled
     */
    get autoDetectSourceLanguage() {
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages) === Exports_js_1.AutoDetectSourceLanguagesOpenRangeOptionName;
    }
    buildSsml(text) {
        const languageToDefaultVoice = {
            ["af-ZA"]: "af-ZA-AdriNeural",
            ["am-ET"]: "am-ET-AmehaNeural",
            ["ar-AE"]: "ar-AE-FatimaNeural",
            ["ar-BH"]: "ar-BH-AliNeural",
            ["ar-DZ"]: "ar-DZ-AminaNeural",
            ["ar-EG"]: "ar-EG-SalmaNeural",
            ["ar-IQ"]: "ar-IQ-BasselNeural",
            ["ar-JO"]: "ar-JO-SanaNeural",
            ["ar-KW"]: "ar-KW-FahedNeural",
            ["ar-LY"]: "ar-LY-ImanNeural",
            ["ar-MA"]: "ar-MA-JamalNeural",
            ["ar-QA"]: "ar-QA-AmalNeural",
            ["ar-SA"]: "ar-SA-HamedNeural",
            ["ar-SY"]: "ar-SY-AmanyNeural",
            ["ar-TN"]: "ar-TN-HediNeural",
            ["ar-YE"]: "ar-YE-MaryamNeural",
            ["bg-BG"]: "bg-BG-BorislavNeural",
            ["bn-BD"]: "bn-BD-NabanitaNeural",
            ["bn-IN"]: "bn-IN-BashkarNeural",
            ["ca-ES"]: "ca-ES-JoanaNeural",
            ["cs-CZ"]: "cs-CZ-AntoninNeural",
            ["cy-GB"]: "cy-GB-AledNeural",
            ["da-DK"]: "da-DK-ChristelNeural",
            ["de-AT"]: "de-AT-IngridNeural",
            ["de-CH"]: "de-CH-JanNeural",
            ["de-DE"]: "de-DE-KatjaNeural",
            ["el-GR"]: "el-GR-AthinaNeural",
            ["en-AU"]: "en-AU-NatashaNeural",
            ["en-CA"]: "en-CA-ClaraNeural",
            ["en-GB"]: "en-GB-LibbyNeural",
            ["en-HK"]: "en-HK-SamNeural",
            ["en-IE"]: "en-IE-ConnorNeural",
            ["en-IN"]: "en-IN-NeerjaNeural",
            ["en-KE"]: "en-KE-AsiliaNeural",
            ["en-NG"]: "en-NG-AbeoNeural",
            ["en-NZ"]: "en-NZ-MitchellNeural",
            ["en-PH"]: "en-PH-JamesNeural",
            ["en-SG"]: "en-SG-LunaNeural",
            ["en-TZ"]: "en-TZ-ElimuNeural",
            ["en-US"]: "en-US-AvaMultilingualNeural",
            ["en-ZA"]: "en-ZA-LeahNeural",
            ["es-AR"]: "es-AR-ElenaNeural",
            ["es-BO"]: "es-BO-MarceloNeural",
            ["es-CL"]: "es-CL-CatalinaNeural",
            ["es-CO"]: "es-CO-GonzaloNeural",
            ["es-CR"]: "es-CR-JuanNeural",
            ["es-CU"]: "es-CU-BelkysNeural",
            ["es-DO"]: "es-DO-EmilioNeural",
            ["es-EC"]: "es-EC-AndreaNeural",
            ["es-ES"]: "es-ES-AlvaroNeural",
            ["es-GQ"]: "es-GQ-JavierNeural",
            ["es-GT"]: "es-GT-AndresNeural",
            ["es-HN"]: "es-HN-CarlosNeural",
            ["es-MX"]: "es-MX-DaliaNeural",
            ["es-NI"]: "es-NI-FedericoNeural",
            ["es-PA"]: "es-PA-MargaritaNeural",
            ["es-PE"]: "es-PE-AlexNeural",
            ["es-PR"]: "es-PR-KarinaNeural",
            ["es-PY"]: "es-PY-MarioNeural",
            ["es-SV"]: "es-SV-LorenaNeural",
            ["es-US"]: "es-US-AlonsoNeural",
            ["es-UY"]: "es-UY-MateoNeural",
            ["es-VE"]: "es-VE-PaolaNeural",
            ["et-EE"]: "et-EE-AnuNeural",
            ["fa-IR"]: "fa-IR-DilaraNeural",
            ["fi-FI"]: "fi-FI-SelmaNeural",
            ["fil-PH"]: "fil-PH-AngeloNeural",
            ["fr-BE"]: "fr-BE-CharlineNeural",
            ["fr-CA"]: "fr-CA-SylvieNeural",
            ["fr-CH"]: "fr-CH-ArianeNeural",
            ["fr-FR"]: "fr-FR-DeniseNeural",
            ["ga-IE"]: "ga-IE-ColmNeural",
            ["gl-ES"]: "gl-ES-RoiNeural",
            ["gu-IN"]: "gu-IN-DhwaniNeural",
            ["he-IL"]: "he-IL-AvriNeural",
            ["hi-IN"]: "hi-IN-MadhurNeural",
            ["hr-HR"]: "hr-HR-GabrijelaNeural",
            ["hu-HU"]: "hu-HU-NoemiNeural",
            ["id-ID"]: "id-ID-ArdiNeural",
            ["is-IS"]: "is-IS-GudrunNeural",
            ["it-IT"]: "it-IT-IsabellaNeural",
            ["ja-JP"]: "ja-JP-NanamiNeural",
            ["jv-ID"]: "jv-ID-DimasNeural",
            ["kk-KZ"]: "kk-KZ-AigulNeural",
            ["km-KH"]: "km-KH-PisethNeural",
            ["kn-IN"]: "kn-IN-GaganNeural",
            ["ko-KR"]: "ko-KR-SunHiNeural",
            ["lo-LA"]: "lo-LA-ChanthavongNeural",
            ["lt-LT"]: "lt-LT-LeonasNeural",
            ["lv-LV"]: "lv-LV-EveritaNeural",
            ["mk-MK"]: "mk-MK-AleksandarNeural",
            ["ml-IN"]: "ml-IN-MidhunNeural",
            ["mr-IN"]: "mr-IN-AarohiNeural",
            ["ms-MY"]: "ms-MY-OsmanNeural",
            ["mt-MT"]: "mt-MT-GraceNeural",
            ["my-MM"]: "my-MM-NilarNeural",
            ["nb-NO"]: "nb-NO-PernilleNeural",
            ["nl-BE"]: "nl-BE-ArnaudNeural",
            ["nl-NL"]: "nl-NL-ColetteNeural",
            ["pl-PL"]: "pl-PL-AgnieszkaNeural",
            ["ps-AF"]: "ps-AF-GulNawazNeural",
            ["pt-BR"]: "pt-BR-FranciscaNeural",
            ["pt-PT"]: "pt-PT-DuarteNeural",
            ["ro-RO"]: "ro-RO-AlinaNeural",
            ["ru-RU"]: "ru-RU-SvetlanaNeural",
            ["si-LK"]: "si-LK-SameeraNeural",
            ["sk-SK"]: "sk-SK-LukasNeural",
            ["sl-SI"]: "sl-SI-PetraNeural",
            ["so-SO"]: "so-SO-MuuseNeural",
            ["sr-RS"]: "sr-RS-NicholasNeural",
            ["su-ID"]: "su-ID-JajangNeural",
            ["sv-SE"]: "sv-SE-SofieNeural",
            ["sw-KE"]: "sw-KE-RafikiNeural",
            ["sw-TZ"]: "sw-TZ-DaudiNeural",
            ["ta-IN"]: "ta-IN-PallaviNeural",
            ["ta-LK"]: "ta-LK-KumarNeural",
            ["ta-SG"]: "ta-SG-AnbuNeural",
            ["te-IN"]: "te-IN-MohanNeural",
            ["th-TH"]: "th-TH-PremwadeeNeural",
            ["tr-TR"]: "tr-TR-AhmetNeural",
            ["uk-UA"]: "uk-UA-OstapNeural",
            ["ur-IN"]: "ur-IN-GulNeural",
            ["ur-PK"]: "ur-PK-AsadNeural",
            ["uz-UZ"]: "uz-UZ-MadinaNeural",
            ["vi-VN"]: "vi-VN-HoaiMyNeural",
            ["zh-CN"]: "zh-CN-XiaoxiaoNeural",
            ["zh-HK"]: "zh-HK-HiuMaanNeural",
            ["zh-TW"]: "zh-TW-HsiaoChenNeural",
            ["zu-ZA"]: "zu-ZA-ThandoNeural",
        };
        let language = this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SynthLanguage, "en-US");
        let voice = this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_SynthVoice, "");
        let ssml = Synthesizer.XMLEncode(text);
        if (this.autoDetectSourceLanguage) {
            language = "en-US";
        }
        else {
            voice = voice || languageToDefaultVoice[language];
        }
        if (voice) {
            ssml = `<voice name='${voice}'>${ssml}</voice>`;
        }
        ssml = `<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xmlns:emo='http://www.w3.org/2009/10/emotionml' xml:lang='${language}'>${ssml}</speak>`;
        return ssml;
    }
    /**
     * This method performs cleanup of resources.
     * The Boolean parameter disposing indicates whether the method is called
     * from Dispose (if disposing is true) or from the finalizer (if disposing is false).
     * Derived classes should override this method to dispose resource if needed.
     * @member Synthesizer.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - Flag to request disposal.
     */
    async dispose(disposing) {
        if (this.privDisposed) {
            return;
        }
        if (disposing) {
            if (this.privAdapter) {
                await this.privAdapter.dispose();
            }
        }
        this.privDisposed = true;
    }
    async adapterSpeak() {
        if (!this.privDisposed && !this.privSynthesizing) {
            this.privSynthesizing = true;
            const request = await this.synthesisRequestQueue.dequeue();
            return this.privAdapter.Speak(request.text, request.isSSML, request.requestId, request.cb, request.err, request.dataStream);
        }
    }
    createSynthesizerConfig(speechConfig) {
        return new Exports_js_1.SynthesizerConfig(speechConfig, this.privProperties);
    }
    // Does the generic synthesizer setup that is common across all synthesizer types.
    implCommonSynthesizeSetup() {
        let osPlatform = (typeof window !== "undefined") ? "Browser" : "Node";
        let osName = "unknown";
        let osVersion = "unknown";
        if (typeof navigator !== "undefined") {
            osPlatform = osPlatform + "/" + navigator.platform;
            osName = navigator.userAgent;
            osVersion = navigator.appVersion;
        }
        const synthesizerConfig = this.createSynthesizerConfig(new Exports_js_1.SpeechServiceConfig(new Exports_js_1.Context(new Exports_js_1.OS(osPlatform, osName, osVersion))));
        const subscriptionKey = this.privProperties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_Key, undefined);
        const authentication = (subscriptionKey && subscriptionKey !== "")
            ? new Exports_js_1.CognitiveSubscriptionKeyAuthentication(subscriptionKey)
            : (this.tokenCredential)
                ? new Exports_js_1.CognitiveTokenAuthentication(async () => {
                    try {
                        const tokenResponse = await this.tokenCredential.getToken("https://cognitiveservices.azure.com/.default");
                        return tokenResponse?.token ?? "";
                    }
                    catch (err) {
                        throw err;
                    }
                }, async () => {
                    try {
                        const tokenResponse = await this.tokenCredential.getToken("https://cognitiveservices.azure.com/.default");
                        return tokenResponse?.token ?? "";
                    }
                    catch (err) {
                        throw err;
                    }
                })
                : new Exports_js_1.CognitiveTokenAuthentication(() => {
                    const authorizationToken = this.privProperties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, undefined);
                    return Promise.resolve(authorizationToken);
                }, () => {
                    const authorizationToken = this.privProperties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, undefined);
                    return Promise.resolve(authorizationToken);
                });
        this.privAdapter = this.createSynthesisAdapter(authentication, this.privConnectionFactory, synthesizerConfig);
        this.privRestAdapter = this.createRestSynthesisAdapter(authentication, synthesizerConfig);
    }
    static XMLEncode(text) {
        return text.replace(/&/g, "&amp;")
            .replace(/</g, "&lt;")
            .replace(/>/g, "&gt;")
            .replace(/"/g, "&quot;")
            .replace(/'/g, "&apos;");
    }
}
exports.Synthesizer = Synthesizer;
class SynthesisRequest {
    constructor(requestId, text, isSSML, cb, err, dataStream) {
        this.requestId = requestId;
        this.text = text;
        this.isSSML = isSSML;
        this.cb = cb;
        this.err = err;
        this.dataStream = dataStream;
    }
}
exports.SynthesisRequest = SynthesisRequest;

//# sourceMappingURL=Synthesizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Conversation.js"
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Conversation.js ***!
  \***************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationImpl = exports.Conversation = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
class Conversation {
    constructor() {
        return;
    }
    /**
     * Create a conversation
     * @param speechConfig
     * @param cb
     * @param err
     */
    static createConversationAsync(speechConfig, arg2, arg3, arg4) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "config"));
        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig.region, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Region"));
        if (!speechConfig.subscriptionKey && !speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceAuthorization_Token])) {
            Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig.subscriptionKey, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Key"));
        }
        let conversationImpl;
        let cb;
        let err;
        if (typeof arg2 === "string") {
            conversationImpl = new ConversationImpl(speechConfig, arg2);
            // eslint-disable-next-line @typescript-eslint/no-empty-function
            (0, Exports_js_2.marshalPromiseToCallbacks)((async () => { })(), arg3, arg4);
        }
        else {
            conversationImpl = new ConversationImpl(speechConfig);
            cb = arg2;
            err = arg3;
            conversationImpl.createConversationAsync((() => {
                if (!!cb) {
                    cb();
                }
            }), (error) => {
                if (!!err) {
                    err(error);
                }
            });
        }
        return conversationImpl;
    }
}
exports.Conversation = Conversation;
class ConversationImpl extends Conversation {
    /**
     * Create a conversation impl
     * @param speechConfig
     * @param {string} id - optional conversationId
     */
    constructor(speechConfig, id) {
        super();
        this.privErrors = Exports_js_1.ConversationConnectionConfig.restErrors;
        /** websocket callbacks */
        /* eslint-disable @typescript-eslint/typedef */
        this.onConnected = (e) => {
            this.privIsConnected = true;
            try {
                if (!!this.privConversationTranslator?.sessionStarted) {
                    this.privConversationTranslator.sessionStarted(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        };
        this.onDisconnected = (e) => {
            try {
                if (!!this.privConversationTranslator?.sessionStopped) {
                    this.privConversationTranslator.sessionStopped(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
            finally {
                void this.close(false);
            }
        };
        this.onCanceled = (r, e) => {
            try {
                if (!!this.privConversationTranslator?.canceled) {
                    this.privConversationTranslator.canceled(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantUpdateCommandReceived = (r, e) => {
            try {
                const updatedParticipant = this.privParticipants.getParticipant(e.id);
                if (updatedParticipant !== undefined) {
                    switch (e.key) {
                        case Exports_js_1.ConversationTranslatorCommandTypes.changeNickname:
                            updatedParticipant.displayName = e.value;
                            break;
                        case Exports_js_1.ConversationTranslatorCommandTypes.setUseTTS:
                            updatedParticipant.isUsingTts = e.value;
                            break;
                        case Exports_js_1.ConversationTranslatorCommandTypes.setProfanityFiltering:
                            updatedParticipant.profanity = e.value;
                            break;
                        case Exports_js_1.ConversationTranslatorCommandTypes.setMute:
                            updatedParticipant.isMuted = e.value;
                            break;
                        case Exports_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages:
                            updatedParticipant.translateToLanguages = e.value;
                            break;
                    }
                    this.privParticipants.addOrUpdateParticipant(updatedParticipant);
                    if (!!this.privConversationTranslator) {
                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.Updated, [this.toParticipant(updatedParticipant)], e.sessionId));
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onLockRoomCommandReceived = () => {
            // TODO
        };
        this.onMuteAllCommandReceived = (r, e) => {
            try {
                this.privParticipants.participants.forEach((p) => p.isMuted = (p.isHost ? false : e.isMuted));
                if (!!this.privConversationTranslator) {
                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.Updated, this.toParticipants(false), e.sessionId));
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantJoinCommandReceived = (r, e) => {
            try {
                const newParticipant = this.privParticipants.addOrUpdateParticipant(e.participant);
                if (newParticipant !== undefined) {
                    if (!!this.privConversationTranslator) {
                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.JoinedConversation, [this.toParticipant(newParticipant)], e.sessionId));
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantLeaveCommandReceived = (r, e) => {
            try {
                const ejectedParticipant = this.privParticipants.getParticipant(e.participant.id);
                if (ejectedParticipant !== undefined) {
                    // remove the participant from the internal participants list
                    this.privParticipants.deleteParticipant(e.participant.id);
                    if (!!this.privConversationTranslator) {
                        // notify subscribers that the participant has left the conversation
                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.LeftConversation, [this.toParticipant(ejectedParticipant)], e.sessionId));
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onTranslationReceived = (r, e) => {
            try {
                switch (e.command) {
                    case Exports_js_1.ConversationTranslatorMessageTypes.final:
                        if (!!this.privConversationTranslator) {
                            this.privConversationTranslator.transcribed(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));
                        }
                        break;
                    case Exports_js_1.ConversationTranslatorMessageTypes.partial:
                        if (!!this.privConversationTranslator) {
                            this.privConversationTranslator.transcribing(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));
                        }
                        break;
                    case Exports_js_1.ConversationTranslatorMessageTypes.instantMessage:
                        if (!!this.privConversationTranslator) {
                            this.privConversationTranslator.textMessageReceived(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));
                        }
                        break;
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantsListReceived = (r, e) => {
            try {
                // check if the session token needs to be updated
                if (e.sessionToken !== undefined && e.sessionToken !== null) {
                    this.privRoom.token = e.sessionToken;
                }
                // save the participants
                this.privParticipants.participants = [...e.participants];
                // enable the conversation
                if (this.privParticipants.me !== undefined) {
                    this.privIsReady = true;
                }
                if (!!this.privConversationTranslator) {
                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.JoinedConversation, this.toParticipants(true), e.sessionId));
                }
                // if this is the host, update the nickname if needed
                if (this.me.isHost) {
                    const nickname = this.privConversationTranslator?.properties.getProperty(Exports_js_3.PropertyId.ConversationTranslator_Name);
                    if (nickname !== undefined && nickname.length > 0 && nickname !== this.me.displayName) {
                        // issue a change nickname request
                        this.changeNicknameAsync(nickname);
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onConversationExpiration = (r, e) => {
            try {
                if (!!this.privConversationTranslator) {
                    this.privConversationTranslator.conversationExpiration(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        };
        this.privIsConnected = false;
        this.privIsDisposed = false;
        this.privConversationId = "";
        this.privProperties = new Exports_js_3.PropertyCollection();
        this.privManager = new Exports_js_1.ConversationManager();
        // check the speech language
        const language = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);
        if (!language) {
            speechConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage], Exports_js_1.ConversationConnectionConfig.defaultLanguageCode);
        }
        this.privLanguage = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);
        if (!id) {
            // check the target language(s)
            if (speechConfig.targetLanguages.length === 0) {
                speechConfig.addTargetLanguage(this.privLanguage);
            }
            // check the profanity setting: speech and conversationTranslator should be in sync
            const profanity = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceResponse_ProfanityOption]);
            if (!profanity) {
                speechConfig.setProfanity(Exports_js_3.ProfanityOption.Masked);
            }
            // check the nickname: it should pass this regex: ^\w+([\s-][\w\(\)]+)*$"
            // TODO: specify the regex required. Nicknames must be unique or get the duplicate nickname error
            // TODO: check what the max length is and if a truncation is required or if the service handles it without an error
            let hostNickname = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.ConversationTranslator_Name]);
            if (hostNickname === undefined || hostNickname === null) {
                hostNickname = "Host";
            }
            Contracts_js_1.Contracts.throwIfNullOrTooLong(hostNickname, "nickname", 50);
            Contracts_js_1.Contracts.throwIfNullOrTooShort(hostNickname, "nickname", 2);
            speechConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.ConversationTranslator_Name], hostNickname);
        }
        else {
            this.privConversationId = id;
        }
        // save the speech config for future usage
        this.privConfig = speechConfig;
        // save the config properties
        const configImpl = speechConfig;
        Contracts_js_1.Contracts.throwIfNull(configImpl, "speechConfig");
        this.privProperties = configImpl.properties.clone();
        this.privIsConnected = false;
        this.privParticipants = new Exports_js_1.InternalParticipants();
        this.privIsReady = false;
        this.privTextMessageMaxLength = 1000;
    }
    // get the internal data about a conversation
    get room() {
        return this.privRoom;
    }
    // get the wrapper for connecting to the websockets
    get connection() {
        return this.privConversationRecognizer; // this.privConnection;
    }
    // get the config
    get config() {
        return this.privConfig;
    }
    // get the conversation Id
    get conversationId() {
        return this.privRoom ? this.privRoom.roomId : this.privConversationId;
    }
    // get the properties
    get properties() {
        return this.privProperties;
    }
    // get the speech language
    get speechRecognitionLanguage() {
        return this.privLanguage;
    }
    get isMutedByHost() {
        return this.privParticipants.me?.isHost ? false : this.privParticipants.me?.isMuted;
    }
    get isConnected() {
        return this.privIsConnected && this.privIsReady;
    }
    get participants() {
        return this.toParticipants(true);
    }
    get me() {
        return this.toParticipant(this.privParticipants.me);
    }
    get host() {
        return this.toParticipant(this.privParticipants.host);
    }
    get transcriberRecognizer() {
        return this.privTranscriberRecognizer;
    }
    get conversationInfo() {
        const convId = this.conversationId;
        const p = this.participants.map((part) => ({
            id: part.id,
            preferredLanguage: part.preferredLanguage,
            voice: part.voice
        }));
        const props = {};
        for (const key of Exports_js_1.ConversationConnectionConfig.transcriptionEventKeys) {
            const val = this.properties.getProperty(key, "");
            if (val !== "") {
                props[key] = val;
            }
        }
        const info = { id: convId, participants: p, conversationProperties: props };
        return info;
    }
    get canSend() {
        return this.privIsConnected && !this.privParticipants.me?.isMuted;
    }
    get canSendAsHost() {
        return this.privIsConnected && this.privParticipants.me?.isHost;
    }
    // get / set the speech auth token
    // eslint-disable-next-line @typescript-eslint/member-ordering
    get authorizationToken() {
        return this.privToken;
    }
    set authorizationToken(value) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, "authorizationToken");
        this.privToken = value;
    }
    set conversationTranslator(conversationTranslator) {
        this.privConversationTranslator = conversationTranslator;
    }
    onToken(token) {
        this.privConversationTranslator.onToken(token);
    }
    /**
     * Create a new conversation as Host
     * @param cb
     * @param err
     */
    createConversationAsync(cb, err) {
        try {
            if (!!this.privConversationRecognizer) {
                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
            }
            this.privManager.createOrJoin(this.privProperties, undefined, ((room) => {
                if (!room) {
                    this.handleError(new Error(this.privErrors.permissionDeniedConnect), err);
                }
                this.privRoom = room;
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Starts a new conversation as host.
     * @param cb
     * @param err
     */
    startConversationAsync(cb, err) {
        try {
            // check if there is already a recognizer
            if (!!this.privConversationRecognizer) {
                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
            }
            // check if there is conversation data available
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedConnect);
            // connect to the conversation websocket
            this.privParticipants.meId = this.privRoom.participantId;
            this.privConversationRecognizer = Exports_js_1.ConversationRecognizerFactory.fromConfig(this, this.privConfig);
            // Because ConversationTranslator manually sets up and manages the connection, Conversation
            // has to forward serviceRecognizer connection events that usually get passed automatically
            this.privConversationRecognizer.connected = this.onConnected;
            this.privConversationRecognizer.disconnected = this.onDisconnected;
            this.privConversationRecognizer.canceled = this.onCanceled;
            this.privConversationRecognizer.participantUpdateCommandReceived = this.onParticipantUpdateCommandReceived;
            this.privConversationRecognizer.lockRoomCommandReceived = this.onLockRoomCommandReceived;
            this.privConversationRecognizer.muteAllCommandReceived = this.onMuteAllCommandReceived;
            this.privConversationRecognizer.participantJoinCommandReceived = this.onParticipantJoinCommandReceived;
            this.privConversationRecognizer.participantLeaveCommandReceived = this.onParticipantLeaveCommandReceived;
            this.privConversationRecognizer.translationReceived = this.onTranslationReceived;
            this.privConversationRecognizer.participantsListReceived = this.onParticipantsListReceived;
            this.privConversationRecognizer.conversationExpiration = this.onConversationExpiration;
            this.privConversationRecognizer.connect(this.privRoom.token, (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Join a conversation as a participant.
     * @param { IParticipant } participant - participant to add
     * @param cb
     * @param err
     */
    addParticipantAsync(participant, cb, err) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(participant, "Participant");
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.addParticipantImplAsync(participant), cb, err);
    }
    /**
     * Join a conversation as a participant.
     * @param conversation
     * @param nickname
     * @param lang
     * @param cb
     * @param err
     */
    joinConversationAsync(conversationId, nickname, lang, cb, err) {
        try {
            // TODO
            // if (!!this.privConversationRecognizer) {
            //     throw new Error(this.privErrors.permissionDeniedStart);
            // }
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(conversationId, this.privErrors.invalidArgs.replace("{arg}", "conversationId"));
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(lang, this.privErrors.invalidArgs.replace("{arg}", "language"));
            // join the conversation
            this.privManager.createOrJoin(this.privProperties, conversationId, ((room) => {
                Contracts_js_1.Contracts.throwIfNullOrUndefined(room, this.privErrors.permissionDeniedConnect);
                this.privRoom = room;
                this.privConfig.authorizationToken = room.cognitiveSpeechAuthToken;
                // join callback
                if (!!cb) {
                    cb(room.cognitiveSpeechAuthToken);
                }
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Deletes a conversation
     * @param cb
     * @param err
     */
    deleteConversationAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.deleteConversationImplAsync(), cb, err);
    }
    async deleteConversationImplAsync() {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privProperties, this.privErrors.permissionDeniedConnect);
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.token, this.privErrors.permissionDeniedConnect);
        await this.privManager.leave(this.privProperties, this.privRoom.token);
        this.dispose();
    }
    /**
     * Issues a request to close the client websockets
     * @param cb
     * @param err
     */
    endConversationAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.endConversationImplAsync(), cb, err);
    }
    endConversationImplAsync() {
        return this.close(true);
    }
    /**
     * Issues a request to lock the conversation
     * @param cb
     * @param err
     */
    lockConversationAsync(cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "lock")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getLockCommand(true), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to mute the conversation
     * @param cb
     * @param err
     */
    muteAllParticipantsAsync(cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversationRecognizer, this.privErrors.permissionDeniedSend);
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            // check the user's permissions
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "mute")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(true), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to mute a participant in the conversation
     * @param userId
     * @param cb
     * @param err
     */
    muteParticipantAsync(userId, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            // check the connection is open (host + participant can perform the mute command)
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            // if not host, check the participant is not muting another participant
            if (!this.me.isHost && this.me.id !== userId) {
                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
            }
            // check the user exists
            const exists = this.privParticipants.getParticipantIndex(userId);
            if (exists === -1) {
                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, true), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to remove a participant from the conversation
     * @param userId
     * @param cb
     * @param err
     */
    removeParticipantAsync(userId, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            if (!!this.privTranscriberRecognizer && userId.hasOwnProperty("id")) {
                // Assume this is a transcription participant
                (0, Exports_js_2.marshalPromiseToCallbacks)(this.removeParticipantImplAsync(userId), cb, err);
            }
            else {
                Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
                if (!this.canSendAsHost) {
                    this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "remove")), err);
                }
                let participantId = "";
                if (typeof userId === "string") {
                    participantId = userId;
                }
                else if (userId.hasOwnProperty("id")) {
                    const participant = userId;
                    participantId = participant.id;
                }
                else if (userId.hasOwnProperty("userId")) {
                    const user = userId;
                    participantId = user.userId;
                }
                Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
                // check the participant exists
                const index = this.participants.findIndex((p) => p.id === participantId);
                if (index === -1) {
                    this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
                }
                if (!!this.privConversationRecognizer) {
                    this.privConversationRecognizer.sendRequest(this.getEjectCommand(participantId), (() => {
                        this.handleCallback(cb, err);
                    }), ((error) => {
                        this.handleError(error, err);
                    }));
                }
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to unlock the conversation
     * @param cb
     * @param err
     */
    unlockConversationAsync(cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unlock")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getLockCommand(false), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to unmute all participants in the conversation
     * @param cb
     * @param err
     */
    unmuteAllParticipantsAsync(cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unmute all")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(false), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to unmute a participant in the conversation
     * @param userId
     * @param cb
     * @param err
     */
    unmuteParticipantAsync(userId, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            // check the connection is open (host + participant can perform the mute command)
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            // if not host, check the participant is not muting another participant
            if (!this.me.isHost && this.me.id !== userId) {
                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
            }
            // check the user exists
            const exists = this.privParticipants.getParticipantIndex(userId);
            if (exists === -1) {
                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, false), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Send a text message
     * @param message
     * @param cb
     * @param err
     */
    sendTextMessageAsync(message, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace("{arg}", "message"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            // TODO: is a max length check required?
            if (message.length > this.privTextMessageMaxLength) {
                this.handleError(new Error(this.privErrors.invalidArgs.replace("{arg}", "message length")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMessageCommand(message), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Set translated to languages
     * @param {string[]} languages - languages to translate to
     * @param cb
     * @param err
     */
    setTranslatedLanguagesAsync(languages, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfArrayEmptyOrWhitespace(languages, this.privErrors.invalidArgs.replace("{arg}", "languages"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getSetTranslateToLanguagesCommand(languages), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Change nickname
     * @param {string} nickname - new nickname for the room
     * @param cb
     * @param err
     */
    changeNicknameAsync(nickname, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getChangeNicknameCommand(nickname), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    dispose() {
        if (this.isDisposed) {
            return;
        }
        this.privIsDisposed = true;
        if (!!this.config) {
            this.config.close();
        }
        this.privConfig = undefined;
        this.privLanguage = undefined;
        this.privProperties = undefined;
        this.privRoom = undefined;
        this.privToken = undefined;
        this.privManager = undefined;
        this.privIsConnected = false;
        this.privIsReady = false;
        this.privParticipants = undefined;
    }
    async connectTranscriberRecognizer(recognizer) {
        if (!!this.privTranscriberRecognizer) {
            await this.privTranscriberRecognizer.close();
        }
        await recognizer.enforceAudioGating();
        this.privTranscriberRecognizer = recognizer;
        this.privTranscriberRecognizer.conversation = this;
    }
    getKeepAlive() {
        const nickname = (!!this.me) ? this.me.displayName : "default_nickname";
        return JSON.stringify({
            id: "0",
            nickname,
            participantId: this.privRoom.participantId,
            roomId: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.keepAlive
        });
    }
    /* eslint-enable @typescript-eslint/typedef */
    addParticipantImplAsync(participant) {
        const newParticipant = this.privParticipants.addOrUpdateParticipant(participant);
        if (newParticipant !== undefined) {
            if (!!this.privTranscriberRecognizer) {
                const conversationInfo = this.conversationInfo;
                conversationInfo.participants = [participant];
                return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, "join");
            }
        }
    }
    removeParticipantImplAsync(participant) {
        this.privParticipants.deleteParticipant(participant.id);
        const conversationInfo = this.conversationInfo;
        conversationInfo.participants = [participant];
        return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, "leave");
    }
    async close(dispose) {
        try {
            this.privIsConnected = false;
            await this.privConversationRecognizer?.close();
            this.privConversationRecognizer = undefined;
            if (!!this.privConversationTranslator) {
                this.privConversationTranslator.dispose();
            }
        }
        catch (e) {
            // ignore error
            throw e;
        }
        if (dispose) {
            this.dispose();
        }
    }
    /** Helpers */
    handleCallback(cb, err) {
        if (!!cb) {
            try {
                cb();
            }
            catch (e) {
                if (!!err) {
                    err(e);
                }
            }
            cb = undefined;
        }
    }
    handleError(error, err) {
        if (!!err) {
            if (error instanceof Error) {
                const typedError = error;
                err(typedError.name + ": " + typedError.message);
            }
            else {
                err(error);
            }
        }
    }
    /** Participant Helpers */
    toParticipants(includeHost) {
        const participants = this.privParticipants.participants.map((p) => (this.toParticipant(p)));
        if (!includeHost) {
            return participants.filter((p) => p.isHost === false);
        }
        else {
            return participants;
        }
    }
    toParticipant(p) {
        return new Exports_js_3.Participant(p.id, p.avatar, p.displayName, p.isHost, p.isMuted, p.isUsingTts, p.preferredLanguage, p.voice);
    }
    getMuteAllCommand(isMuted) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.setMuteAll,
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: isMuted
        });
    }
    getMuteCommand(participantId, isMuted) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.setMute,
            // eslint-disable-next-line object-shorthand
            participantId: participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: isMuted
        });
    }
    getLockCommand(isLocked) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.setLockState,
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: isLocked
        });
    }
    getEjectCommand(participantId) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.ejectParticipant,
            // eslint-disable-next-line object-shorthand
            participantId: participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
        });
    }
    getSetTranslateToLanguagesCommand(languages) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages,
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: languages
        });
    }
    getChangeNicknameCommand(nickname) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, "nickname");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.changeNickname,
            nickname,
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: nickname
        });
    }
    getMessageCommand(message) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, "message");
        return JSON.stringify({
            participantId: this.privRoom.participantId,
            roomId: this.privRoom.roomId,
            text: message,
            type: Exports_js_1.ConversationTranslatorMessageTypes.instantMessage
        });
    }
}
exports.ConversationImpl = ConversationImpl;

//# sourceMappingURL=Conversation.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationCommon.js"
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationCommon.js ***!
  \*********************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationCommon = void 0;
class ConversationCommon {
    constructor(audioConfig) {
        this.privAudioConfig = audioConfig;
    }
    handleCallback(cb, err) {
        if (!!cb) {
            try {
                cb();
            }
            catch (e) {
                if (!!err) {
                    err(e);
                }
            }
            cb = undefined;
        }
    }
    handleError(error, err) {
        if (!!err) {
            if (error instanceof Error) {
                const typedError = error;
                err(typedError.name + ": " + typedError.message);
            }
            else {
                err(error);
            }
        }
    }
}
exports.ConversationCommon = ConversationCommon;

//# sourceMappingURL=ConversationCommon.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationExpirationEventArgs.js"
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationExpirationEventArgs.js ***!
  \**********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationExpirationEventArgs = void 0;
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
class ConversationExpirationEventArgs extends Exports_js_1.SessionEventArgs {
    constructor(expirationTime, sessionId) {
        super(sessionId);
        this.privExpirationTime = expirationTime;
    }
    /** How much longer until the conversation expires (in minutes). */
    get expirationTime() {
        return this.privExpirationTime;
    }
}
exports.ConversationExpirationEventArgs = ConversationExpirationEventArgs;

//# sourceMappingURL=ConversationExpirationEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js"
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js ***!
  \*******************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationParticipantsChangedEventArgs = void 0;
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
class ConversationParticipantsChangedEventArgs extends Exports_js_1.SessionEventArgs {
    constructor(reason, participants, sessionId) {
        super(sessionId);
        this.privReason = reason;
        this.privParticipant = participants;
    }
    get reason() {
        return this.privReason;
    }
    get participants() {
        return this.privParticipant;
    }
}
exports.ConversationParticipantsChangedEventArgs = ConversationParticipantsChangedEventArgs;

//# sourceMappingURL=ConversationParticipantsChangedEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriber.js"
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriber.js ***!
  \**************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranscriber = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ../../common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
const Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Performs speech recognition with speaker separation from microphone, file, or other audio input streams, and gets transcribed text as result.
 * @class ConversationTranscriber
 */
class ConversationTranscriber extends Exports_js_3.Recognizer {
    /**
     * ConversationTranscriber constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    constructor(speechConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        Contracts_js_1.Contracts.throwIfNull(speechConfigImpl, "speechConfig");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);
        super(audioConfig, speechConfigImpl.properties, new Exports_js_1.ConversationTranscriberConnectionFactory(), speechConfig.tokenCredential);
        this.privProperties.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, "2");
        this.privDisposedRecognizer = false;
    }
    /**
     * ConversationTranscriber constructor.
     * @constructor
     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer
     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {
        const speechConfigImpl = speechConfig;
        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);
        const recognizer = new ConversationTranscriber(speechConfig, audioConfig);
        return recognizer;
    }
    /**
     * Gets the endpoint id of a customized speech model that is used for transcription.
     * @member ConversationTranscriber.prototype.endpointId
     * @function
     * @public
     * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.
     */
    get endpointId() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_EndpointId, "00000000-0000-0000-0000-000000000000");
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member ConversationTranscriber.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member ConversationTranscriber.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, token);
    }
    /**
     * Gets the spoken language of transcription.
     * @member ConversationTranscriber.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @returns {string} The spoken language of transcription.
     */
    get speechRecognitionLanguage() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage);
    }
    /**
     * Gets the output format of transcription.
     * @member ConversationTranscriber.prototype.outputFormat
     * @function
     * @public
     * @returns {OutputFormat} The output format of transcription.
     */
    get outputFormat() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        if (this.properties.getProperty(Exports_js_1.OutputFormatPropertyName, Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]) === Exports_js_3.OutputFormat[Exports_js_3.OutputFormat.Simple]) {
            return Exports_js_3.OutputFormat.Simple;
        }
        else {
            return Exports_js_3.OutputFormat.Detailed;
        }
    }
    /**
     * The collection of properties and their values defined for this conversation transcriber.
     * @member ConversationTranscriber.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Starts conversation transcription, until stopTranscribingAsync() is called.
     * User must subscribe to events to receive transcription results.
     * @member ConversationTranscriber.prototype.startTranscribingAsync
     * @function
     * @public
     * @param cb - Callback invoked once the transcription has started.
     * @param err - Callback invoked in case of an error.
     */
    startTranscribingAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(PhraseDetectionContext_js_1.RecognitionMode.Conversation), cb, err);
    }
    /**
     * Stops conversation transcription.
     * @member ConversationTranscriber.prototype.stopTranscribingAsync
     * @function
     * @public
     * @param cb - Callback invoked once the transcription has stopped.
     * @param err - Callback invoked in case of an error.
     */
    stopTranscribingAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member ConversationTranscriber.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
    }
    /**
     * Disposes any resources held by the object.
     * @member SpeechRecognizer.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - true if disposing the object.
     */
    async dispose(disposing) {
        if (this.privDisposedRecognizer) {
            return;
        }
        if (disposing) {
            this.privDisposedRecognizer = true;
            await this.implRecognizerStop();
        }
        await super.dispose(disposing);
    }
    createRecognizerConfig(speechConfig) {
        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const configImpl = audioConfig;
        recognizerConfig.isSpeakerDiarizationEnabled = true;
        return new Exports_js_1.ConversationTranscriptionServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
    }
}
exports.ConversationTranscriber = ConversationTranscriber;

//# sourceMappingURL=ConversationTranscriber.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriptionResult.js"
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriptionResult.js ***!
  \**********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranscriptionResult = void 0;
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Defines result of conversation transcription.
 * @class ConversationTranscriptionResult
 */
class ConversationTranscriptionResult extends Exports_js_1.RecognitionResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @public
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {string} text - The recognized text.
     * @param {number} duration - The duration.
     * @param {number} offset - The offset into the stream.
     * @param {string} language - Primary Language detected, if provided.
     * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
     * @param {string} speakerId - speaker id for conversation transcription.
     * @param {string} errorDetails - Error details, if provided.
     * @param {string} json - Additional Json, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {
        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);
        this.privSpeakerId = speakerId;
    }
    /**
     * speaker id
     * @member ConversationTranscriptionResult.prototype.speakerId
     * @function
     * @public
     * @returns {string} id of speaker in given result
     */
    get speakerId() {
        return this.privSpeakerId;
    }
}
exports.ConversationTranscriptionResult = ConversationTranscriptionResult;

//# sourceMappingURL=ConversationTranscriptionResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js"
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js ***!
  \*******************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranslationCanceledEventArgs = void 0;
const CancellationEventArgsBase_js_1 = __webpack_require__(/*! ../CancellationEventArgsBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js");
class ConversationTranslationCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {
}
exports.ConversationTranslationCanceledEventArgs = ConversationTranslationCanceledEventArgs;

//# sourceMappingURL=ConversationTranslationCanceledEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationEventArgs.js"
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationEventArgs.js ***!
  \***********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranslationEventArgs = void 0;
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
class ConversationTranslationEventArgs extends Exports_js_1.RecognitionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {ConversationTranslationResult} result - The translation recognition result.
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(result, offset, sessionId) {
        super(offset, sessionId);
        this.privResult = result;
    }
    /**
     * Specifies the recognition result.
     * @returns {ConversationTranslationResult} the recognition result.
     */
    get result() {
        return this.privResult;
    }
}
exports.ConversationTranslationEventArgs = ConversationTranslationEventArgs;

//# sourceMappingURL=ConversationTranslationEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationResult.js"
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationResult.js ***!
  \********************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranslationResult = void 0;
const TranslationRecognitionResult_js_1 = __webpack_require__(/*! ../TranslationRecognitionResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionResult.js");
class ConversationTranslationResult extends TranslationRecognitionResult_js_1.TranslationRecognitionResult {
    constructor(participantId, translations, originalLanguage, resultId, reason, text, duration, offset, errorDetails, json, properties) {
        super(translations, resultId, reason, text, duration, offset, undefined, undefined, errorDetails, json, properties);
        this.privId = participantId;
        this.privOrigLang = originalLanguage;
    }
    /**
     * The unique identifier for the participant this result is for.
     */
    get participantId() {
        return this.privId;
    }
    /**
     * The original language this result was in.
     */
    get originalLang() {
        return this.privOrigLang;
    }
}
exports.ConversationTranslationResult = ConversationTranslationResult;

//# sourceMappingURL=ConversationTranslationResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslator.js"
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslator.js ***!
  \*************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranslator = exports.SpeechState = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const ConversationTranslatorConnectionFactory_js_1 = __webpack_require__(/*! ../../common.speech/Transcription/ConversationTranslatorConnectionFactory.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Transcription/ConversationTranslatorConnectionFactory.js");
const Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Conversation_js_1 = __webpack_require__(/*! ./Conversation.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Conversation.js");
const Exports_js_4 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js");
var SpeechState;
(function (SpeechState) {
    SpeechState[SpeechState["Inactive"] = 0] = "Inactive";
    SpeechState[SpeechState["Connecting"] = 1] = "Connecting";
    SpeechState[SpeechState["Connected"] = 2] = "Connected";
})(SpeechState = exports.SpeechState || (exports.SpeechState = {}));
// child class of TranslationRecognizer meant only for use with ConversationTranslator
class ConversationTranslationRecognizer extends Exports_js_3.TranslationRecognizer {
    constructor(speechConfig, audioConfig, translator, convGetter) {
        super(speechConfig, audioConfig, new ConversationTranslatorConnectionFactory_js_1.ConversationTranslatorConnectionFactory(convGetter));
        this.privSpeechState = SpeechState.Inactive;
        if (!!translator) {
            this.privTranslator = translator;
            this.sessionStarted = () => {
                this.privSpeechState = SpeechState.Connected;
            };
            this.sessionStopped = () => {
                this.privSpeechState = SpeechState.Inactive;
            };
            this.recognizing = (tr, e) => {
                if (!!this.privTranslator.recognizing) {
                    this.privTranslator.recognizing(this.privTranslator, e);
                }
            };
            // eslint-disable-next-line @typescript-eslint/no-misused-promises
            this.recognized = async (tr, e) => {
                // if there is an error connecting to the conversation service from the speech service the error will be returned in the ErrorDetails field.
                if (e.result?.errorDetails) {
                    await this.cancelSpeech();
                    // TODO: format the error message contained in 'errorDetails'
                    this.fireCancelEvent(e.result.errorDetails);
                }
                else {
                    if (!!this.privTranslator.recognized) {
                        this.privTranslator.recognized(this.privTranslator, e);
                    }
                }
                return;
            };
            // eslint-disable-next-line @typescript-eslint/no-misused-promises
            this.canceled = async () => {
                if (this.privSpeechState !== SpeechState.Inactive) {
                    try {
                        await this.cancelSpeech();
                    }
                    catch (error) {
                        this.privSpeechState = SpeechState.Inactive;
                    }
                }
            };
        }
    }
    get state() {
        return this.privSpeechState;
    }
    set state(newState) {
        this.privSpeechState = newState;
    }
    set authentication(token) {
        this.privReco.authentication = token;
    }
    onConnection() {
        this.privSpeechState = SpeechState.Connected;
    }
    async onCancelSpeech() {
        this.privSpeechState = SpeechState.Inactive;
        await this.cancelSpeech();
    }
    /**
     * Fire a cancel event
     * @param error
     */
    fireCancelEvent(error) {
        try {
            if (!!this.privTranslator.canceled) {
                const cancelEvent = new Exports_js_4.ConversationTranslationCanceledEventArgs(Exports_js_3.CancellationReason.Error, error, Exports_js_3.CancellationErrorCode.RuntimeError);
                this.privTranslator.canceled(this.privTranslator, cancelEvent);
            }
        }
        catch (e) {
            //
        }
    }
    async cancelSpeech() {
        try {
            this.stopContinuousRecognitionAsync();
            await this.privReco?.disconnect();
            this.privSpeechState = SpeechState.Inactive;
        }
        catch (e) {
            // ignore the error
        }
    }
}
/**
 * Join, leave or connect to a conversation.
 */
class ConversationTranslator extends Exports_js_4.ConversationCommon {
    constructor(audioConfig) {
        super(audioConfig);
        this.privErrors = Exports_js_1.ConversationConnectionConfig.restErrors;
        this.privIsDisposed = false;
        this.privIsSpeaking = false;
        this.privPlaceholderKey = "abcdefghijklmnopqrstuvwxyz012345";
        this.privPlaceholderRegion = "westus";
        this.privProperties = new Exports_js_3.PropertyCollection();
    }
    get properties() {
        return this.privProperties;
    }
    get speechRecognitionLanguage() {
        return this.privSpeechRecognitionLanguage;
    }
    get participants() {
        return this.privConversation?.participants;
    }
    get canSpeak() {
        // is there a Conversation websocket available and has the Recognizer been set up
        if (!this.privConversation.isConnected || !this.privCTRecognizer) {
            return false;
        }
        // is the user already speaking
        if (this.privIsSpeaking || this.privCTRecognizer.state === SpeechState.Connected || this.privCTRecognizer.state === SpeechState.Connecting) {
            return false;
        }
        // is the user muted
        if (this.privConversation.isMutedByHost) {
            return false;
        }
        return true;
    }
    onToken(token) {
        this.privCTRecognizer.authentication = token;
    }
    setServiceProperty(name, value) {
        const currentProperties = JSON.parse(this.privProperties.getProperty(Exports_js_1.ServicePropertiesPropertyName, "{}"));
        currentProperties[name] = value;
        this.privProperties.setProperty(Exports_js_1.ServicePropertiesPropertyName, JSON.stringify(currentProperties));
    }
    joinConversationAsync(conversation, nickname, param1, param2, param3) {
        try {
            if (typeof conversation === "string") {
                Contracts_js_1.Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace("{arg}", "conversation id"));
                Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
                if (!!this.privConversation) {
                    this.handleError(new Error(this.privErrors.permissionDeniedStart), param3);
                }
                let lang = param1;
                if (lang === undefined || lang === null || lang === "") {
                    lang = Exports_js_1.ConversationConnectionConfig.defaultLanguageCode;
                }
                // create a placeholder config
                this.privSpeechTranslationConfig = Exports_js_3.SpeechTranslationConfig.fromSubscription(this.privPlaceholderKey, this.privPlaceholderRegion);
                this.privSpeechTranslationConfig.setProfanity(Exports_js_3.ProfanityOption.Masked);
                this.privSpeechTranslationConfig.addTargetLanguage(lang);
                this.privSpeechTranslationConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage], lang);
                this.privSpeechTranslationConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.ConversationTranslator_Name], nickname);
                const propertyIdsToCopy = [
                    Exports_js_3.PropertyId.SpeechServiceConnection_Host,
                    Exports_js_3.PropertyId.ConversationTranslator_Host,
                    Exports_js_3.PropertyId.SpeechServiceConnection_Endpoint,
                    Exports_js_3.PropertyId.SpeechServiceConnection_ProxyHostName,
                    Exports_js_3.PropertyId.SpeechServiceConnection_ProxyPassword,
                    Exports_js_3.PropertyId.SpeechServiceConnection_ProxyPort,
                    Exports_js_3.PropertyId.SpeechServiceConnection_ProxyUserName,
                    "ConversationTranslator_MultiChannelAudio",
                    "ConversationTranslator_Region"
                ];
                for (const prop of propertyIdsToCopy) {
                    const value = this.privProperties.getProperty(prop);
                    if (value) {
                        const key = typeof prop === "string" ? prop : Exports_js_3.PropertyId[prop];
                        this.privSpeechTranslationConfig.setProperty(key, value);
                    }
                }
                const currentProperties = JSON.parse(this.privProperties.getProperty(Exports_js_1.ServicePropertiesPropertyName, "{}"));
                for (const prop of Object.keys(currentProperties)) {
                    this.privSpeechTranslationConfig.setServiceProperty(prop, currentProperties[prop], Exports_js_3.ServicePropertyChannel.UriQueryParameter);
                }
                // join the conversation
                this.privConversation = new Conversation_js_1.ConversationImpl(this.privSpeechTranslationConfig);
                this.privConversation.conversationTranslator = this;
                this.privConversation.joinConversationAsync(conversation, nickname, lang, ((result) => {
                    if (!result) {
                        this.handleError(new Error(this.privErrors.permissionDeniedConnect), param3);
                    }
                    this.privSpeechTranslationConfig.authorizationToken = result;
                    this.privConversation.room.isHost = false;
                    // connect to the ws
                    this.privConversation.startConversationAsync((() => {
                        this.handleCallback(param2, param3);
                    }), ((error) => {
                        this.handleError(error, param3);
                    }));
                }), ((error) => {
                    this.handleError(error, param3);
                }));
            }
            else if (typeof conversation === "object") {
                Contracts_js_1.Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace("{arg}", "conversation id"));
                Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
                // save the nickname
                this.privProperties.setProperty(Exports_js_3.PropertyId.ConversationTranslator_Name, nickname);
                // ref the conversation object
                this.privConversation = conversation;
                // ref the conversation translator object
                this.privConversation.conversationTranslator = this;
                this.privConversation.room.isHost = true;
                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedConnect);
                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);
                this.privSpeechTranslationConfig = conversation.config;
                this.handleCallback(param1, param2);
            }
            else {
                this.handleError(new Error(this.privErrors.invalidArgs.replace("{arg}", "invalid conversation type")), param2);
            }
        }
        catch (error) {
            this.handleError(error, typeof param1 === "string" ? param3 : param2);
        }
    }
    /**
     * Leave the conversation
     * @param cb
     * @param err
     */
    leaveConversationAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)((async () => {
            // stop the speech websocket
            await this.cancelSpeech();
            // stop the websocket
            await this.privConversation.endConversationImplAsync();
            // https delete request
            await this.privConversation.deleteConversationImplAsync();
            this.dispose();
        })(), cb, err);
    }
    /**
     * Send a text message
     * @param message
     * @param cb
     * @param err
     */
    sendTextMessageAsync(message, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace("{arg}", message));
            this.privConversation.sendTextMessageAsync(message, cb, err);
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Start speaking
     * @param cb
     * @param err
     */
    startTranscribingAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)((async () => {
            try {
                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);
                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);
                if (this.privCTRecognizer === undefined) {
                    await this.connectTranslatorRecognizer();
                }
                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privCTRecognizer, this.privErrors.permissionDeniedSend);
                if (!this.canSpeak) {
                    this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
                }
                await this.startContinuousRecognition();
                this.privIsSpeaking = true;
            }
            catch (error) {
                this.privIsSpeaking = false;
                await this.cancelSpeech();
                throw error;
            }
        })(), cb, err);
    }
    /**
     * Stop speaking
     * @param cb
     * @param err
     */
    stopTranscribingAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)((async () => {
            try {
                if (!this.privIsSpeaking) {
                    // stop speech
                    await this.cancelSpeech();
                    return;
                }
                // stop the recognition but leave the websocket open
                this.privIsSpeaking = false;
                await new Promise((resolve, reject) => {
                    this.privCTRecognizer.stopContinuousRecognitionAsync(resolve, reject);
                });
            }
            catch (error) {
                await this.cancelSpeech();
            }
        })(), cb, err);
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    dispose(reason, success, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)((async () => {
            if (this.isDisposed && !this.privIsSpeaking) {
                return;
            }
            await this.cancelSpeech();
            this.privIsDisposed = true;
            this.privSpeechTranslationConfig.close();
            this.privSpeechRecognitionLanguage = undefined;
            this.privProperties = undefined;
            this.privAudioConfig = undefined;
            this.privSpeechTranslationConfig = undefined;
            this.privConversation.dispose();
            this.privConversation = undefined;
        })(), success, err);
    }
    /**
     * Cancel the speech websocket
     */
    async cancelSpeech() {
        try {
            this.privIsSpeaking = false;
            await this.privCTRecognizer?.onCancelSpeech();
            this.privCTRecognizer = undefined;
        }
        catch (e) {
            // ignore the error
        }
    }
    /**
     * Connect to the speech translation recognizer.
     * Currently there is no language validation performed before sending the SpeechLanguage code to the service.
     * If it's an invalid language the raw error will be: 'Error during WebSocket handshake: Unexpected response code: 400'
     * e.g. pass in 'fr' instead of 'fr-FR', or a text-only language 'cy'
     */
    async connectTranslatorRecognizer() {
        try {
            if (this.privAudioConfig === undefined) {
                this.privAudioConfig = Exports_js_3.AudioConfig.fromDefaultMicrophoneInput();
            }
            // clear the temp subscription key if it's a participant joining
            if (this.privSpeechTranslationConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_Key])
                === this.privPlaceholderKey) {
                this.privSpeechTranslationConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_Key], "");
            }
            const convGetter = () => this.privConversation;
            this.privCTRecognizer = new ConversationTranslationRecognizer(this.privSpeechTranslationConfig, this.privAudioConfig, this, convGetter);
        }
        catch (error) {
            await this.cancelSpeech();
            throw error;
        }
    }
    /**
     * Handle the start speaking request
     */
    startContinuousRecognition() {
        return new Promise((resolve, reject) => {
            this.privCTRecognizer.startContinuousRecognitionAsync(resolve, reject);
        });
    }
}
exports.ConversationTranslator = ConversationTranslator;

//# sourceMappingURL=ConversationTranslator.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js"
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js ***!
  \**********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ConversationTranscriptionResult = exports.MeetingTranscriber = exports.MeetingTranscriptionCanceledEventArgs = exports.MeetingImpl = exports.Meeting = exports.ParticipantChangedReason = exports.User = exports.Participant = exports.ConversationTranscriber = exports.ConversationTranslator = exports.ConversationTranslationResult = exports.ConversationTranslationEventArgs = exports.ConversationTranslationCanceledEventArgs = exports.ConversationParticipantsChangedEventArgs = exports.ConversationExpirationEventArgs = exports.ConversationCommon = exports.ConversationImpl = exports.Conversation = void 0;
var Conversation_js_1 = __webpack_require__(/*! ./Conversation.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Conversation.js");
Object.defineProperty(exports, "Conversation", ({ enumerable: true, get: function () { return Conversation_js_1.Conversation; } }));
Object.defineProperty(exports, "ConversationImpl", ({ enumerable: true, get: function () { return Conversation_js_1.ConversationImpl; } }));
var ConversationCommon_js_1 = __webpack_require__(/*! ./ConversationCommon.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationCommon.js");
Object.defineProperty(exports, "ConversationCommon", ({ enumerable: true, get: function () { return ConversationCommon_js_1.ConversationCommon; } }));
var ConversationExpirationEventArgs_js_1 = __webpack_require__(/*! ./ConversationExpirationEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationExpirationEventArgs.js");
Object.defineProperty(exports, "ConversationExpirationEventArgs", ({ enumerable: true, get: function () { return ConversationExpirationEventArgs_js_1.ConversationExpirationEventArgs; } }));
var ConversationParticipantsChangedEventArgs_js_1 = __webpack_require__(/*! ./ConversationParticipantsChangedEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js");
Object.defineProperty(exports, "ConversationParticipantsChangedEventArgs", ({ enumerable: true, get: function () { return ConversationParticipantsChangedEventArgs_js_1.ConversationParticipantsChangedEventArgs; } }));
var ConversationTranslationCanceledEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranslationCanceledEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js");
Object.defineProperty(exports, "ConversationTranslationCanceledEventArgs", ({ enumerable: true, get: function () { return ConversationTranslationCanceledEventArgs_js_1.ConversationTranslationCanceledEventArgs; } }));
var ConversationTranslationEventArgs_js_1 = __webpack_require__(/*! ./ConversationTranslationEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationEventArgs.js");
Object.defineProperty(exports, "ConversationTranslationEventArgs", ({ enumerable: true, get: function () { return ConversationTranslationEventArgs_js_1.ConversationTranslationEventArgs; } }));
var ConversationTranslationResult_js_1 = __webpack_require__(/*! ./ConversationTranslationResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslationResult.js");
Object.defineProperty(exports, "ConversationTranslationResult", ({ enumerable: true, get: function () { return ConversationTranslationResult_js_1.ConversationTranslationResult; } }));
var ConversationTranslator_js_1 = __webpack_require__(/*! ./ConversationTranslator.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranslator.js");
Object.defineProperty(exports, "ConversationTranslator", ({ enumerable: true, get: function () { return ConversationTranslator_js_1.ConversationTranslator; } }));
var ConversationTranscriber_js_1 = __webpack_require__(/*! ./ConversationTranscriber.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriber.js");
Object.defineProperty(exports, "ConversationTranscriber", ({ enumerable: true, get: function () { return ConversationTranscriber_js_1.ConversationTranscriber; } }));
var IParticipant_js_1 = __webpack_require__(/*! ./IParticipant.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/IParticipant.js");
Object.defineProperty(exports, "Participant", ({ enumerable: true, get: function () { return IParticipant_js_1.Participant; } }));
Object.defineProperty(exports, "User", ({ enumerable: true, get: function () { return IParticipant_js_1.User; } }));
var ParticipantChangedReason_js_1 = __webpack_require__(/*! ./ParticipantChangedReason.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ParticipantChangedReason.js");
Object.defineProperty(exports, "ParticipantChangedReason", ({ enumerable: true, get: function () { return ParticipantChangedReason_js_1.ParticipantChangedReason; } }));
var Meeting_js_1 = __webpack_require__(/*! ./Meeting.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Meeting.js");
Object.defineProperty(exports, "Meeting", ({ enumerable: true, get: function () { return Meeting_js_1.Meeting; } }));
Object.defineProperty(exports, "MeetingImpl", ({ enumerable: true, get: function () { return Meeting_js_1.MeetingImpl; } }));
var MeetingTranscriptionCanceledEventArgs_js_1 = __webpack_require__(/*! ./MeetingTranscriptionCanceledEventArgs.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriptionCanceledEventArgs.js");
Object.defineProperty(exports, "MeetingTranscriptionCanceledEventArgs", ({ enumerable: true, get: function () { return MeetingTranscriptionCanceledEventArgs_js_1.MeetingTranscriptionCanceledEventArgs; } }));
var MeetingTranscriber_js_1 = __webpack_require__(/*! ./MeetingTranscriber.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriber.js");
Object.defineProperty(exports, "MeetingTranscriber", ({ enumerable: true, get: function () { return MeetingTranscriber_js_1.MeetingTranscriber; } }));
var ConversationTranscriptionResult_js_1 = __webpack_require__(/*! ./ConversationTranscriptionResult.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ConversationTranscriptionResult.js");
Object.defineProperty(exports, "ConversationTranscriptionResult", ({ enumerable: true, get: function () { return ConversationTranscriptionResult_js_1.ConversationTranscriptionResult; } }));

//# sourceMappingURL=Exports.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/IParticipant.js"
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/IParticipant.js ***!
  \***************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Participant = exports.User = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
class User {
    constructor(userId) {
        this.privUserId = userId;
    }
    get userId() {
        return this.privUserId;
    }
}
exports.User = User;
class Participant {
    constructor(id, avatar, displayName, isHost, isMuted, isUsingTts, preferredLanguage, voice) {
        this.privId = id;
        this.privAvatar = avatar;
        this.privDisplayName = displayName;
        this.privIsHost = isHost;
        this.privIsMuted = isMuted;
        this.privIsUsingTts = isUsingTts;
        this.privPreferredLanguage = preferredLanguage;
        this.privVoice = voice;
        this.privProperties = new Exports_js_1.PropertyCollection();
    }
    get avatar() {
        return this.privAvatar;
    }
    get displayName() {
        return this.privDisplayName;
    }
    get id() {
        return this.privId;
    }
    get preferredLanguage() {
        return this.privPreferredLanguage;
    }
    get isHost() {
        return this.privIsHost;
    }
    get isMuted() {
        return this.privIsMuted;
    }
    get isUsingTts() {
        return this.privIsUsingTts;
    }
    get voice() {
        return this.privVoice;
    }
    get properties() {
        return this.privProperties;
    }
    static From(id, language, voice) {
        return new Participant(id, "", id, false, false, false, language, voice);
    }
}
exports.Participant = Participant;

//# sourceMappingURL=IParticipant.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Meeting.js"
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Meeting.js ***!
  \**********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MeetingImpl = exports.Meeting = void 0;
/* eslint-disable max-classes-per-file */
const Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
class Meeting {
    constructor() {
        return;
    }
    /**
     * Create a meeting
     * @param speechConfig
     * @param meetingId
     * @param cb
     * @param err
     */
    static createMeetingAsync(speechConfig, meetingId, arg3, arg4) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "config"));
        Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig.region, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Region"));
        Contracts_js_1.Contracts.throwIfNull(meetingId, "meetingId");
        if (meetingId.length === 0) {
            throw new Error("meetingId cannot be empty");
        }
        if (!speechConfig.subscriptionKey && !speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceAuthorization_Token])) {
            Contracts_js_1.Contracts.throwIfNullOrUndefined(speechConfig.subscriptionKey, Exports_js_1.ConversationConnectionConfig.restErrors.invalidArgs.replace("{arg}", "SpeechServiceConnection_Key"));
        }
        const meetingImpl = new MeetingImpl(speechConfig, meetingId);
        // eslint-disable-next-line @typescript-eslint/no-empty-function
        (0, Exports_js_2.marshalPromiseToCallbacks)((async () => { })(), arg3, arg4);
        return meetingImpl;
    }
}
exports.Meeting = Meeting;
class MeetingImpl extends Meeting {
    /**
     * Create a Meeting impl
     * @param speechConfig
     * @param {string} id - optional conversationId
     */
    constructor(speechConfig, id) {
        super();
        this.privErrors = Exports_js_1.ConversationConnectionConfig.restErrors;
        /** websocket callbacks */
        /* eslint-disable @typescript-eslint/typedef */
        this.onConnected = (e) => {
            this.privIsConnected = true;
            try {
                if (!!this.privConversationTranslator?.sessionStarted) {
                    this.privConversationTranslator.sessionStarted(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        };
        this.onDisconnected = (e) => {
            try {
                if (!!this.privConversationTranslator?.sessionStopped) {
                    this.privConversationTranslator.sessionStopped(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
            finally {
                void this.close(false);
            }
        };
        this.onCanceled = (r, e) => {
            try {
                if (!!this.privConversationTranslator?.canceled) {
                    this.privConversationTranslator.canceled(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantUpdateCommandReceived = (r, e) => {
            try {
                const updatedParticipant = this.privParticipants.getParticipant(e.id);
                if (updatedParticipant !== undefined) {
                    switch (e.key) {
                        case Exports_js_1.ConversationTranslatorCommandTypes.changeNickname:
                            updatedParticipant.displayName = e.value;
                            break;
                        case Exports_js_1.ConversationTranslatorCommandTypes.setUseTTS:
                            updatedParticipant.isUsingTts = e.value;
                            break;
                        case Exports_js_1.ConversationTranslatorCommandTypes.setProfanityFiltering:
                            updatedParticipant.profanity = e.value;
                            break;
                        case Exports_js_1.ConversationTranslatorCommandTypes.setMute:
                            updatedParticipant.isMuted = e.value;
                            break;
                        case Exports_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages:
                            updatedParticipant.translateToLanguages = e.value;
                            break;
                    }
                    this.privParticipants.addOrUpdateParticipant(updatedParticipant);
                    if (!!this.privConversationTranslator) {
                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.Updated, [this.toParticipant(updatedParticipant)], e.sessionId));
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onLockRoomCommandReceived = () => {
            // TODO
        };
        this.onMuteAllCommandReceived = (r, e) => {
            try {
                this.privParticipants.participants.forEach((p) => p.isMuted = (p.isHost ? false : e.isMuted));
                if (!!this.privConversationTranslator) {
                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.Updated, this.toParticipants(false), e.sessionId));
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantJoinCommandReceived = (r, e) => {
            try {
                const newParticipant = this.privParticipants.addOrUpdateParticipant(e.participant);
                if (newParticipant !== undefined) {
                    if (!!this.privConversationTranslator) {
                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.JoinedConversation, [this.toParticipant(newParticipant)], e.sessionId));
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantLeaveCommandReceived = (r, e) => {
            try {
                const ejectedParticipant = this.privParticipants.getParticipant(e.participant.id);
                if (ejectedParticipant !== undefined) {
                    // remove the participant from the internal participants list
                    this.privParticipants.deleteParticipant(e.participant.id);
                    if (!!this.privConversationTranslator) {
                        // notify subscribers that the participant has left the conversation
                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.LeftConversation, [this.toParticipant(ejectedParticipant)], e.sessionId));
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onTranslationReceived = (r, e) => {
            try {
                switch (e.command) {
                    case Exports_js_1.ConversationTranslatorMessageTypes.final:
                        if (!!this.privConversationTranslator) {
                            this.privConversationTranslator.transcribed(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));
                        }
                        break;
                    case Exports_js_1.ConversationTranslatorMessageTypes.partial:
                        if (!!this.privConversationTranslator) {
                            this.privConversationTranslator.transcribing(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));
                        }
                        break;
                    case Exports_js_1.ConversationTranslatorMessageTypes.instantMessage:
                        if (!!this.privConversationTranslator) {
                            this.privConversationTranslator.textMessageReceived(this.privConversationTranslator, new Exports_js_3.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));
                        }
                        break;
                }
            }
            catch (e) {
                //
            }
        };
        this.onParticipantsListReceived = (r, e) => {
            try {
                // check if the session token needs to be updated
                if (e.sessionToken !== undefined && e.sessionToken !== null) {
                    this.privRoom.token = e.sessionToken;
                }
                // save the participants
                this.privParticipants.participants = [...e.participants];
                // enable the conversation
                if (this.privParticipants.me !== undefined) {
                    this.privIsReady = true;
                }
                if (!!this.privConversationTranslator) {
                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new Exports_js_3.ConversationParticipantsChangedEventArgs(Exports_js_3.ParticipantChangedReason.JoinedConversation, this.toParticipants(true), e.sessionId));
                }
                // if this is the host, update the nickname if needed
                if (this.me.isHost) {
                    const nickname = this.privConversationTranslator?.properties.getProperty(Exports_js_3.PropertyId.ConversationTranslator_Name);
                    if (nickname !== undefined && nickname.length > 0 && nickname !== this.me.displayName) {
                        // issue a change nickname request
                        this.changeNicknameAsync(nickname);
                    }
                }
            }
            catch (e) {
                //
            }
        };
        this.onConversationExpiration = (r, e) => {
            try {
                if (!!this.privConversationTranslator) {
                    this.privConversationTranslator.conversationExpiration(this.privConversationTranslator, e);
                }
            }
            catch (e) {
                //
            }
        };
        this.privIsConnected = false;
        this.privIsDisposed = false;
        this.privConversationId = "";
        this.privProperties = new Exports_js_3.PropertyCollection();
        this.privManager = new Exports_js_1.ConversationManager();
        // check the speech language
        const language = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);
        if (!language) {
            speechConfig.setProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage], Exports_js_1.ConversationConnectionConfig.defaultLanguageCode);
        }
        this.privLanguage = speechConfig.getProperty(Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);
        this.privConversationId = id;
        // save the speech config for future usage
        this.privConfig = speechConfig;
        // save the config properties
        const configImpl = speechConfig;
        Contracts_js_1.Contracts.throwIfNull(configImpl, "speechConfig");
        this.privProperties = configImpl.properties.clone();
        this.privIsConnected = false;
        this.privParticipants = new Exports_js_1.InternalParticipants();
        this.privIsReady = false;
        this.privTextMessageMaxLength = 1000;
    }
    // get the internal data about a conversation
    get room() {
        return this.privRoom;
    }
    // get the wrapper for connecting to the websockets
    get connection() {
        return this.privConversationRecognizer; // this.privConnection;
    }
    // get the config
    get config() {
        return this.privConfig;
    }
    // get the meeting Id
    get meetingId() {
        return this.privRoom ? this.privRoom.roomId : this.privConversationId;
    }
    // get the properties
    get properties() {
        return this.privProperties;
    }
    // get the speech language
    get speechRecognitionLanguage() {
        return this.privLanguage;
    }
    get isMutedByHost() {
        return this.privParticipants.me?.isHost ? false : this.privParticipants.me?.isMuted;
    }
    get isConnected() {
        return this.privIsConnected && this.privIsReady;
    }
    get participants() {
        return this.toParticipants(true);
    }
    get me() {
        return this.toParticipant(this.privParticipants.me);
    }
    get host() {
        return this.toParticipant(this.privParticipants.host);
    }
    get transcriberRecognizer() {
        return this.privTranscriberRecognizer;
    }
    get meetingInfo() {
        const convId = this.meetingId;
        const p = this.participants.map((part) => ({
            id: part.id,
            preferredLanguage: part.preferredLanguage,
            voice: part.voice
        }));
        const props = {};
        for (const key of Exports_js_1.ConversationConnectionConfig.transcriptionEventKeys) {
            const val = this.properties.getProperty(key, "");
            if (val !== "") {
                props[key] = val;
            }
        }
        const info = { id: convId, participants: p, meetingProperties: props };
        return info;
    }
    get canSend() {
        return this.privIsConnected && !this.privParticipants.me?.isMuted;
    }
    get canSendAsHost() {
        return this.privIsConnected && this.privParticipants.me?.isHost;
    }
    // get / set the speech auth token
    // eslint-disable-next-line @typescript-eslint/member-ordering
    get authorizationToken() {
        return this.privToken;
    }
    set authorizationToken(value) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(value, "authorizationToken");
        this.privToken = value;
    }
    /**
     * Create a new meeting as Host
     * @param cb
     * @param err
     */
    createMeetingAsync(cb, err) {
        try {
            if (!!this.privConversationRecognizer) {
                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
            }
            this.privManager.createOrJoin(this.privProperties, undefined, ((room) => {
                if (!room) {
                    this.handleError(new Error(this.privErrors.permissionDeniedConnect), err);
                }
                this.privRoom = room;
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Starts a new meeting as host.
     * @param cb
     * @param err
     */
    startMeetingAsync(cb, err) {
        try {
            // check if there is already a recognizer
            if (!!this.privConversationRecognizer) {
                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);
            }
            // check if there is conversation data available
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedConnect);
            // connect to the conversation websocket
            this.privParticipants.meId = this.privRoom.participantId;
            // Because ConversationTranslator manually sets up and manages the connection, Conversation
            // has to forward serviceRecognizer connection events that usually get passed automatically
            this.privConversationRecognizer.connected = this.onConnected;
            this.privConversationRecognizer.disconnected = this.onDisconnected;
            this.privConversationRecognizer.canceled = this.onCanceled;
            this.privConversationRecognizer.participantUpdateCommandReceived = this.onParticipantUpdateCommandReceived;
            this.privConversationRecognizer.lockRoomCommandReceived = this.onLockRoomCommandReceived;
            this.privConversationRecognizer.muteAllCommandReceived = this.onMuteAllCommandReceived;
            this.privConversationRecognizer.participantJoinCommandReceived = this.onParticipantJoinCommandReceived;
            this.privConversationRecognizer.participantLeaveCommandReceived = this.onParticipantLeaveCommandReceived;
            this.privConversationRecognizer.translationReceived = this.onTranslationReceived;
            this.privConversationRecognizer.participantsListReceived = this.onParticipantsListReceived;
            this.privConversationRecognizer.conversationExpiration = this.onConversationExpiration;
            this.privConversationRecognizer.connect(this.privRoom.token, (() => {
                this.handleCallback(cb, err);
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Join a meeting as a participant.
     * @param { IParticipant } participant - participant to add
     * @param cb
     * @param err
     */
    addParticipantAsync(participant, cb, err) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(participant, "Participant");
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.addParticipantImplAsync(participant), cb, err);
    }
    /**
     * Join a meeting as a participant.
     * @param meeting
     * @param nickname
     * @param lang
     * @param cb
     * @param err
     */
    joinMeetingAsync(meetingId, nickname, lang, cb, err) {
        try {
            // TODO
            // if (!!this.privConversationRecognizer) {
            //     throw new Error(this.privErrors.permissionDeniedStart);
            // }
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(meetingId, this.privErrors.invalidArgs.replace("{arg}", "conversationId"));
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(lang, this.privErrors.invalidArgs.replace("{arg}", "language"));
            // join the conversation
            this.privManager.createOrJoin(this.privProperties, meetingId, ((room) => {
                Contracts_js_1.Contracts.throwIfNullOrUndefined(room, this.privErrors.permissionDeniedConnect);
                this.privRoom = room;
                this.privConfig.authorizationToken = room.cognitiveSpeechAuthToken;
                // join callback
                if (!!cb) {
                    cb(room.cognitiveSpeechAuthToken);
                }
            }), ((error) => {
                this.handleError(error, err);
            }));
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Deletes a meeting
     * @param cb
     * @param err
     */
    deleteMeetingAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.deleteMeetingImplAsync(), cb, err);
    }
    async deleteMeetingImplAsync() {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privProperties, this.privErrors.permissionDeniedConnect);
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.token, this.privErrors.permissionDeniedConnect);
        await this.privManager.leave(this.privProperties, this.privRoom.token);
        this.dispose();
    }
    /**
     * Issues a request to close the client websockets
     * @param cb
     * @param err
     */
    endMeetingAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.endMeetingImplAsync(), cb, err);
    }
    endMeetingImplAsync() {
        return this.close(true);
    }
    /**
     * Issues a request to lock the conversation
     * @param cb
     * @param err
     */
    lockMeetingAsync(cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "lock")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getLockCommand(true), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to mute the meeting
     * @param cb
     * @param err
     */
    muteAllParticipantsAsync(cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privConversationRecognizer, this.privErrors.permissionDeniedSend);
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            // check the user's permissions
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "mute")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(true), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to mute a participant in the meeting
     * @param userId
     * @param cb
     * @param err
     */
    muteParticipantAsync(userId, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            // check the connection is open (host + participant can perform the mute command)
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            // if not host, check the participant is not muting another participant
            if (!this.me.isHost && this.me.id !== userId) {
                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
            }
            // check the user exists
            const exists = this.privParticipants.getParticipantIndex(userId);
            if (exists === -1) {
                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, true), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to remove a participant from the conversation
     * @param userId
     * @param cb
     * @param err
     */
    removeParticipantAsync(userId, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            if (!!this.privTranscriberRecognizer && userId.hasOwnProperty("id")) {
                // Assume this is a transcription participant
                (0, Exports_js_2.marshalPromiseToCallbacks)(this.removeParticipantImplAsync(userId), cb, err);
            }
            else {
                Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
                Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
                if (!this.canSendAsHost) {
                    this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "remove")), err);
                }
                let participantId = "";
                if (typeof userId === "string") {
                    participantId = userId;
                }
                else if (userId.hasOwnProperty("id")) {
                    const participant = userId;
                    participantId = participant.id;
                }
                else if (userId.hasOwnProperty("userId")) {
                    const user = userId;
                    participantId = user.userId;
                }
                Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
                // check the participant exists
                const index = this.participants.findIndex((p) => p.id === participantId);
                if (index === -1) {
                    this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
                }
                if (!!this.privConversationRecognizer) {
                    this.privConversationRecognizer.sendRequest(this.getEjectCommand(participantId), (() => {
                        this.handleCallback(cb, err);
                    }), ((error) => {
                        this.handleError(error, err);
                    }));
                }
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to unlock the meeting
     * @param cb
     * @param err
     */
    unlockMeetingAsync(cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unlock")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getLockCommand(false), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to unmute all participants in the meeting
     * @param cb
     * @param err
     */
    unmuteAllParticipantsAsync(cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSendAsHost) {
                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace("{command}", "unmute all")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(false), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Issues a request to unmute a participant in the meeting
     * @param userId
     * @param cb
     * @param err
     */
    unmuteParticipantAsync(userId, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace("{arg}", "userId"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            // check the connection is open (host + participant can perform the mute command)
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            // if not host, check the participant is not muting another participant
            if (!this.me.isHost && this.me.id !== userId) {
                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace("{command}", "mute")), err);
            }
            // check the user exists
            const exists = this.privParticipants.getParticipantIndex(userId);
            if (exists === -1) {
                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, false), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Send a text message
     * @param message
     * @param cb
     * @param err
     */
    sendTextMessageAsync(message, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace("{arg}", "message"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            // TODO: is a max length check required?
            if (message.length > this.privTextMessageMaxLength) {
                this.handleError(new Error(this.privErrors.invalidArgs.replace("{arg}", "message length")), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getMessageCommand(message), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Set translated to languages
     * @param {string[]} languages - languages to translate to
     * @param cb
     * @param err
     */
    setTranslatedLanguagesAsync(languages, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfArrayEmptyOrWhitespace(languages, this.privErrors.invalidArgs.replace("{arg}", "languages"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getSetTranslateToLanguagesCommand(languages), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    /**
     * Change nickname
     * @param {string} nickname - new nickname for the room
     * @param cb
     * @param err
     */
    changeNicknameAsync(nickname, cb, err) {
        try {
            Contracts_js_1.Contracts.throwIfDisposed(this.privIsDisposed);
            Contracts_js_1.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace("{arg}", "nickname"));
            Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);
            if (!this.canSend) {
                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);
            }
            if (!!this.privConversationRecognizer) {
                this.privConversationRecognizer.sendRequest(this.getChangeNicknameCommand(nickname), (() => {
                    this.handleCallback(cb, err);
                }), ((error) => {
                    this.handleError(error, err);
                }));
            }
        }
        catch (error) {
            this.handleError(error, err);
        }
    }
    isDisposed() {
        return this.privIsDisposed;
    }
    dispose() {
        if (this.isDisposed) {
            return;
        }
        this.privIsDisposed = true;
        if (!!this.config) {
            this.config.close();
        }
        this.privConfig = undefined;
        this.privLanguage = undefined;
        this.privProperties = undefined;
        this.privRoom = undefined;
        this.privToken = undefined;
        this.privManager = undefined;
        this.privIsConnected = false;
        this.privIsReady = false;
        this.privParticipants = undefined;
    }
    async connectTranscriberRecognizer(recognizer) {
        if (!!this.privTranscriberRecognizer) {
            await this.privTranscriberRecognizer.close();
        }
        await recognizer.enforceAudioGating();
        this.privTranscriberRecognizer = recognizer;
        this.privTranscriberRecognizer.meeting = this;
    }
    getKeepAlive() {
        const nickname = (!!this.me) ? this.me.displayName : "default_nickname";
        return JSON.stringify({
            id: "0",
            nickname,
            participantId: this.privRoom.participantId,
            roomId: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.keepAlive
        });
    }
    /* eslint-enable @typescript-eslint/typedef */
    addParticipantImplAsync(participant) {
        const newParticipant = this.privParticipants.addOrUpdateParticipant(participant);
        if (newParticipant !== undefined) {
            if (!!this.privTranscriberRecognizer) {
                const meetingInfo = this.meetingInfo;
                meetingInfo.participants = [participant];
                return this.privTranscriberRecognizer.pushMeetingEvent(meetingInfo, "join");
            }
        }
    }
    removeParticipantImplAsync(participant) {
        this.privParticipants.deleteParticipant(participant.id);
        const meetingInfo = this.meetingInfo;
        meetingInfo.participants = [participant];
        return this.privTranscriberRecognizer.pushMeetingEvent(meetingInfo, "leave");
    }
    async close(dispose) {
        try {
            this.privIsConnected = false;
            await this.privConversationRecognizer?.close();
            this.privConversationRecognizer = undefined;
            if (!!this.privConversationTranslator) {
                this.privConversationTranslator.dispose();
            }
        }
        catch (e) {
            // ignore error
            throw e;
        }
        if (dispose) {
            this.dispose();
        }
    }
    /** Helpers */
    handleCallback(cb, err) {
        if (!!cb) {
            try {
                cb();
            }
            catch (e) {
                if (!!err) {
                    err(e);
                }
            }
            cb = undefined;
        }
    }
    handleError(error, err) {
        if (!!err) {
            if (error instanceof Error) {
                const typedError = error;
                err(typedError.name + ": " + typedError.message);
            }
            else {
                err(error);
            }
        }
    }
    /** Participant Helpers */
    toParticipants(includeHost) {
        const participants = this.privParticipants.participants.map((p) => (this.toParticipant(p)));
        if (!includeHost) {
            return participants.filter((p) => p.isHost === false);
        }
        else {
            return participants;
        }
    }
    toParticipant(p) {
        return new Exports_js_3.Participant(p.id, p.avatar, p.displayName, p.isHost, p.isMuted, p.isUsingTts, p.preferredLanguage, p.voice);
    }
    getMuteAllCommand(isMuted) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "meetingd");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.setMuteAll,
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: isMuted
        });
    }
    getMuteCommand(participantId, isMuted) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "conversationId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.setMute,
            // eslint-disable-next-line object-shorthand
            participantId: participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: isMuted
        });
    }
    getLockCommand(isLocked) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "meetingId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.setLockState,
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: isLocked
        });
    }
    getEjectCommand(participantId) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "meetingId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.ejectParticipant,
            // eslint-disable-next-line object-shorthand
            participantId: participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
        });
    }
    getSetTranslateToLanguagesCommand(languages) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "meetingId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.setTranslateToLanguages,
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: languages
        });
    }
    getChangeNicknameCommand(nickname) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "meetingId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(nickname, "nickname");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        return JSON.stringify({
            command: Exports_js_1.ConversationTranslatorCommandTypes.changeNickname,
            nickname,
            participantId: this.privRoom.participantId,
            roomid: this.privRoom.roomId,
            type: Exports_js_1.ConversationTranslatorMessageTypes.participantCommand,
            value: nickname
        });
    }
    getMessageCommand(message) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, "meetingId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, "participantId");
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(message, "message");
        return JSON.stringify({
            participantId: this.privRoom.participantId,
            roomId: this.privRoom.roomId,
            text: message,
            type: Exports_js_1.ConversationTranslatorMessageTypes.instantMessage
        });
    }
}
exports.MeetingImpl = MeetingImpl;

//# sourceMappingURL=Meeting.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriber.js"
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriber.js ***!
  \*********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MeetingTranscriber = void 0;
const Exports_js_1 = __webpack_require__(/*! ../../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const Exports_js_2 = __webpack_require__(/*! ../../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Contracts_js_1 = __webpack_require__(/*! ../Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ../Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
const Exports_js_4 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/Exports.js");
class MeetingTranscriber {
    /**
     * MeetingTranscriber constructor.
     * @constructor
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    constructor(audioConfig) {
        this.privAudioConfig = audioConfig;
        this.privProperties = new Exports_js_3.PropertyCollection();
        this.privRecognizer = undefined;
        this.privDisposedRecognizer = false;
    }
    /**
     * Gets the spoken language of recognition.
     * @member MeetingTranscriber.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @returns {string} The spoken language of recognition.
     */
    get speechRecognitionLanguage() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage);
    }
    /**
     * The collection of properties and their values defined for this MeetingTranscriber.
     * @member MeetingTranscriber.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this MeetingTranscriber.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * @Internal
     * Internal data member to support fromRecognizer* pattern methods on other classes.
     * Do not use externally, object returned will change without warning or notice.
     */
    get internalData() {
        return this.privRecognizer.internalData;
    }
    /**
     * @Deprecated
     * @Obsolete
     * Please use the Connection.fromRecognizer pattern to obtain a connection object
     */
    get connection() {
        return Exports_js_3.Connection.fromRecognizer(this.privRecognizer);
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member MeetingTranscriber.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member MeetingTranscriber.prototype.authorizationToken
     * @function
     * @public
     * @param {string} token - Authorization token.
     */
    set authorizationToken(token) {
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(token, "token");
        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, token);
    }
    /**
     * @param {Meeting} meeting - meeting to be recognized
     */
    joinMeetingAsync(meeting, cb, err) {
        /* eslint-disable no-console */
        // console.log(">> MeetingTranscriber::joinMeetingAsync");
        /* eslint-enable no-console */
        const meetingImpl = meeting;
        Contracts_js_1.Contracts.throwIfNullOrUndefined(Exports_js_4.MeetingImpl, "Meeting");
        // ref the meeting object
        // create recognizer and subscribe to recognizer events
        this.privRecognizer = new Exports_js_1.TranscriberRecognizer(meeting.config, this.privAudioConfig);
        Contracts_js_1.Contracts.throwIfNullOrUndefined(this.privRecognizer, "Recognizer");
        this.privRecognizer.connectMeetingCallbacks(this);
        (0, Exports_js_2.marshalPromiseToCallbacks)(meetingImpl.connectTranscriberRecognizer(this.privRecognizer), cb, err);
    }
    /**
     * Starts meeting transcription, until stopTranscribingAsync() is called.
     * User must subscribe to events to receive transcription results.
     * @member MeetingTranscriber.prototype.startTranscribingAsync
     * @function
     * @public
     * @param cb - Callback invoked once the transcription has started.
     * @param err - Callback invoked in case of an error.
     */
    startTranscribingAsync(cb, err) {
        this.privRecognizer.startContinuousRecognitionAsync(cb, err);
    }
    /**
     * Starts meeting transcription, until stopTranscribingAsync() is called.
     * User must subscribe to events to receive transcription results.
     * @member MeetingTranscriber.prototype.stopTranscribingAsync
     * @function
     * @public
     * @param cb - Callback invoked once the transcription has started.
     * @param err - Callback invoked in case of an error.
     */
    stopTranscribingAsync(cb, err) {
        this.privRecognizer.stopContinuousRecognitionAsync(cb, err);
    }
    /**
     * Leave the current meeting. After this is called, you will no longer receive any events.
     */
    leaveMeetingAsync(cb, err) {
        this.privRecognizer.disconnectCallbacks();
        // eslint-disable-next-line
        (0, Exports_js_2.marshalPromiseToCallbacks)((async () => { return; })(), cb, err);
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member MeetingTranscriber.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedRecognizer);
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
    }
    /**
     * Disposes any resources held by the object.
     * @member MeetingTranscriber.prototype.dispose
     * @function
     * @public
     * @param {boolean} disposing - true if disposing the object.
     */
    async dispose(disposing) {
        if (this.privDisposedRecognizer) {
            return;
        }
        if (!!this.privRecognizer) {
            await this.privRecognizer.close();
            this.privRecognizer = undefined;
        }
        if (disposing) {
            this.privDisposedRecognizer = true;
        }
    }
}
exports.MeetingTranscriber = MeetingTranscriber;

//# sourceMappingURL=MeetingTranscriber.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriptionCanceledEventArgs.js"
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/MeetingTranscriptionCanceledEventArgs.js ***!
  \****************************************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.MeetingTranscriptionCanceledEventArgs = void 0;
const CancellationEventArgsBase_js_1 = __webpack_require__(/*! ../CancellationEventArgsBase.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/CancellationEventArgsBase.js");
class MeetingTranscriptionCanceledEventArgs extends CancellationEventArgsBase_js_1.CancellationEventArgsBase {
}
exports.MeetingTranscriptionCanceledEventArgs = MeetingTranscriptionCanceledEventArgs;

//# sourceMappingURL=MeetingTranscriptionCanceledEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ParticipantChangedReason.js"
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Transcription/ParticipantChangedReason.js ***!
  \***************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
// Multi-device Conversation is a Preview feature.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.ParticipantChangedReason = void 0;
var ParticipantChangedReason;
(function (ParticipantChangedReason) {
    /** Participant has joined the conversation. */
    ParticipantChangedReason[ParticipantChangedReason["JoinedConversation"] = 0] = "JoinedConversation";
    /** Participant has left the conversation. This could be voluntary, or involuntary
     * (e.g. they are experiencing networking issues).
     */
    ParticipantChangedReason[ParticipantChangedReason["LeftConversation"] = 1] = "LeftConversation";
    /** The participants' state has changed (e.g. they became muted, changed their nickname). */
    ParticipantChangedReason[ParticipantChangedReason["Updated"] = 2] = "Updated";
})(ParticipantChangedReason = exports.ParticipantChangedReason || (exports.ParticipantChangedReason = {}));

//# sourceMappingURL=ParticipantChangedReason.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionCanceledEventArgs.js"
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionCanceledEventArgs.js ***!
  \****************************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationRecognitionCanceledEventArgs = void 0;
/**
 * Define payload of speech recognition canceled result events.
 * @class TranslationRecognitionCanceledEventArgs
 */
class TranslationRecognitionCanceledEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} sessionid - The session id.
     * @param {CancellationReason} cancellationReason - The cancellation reason.
     * @param {string} errorDetails - Error details, if provided.
     * @param {TranslationRecognitionResult} result - The result.
     */
    constructor(sessionid, cancellationReason, errorDetails, errorCode, result) {
        this.privCancelReason = cancellationReason;
        this.privErrorDetails = errorDetails;
        this.privResult = result;
        this.privSessionId = sessionid;
        this.privErrorCode = errorCode;
    }
    /**
     * Specifies the recognition result.
     * @member TranslationRecognitionCanceledEventArgs.prototype.result
     * @function
     * @public
     * @returns {TranslationRecognitionResult} the recognition result.
     */
    get result() {
        return this.privResult;
    }
    /**
     * Specifies the session identifier.
     * @member TranslationRecognitionCanceledEventArgs.prototype.sessionId
     * @function
     * @public
     * @returns {string} the session identifier.
     */
    get sessionId() {
        return this.privSessionId;
    }
    /**
     * The reason the recognition was canceled.
     * @member TranslationRecognitionCanceledEventArgs.prototype.reason
     * @function
     * @public
     * @returns {CancellationReason} Specifies the reason canceled.
     */
    get reason() {
        return this.privCancelReason;
    }
    /**
     * The error code in case of an unsuccessful recognition.
     * Added in version 1.1.0.
     * @return An error code that represents the error reason.
     */
    get errorCode() {
        return this.privErrorCode;
    }
    /**
     * In case of an unsuccessful recognition, provides details of the occurred error.
     * @member TranslationRecognitionCanceledEventArgs.prototype.errorDetails
     * @function
     * @public
     * @returns {string} A String that represents the error details.
     */
    get errorDetails() {
        return this.privErrorDetails;
    }
}
exports.TranslationRecognitionCanceledEventArgs = TranslationRecognitionCanceledEventArgs;

//# sourceMappingURL=TranslationRecognitionCanceledEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionEventArgs.js"
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionEventArgs.js ***!
  \********************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationRecognitionEventArgs = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Translation text result event arguments.
 * @class TranslationRecognitionEventArgs
 */
class TranslationRecognitionEventArgs extends Exports_js_1.RecognitionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {TranslationRecognitionResult} result - The translation recognition result.
     * @param {number} offset - The offset.
     * @param {string} sessionId - The session id.
     */
    constructor(result, offset, sessionId) {
        super(offset, sessionId);
        this.privResult = result;
    }
    /**
     * Specifies the recognition result.
     * @member TranslationRecognitionEventArgs.prototype.result
     * @function
     * @public
     * @returns {TranslationRecognitionResult} the recognition result.
     */
    get result() {
        return this.privResult;
    }
}
exports.TranslationRecognitionEventArgs = TranslationRecognitionEventArgs;

//# sourceMappingURL=TranslationRecognitionEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionResult.js"
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognitionResult.js ***!
  \*****************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationRecognitionResult = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Translation text result.
 * @class TranslationRecognitionResult
 */
class TranslationRecognitionResult extends Exports_js_1.SpeechRecognitionResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {Translations} translations - The translations.
     * @param {string} resultId - The result id.
     * @param {ResultReason} reason - The reason.
     * @param {string} text - The recognized text.
     * @param {number} duration - The duration.
     * @param {number} offset - The offset into the stream.
     * @param {string} language - Primary Language detected, if provided.
     * @param {string} languageDetectionConfidence - Primary Language confidence ("Unknown," "Low," "Medium," "High"...), if provided.
     * @param {string} errorDetails - Error details, if provided.
     * @param {string} json - Additional Json, if provided.
     * @param {PropertyCollection} properties - Additional properties, if provided.
     */
    constructor(translations, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {
        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, undefined, errorDetails, json, properties);
        this.privTranslations = translations;
    }
    static fromSpeechRecognitionResult(result) {
        return new TranslationRecognitionResult(undefined, result.resultId, result.reason, result.text, result.duration, result.offset, result.language, result.languageDetectionConfidence, result.errorDetails, result.json, result.properties);
    }
    /**
     * Presents the translation results. Each item in the dictionary represents
     * a translation result in one of target languages, where the key is the name
     * of the target language, in BCP-47 format, and the value is the translation
     * text in the specified language.
     * @member TranslationRecognitionResult.prototype.translations
     * @function
     * @public
     * @returns {Translations} the current translation map that holds all translations requested.
     */
    get translations() {
        return this.privTranslations;
    }
}
exports.TranslationRecognitionResult = TranslationRecognitionResult;

//# sourceMappingURL=TranslationRecognitionResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognizer.js"
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationRecognizer.js ***!
  \**********************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationRecognizer = void 0;
const Exports_js_1 = __webpack_require__(/*! ../common.speech/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports.js");
const PhraseDetectionContext_js_1 = __webpack_require__(/*! ../common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/PhraseDetection/PhraseDetectionContext.js");
const Exports_js_2 = __webpack_require__(/*! ../common/Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports.js");
const Connection_js_1 = __webpack_require__(/*! ./Connection.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Connection.js");
const Contracts_js_1 = __webpack_require__(/*! ./Contracts.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Contracts.js");
const Exports_js_3 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Translation recognizer
 * @class TranslationRecognizer
 */
class TranslationRecognizer extends Exports_js_3.Recognizer {
    /**
     * Initializes an instance of the TranslationRecognizer.
     * @constructor
     * @param {SpeechTranslationConfig} speechConfig - Set of properties to configure this recognizer.
     * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
     * @param {IConnectionFactory} connectionFactory - An optional connection factory to use to generate the endpoint URIs, headers to set, etc...
     */
    constructor(speechConfig, audioConfig, connectionFactory) {
        const configImpl = speechConfig;
        Contracts_js_1.Contracts.throwIfNull(configImpl, "speechConfig");
        super(audioConfig, configImpl.properties, connectionFactory || new Exports_js_1.TranslationConnectionFactory(), speechConfig.tokenCredential);
        this.privDisposedTranslationRecognizer = false;
        if (this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice, undefined) !== undefined) {
            Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice]);
        }
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages]);
        Contracts_js_1.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage), Exports_js_3.PropertyId[Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage]);
    }
    /**
     * TranslationRecognizer constructor.
     * @constructor
     * @param {SpeechTranslationConfig} speechTranslationConfig - an set of initial properties for this recognizer
     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer
     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
     */
    static FromConfig(speechTranslationConfig, autoDetectSourceLanguageConfig, audioConfig) {
        const speechTranslationConfigImpl = speechTranslationConfig;
        autoDetectSourceLanguageConfig.properties.mergeTo(speechTranslationConfigImpl.properties);
        if (autoDetectSourceLanguageConfig.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, undefined) === Exports_js_1.AutoDetectSourceLanguagesOpenRangeOptionName) {
            speechTranslationConfigImpl.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage, "en-US");
        }
        return new TranslationRecognizer(speechTranslationConfig, audioConfig);
    }
    /**
     * Gets the language name that was set when the recognizer was created.
     * @member TranslationRecognizer.prototype.speechRecognitionLanguage
     * @function
     * @public
     * @returns {string} Gets the language name that was set when the recognizer was created.
     */
    get speechRecognitionLanguage() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_RecoLanguage);
    }
    /**
     * Gets target languages for translation that were set when the recognizer was created.
     * The language is specified in BCP-47 format. The translation will provide translated text for each of language.
     * @member TranslationRecognizer.prototype.targetLanguages
     * @function
     * @public
     * @returns {string[]} Gets target languages for translation that were set when the recognizer was created.
     */
    get targetLanguages() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
    }
    /**
     * Gets the name of output voice.
     * @member TranslationRecognizer.prototype.voiceName
     * @function
     * @public
     * @returns {string} the name of output voice.
     */
    get voiceName() {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);
    }
    /**
     * The collection of properties and their values defined for this TranslationRecognizer.
     * @member TranslationRecognizer.prototype.properties
     * @function
     * @public
     * @returns {PropertyCollection} The collection of properties and their values defined for this TranslationRecognizer.
     */
    get properties() {
        return this.privProperties;
    }
    /**
     * Gets the authorization token used to communicate with the service.
     * @member TranslationRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @returns {string} Authorization token.
     */
    get authorizationToken() {
        return this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token);
    }
    /**
     * Gets/Sets the authorization token used to communicate with the service.
     * @member TranslationRecognizer.prototype.authorizationToken
     * @function
     * @public
     * @param {string} value - Authorization token.
     */
    set authorizationToken(value) {
        this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceAuthorization_Token, value);
    }
    /**
     * Starts recognition and translation, and stops after the first utterance is recognized.
     * The task returns the translation text as result.
     * Note: recognizeOnceAsync returns when the first utterance has been recognized, so it is suitable only
     * for single shot recognition like command or query. For long-running recognition,
     * use startContinuousRecognitionAsync() instead.
     * @member TranslationRecognizer.prototype.recognizeOnceAsync
     * @function
     * @public
     * @param cb - Callback that received the result when the translation has completed.
     * @param err - Callback invoked in case of an error.
     */
    recognizeOnceAsync(cb, err) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.recognizeOnceAsyncImpl(PhraseDetectionContext_js_1.RecognitionMode.Interactive), cb, err);
    }
    /**
     * Starts recognition and translation, until stopContinuousRecognitionAsync() is called.
     * User must subscribe to events to receive translation results.
     * @member TranslationRecognizer.prototype.startContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback that received the translation has started.
     * @param err - Callback invoked in case of an error.
     */
    startContinuousRecognitionAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(PhraseDetectionContext_js_1.RecognitionMode.Conversation), cb, err);
    }
    /**
     * Stops continuous recognition and translation.
     * @member TranslationRecognizer.prototype.stopContinuousRecognitionAsync
     * @function
     * @public
     * @param cb - Callback that received the translation has stopped.
     * @param err - Callback invoked in case of an error.
     */
    stopContinuousRecognitionAsync(cb, err) {
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);
    }
    /**
     * dynamically remove a language from list of target language
     * (can be used while recognition is ongoing)
     * @member TranslationRecognizer.prototype.removeTargetLanguage
     * @function
     * @param lang - language to be removed
     * @public
     */
    removeTargetLanguage(lang) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(lang, "language to be removed");
        if (this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
            const languages = this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
            const index = languages.indexOf(lang);
            if (index > -1) {
                languages.splice(index, 1);
                this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(","));
                this.updateLanguages(languages);
            }
        }
    }
    /**
     * dynamically add a language to list of target language
     * (can be used while recognition is ongoing)
     * @member TranslationRecognizer.prototype.addTargetLanguage
     * @function
     * @param lang - language to be added
     * @public
     */
    addTargetLanguage(lang) {
        Contracts_js_1.Contracts.throwIfNullOrUndefined(lang, "language to be added");
        let languages = [];
        if (this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {
            languages = this.properties.getProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(",");
            if (!languages.includes(lang)) {
                languages.push(lang);
                this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(","));
            }
        }
        else {
            this.properties.setProperty(Exports_js_3.PropertyId.SpeechServiceConnection_TranslationToLanguages, lang);
            languages = [lang];
        }
        this.updateLanguages(languages);
    }
    /**
     * closes all external resources held by an instance of this class.
     * @member TranslationRecognizer.prototype.close
     * @function
     * @public
     */
    close(cb, errorCb) {
        Contracts_js_1.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);
        (0, Exports_js_2.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);
    }
    /**
     * handles ConnectionEstablishedEvent for conversation translation scenarios.
     * @member TranslationRecognizer.prototype.onConnection
     * @function
     * @public
     */
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    onConnection() { }
    async dispose(disposing) {
        if (this.privDisposedTranslationRecognizer) {
            return;
        }
        this.privDisposedTranslationRecognizer = true;
        if (disposing) {
            await this.implRecognizerStop();
            await super.dispose(disposing);
        }
    }
    createRecognizerConfig(speechConfig) {
        return new Exports_js_1.RecognizerConfig(speechConfig, this.privProperties);
    }
    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {
        const configImpl = audioConfig;
        return new Exports_js_1.TranslationServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);
    }
    updateLanguages(languages) {
        const conn = Connection_js_1.Connection.fromRecognizer(this);
        if (!!conn) {
            conn.setMessageProperty("speech.context", "translationcontext", { to: languages });
            conn.sendMessageAsync("event", JSON.stringify({
                id: "translation",
                name: "updateLanguage",
                to: languages
            }));
        }
    }
}
exports.TranslationRecognizer = TranslationRecognizer;

//# sourceMappingURL=TranslationRecognizer.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisEventArgs.js"
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisEventArgs.js ***!
  \******************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationSynthesisEventArgs = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Translation Synthesis event arguments
 * @class TranslationSynthesisEventArgs
 */
class TranslationSynthesisEventArgs extends Exports_js_1.SessionEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {TranslationSynthesisResult} result - The translation synthesis result.
     * @param {string} sessionId - The session id.
     */
    constructor(result, sessionId) {
        super(sessionId);
        this.privResult = result;
    }
    /**
     * Specifies the translation synthesis result.
     * @member TranslationSynthesisEventArgs.prototype.result
     * @function
     * @public
     * @returns {TranslationSynthesisResult} Specifies the translation synthesis result.
     */
    get result() {
        return this.privResult;
    }
}
exports.TranslationSynthesisEventArgs = TranslationSynthesisEventArgs;

//# sourceMappingURL=TranslationSynthesisEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisResult.js"
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TranslationSynthesisResult.js ***!
  \***************************************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TranslationSynthesisResult = void 0;
/**
 * Defines translation synthesis result, i.e. the voice output of the translated
 * text in the target language.
 * @class TranslationSynthesisResult
 */
class TranslationSynthesisResult {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {ResultReason} reason - The synthesis reason.
     * @param {ArrayBuffer} audio - The audio data.
     */
    constructor(reason, audio) {
        this.privReason = reason;
        this.privAudio = audio;
    }
    /**
     * Translated text in the target language.
     * @member TranslationSynthesisResult.prototype.audio
     * @function
     * @public
     * @returns {ArrayBuffer} Translated audio in the target language.
     */
    get audio() {
        return this.privAudio;
    }
    /**
     * The synthesis status.
     * @member TranslationSynthesisResult.prototype.reason
     * @function
     * @public
     * @returns {ResultReason} The synthesis status.
     */
    get reason() {
        return this.privReason;
    }
}
exports.TranslationSynthesisResult = TranslationSynthesisResult;

//# sourceMappingURL=TranslationSynthesisResult.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Translations.js"
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Translations.js ***!
  \*************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Translations = void 0;
const Exports_js_1 = __webpack_require__(/*! ./Exports.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js");
/**
 * Represents collection of parameters and their values.
 * @class Translations
 */
class Translations {
    constructor() {
        // Use an PropertyCollection internally, just wrapping it to hide the | enum syntax it has.
        this.privMap = new Exports_js_1.PropertyCollection();
    }
    /**
     * Get the languages in the object in a String array.
     * @member Translations.prototype.languages
     * @function
     * @public
     * @returns {string[]} languages in translations object.
     */
    get languages() {
        return this.privMap.keys;
    }
    /**
     * Returns the parameter value in type String. The parameter must have the same type as String.
     * Currently only String, int and bool are allowed.
     * If the name is not available, the specified defaultValue is returned.
     * @member Translations.prototype.get
     * @function
     * @public
     * @param {string} key - The parameter name.
     * @param {string} def - The default value which is returned if the parameter is not available in the collection.
     * @returns {string} value of the parameter.
     */
    get(key, def) {
        return this.privMap.getProperty(key, def);
    }
    /**
     * Sets the String value of the parameter specified by name.
     * @member Translations.prototype.set
     * @function
     * @public
     * @param {string} key - The parameter name.
     * @param {string} value - The value of the parameter.
     */
    set(key, value) {
        this.privMap.setProperty(key, value);
    }
}
exports.Translations = Translations;

//# sourceMappingURL=Translations.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TurnStatusReceivedEventArgs.js"
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/TurnStatusReceivedEventArgs.js ***!
  \****************************************************************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.TurnStatusReceivedEventArgs = void 0;
const TurnStatusPayload_js_1 = __webpack_require__(/*! ../common.speech/ServiceMessages/TurnStatusPayload.js */ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/ServiceMessages/TurnStatusPayload.js");
/**
 * Defines contents of received message/events.
 * @class TurnStatusReceivedEventArgs
 */
class TurnStatusReceivedEventArgs {
    /**
     * Creates and initializes an instance of this class.
     * @constructor
     * @param {string} turnStatus - The JSON-encoded turn status message.
     */
    constructor(turnStatus) {
        this.privTurnStatus = TurnStatusPayload_js_1.TurnStatusResponsePayload.fromJSON(turnStatus);
    }
    /**
     * Gets the interaction identifier associated with this turn status event.
     * @member TurnStatusReceivedEventArgs.prototype.interactionId
     * @function
     * @public
     * @returns {any} the received interaction id.
     */
    get interactionId() {
        return this.privTurnStatus.interactionId;
    }
    /**
     * Gets the conversation identifier associated with this turn status event.
     * @member TurnStatusReceivedEventArgs.prototype.conversationId
     * @function
     * @public
     * @returns {any} the received conversation id.
     */
    get conversationId() {
        return this.privTurnStatus.conversationId;
    }
    /**
     * Gets the received turn status code.
     * @member TurnStatusReceivedEventArgs.prototype.statusCode
     * @function
     * @public
     * @returns {number} the received turn status.
     */
    get statusCode() {
        return this.privTurnStatus.statusCode; // eslint-disable-line @typescript-eslint/no-unsafe-return
    }
}
exports.TurnStatusReceivedEventArgs = TurnStatusReceivedEventArgs;

//# sourceMappingURL=TurnStatusReceivedEventArgs.js.map


/***/ },

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceInfo.js"
/*!**********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/VoiceInfo.js ***!
  \**********************************************************************************************/
(__unused_webpack_module, exports) {

"use strict";

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT license.
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.VoiceInfo = exports.SynthesisVoiceType = exports.SynthesisVoiceGender = void 0;
/**
 * Defines the gender of synthesis voices.
 * Added in version 1.20.0.
 */
var SynthesisVoiceGender;
(function (SynthesisVoiceGender) {
    /** Gender unknown */
    SynthesisVoiceGender[SynthesisVoiceGender["Unknown"] = 0] = "Unknown";
    /** Female voice */
    SynthesisVoiceGender[SynthesisVoiceGender["Female"] = 1] = "Female";
    /** Male voice */
    SynthesisVoiceGender[SynthesisVoiceGender["Male"] = 2] = "Male";
    /** Neutral voice */
    SynthesisVoiceGender[SynthesisVoiceGender["Neutral"] = 3] = "Neutral";
})(SynthesisVoiceGender = exports.SynthesisVoiceGender || (exports.SynthesisVoiceGender = {}));
var SynthesisVoiceType;
(function (SynthesisVoiceType) {
    /**
     * Voice type is not known.
     */
    SynthesisVoiceType[SynthesisVoiceType["Unknown"] = 0] = "Unknown";
    /**
     * Online neural voices.
     */
    SynthesisVoiceType[SynthesisVoiceType["OnlineNeural"] = 1] = "OnlineNeural";
    /**
     * Online standard voices. These voices are deprecated.
     */
    SynthesisVoiceType[SynthesisVoiceType["OnlineStandard"] = 2] = "OnlineStandard";
    /**
     * Offline neural voices.
     */
    SynthesisVoiceType[SynthesisVoiceType["OfflineNeural"] = 3] = "OfflineNeural";
    /**
     * Offline standard voices.
     */
    SynthesisVoiceType[SynthesisVoiceType["OfflineStandard"] = 4] = "OfflineStandard";
    /**
     * High definition (HD) voices. Refer to https://learn.microsoft.com/azure/ai-services/speech-service/high-definition-voices
     */
    SynthesisVoiceType[SynthesisVoiceType["OnlineNeuralHD"] = 5] = "OnlineNeuralHD";
})(SynthesisVoiceType = exports.SynthesisVoiceType || (exports.SynthesisVoiceType = {}));
const GENDER_LOOKUP = {
    [SynthesisVoiceGender[SynthesisVoiceGender.Neutral]]: SynthesisVoiceGender.Neutral,
    [SynthesisVoiceGender[SynthesisVoiceGender.Male]]: SynthesisVoiceGender.Male,
    [SynthesisVoiceGender[SynthesisVoiceGender.Female]]: SynthesisVoiceGender.Female,
};
const VOICE_TYPE_LOOKUP = {
    Neural: SynthesisVoiceType.OnlineNeural,
    NeuralHD: SynthesisVoiceType.OnlineNeuralHD,
};
/**
 * Information about Speech Synthesis voice
 * Added in version 1.20.0.
 * @class VoiceInfo
 */
class VoiceInfo {
    constructor(json) {
        this.privStyleList = [];
        if (!!json) {
            this.privName = json.Name;
            this.privLocale = json.Locale;
            this.privShortName = json.ShortName;
            this.privLocaleName = json.LocaleName;
            this.privDisplayName = json.DisplayName;
            this.privLocalName = json.LocalName;
            this.privVoiceType = VOICE_TYPE_LOOKUP[json.VoiceType] || SynthesisVoiceType.Unknown;
            this.privGender = GENDER_LOOKUP[json.Gender] || SynthesisVoiceGender.Unknown;
            if (!!json.StyleList && Array.isArray(json.StyleList)) {
                for (const style of json.StyleList) {
                    this.privStyleList.push(style);
                }
            }
            this.privSampleRateHertz = json.SampleRateHertz;
            this.privStatus = json.Status;
            if (json.ExtendedPropertyMap) {
                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
                this.privExtendedPropertyMap = json.ExtendedPropertyMap;
            }
            this.privWordsPerMinute = json.WordsPerMinute;
            if (Array.isArray(json.SecondaryLocaleList)) {
                this.privSecondaryLocaleList = [...json.SecondaryLocaleList];
            }
            if (Array.isArray(json.RolePlayList)) {
                this.privRolePlayList = [...json.RolePlayList];
            }
            if (json.VoiceTag) {
                this.privVoiceTag = json.VoiceTag;
            }
        }
    }
    get name() {
        return this.privName;
    }
    get locale() {
        return this.privLocale;
    }
    get shortName() {
        return this.privShortName;
    }
    get displayName() {
        return this.privDisplayName;
    }
    get localName() {
        return this.privLocalName;
    }
    get localeName() {
        return this.privLocaleName;
    }
    get gender() {
        return this.privGender;
    }
    get voiceType() {
        return this.privVoiceType;
    }
    get styleList() {
        return this.privStyleList;
    }
    get sampleRateHertz() {
        return this.privSampleRateHertz;
    }
    get status() {
        return this.privStatus;
    }
    get extendedPropertyMap() {
        // eslint-disable-next-line @typescript-eslint/no-unsafe-return
        return this.privExtendedPropertyMap;
    }
    get wordsPerMinute() {
        return this.privWordsPerMinute;
    }
    get secondaryLocaleList() {
        return this.privSecondaryLocaleList;
    }
    get rolePlayList() {
        return this.privRolePlayList;
    }
    get voiceTag() {
        return this.privVoiceTag;
    }
}
exports.VoiceInfo = VoiceInfo;

//# sourceMappingURL=VoiceInfo.js.map


/***/ },

/***/ "./src/styles.css"
/*!************************!*\
  !*** ./src/styles.css ***!
  \************************/
(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
// extracted by mini-css-extract-plugin


/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/index.js"
/*!**********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/index.js ***!
  \**********************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
Object.defineProperty(exports, "NIL", ({
  enumerable: true,
  get: function get() {
    return _nil.default;
  }
}));
Object.defineProperty(exports, "parse", ({
  enumerable: true,
  get: function get() {
    return _parse.default;
  }
}));
Object.defineProperty(exports, "stringify", ({
  enumerable: true,
  get: function get() {
    return _stringify.default;
  }
}));
Object.defineProperty(exports, "v1", ({
  enumerable: true,
  get: function get() {
    return _v.default;
  }
}));
Object.defineProperty(exports, "v3", ({
  enumerable: true,
  get: function get() {
    return _v2.default;
  }
}));
Object.defineProperty(exports, "v4", ({
  enumerable: true,
  get: function get() {
    return _v3.default;
  }
}));
Object.defineProperty(exports, "v5", ({
  enumerable: true,
  get: function get() {
    return _v4.default;
  }
}));
Object.defineProperty(exports, "validate", ({
  enumerable: true,
  get: function get() {
    return _validate.default;
  }
}));
Object.defineProperty(exports, "version", ({
  enumerable: true,
  get: function get() {
    return _version.default;
  }
}));

var _v = _interopRequireDefault(__webpack_require__(/*! ./v1.js */ "./node_modules/uuid/dist/commonjs-browser/v1.js"));

var _v2 = _interopRequireDefault(__webpack_require__(/*! ./v3.js */ "./node_modules/uuid/dist/commonjs-browser/v3.js"));

var _v3 = _interopRequireDefault(__webpack_require__(/*! ./v4.js */ "./node_modules/uuid/dist/commonjs-browser/v4.js"));

var _v4 = _interopRequireDefault(__webpack_require__(/*! ./v5.js */ "./node_modules/uuid/dist/commonjs-browser/v5.js"));

var _nil = _interopRequireDefault(__webpack_require__(/*! ./nil.js */ "./node_modules/uuid/dist/commonjs-browser/nil.js"));

var _version = _interopRequireDefault(__webpack_require__(/*! ./version.js */ "./node_modules/uuid/dist/commonjs-browser/version.js"));

var _validate = _interopRequireDefault(__webpack_require__(/*! ./validate.js */ "./node_modules/uuid/dist/commonjs-browser/validate.js"));

var _stringify = _interopRequireDefault(__webpack_require__(/*! ./stringify.js */ "./node_modules/uuid/dist/commonjs-browser/stringify.js"));

var _parse = _interopRequireDefault(__webpack_require__(/*! ./parse.js */ "./node_modules/uuid/dist/commonjs-browser/parse.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/md5.js"
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/md5.js ***!
  \********************************************************/
(__unused_webpack_module, exports) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

/*
 * Browser-compatible JavaScript MD5
 *
 * Modification of JavaScript MD5
 * https://github.com/blueimp/JavaScript-MD5
 *
 * Copyright 2011, Sebastian Tschan
 * https://blueimp.net
 *
 * Licensed under the MIT license:
 * https://opensource.org/licenses/MIT
 *
 * Based on
 * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message
 * Digest Algorithm, as defined in RFC 1321.
 * Version 2.2 Copyright (C) Paul Johnston 1999 - 2009
 * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
 * Distributed under the BSD License
 * See http://pajhome.org.uk/crypt/md5 for more info.
 */
function md5(bytes) {
  if (typeof bytes === 'string') {
    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape

    bytes = new Uint8Array(msg.length);

    for (let i = 0; i < msg.length; ++i) {
      bytes[i] = msg.charCodeAt(i);
    }
  }

  return md5ToHexEncodedArray(wordsToMd5(bytesToWords(bytes), bytes.length * 8));
}
/*
 * Convert an array of little-endian words to an array of bytes
 */


function md5ToHexEncodedArray(input) {
  const output = [];
  const length32 = input.length * 32;
  const hexTab = '0123456789abcdef';

  for (let i = 0; i < length32; i += 8) {
    const x = input[i >> 5] >>> i % 32 & 0xff;
    const hex = parseInt(hexTab.charAt(x >>> 4 & 0x0f) + hexTab.charAt(x & 0x0f), 16);
    output.push(hex);
  }

  return output;
}
/**
 * Calculate output length with padding and bit length
 */


function getOutputLength(inputLength8) {
  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;
}
/*
 * Calculate the MD5 of an array of little-endian words, and a bit length.
 */


function wordsToMd5(x, len) {
  /* append padding */
  x[len >> 5] |= 0x80 << len % 32;
  x[getOutputLength(len) - 1] = len;
  let a = 1732584193;
  let b = -271733879;
  let c = -1732584194;
  let d = 271733878;

  for (let i = 0; i < x.length; i += 16) {
    const olda = a;
    const oldb = b;
    const oldc = c;
    const oldd = d;
    a = md5ff(a, b, c, d, x[i], 7, -680876936);
    d = md5ff(d, a, b, c, x[i + 1], 12, -389564586);
    c = md5ff(c, d, a, b, x[i + 2], 17, 606105819);
    b = md5ff(b, c, d, a, x[i + 3], 22, -1044525330);
    a = md5ff(a, b, c, d, x[i + 4], 7, -176418897);
    d = md5ff(d, a, b, c, x[i + 5], 12, 1200080426);
    c = md5ff(c, d, a, b, x[i + 6], 17, -1473231341);
    b = md5ff(b, c, d, a, x[i + 7], 22, -45705983);
    a = md5ff(a, b, c, d, x[i + 8], 7, 1770035416);
    d = md5ff(d, a, b, c, x[i + 9], 12, -1958414417);
    c = md5ff(c, d, a, b, x[i + 10], 17, -42063);
    b = md5ff(b, c, d, a, x[i + 11], 22, -1990404162);
    a = md5ff(a, b, c, d, x[i + 12], 7, 1804603682);
    d = md5ff(d, a, b, c, x[i + 13], 12, -40341101);
    c = md5ff(c, d, a, b, x[i + 14], 17, -1502002290);
    b = md5ff(b, c, d, a, x[i + 15], 22, 1236535329);
    a = md5gg(a, b, c, d, x[i + 1], 5, -165796510);
    d = md5gg(d, a, b, c, x[i + 6], 9, -1069501632);
    c = md5gg(c, d, a, b, x[i + 11], 14, 643717713);
    b = md5gg(b, c, d, a, x[i], 20, -373897302);
    a = md5gg(a, b, c, d, x[i + 5], 5, -701558691);
    d = md5gg(d, a, b, c, x[i + 10], 9, 38016083);
    c = md5gg(c, d, a, b, x[i + 15], 14, -660478335);
    b = md5gg(b, c, d, a, x[i + 4], 20, -405537848);
    a = md5gg(a, b, c, d, x[i + 9], 5, 568446438);
    d = md5gg(d, a, b, c, x[i + 14], 9, -1019803690);
    c = md5gg(c, d, a, b, x[i + 3], 14, -187363961);
    b = md5gg(b, c, d, a, x[i + 8], 20, 1163531501);
    a = md5gg(a, b, c, d, x[i + 13], 5, -1444681467);
    d = md5gg(d, a, b, c, x[i + 2], 9, -51403784);
    c = md5gg(c, d, a, b, x[i + 7], 14, 1735328473);
    b = md5gg(b, c, d, a, x[i + 12], 20, -1926607734);
    a = md5hh(a, b, c, d, x[i + 5], 4, -378558);
    d = md5hh(d, a, b, c, x[i + 8], 11, -2022574463);
    c = md5hh(c, d, a, b, x[i + 11], 16, 1839030562);
    b = md5hh(b, c, d, a, x[i + 14], 23, -35309556);
    a = md5hh(a, b, c, d, x[i + 1], 4, -1530992060);
    d = md5hh(d, a, b, c, x[i + 4], 11, 1272893353);
    c = md5hh(c, d, a, b, x[i + 7], 16, -155497632);
    b = md5hh(b, c, d, a, x[i + 10], 23, -1094730640);
    a = md5hh(a, b, c, d, x[i + 13], 4, 681279174);
    d = md5hh(d, a, b, c, x[i], 11, -358537222);
    c = md5hh(c, d, a, b, x[i + 3], 16, -722521979);
    b = md5hh(b, c, d, a, x[i + 6], 23, 76029189);
    a = md5hh(a, b, c, d, x[i + 9], 4, -640364487);
    d = md5hh(d, a, b, c, x[i + 12], 11, -421815835);
    c = md5hh(c, d, a, b, x[i + 15], 16, 530742520);
    b = md5hh(b, c, d, a, x[i + 2], 23, -995338651);
    a = md5ii(a, b, c, d, x[i], 6, -198630844);
    d = md5ii(d, a, b, c, x[i + 7], 10, 1126891415);
    c = md5ii(c, d, a, b, x[i + 14], 15, -1416354905);
    b = md5ii(b, c, d, a, x[i + 5], 21, -57434055);
    a = md5ii(a, b, c, d, x[i + 12], 6, 1700485571);
    d = md5ii(d, a, b, c, x[i + 3], 10, -1894986606);
    c = md5ii(c, d, a, b, x[i + 10], 15, -1051523);
    b = md5ii(b, c, d, a, x[i + 1], 21, -2054922799);
    a = md5ii(a, b, c, d, x[i + 8], 6, 1873313359);
    d = md5ii(d, a, b, c, x[i + 15], 10, -30611744);
    c = md5ii(c, d, a, b, x[i + 6], 15, -1560198380);
    b = md5ii(b, c, d, a, x[i + 13], 21, 1309151649);
    a = md5ii(a, b, c, d, x[i + 4], 6, -145523070);
    d = md5ii(d, a, b, c, x[i + 11], 10, -1120210379);
    c = md5ii(c, d, a, b, x[i + 2], 15, 718787259);
    b = md5ii(b, c, d, a, x[i + 9], 21, -343485551);
    a = safeAdd(a, olda);
    b = safeAdd(b, oldb);
    c = safeAdd(c, oldc);
    d = safeAdd(d, oldd);
  }

  return [a, b, c, d];
}
/*
 * Convert an array bytes to an array of little-endian words
 * Characters >255 have their high-byte silently ignored.
 */


function bytesToWords(input) {
  if (input.length === 0) {
    return [];
  }

  const length8 = input.length * 8;
  const output = new Uint32Array(getOutputLength(length8));

  for (let i = 0; i < length8; i += 8) {
    output[i >> 5] |= (input[i / 8] & 0xff) << i % 32;
  }

  return output;
}
/*
 * Add integers, wrapping at 2^32. This uses 16-bit operations internally
 * to work around bugs in some JS interpreters.
 */


function safeAdd(x, y) {
  const lsw = (x & 0xffff) + (y & 0xffff);
  const msw = (x >> 16) + (y >> 16) + (lsw >> 16);
  return msw << 16 | lsw & 0xffff;
}
/*
 * Bitwise rotate a 32-bit number to the left.
 */


function bitRotateLeft(num, cnt) {
  return num << cnt | num >>> 32 - cnt;
}
/*
 * These functions implement the four basic operations the algorithm uses.
 */


function md5cmn(q, a, b, x, s, t) {
  return safeAdd(bitRotateLeft(safeAdd(safeAdd(a, q), safeAdd(x, t)), s), b);
}

function md5ff(a, b, c, d, x, s, t) {
  return md5cmn(b & c | ~b & d, a, b, x, s, t);
}

function md5gg(a, b, c, d, x, s, t) {
  return md5cmn(b & d | c & ~d, a, b, x, s, t);
}

function md5hh(a, b, c, d, x, s, t) {
  return md5cmn(b ^ c ^ d, a, b, x, s, t);
}

function md5ii(a, b, c, d, x, s, t) {
  return md5cmn(c ^ (b | ~d), a, b, x, s, t);
}

var _default = md5;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/native.js"
/*!***********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/native.js ***!
  \***********************************************************/
(__unused_webpack_module, exports) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;
const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);
var _default = {
  randomUUID
};
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/nil.js"
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/nil.js ***!
  \********************************************************/
(__unused_webpack_module, exports) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;
var _default = '00000000-0000-0000-0000-000000000000';
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/parse.js"
/*!**********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/parse.js ***!
  \**********************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _validate = _interopRequireDefault(__webpack_require__(/*! ./validate.js */ "./node_modules/uuid/dist/commonjs-browser/validate.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function parse(uuid) {
  if (!(0, _validate.default)(uuid)) {
    throw TypeError('Invalid UUID');
  }

  let v;
  const arr = new Uint8Array(16); // Parse ########-....-....-....-............

  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;
  arr[1] = v >>> 16 & 0xff;
  arr[2] = v >>> 8 & 0xff;
  arr[3] = v & 0xff; // Parse ........-####-....-....-............

  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;
  arr[5] = v & 0xff; // Parse ........-....-####-....-............

  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;
  arr[7] = v & 0xff; // Parse ........-....-....-####-............

  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;
  arr[9] = v & 0xff; // Parse ........-....-....-....-############
  // (Use "/" to avoid 32-bit truncation when bit-shifting high-order bytes)

  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;
  arr[11] = v / 0x100000000 & 0xff;
  arr[12] = v >>> 24 & 0xff;
  arr[13] = v >>> 16 & 0xff;
  arr[14] = v >>> 8 & 0xff;
  arr[15] = v & 0xff;
  return arr;
}

var _default = parse;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/regex.js"
/*!**********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/regex.js ***!
  \**********************************************************/
(__unused_webpack_module, exports) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;
var _default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/rng.js"
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/rng.js ***!
  \********************************************************/
(__unused_webpack_module, exports) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = rng;
// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
let getRandomValues;
const rnds8 = new Uint8Array(16);

function rng() {
  // lazy load so that environments that need to polyfill have a chance to do so
  if (!getRandomValues) {
    // getRandomValues needs to be invoked in a context where "this" is a Crypto implementation.
    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);

    if (!getRandomValues) {
      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
    }
  }

  return getRandomValues(rnds8);
}

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/sha1.js"
/*!*********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/sha1.js ***!
  \*********************************************************/
(__unused_webpack_module, exports) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

// Adapted from Chris Veness' SHA1 code at
// http://www.movable-type.co.uk/scripts/sha1.html
function f(s, x, y, z) {
  switch (s) {
    case 0:
      return x & y ^ ~x & z;

    case 1:
      return x ^ y ^ z;

    case 2:
      return x & y ^ x & z ^ y & z;

    case 3:
      return x ^ y ^ z;
  }
}

function ROTL(x, n) {
  return x << n | x >>> 32 - n;
}

function sha1(bytes) {
  const K = [0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6];
  const H = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];

  if (typeof bytes === 'string') {
    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape

    bytes = [];

    for (let i = 0; i < msg.length; ++i) {
      bytes.push(msg.charCodeAt(i));
    }
  } else if (!Array.isArray(bytes)) {
    // Convert Array-like to Array
    bytes = Array.prototype.slice.call(bytes);
  }

  bytes.push(0x80);
  const l = bytes.length / 4 + 2;
  const N = Math.ceil(l / 16);
  const M = new Array(N);

  for (let i = 0; i < N; ++i) {
    const arr = new Uint32Array(16);

    for (let j = 0; j < 16; ++j) {
      arr[j] = bytes[i * 64 + j * 4] << 24 | bytes[i * 64 + j * 4 + 1] << 16 | bytes[i * 64 + j * 4 + 2] << 8 | bytes[i * 64 + j * 4 + 3];
    }

    M[i] = arr;
  }

  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);
  M[N - 1][14] = Math.floor(M[N - 1][14]);
  M[N - 1][15] = (bytes.length - 1) * 8 & 0xffffffff;

  for (let i = 0; i < N; ++i) {
    const W = new Uint32Array(80);

    for (let t = 0; t < 16; ++t) {
      W[t] = M[i][t];
    }

    for (let t = 16; t < 80; ++t) {
      W[t] = ROTL(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1);
    }

    let a = H[0];
    let b = H[1];
    let c = H[2];
    let d = H[3];
    let e = H[4];

    for (let t = 0; t < 80; ++t) {
      const s = Math.floor(t / 20);
      const T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[t] >>> 0;
      e = d;
      d = c;
      c = ROTL(b, 30) >>> 0;
      b = a;
      a = T;
    }

    H[0] = H[0] + a >>> 0;
    H[1] = H[1] + b >>> 0;
    H[2] = H[2] + c >>> 0;
    H[3] = H[3] + d >>> 0;
    H[4] = H[4] + e >>> 0;
  }

  return [H[0] >> 24 & 0xff, H[0] >> 16 & 0xff, H[0] >> 8 & 0xff, H[0] & 0xff, H[1] >> 24 & 0xff, H[1] >> 16 & 0xff, H[1] >> 8 & 0xff, H[1] & 0xff, H[2] >> 24 & 0xff, H[2] >> 16 & 0xff, H[2] >> 8 & 0xff, H[2] & 0xff, H[3] >> 24 & 0xff, H[3] >> 16 & 0xff, H[3] >> 8 & 0xff, H[3] & 0xff, H[4] >> 24 & 0xff, H[4] >> 16 & 0xff, H[4] >> 8 & 0xff, H[4] & 0xff];
}

var _default = sha1;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/stringify.js"
/*!**************************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/stringify.js ***!
  \**************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;
exports.unsafeStringify = unsafeStringify;

var _validate = _interopRequireDefault(__webpack_require__(/*! ./validate.js */ "./node_modules/uuid/dist/commonjs-browser/validate.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */
const byteToHex = [];

for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).slice(1));
}

function unsafeStringify(arr, offset = 0) {
  // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434
  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];
}

function stringify(arr, offset = 0) {
  const uuid = unsafeStringify(arr, offset); // Consistency check for valid UUID.  If this throws, it's likely due to one
  // of the following:
  // - One or more input array values don't map to a hex octet (leading to
  // "undefined" in the uuid)
  // - Invalid input values for the RFC `version` or `variant` fields

  if (!(0, _validate.default)(uuid)) {
    throw TypeError('Stringified UUID is invalid');
  }

  return uuid;
}

var _default = stringify;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/v1.js"
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v1.js ***!
  \*******************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _rng = _interopRequireDefault(__webpack_require__(/*! ./rng.js */ "./node_modules/uuid/dist/commonjs-browser/rng.js"));

var _stringify = __webpack_require__(/*! ./stringify.js */ "./node_modules/uuid/dist/commonjs-browser/stringify.js");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

// **`v1()` - Generate time-based UUID**
//
// Inspired by https://github.com/LiosK/UUID.js
// and http://docs.python.org/library/uuid.html
let _nodeId;

let _clockseq; // Previous uuid creation time


let _lastMSecs = 0;
let _lastNSecs = 0; // See https://github.com/uuidjs/uuid for API details

function v1(options, buf, offset) {
  let i = buf && offset || 0;
  const b = buf || new Array(16);
  options = options || {};
  let node = options.node || _nodeId;
  let clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq; // node and clockseq need to be initialized to random values if they're not
  // specified.  We do this lazily to minimize issues related to insufficient
  // system entropy.  See #189

  if (node == null || clockseq == null) {
    const seedBytes = options.random || (options.rng || _rng.default)();

    if (node == null) {
      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)
      node = _nodeId = [seedBytes[0] | 0x01, seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];
    }

    if (clockseq == null) {
      // Per 4.2.2, randomize (14 bit) clockseq
      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;
    }
  } // UUID timestamps are 100 nano-second units since the Gregorian epoch,
  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so
  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'
  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.


  let msecs = options.msecs !== undefined ? options.msecs : Date.now(); // Per 4.2.1.2, use count of uuid's generated during the current clock
  // cycle to simulate higher resolution clock

  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1; // Time since last uuid creation (in msecs)

  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000; // Per 4.2.1.2, Bump clockseq on clock regression

  if (dt < 0 && options.clockseq === undefined) {
    clockseq = clockseq + 1 & 0x3fff;
  } // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new
  // time interval


  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {
    nsecs = 0;
  } // Per 4.2.1.2 Throw error if too many uuids are requested


  if (nsecs >= 10000) {
    throw new Error("uuid.v1(): Can't create more than 10M uuids/sec");
  }

  _lastMSecs = msecs;
  _lastNSecs = nsecs;
  _clockseq = clockseq; // Per 4.1.4 - Convert from unix epoch to Gregorian epoch

  msecs += 12219292800000; // `time_low`

  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;
  b[i++] = tl >>> 24 & 0xff;
  b[i++] = tl >>> 16 & 0xff;
  b[i++] = tl >>> 8 & 0xff;
  b[i++] = tl & 0xff; // `time_mid`

  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;
  b[i++] = tmh >>> 8 & 0xff;
  b[i++] = tmh & 0xff; // `time_high_and_version`

  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version

  b[i++] = tmh >>> 16 & 0xff; // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)

  b[i++] = clockseq >>> 8 | 0x80; // `clock_seq_low`

  b[i++] = clockseq & 0xff; // `node`

  for (let n = 0; n < 6; ++n) {
    b[i + n] = node[n];
  }

  return buf || (0, _stringify.unsafeStringify)(b);
}

var _default = v1;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/v3.js"
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v3.js ***!
  \*******************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _v = _interopRequireDefault(__webpack_require__(/*! ./v35.js */ "./node_modules/uuid/dist/commonjs-browser/v35.js"));

var _md = _interopRequireDefault(__webpack_require__(/*! ./md5.js */ "./node_modules/uuid/dist/commonjs-browser/md5.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const v3 = (0, _v.default)('v3', 0x30, _md.default);
var _default = v3;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/v35.js"
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v35.js ***!
  \********************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports.URL = exports.DNS = void 0;
exports["default"] = v35;

var _stringify = __webpack_require__(/*! ./stringify.js */ "./node_modules/uuid/dist/commonjs-browser/stringify.js");

var _parse = _interopRequireDefault(__webpack_require__(/*! ./parse.js */ "./node_modules/uuid/dist/commonjs-browser/parse.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function stringToBytes(str) {
  str = unescape(encodeURIComponent(str)); // UTF8 escape

  const bytes = [];

  for (let i = 0; i < str.length; ++i) {
    bytes.push(str.charCodeAt(i));
  }

  return bytes;
}

const DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';
exports.DNS = DNS;
const URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';
exports.URL = URL;

function v35(name, version, hashfunc) {
  function generateUUID(value, namespace, buf, offset) {
    var _namespace;

    if (typeof value === 'string') {
      value = stringToBytes(value);
    }

    if (typeof namespace === 'string') {
      namespace = (0, _parse.default)(namespace);
    }

    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {
      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');
    } // Compute hash of namespace and value, Per 4.3
    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =
    // hashfunc([...namespace, ... value])`


    let bytes = new Uint8Array(16 + value.length);
    bytes.set(namespace);
    bytes.set(value, namespace.length);
    bytes = hashfunc(bytes);
    bytes[6] = bytes[6] & 0x0f | version;
    bytes[8] = bytes[8] & 0x3f | 0x80;

    if (buf) {
      offset = offset || 0;

      for (let i = 0; i < 16; ++i) {
        buf[offset + i] = bytes[i];
      }

      return buf;
    }

    return (0, _stringify.unsafeStringify)(bytes);
  } // Function#name is not settable on some platforms (#270)


  try {
    generateUUID.name = name; // eslint-disable-next-line no-empty
  } catch (err) {} // For CommonJS default export support


  generateUUID.DNS = DNS;
  generateUUID.URL = URL;
  return generateUUID;
}

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/v4.js"
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v4.js ***!
  \*******************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _native = _interopRequireDefault(__webpack_require__(/*! ./native.js */ "./node_modules/uuid/dist/commonjs-browser/native.js"));

var _rng = _interopRequireDefault(__webpack_require__(/*! ./rng.js */ "./node_modules/uuid/dist/commonjs-browser/rng.js"));

var _stringify = __webpack_require__(/*! ./stringify.js */ "./node_modules/uuid/dist/commonjs-browser/stringify.js");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function v4(options, buf, offset) {
  if (_native.default.randomUUID && !buf && !options) {
    return _native.default.randomUUID();
  }

  options = options || {};

  const rnds = options.random || (options.rng || _rng.default)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`


  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  if (buf) {
    offset = offset || 0;

    for (let i = 0; i < 16; ++i) {
      buf[offset + i] = rnds[i];
    }

    return buf;
  }

  return (0, _stringify.unsafeStringify)(rnds);
}

var _default = v4;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/v5.js"
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v5.js ***!
  \*******************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _v = _interopRequireDefault(__webpack_require__(/*! ./v35.js */ "./node_modules/uuid/dist/commonjs-browser/v35.js"));

var _sha = _interopRequireDefault(__webpack_require__(/*! ./sha1.js */ "./node_modules/uuid/dist/commonjs-browser/sha1.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const v5 = (0, _v.default)('v5', 0x50, _sha.default);
var _default = v5;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/validate.js"
/*!*************************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/validate.js ***!
  \*************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _regex = _interopRequireDefault(__webpack_require__(/*! ./regex.js */ "./node_modules/uuid/dist/commonjs-browser/regex.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function validate(uuid) {
  return typeof uuid === 'string' && _regex.default.test(uuid);
}

var _default = validate;
exports["default"] = _default;

/***/ },

/***/ "./node_modules/uuid/dist/commonjs-browser/version.js"
/*!************************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/version.js ***!
  \************************************************************/
(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


Object.defineProperty(exports, "__esModule", ({
  value: true
}));
exports["default"] = void 0;

var _validate = _interopRequireDefault(__webpack_require__(/*! ./validate.js */ "./node_modules/uuid/dist/commonjs-browser/validate.js"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function version(uuid) {
  if (!(0, _validate.default)(uuid)) {
    throw TypeError('Invalid UUID');
  }

  return parseInt(uuid.slice(14, 15), 16);
}

var _default = version;
exports["default"] = _default;

/***/ },

/***/ "?875c"
/*!****************************!*\
  !*** agent-base (ignored) ***!
  \****************************/
() {

/* (ignored) */

/***/ },

/***/ "?f824"
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
() {

/* (ignored) */

/***/ },

/***/ "?a523"
/*!***********************************!*\
  !*** https-proxy-agent (ignored) ***!
  \***********************************/
() {

/* (ignored) */

/***/ },

/***/ "?540f"
/*!*********************!*\
  !*** net (ignored) ***!
  \*********************/
() {

/* (ignored) */

/***/ },

/***/ "?71f6"
/*!*********************!*\
  !*** tls (ignored) ***!
  \*********************/
() {

/* (ignored) */

/***/ },

/***/ "?3dbe"
/*!********************!*\
  !*** ws (ignored) ***!
  \********************/
() {

/* (ignored) */

/***/ },

/***/ "?c417"
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
() {

/* (ignored) */

/***/ }

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Check if module exists (development only)
/******/ 		if (__webpack_modules__[moduleId] === undefined) {
/******/ 			var e = new Error("Cannot find module '" + moduleId + "'");
/******/ 			e.code = 'MODULE_NOT_FOUND';
/******/ 			throw e;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
var __webpack_exports__ = {};
// This entry needs to be wrapped in an IIFE because it needs to be in strict mode.
(() => {
"use strict";
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)
/* harmony export */ });
/* harmony import */ var _VoiceWidget_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./VoiceWidget.js */ "./src/VoiceWidget.js");
function _typeof(o) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && "function" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? "symbol" : typeof o; }, _typeof(o); }
function ownKeys(e, r) { var t = Object.keys(e); if (Object.getOwnPropertySymbols) { var o = Object.getOwnPropertySymbols(e); r && (o = o.filter(function (r) { return Object.getOwnPropertyDescriptor(e, r).enumerable; })), t.push.apply(t, o); } return t; }
function _objectSpread(e) { for (var r = 1; r < arguments.length; r++) { var t = null != arguments[r] ? arguments[r] : {}; r % 2 ? ownKeys(Object(t), !0).forEach(function (r) { _defineProperty(e, r, t[r]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) { Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r)); }); } return e; }
function _defineProperty(e, r, t) { return (r = _toPropertyKey(r)) in e ? Object.defineProperty(e, r, { value: t, enumerable: !0, configurable: !0, writable: !0 }) : e[r] = t, e; }
function _toPropertyKey(t) { var i = _toPrimitive(t, "string"); return "symbol" == _typeof(i) ? i : i + ""; }
function _toPrimitive(t, r) { if ("object" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || "default"); if ("object" != _typeof(i)) return i; throw new TypeError("@@toPrimitive must return a primitive value."); } return ("string" === r ? String : Number)(t); }
/**
 * LiaPlus Voice Navigation Widget
 * Main entry point for CDN distribution
 * 
 * Usage:
 * ```html
 * <script src="https://cdn.jsdelivr.net/gh/liaplus/voice-widget@1.0.0/cdn/dist/voice-widget.min.js"></script>
 * <script>
 *   LiaPlusVoice.init({
 *     apiBase: 'https://liaplus.com/api',
 *     language: 'en-US'
 *   });
 * </script>
 * ```
 */



// Global widget instance
var widgetInstance = null;

// Main API
var LiaPlusVoice = {
  /**
   * Initialize the widget
   */
  init: function init() {
    var config = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
    if (widgetInstance) {
      console.warn('[LiaPlusVoice] Widget already initialized. Call destroy() first.');
      return widgetInstance;
    }
    widgetInstance = new _VoiceWidget_js__WEBPACK_IMPORTED_MODULE_0__.VoiceWidget(config);
    return widgetInstance;
  },
  /**
   * Start listening
   */
  start: function start() {
    if (!widgetInstance) {
      console.error('[LiaPlusVoice] Widget not initialized. Call init() first.');
      return;
    }
    if (!widgetInstance.state.isListening) {
      widgetInstance.toggleListening();
    }
  },
  /**
   * Stop listening
   */
  stop: function stop() {
    if (!widgetInstance) {
      console.error('[LiaPlusVoice] Widget not initialized. Call init() first.');
      return;
    }
    if (widgetInstance.state.isListening) {
      widgetInstance.toggleListening();
    }
  },
  /**
   * Toggle listening
   */
  toggle: function toggle() {
    if (!widgetInstance) {
      console.error('[LiaPlusVoice] Widget not initialized. Call init() first.');
      return;
    }
    widgetInstance.toggleListening();
  },
  /**
   * Analyze page (re-scan DOM)
   */
  analyzePage: function analyzePage() {
    if (!widgetInstance) {
      console.error('[LiaPlusVoice] Widget not initialized. Call init() first.');
      return;
    }
    widgetInstance.analyzePage();
  },
  /**
   * Update configuration
   */
  updateConfig: function updateConfig(newConfig) {
    if (!widgetInstance) {
      console.error('[LiaPlusVoice] Widget not initialized. Call init() first.');
      return;
    }
    widgetInstance.config = _objectSpread(_objectSpread({}, widgetInstance.config), newConfig);

    // Reinitialize if language changed
    if (newConfig.language && newConfig.language !== widgetInstance.state.language) {
      widgetInstance.setState({
        language: newConfig.language
      });
      widgetInstance.reinitializeRecognition();
    }
  },
  /**
   * Destroy widget
   */
  destroy: function destroy() {
    if (!widgetInstance) {
      console.warn('[LiaPlusVoice] Widget not initialized.');
      return;
    }
    widgetInstance.destroy();
    widgetInstance = null;
  },
  /**
   * Get current state
   */
  getState: function getState() {
    if (!widgetInstance) {
      console.error('[LiaPlusVoice] Widget not initialized. Call init() first.');
      return null;
    }
    return _objectSpread({}, widgetInstance.state);
  },
  /**
   * Get widget instance (for advanced usage)
   */
  getInstance: function getInstance() {
    return widgetInstance;
  }
};

// Export for UMD
/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (LiaPlusVoice);

// Also attach to window for CDN usage
if (typeof window !== 'undefined') {
  window.LiaPlusVoice = LiaPlusVoice;
}
})();

__webpack_exports__ = __webpack_exports__["default"];
/******/ 	return __webpack_exports__;
/******/ })()
;
});
//# sourceMappingURL=voice-widget.dev.js.map